URL,ID,header,DataFolder,DataSetCharacteristics,NumberofInstances,Area,AttributeCharacteristics,NumberofAttributes,DateDonated,AssociatedTasks,MissingValues,NumberofWebHits,Source,DataSetInformation,AttributeInformation,RelevantPapers,CitationRequest,PapersThatCiteThisDataSet
http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions,0,Smartphone-Based Recognition of Human Activities and Postural Transitions Data Set,../machine-learning-databases/00341/,"Multivariate, Time-Series",10929,Life,Real,561,7/29/2015,Classification,N/A,173081,"Jorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Luca Oneto(1) and Xavier Parra(2)1 - Smartlab, DIBRIS - UniversitÃ   degli Studi di Genova, Genoa (16145), Italy. 2 - CETpD - Universitat PolitÃ¨cnica de Catalunya. Vilanova i la GeltrÃº (08800), Spainhar '@' smartlab.ws www.smartlab.ws","The experiments were carried out with a group of 30 volunteers within an age bracket of 19-48 years. They performed a protocol of activities composed of six basic activities: three static postures (standing, sitting, lying) and three dynamic activities (walking, walking downstairs and walking upstairs). The experiment also included postural transitions that occurred between the static postures. These are: stand-to-sit, sit-to-stand, sit-to-lie, lie-to-sit, stand-to-lie, and lie-to-stand. All the participants were wearing a smartphone (Samsung Galaxy S II) on the waist during the experiment execution. We captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz using the embedded accelerometer and gyroscope of the device. The experiments were video-recorded to label the data manually. The obtained dataset was randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.  The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of 561 features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details.  This dataset is an updated version of the UCI Human Activity Recognition Using smartphones Dataset that can be found at: [Web Link] This version provides the original raw inertial signals from the smartphone sensors, instead of the ones pre-processed into windows which were provided in version 1. This change was done in order to be able to make online tests with the raw data. Moreover, the activity labels were updated in order to include postural transitions that were not part of the previous version of the dataset. ","The dataset is then divided in two parts and they can be used separately.   1. Inertial sensor data - Raw triaxial signals from the accelerometer and gyroscope of all the trials with with participants. - The labels of all the performed activities. 2. Records of activity windows. Each one composed of:- A 561-feature vector with time and frequency domain variables. - Its associated activity label. - An identifier of the subject who carried out the experiment. The dataset includes the following files:========================================= - 'README.txt' - '[Web Link]': The raw triaxial acceleration signal for the experiment number XX and associated to the user number YY. Every row is one acceleration sample (three axis) captured at a frequency of 50Hz.  - '[Web Link]': The raw triaxial angular speed signal for the experiment number XX and associated to the user number YY. Every row is one angular velocity sample (three axis) captured at a frequency of 50Hz.  - '[Web Link]': include all the activity labels available for the dataset (1 per row).    Column 1: experiment number ID,    Column 2: user number ID,    Column 3: activity number ID    Column 4: Label start point (in number of signal log samples (recorded at 50Hz))   Column 5: Label end point (in number of signal log samples) - 'features_info.txt': Shows information about the variables used on the feature vector. - 'features.txt': List of all features. - 'activity_labels.txt': Links the activity ID with their activity name. - '[Web Link]': Training set. - '[Web Link]': Training labels. - '[Web Link]': Test set. - '[Web Link]': Test labels. - '[Web Link]': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30.  - '[Web Link]': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30.  Notes: ====== - Features are normalized and bounded within [-1,1].- Each feature vector is a row on the 'X' and 'y' files.- The units used for the accelerations (total and body) are 'g's (gravity of earth -> 9.80665 m/seg2).- The gyroscope units are rad/seg.- A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: [Web Link]  For more information about this dataset please contact har '@' smartlab.ws or check our website www.smartlab.ws","- Jorge-Luis Reyes-Ortiz, Luca Oneto, Alessandro Ghio, Albert SamÃ¡, Davide Anguita and Xavier Parra. Human Activity Recognition on Smartphones With Awareness of Basic Activities and Postural Transitions. Artificial Neural Networks and Machine Learning â€“ ICANN 2014. Lecture Notes in Computer Science. Springer. 2014. - Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.  - Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge L. Reyes-Ortiz. Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic. Journal of Universal Computer Science. Special Issue in Ambient Assisted Living: Home Care.   Volume 19, Issue 9. May 2013 - Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 4th International Workshop of Ambient Assited Living, IWAAL 2012, Vitoria-Gasteiz, Spain, December 3-5, 2012. Proceedings. Lecture Notes in Computer Science 2012, pp 216-223.  - Jorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra-Llanas, Davide Anguita, Joan Cabestany, Andreu CatalÃ . Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.  ","- Jorge-L. Reyes-Ortiz, Luca Oneto, Albert SamÃ , Xavier Parra, Davide Anguita. Transition-Aware Human Activity Recognition Using Smartphones. Neurocomputing. Springer 2015.",
http://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set,1,Divorce Predictors data set Data Set,../machine-learning-databases/00497/,"Multivariate, Univariate",170,Life,Integer,54,7/24/2019,Classification,N/A,77119,"Dr. Mustafa Kemal Yöntem, Nevşehir Hacı Bektaş Veli University, Faculty of Education, Department of Educational Sciences, muskemtem '@' hotmail.com Dr. Kemal ADEM, Aksaray University, Faculty of Economics and Administrative Sciences, Department of Management Information Systems, kemaladem '@' gmail.com Prof. Dr. Tahsin İlhan, Tokat GAZİOSMANPAŞA University, Faculty of Education, Department of Educational Sciences, tahsinilhan73 '@' gmail.com Lecturer Serhat Kılıçarslan, Tokat GAZİOSMANPAŞA University, Rectorate, Department of Informatics, serhatklc '@' gmail.com ",Provide all relevant information about your data set.,"1. If one of us apologizes when our discussion deteriorates, the discussion ends.2. I know we can ignore our differences, even if things get hard sometimes.3. When we need it, we can take our discussions with my spouse from the beginning and correct it.4. When I discuss with my spouse, to contact him will eventually work.5. The time I spent with my wife is special for us.6. We don't have time at home as partners.7. We are like two strangers who share the same environment at home rather than family.8. I enjoy our holidays with my wife.9. I enjoy traveling with my wife.10. Most of our goals are common to my spouse.11. I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.12. My spouse and I have similar values in terms of personal freedom.13. My spouse and I have similar sense of entertainment.14. Most of our goals for people (children, friends, etc.) are the same.15. Our dreams with my spouse are similar and harmonious.16. We're compatible with my spouse about what love should be.17. We share the same views about being happy in our life with my spouse18. My spouse and I have similar ideas about how marriage should be19. My spouse and I have similar ideas about how roles should be in marriage20. My spouse and I have similar values in trust.21. I know exactly what my wife likes.22. I know how my spouse wants to be taken care of when she/he sick.23. I know my spouse's favorite food.24. I can tell you what kind of stress my spouse is facing in her/his life.25. I have knowledge of my spouse's inner world.26. I know my spouse's basic anxieties. 27. I know what my spouse's current sources of stress are.28. I know my spouse's hopes and wishes.29. I know my spouse very well.30. I know my spouse's friends and their social relationships.31. I feel aggressive when I argue with my spouse.32. When discussing with my spouse, I usually use expressions such as ‘you always’ or ‘you never’ .33. I can use negative statements about my spouse's personality during our discussions.34. I can use offensive expressions during our discussions.35. I can insult my spouse during our discussions.36. I can be humiliating when we discussions.37. My discussion with my spouse is not calm.38. I hate my spouse's way of open a subject.39. Our discussions often occur suddenly.40. We're just starting a discussion before I know what's going on.41. When I talk to my spouse about something, my calm suddenly breaks.42. When I argue with my spouse, ı only go out and I don't say a word.43. I mostly stay silent to calm the environment a little bit.44. Sometimes I think it's good for me to leave home for a while.45. I'd rather stay silent than discuss with my spouse.46. Even if I'm right in the discussion, I stay silent to hurt my spouse.47. When I discuss with my spouse, I stay silent because I am afraid of not being able to control my anger.48. I feel right in our discussions.49. I have nothing to do with what I've been accused of.50. I'm not actually the one who's guilty about what I'm accused of.51. I'm not the one who's wrong about problems at home.52. I wouldn't hesitate to tell my spouse about her/his inadequacy.53. When I discuss, I remind my spouse of her/his inadequacy.54. I'm not afraid to tell my spouse about her/his incompetence.","Yöntem, M , Adem, K , İlhan, T , Kılıçarslan, S. (2019). DIVORCE PREDICTION USING CORRELATION BASED FEATURE SELECTION AND ARTIFICIAL NEURAL NETWORKS. Nevşehir Hacı Bektaş Veli University SBE Dergisi, 9 (1), 259-273. Retrieved from [Web Link] ","Yöntem, M , Adem, K , İlhan, T , Kılıçarslan, S. (2019). DIVORCE PREDICTION USING CORRELATION BASED FEATURE SELECTION AND ARTIFICIAL NEURAL NETWORKS. Nevşehir Hacı Bektaş Veli University SBE Dergisi, 9 (1), 259-273. Retrieved from [Web Link] ",
http://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset,2,Online Shoppers Purchasing Intention Dataset Data Set,../machine-learning-databases/00468/,Multivariate,12330,Business,"Integer, Real",18,8/31/2018,"Classification, Clustering",N/A,86113,"Source1. C. Okan SakarDepartment of Computer Engineering, Faculty ofEngineering and Natural Sciences, Bahcesehir University,34349 Besiktas, Istanbul, Turkey 2. Yomi KastroInveon Information Technologies Consultancy and Trade,34335 Istanbul, Turkey","The dataset consists of feature vectors belonging to 12,330 sessions. The dataset was formed so that each sessionwould belong to a different user in a 1-year period to avoidany tendency to a specific campaign, special day, userprofile, or period. ","The dataset consists of 10 numerical and 8 categorical attributes.The 'Revenue' attribute can be used as the class label. ""Administrative"", ""Administrative Duration"", ""Informational"", ""Informational Duration"", ""Product Related"" and ""Product Related Duration"" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The ""Bounce Rate"", ""Exit Rate"" and ""Page Value"" features represent the metrics measured by ""Google Analytics"" for each page in the e-commerce site. The value of ""Bounce Rate"" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (""bounce"") without triggering any other requests to the analytics server during that session. The value of ""Exit Rate"" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The ""Page Value"" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The ""Special Day"" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.","Sakar, C.O., Polat, S.O., Katircioglu, M. et al. Neural Comput & Applic (2018). [Web Link]","If you use this dataset, please cite:Sakar, C.O., Polat, S.O., Katircioglu, M. et al. Neural Comput & Applic (2018). [Web Link]",
http://archive.ics.uci.edu/ml/datasets/University,3,University Data Set,../machine-learning-databases/university/,Multivariate,285,N/A,"Categorical, Integer",17,7/1/1988,Classification,Yes,220698,"Original Owner:  unknown Donor:   Steve Souders <souders '@' ads.com>","Format: Each observation concerns one university. In some cases, more information is provided about the attribute (e.g., units or domain). Some duplicates may exist and a single observation may have more than one value for a given attribute (esp. academic emphasis). It appears that several attributes could serve as a distinguished class attribute for this database.  The data file remains in the state as given to us by Steve Souders.  It is a LISP readable file with a few relevant functions at the end of the data file.  The info on missing data values have not been calculated.  We hope to get to this in the future.","     1. University-name     2. State     3. location     4. Control     5. number-of-students     6. male:female (ratio)     7. student:faculty (ratio)     8. sat-verbal     9. sat-math    10. expenses    11. percent-financial-aid    12. number-of-applicants    13. percent-admittance    14. percent-enrolled    15. academics     16. social    17. quality-of-life    18. academic-emphasis","Lebowitz M. ""Concept learning in a rich input domain : generalization-based memory."" Machine Learning, Vol 2, No 2, September 1987.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/QtyT40I10D100K,4,QtyT40I10D100K Data Set,../machine-learning-databases/00238/,Sequential,3960456,N/A,Integer,4,10/21/2012,N/A,N/A,41246,"Omid Shakeri, M.Sc omid.shakeri '@' tmu.ac.ir ; omid.shakeri '@' gmail.com Data Mining Lab., Computer Engineering Department, Kharazmi University, Karaj/Tehran, Iran Mir Mohsen Pedram, Ph.Dpedram '@' tmu.ac.ir Data Mining Lab., Computer Engineering Department, Kharazmi University, Karaj/Tehran, Iran","This data set is generated from the original T40I10D100K data set, to mine fuzzy sequential patterns over quantitative streams. While the original T40I10D100K is generated from the synthetic data generator described in â€œR. Agrawal, R. Srikant, Fast algorithms for mining association rules, 20th Intl. Conf. on Very Large Databases (VLDBâ€™94), pp. 487-499. 1994â€.The data set is a SQL Server 2008 database, which can be attached to a SQL Server Instance to use","CustomerID: the ID of the customer who has performed the transaction (randomly generated [1 100])Time: the time that the transaction has been performedTransaction: the transaction which has been performedQuantity: the quantity value of each transaction (randomly generated [1 10])",The papers which use this data set are being reviewed by referees.,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Crop+mapping+using+fused+optical-radar+data+set,5,Crop mapping using fused optical-radar data set Data Set,../machine-learning-databases/00525/,"Multivariate, Time-Series",325834,N/A,Real,175,6/16/2020,Classification,N/A,1506,"Dr. Iman Khosravi,Postdoctoral researcher,Department of Remote Sensing & GIS, Faculty of Geography, University of Tehran, Tehran, I.R. Iran, 1417853933E-Mail: iman.khosravi '@' ut.ac.ir Website: http://i-khosravi.ir","This big data set is a fused bi-temporal optical-radar data for cropland classification. The images were collected by RapidEye satellites (optical) and the Unmanned Aerial Vehicle Synthetic Aperture Radar (UAVSAR) system (Radar) over an agricultural region near Winnipeg, Manitoba, Canada on 2012.There are 2 * 49 radar features and 2 * 38 optical features for two dates: 05 and 14 July 2012.Seven crop type classes exist for this data set as follows: 1-Corn; 2-Peas; 3- Canola; 4-Soybeans; 5- Oats; 6- Wheat; and 7-Broadleaf.","175 attributes including:      1- class;      2- f1 to f49:Polarimetric features on 05 July 2012;      3- f50 to f98:Polarimetric features on 14 July 2012;      4- f99 to f136:Optical features on 05 July 2012;      5- f137 to f174:Optical features on 14 July 2012; Details:label:crop type classf1:sigHH_Rad05Julyf2:sigHV_Rad05Julyf3:sigVV_Rad05Julyf4:sigRR_Rad05Julyf5:sigRL_Rad05Julyf6:sigLL_Rad05Julyf7:Rhhvv_Rad05Julyf8:Rhvhh_Rad05Julyf9:Rhvvv_Rad05Julyf10:Rrrll_Rad05Julyf11:Rrlrr_Rad05Julyf12:Rrlll_Rad05Julyf13:Rhh_Rad05Julyf14:Rhv_Rad05Julyf15:Rvv_Rad05Julyf16:Rrr_Rad05Julyf17:Rrl_Rad05Julyf18:Rll_Rad05Julyf19:Ro12_Rad05Julyf20:Ro13_Rad05Julyf21:Ro23_Rad05Julyf22:Ro12cir_Rad05Julyf23:Ro13cir_Rad05Julyf24:Ro23cir_Rad05Julyf25:l1_Rad05Julyf26:l2_Rad05Julyf27:l3_Rad05Julyf28:H_Rad05Julyf29:A_Rad05Julyf30:a_Rad05Julyf31:HA_Rad05Julyf32:H1mA_Rad05Julyf33:1mHA_Rad05Julyf34:1mH1mA_Rad05Julyf35:PH_Rad05Julyf36:rvi_Rad05Julyf37:paulalpha_Rad05Julyf38:paulbeta_Rad05Julyf39:paulgamma_Rad05Julyf40:krogks_Rad05Julyf41:krogkd_Rad05Julyf42:krogkh_Rad05Julyf43:freeodd_Rad05Julyf44:freedbl_Rad05Julyf45:freevol_Rad05Julyf46:yamodd_Rad05Julyf47:yamdbl_Rad05Julyf48:yamhlx_Rad05Julyf49:yamvol_Rad05Julyf50:sigHH_Rad14Julyf51:sigHV_Rad14Julyf52:sigVV_Rad14Julyf53:sigRR_Rad14Julyf54:sigRL_Rad14Julyf55:sigLL_Rad14Julyf56:Rhhvv_Rad14Julyf57:Rhvhh_Rad14Julyf58:Rhvvv_Rad14Julyf59:Rrrll_Rad14Julyf60:Rrlrr_Rad14Julyf61:Rrlll_Rad14Julyf62:Rhh_Rad14Julyf63:Rhv_Rad14Julyf64:Rvv_Rad14Julyf65:Rrr_Rad14Julyf66:Rrl_Rad14Julyf67:Rll_Rad14Julyf68:Ro12_Rad14Julyf69:Ro13_Rad14Julyf70:Ro23_Rad14Julyf71:Ro12cir_Rad14Julyf72:Ro13cir_Rad14Julyf73:Ro23cir_Rad14Julyf74:l1_Rad14Julyf75:l2_Rad14Julyf76:l3_Rad14Julyf77:H_Rad14Julyf78:A_Rad14Julyf79:a_Rad14Julyf80:HA_Rad14Julyf81:H1mA_Rad14Julyf82:1mHA_Rad14Julyf83:1mH1mA_Rad14Julyf84:PH_Rad14Julyf85:rvi_Rad14Julyf86:paulalpha_Rad14Julyf87:paulbeta_Rad14Julyf88:paulgamma_Rad14Julyf89:krogks_Rad14Julyf90:krogkd_Rad14Julyf91:krogkh_Rad14Julyf92:freeodd_Rad14Julyf93:freedbl_Rad14Julyf94:freevol_Rad14Julyf95:yamodd_Rad14Julyf96:yamdbl_Rad14Julyf97:yamhlx_Rad14Julyf98:yamvol_Rad14Julyf99:B_Opt05Julyf100:G_Opt05Julyf101:R_Opt05Julyf102:Redge_Opt05Julyf103:NIR_Opt05Julyf104:NDVI_Opt05Julyf105:SR_Opt05Julyf106:RGRI_Opt05Julyf107:EVI_Opt05Julyf108:ARVI_Opt05Julyf109:SAVI_Opt05Julyf110:NDGI_Opt05Julyf111:gNDVI_Opt05Julyf112:MTVI2_Opt05Julyf113:NDVIre_Opt05Julyf114:SRre_Opt05Julyf115:NDGIre_Opt05Julyf116:RTVIcore_Opt05Julyf117:RNDVI_Opt05Julyf118:TCARI_Opt05Julyf119:TVI_Opt05Julyf120:PRI2_Opt05Julyf121:MeanPC1_Opt05Julyf122:VarPC1_Opt05Julyf123:HomPC1_Opt05Julyf124:ConPC1_Opt05Julyf125:DisPC1_Opt05Julyf126:EntPC1_Opt05Julyf127:SecMomPC1_Opt05Julyf128:CorPC1_Opt05Julyf129:MeanPC2_Opt05Julyf130:VarPC2_Opt05Julyf131:HomPC2_Opt05Julyf132:ConPC2_Opt05Julyf133:DisPC2_Opt05Julyf134:EntPC2_Opt05Julyf135:SecMomPC2_Opt05Julyf136:CorPC2_Opt05Julyf137:B_Opt14Julyf138:G_Opt14Julyf139:R_Opt14Julyf140:Redge_Opt14Julyf141:NIR_Opt14Julyf142:NDVI_Opt14Julyf143:SR_Opt14Julyf144:RGRI_Opt14Julyf145:EVI_Opt14Julyf146:ARVI_Opt14Julyf147:SAVI_Opt14Julyf148:NDGI_Opt14Julyf149:gNDVI_Opt14Julyf150:MTVI2_Opt14Julyf151:NDVIre_Opt14Julyf152:SRre_Opt14Julyf153:NDGIre_Opt14Julyf154:RTVIcore_Opt14Julyf155:RNDVI_Opt14Julyf156:TCARI_Opt14Julyf157:TVI_Opt14Julyf158:PRI2_Opt14Julyf159:MeanPC1_Opt14Julyf160:VarPC1_Opt14Julyf161:HomPC1_Opt14Julyf162:ConPC1_Opt14Julyf163:DisPC1_Opt14Julyf164:EntPC1_Opt14Julyf165:SecMomPC1_Opt14Julyf166:CorPC1_Opt14Julyf167:MeanPC2_Opt14Julyf168:VarPC2_Opt14Julyf169:HomPC2_Opt14Julyf170:ConPC2_Opt14Julyf171:DisPC2_Opt14Julyf172:EntPC2_Opt14Julyf173:SecMomPC2_Opt14Julyf174:CorPC2_Opt14July For more information about these attributes, please refer to relevant papers.","1- Khosravi, I., & Alavipanah, S. K. (2019). A random forest-based framework for crop mapping using temporal, spectral, textural and polarimetric observations. International Journal of Remote Sensing, 40(18), 7221-7251.â€2- Khosravi, I., et al. (2018). MSMD: maximum separability and minimum dependency feature selection for cropland classification from optical and radar data. International Journal of Remote Sensing, 39(8), 2159-2176.â€ These papers can be downloaded from [Web Link]","I'd like to present my acknowledgment to the JPL NASA for the PolSAR images, and the SMAPVEX 2012 team, the Agriculture and Agri-Food Canada, for providing the PolSAR and the optical images.Please cite my relevant papers.",
http://archive.ics.uci.edu/ml/datasets/PAMAP2+Physical+Activity+Monitoring,6,PAMAP2 Physical Activity Monitoring Data Set,../machine-learning-databases/00231/,"Multivariate, Time-Series",3850505,Computer,Real,52,8/6/2012,Classification,Yes,93948,"Attila Reiss, Department Augmented Vision, DFKI, Germany, attila.reiss '@' dfki.deDate: August 2012.","The PAMAP2 Physical Activity Monitoring dataset contains data of 18 different physical activities (such as walking, cycling, playing soccer, etc.), performed by 9 subjects wearing 3 inertial measurement units and a heart rate monitor. The dataset can be used for activity recognition and intensity estimation, while developing and applying algorithms of data processing, segmentation, feature extraction and classification. ** Sensors **3 Colibri wireless inertial measurement units (IMU):  - sampling frequency: 100Hz  - position of the sensors:       - 1 IMU over the wrist on the dominant arm        - 1 IMU on the chest        - 1 IMU on the dominant side's ankle HR-monitor:  - sampling frequency: ~9Hz ** Data collection protocol **Each of the subjects had to follow a protocol, containing 12 different activities. The folder â€œProtocolâ€ contains these recordings by subject.Furthermore, some of the subjects also performed a few optional activities. The folder â€œOptionalâ€ contains these recordings by subject. ** Data files **Raw sensory data can be found in space-separated text-files (.dat), 1 data file per subject per session (protocol or optional). Missing values are indicated with NaN. One line in the data files correspond to one timestamped and labeled instance of sensory data. The data files contain 54 columns: each line consists of a timestamp, an activity label (the ground truth) and 52 attributes of raw sensory data.","The 54 columns in the data files are organized as follows:  1.		timestamp (s)  2.		activityID (see below for the mapping to the activities)  3.		heart rate (bpm)  4-20.		IMU hand  21-37.	IMU chest  38-54.	IMU ankle The IMU sensory data contains the following columns:   1.		temperature (Â°C)   2-4.		3D-acceleration data (ms-2), scale: Â±16g, resolution: 13-bit   5-7.		3D-acceleration data (ms-2), scale: Â±6g, resolution: 13-bit  8-10.		3D-gyroscope data (rad/s)   11-13.	3D-magnetometer data (Î¼T)   14-17.	orientation (invalid in this data collection)  List of activityIDs and corresponding activities: 1	lying 2	sitting 3	standing 4	walking 5	running 6	cycling 7	Nordic walking 9	watching TV 10	computer work 11	car driving 12	ascending stairs 13	descending stairs 16	vacuum cleaning 17	ironing 18	folding laundry 19	house cleaning 20	playing soccer 24	rope jumping 0	other (transient activities)","The following two publications describe the dataset and provide a baseline benchmark on various tasks of physical activity recognition and intensity estimation: [1] A. Reiss and D. Stricker. Introducing a New Benchmarked Dataset for Activity Monitoring. The 16th IEEE International Symposium on Wearable Computers (ISWC), 2012. [2] A. Reiss and D. Stricker. Creating and Benchmarking a New Dataset for Physical Activity Monitoring. The 5th Workshop on Affect and Behaviour Related Assistance (ABRA), 2012.  Further information (detailed description of the protocol and the various activities, statistics of the dataset, the subjects, etc.) can be found in the documentation attached to the dataset. Please refer to the file readme.pdf.","This dataset is freely available for academic research, there are no (legal or other) constraints on using the data for scientific purposes. We would appreciate referencing one of the below publications ([1] or [2]) if you use this dataset.If you have any questions or suggestions, please contact Attila Reiss ([firstname].[lastname]@dfki.de). Also, please let us know if you have any publications that uses this dataset. We recommend to refer to this dataset as the â€œPAMAP2 Datasetâ€ or the â€œPAMAP2 Physical Activity Monitoring Datasetâ€. [1] A. Reiss and D. Stricker. Introducing a New Benchmarked Dataset for Activity Monitoring. The 16th IEEE International Symposium on Wearable Computers (ISWC), 2012. [2] A. Reiss and D. Stricker. Creating and Benchmarking a New Dataset for Physical Activity Monitoring. The 5th Workshop on Affect and Behaviour Related Assistance (ABRA), 2012.",
http://archive.ics.uci.edu/ml/datasets/Rice+Leaf+Diseases,7,Rice Leaf Diseases Data Set,../machine-learning-databases/00486/,Multivariate,120,Computer,Integer,N/A,4/14/2019,Classification,N/A,40680,"Jitesh P. Shah, Email: jitesh2k12 '@' gmail.com, Institute: Department of Information Technology, Dharmsinh Desai University,Nadiad-387001, Gujarat, INDIA. Creator Name: Harshadkumar B. Prajapati, Email: prajapatihb.it '@' ddu.ac.in, Institute: Department of Information Technology, Dharmsinh Desai University,Nadiad-387001, Gujarat, INDIA. Creator Name: Vipul K. Dabhi, Email: vipuldabhi.it '@' ddu.ac.in, Institute: Department of Information Technology, Dharmsinh Desai University,Nadiad-387001, Gujarat, INDIA. ","The dataset was created by manually separating infected leaves into different disease classes. We had consulted the farmers and had asked them to provide names of diseases for sample leaves. Farmers had provided names in their native languages (Gujarati) and we identiï¬ed and veriï¬ed English names of those diseases by consulting with experts of agriculture ï¬eld. This dataset was used for Detection and Classiï¬cation of Rice Plant Diseases. As part of the work, the following activities were carried out (1) How to extract various image features (2) which image processing operations can provide needed information (3) which image features can provide substantial input for classification. The survey work is available in IEEE conference paper:   A Survey on Detection and Classification of Rice Plant Diseases, available at [Web Link]. A classification model was developed using SVM. The detailed information is available in the published journal article:Detection and classification of rice plant diseases, in Intelligent Decision Technologies, IOS Press, available at [Web Link]","Image Format: .jpg, The images were captured with a white background, in direct sunlight. The images were reduced to the desired resolution for processing.","(1) Prajapati HB, Shah JP, Dabhi VK. Detection and classification of rice plant diseases. Intelligent Decision Technologies. 2017 Jan 1;11(3):357-73, doi: 10.3233/IDT-170301. (2)  Shah JP, Prajapati HB, Dabhi VK. A survey on detection and classification of rice plant diseases. InCurrent Trends in Advanced Computing (ICCTAC), IEEE International Conference on 2016 Mar 10 (pp. 1-8). IEEE.","Prajapati HB, Shah JP, Dabhi VK. Detection and classification of rice plant diseases. Intelligent Decision Technologies. 2017 Jan 1;11(3):357-73, doi: 10.3233/IDT-170301.",
http://archive.ics.uci.edu/ml/datasets/wiki4HE,8,wiki4HE Data Set,../machine-learning-databases/00334/,Multivariate,913,Social,N/A,53,5/4/2015,"Regression, Clustering, Causal-Discovery",Yes,47677,"E. Aibar, J. LladÃ³s, A. Meseguer, J. MinguillÃ³n (jminguillona[at]uoc[dot]edu), M. Lerga. Universitat Oberta de Catalunya, Barcelona, Spain.","Ongoing research on university faculty perceptions and practices of using Wikipedia as a teaching resource. Based on a Technology Acceptance Model, the relationships within the internal and external constructs of the model are analyzed. Both the perception of colleaguesâ€™ opinion about Wikipedia and the perceived quality of the information in Wikipedia play a central role in the obtained model. ","AGE: numericGENDER: 0=Male; 1=FemaleDOMAIN: 1=Arts & Humanities; 2=Sciences; 3=Health Sciences; 4=Engineering & Architecture; 5=Law & PoliticsPhD: 0=No; 1=YesYEARSEXP (years of university teaching experience): numericUNIVERSITY: 1=UOC; 2=UPFUOC_POSITION (academic position of UOC members): 1=Professor; 2=Associate; 3=Assistant; 4=Lecturer; 5=Instructor; 6=AdjunctOTHER (main job in another university for part-time members): 1=Yes; 2=NoOTHER_POSITION (work as part-time in another university and UPF members): 1=Professor; 2=Associate; 3=Assistant; 4=Lecturer; 5=Instructor; 6=AdjunctUSERWIKI (Wikipedia registered user): 0=No; 1=Yes The following survey items are Likert scale (1-5) ranging from strongly disagree / never (1) to strongly agree / always (5) Perceived UsefulnessPU1: The use of Wikipedia makes it easier for students to develop new skillsPU2: The use of Wikipedia improves students' learningPU3: Wikipedia is useful for teaching Perceived Ease of UsePEU1: Wikipedia is user-friendlyPEU2: It is easy to find in Wikipedia the information you seekPEU3: It is easy to add or edit information in Wikipedia Perceived EnjoymentENJ1: The use of Wikipedia stimulates curiosityENJ2: The use of Wikipedia is entertaining QualityQU1: Articles in Wikipedia are reliableQU2: Articles in Wikipedia are updatedQU3: Articles in Wikipedia are comprehensiveQU4: In my area of expertise, Wikipedia has a lower quality than other educational resourcesQU5: I trust in the editing system of Wikipedia VisibilityVIS1: Wikipedia improves visibility of students' workVIS2: It is easy to have a record of the contributions made in WikipediaVIS3: I cite Wikipedia in my academic papers Social ImageIM1: The use of Wikipedia is well considered among colleaguesIM2: In academia, sharing open educational resources is appreciatedIM3: My colleagues use Wikipedia Sharing attitudeSA1: It is important to share academic content in open platformsSA2: It is important to publish research results in other media than academic journals or booksSA3: It is important that students become familiar with online collaborative environments Use behaviourUSE1: I use Wikipedia to develop my teaching materialsUSE2: I use Wikipedia as a platform to develop educational activities with studentsUSE3: I recommend my students to use WikipediaUSE4: I recommend my colleagues to use WikipediaUSE5: I agree my students use Wikipedia in my courses Profile 2.0PF1: I contribute to blogsPF2: I actively participate in social networksPF3: I publish academic content in open platforms Job relevanceJR1: My university promotes the use of open collaborative environments in the InternetJR2: My university considers the use of open collaborative environments in the Internet as a teaching merit Behavioral intentionBI1: In the future I will recommend the use of Wikipedia to my colleagues and studentsBI2: In the future I will use Wikipedia in my teaching activity IncentivesINC1: To design educational activities using Wikipedia, it would be helpful: a best practices guideINC2: To design educational activities using Wikipedia, it would be helpful: getting instruction from a colleagueINC3: To design educational activities using Wikipedia, it would be helpful: getting specific trainingINC4: To design educational activities using Wikipedia, it would be helpfull: greater institutional recognition ExperienceEXP1: I consult Wikipedia for issues related to my field of expertiseEXP2: I consult Wikipedia for other academic related issuesEXP3: I consult Wikipedia for personal issuesEXP4: I contribute to Wikipedia (editions, revisions, articles improvement...)EXP5: I use wikis to work with my students","Meseguer, A., Aibar, E., LladÃ³s, J., MinguillÃ³n, J., Lerga, M. (2015). â€œFactors that influence the teaching use of Wikipedia in Higher Educationâ€. JASIST, Journal of the Association for Information Science and Technology. ISSN: 2330-1635. doi: 10.1002/asi.23488.",Please cite our JASIST paper if you use this dataset.,
http://archive.ics.uci.edu/ml/datasets/Twin+gas+sensor+arrays,9,Twin gas sensor arrays Data Set,../machine-learning-databases/00361/,"Multivariate, Time-Series, Domain-Theory",640,Computer,Real,480000,5/19/2016,"Classification, Regression",N/A,47611,"Jordi Fonollosa, jfonollosa '@' ibecbarcelona.eu, Institute for Bioengineering of Catalunya. ","This dataset includes the recordings of five replicates of an 8-sensor array. Each unit holds 8 MOX sensors and integrates custom-designed electronics for sensor operating temperature control and signal acquisition. The same experimental protocol was followed to measure the response of the 5 twin units. Each day, a different unit was tested, which included the presentationof 40 different gas conditions, presented in random order. In particular, the unit under test was exposed to 10 concentration levels of Ethanol, Methane, Ethylene, and Carbon Monoxide.The duration of each experiment was 600 s, and the conductivity of each sensor was acquired at 100Hz. Channel, sensor type (from Figaro), and mean voltage in the heater are as follows: 0: TGS2611 5.65 V1: TGS2612 5.65 V2: TGS2610 5.65 V3: TGS2602 5.65 V4: TGS2611 5.00 V5: TGS2612 5.00 V6: TGS2610 5.00 V7: TGS2602 5.00 V Presented concentration levels are as follows (in ppm):Ethylene: 12.5, 25, 37.5, 50.0, 62.5, 75.0, 87.5, 100.0 , 112.5, 125.0Ethanol: 12.5, 25.0, 37.5, 50.0, 62.5, 75.0, 87.5, 100.0 , 112.5, 125.0Carbon Monoxide: 25.0, 50.0, 75.0, 100.0 , 125.0 ,150.0, 175.0, 200.0, 225.0 , 250.0Methane: 25.0, 50.0, 75.0, 100.0 , 125.0 ,150.0, 175.0, 200.0, 225.0 , 250.0 Days in which each detection platform was tested.Unit 1: 4,10,15,21Unit 2: 1,7,11,16Unit 3: 2,8,14,17Unit 4: 3,9Unit 5: 18,22 More information at:J. Fonollosa, L. Fernandez, A. Gutierrez-Galvez, R. Huerta, S. Marco. 'Calibration transfer and drift counteraction in chemical sensor arrays using Direct Standardization'. Sensors and Actuators B: Chemical (2016). [Web Link]  The data set can be used exclusively for research purposes. Commercial purposes are fully excluded. ","The responses of the sensors are provided in a .txt file for each experiment. File name codes the unit number, gas (Ea: Ethanol, CO: CO, Ey: Ethylene, Me: Methane), concentration (010-100 of the corresponding gas), and repetition. For example, B1_GEa_F040_R2.txt indicates B1 (board 1), Ea (Ethanol), 50 ppm, Repetition 2. Each file includes the elapsed time (in seconds) and the resistance of each sensor (in KOhm). First column is time, and 8 following columns are channels 0-7 as specified before. ",N/A,"Citation required:J. Fonollosa, L. Fernandez, A. Gutierrez-Galvez, R. Huerta, S. Marco. 'Calibration transfer and drift counteraction in chemical sensor arrays using Direct Standardization'. Sensors and Actuators B: Chemical (2016). [Web Link] ",
http://archive.ics.uci.edu/ml/datasets/Activities+of+Daily+Living+%28ADLs%29+Recognition+Using+Binary+Sensors,10,Activities of Daily Living (ADLs) Recognition Using Binary Sensors Data Set,../machine-learning-databases/00271/,"Multivariate, Sequential, Time-Series",2747,Computer,N/A,N/A,10/28/2013,"Classification, Clustering",N/A,90872,"Francisco Javier OrdÃ³Ã±ez, Carlos III University of Madrid, fordonez '@' inf.uc3m.es","This dataset comprises information regarding the ADLs performed by two users on a daily basis in their own homes. This dataset is composed by two instances of data, each one corresponding to a different user and summing up to 35 days of fully labelled data. Each instance of the dataset is described by three text files, namely: description, sensors events (features), activities of the daily living (labels). Sensor events were recorded using a wireless sensor network and data were labelled manually.",The features are the sensor events captured for the corresponding Wireless Sensor Network.,N/A,"OrdÃ³Ã±ez, F.J.; de Toledo, P.; Sanchis, A. Activity Recognition Using Hybrid Generative/Discriminative Models on Home Environments Using Binary Sensors. Sensors 2013, 13, 5460-5477.",
http://archive.ics.uci.edu/ml/datasets/Undocumented,11,Undocumented Data Set,../machine-learning-databases/undocumented/,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,27842,N/A,N/A,N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/sEMG+for+Basic+Hand+movements,12,sEMG for Basic Hand movements Data Set,../machine-learning-databases/00313/,Time-Series,3000,Life,Real,2500,11/18/2014,Classification,N/A,68041,"Christos Sapsanis (csapsanis @ gmail.com) and Anthony TzesANeMoS LabSchool of Electrical and Computer EngineeringUniversity of Patras G. Georgoulas KIC LaboratoryDepartment of Informatics and Telecommunications Technology, Technological Educational Institute of Epirus","Instrumentation:The data were collected at a sampling rate of 500 Hz, using as a programming kernel the National Instruments (NI) Labview. The signals were band-pass filtered using a Butterworth Band Pass filter with low and high cutoff at 15Hz and 500Hz respectively and a notch filter at 50Hz to eliminate line interference artifacts.The hardware that was used was an NI analog/digital conversion card NI USB- 009, mounted on a PC. The signal was taken from two Differential EMG Sensors and the signals were transmitted to a 2-channel EMG system by Delsys Bagnoliâ Handheld EMG Systems. Protocol: The experiments consisted of freely and repeatedly grasping of different items, which were essential to conduct the hand movements. The speed and force were intentionally left to the subjects will. There were two forearm surface EMG electrodes Flexor Capri Ulnaris and Extensor Capri Radialis, Longus and Brevis) held in place by elastic bands and the reference electrode in the middle, in order to gather information about the muscle activation. The subjects were asked to perform repeatedly the following six movements, which can be considered as daily hand grasps:a) Spherical: for holding spherical toolsb) Tip: for holding small tools c) Palmar: for grasping with palm facing the objectd) Lateral: for holding thin, flat objectse) Cylindrical: for holding cylindrical toolsf) Hook: for supporting a heavy load An illustrative photo is included in the data folder. Two different databases are included:1) 5 healthy subjects (two males and three females) of the same age approximately (20 to 22-year-old) conducted the six grasps for 30 times each. The measured time is 6 sec. There is a mat file available for every subject. 2) 1 healthy subject (male, 22-year-old) conducted the six grasps for 100 times each for 3 consecutive days. The measured time is 5 sec. There is a mat file available for every day.","Data Format:The format of each mat file is the following: The data per grasp and per channel are in separate table with an obvious naming. {Spherical --> (spher_ch1, spher_ch2), Tip --> (tip_ch1, tip_ch2), Palmar --> (palm_ch1, palm_ch2), Lateral --> (lat_ch1, lat_ch2), Cylindrical --> (cyl_ch1, cyl_ch2), Hook --> (hook_ch1, hook_ch2)}Each row of these tables has the whole signal per trial. The signal value is measured in Voltage. In summary, in each subject, there will be a mat file with 12 matrixes, in which matrix there will be 30 (trials) rows and 3000 (points of the signal) columns for database 1 (or 100 rows and 2500 columns for database 2).","Since the data is signals in time domain, part of it can be used for classification using signal processing techniques and methods, such as Empirical Mode Decomposition (EMD). Moreover, suggested features for extraction can be Integrated Electromyogram (IEMG), Zero Crossing (ZC), Slope Sign Changes (SSC), Waveform Length (WL), Willison Amplitude (WAMP) etc.  More information can be found in the following paper:C. Sapsanis, G. Georgoulas, A. Tzes, EMG based classification of basic hand movements based on time-frequency features in 21th IEEE Mediterranean Conference on Control and Automation (MED 13), June 25 - 28, pp. 716 - 722, 2013.","If you found useful these databases, please cite the following:For the database 1), C. Sapsanis, G. Georgoulas, A. Tzes, D. Lymberopoulos, Improving EMG based classification of basic hand movements using EMD in 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society 13 (EMBC 13), July 3-7, pp. 5754 - 5757, 2013.For the database 2):C. Sapsanis, Recognition of Basic Hand Movements Using Electromyography, Diploma Thesis, University of Patras, 2013 BibTex@mastersthesis{sapsanis2013recognition,title={Recognition of basic hand movements using Electromyography},author={Sapsanis, Christos},school={University of Patras} ,year={2013}}    ",
http://archive.ics.uci.edu/ml/datasets/Poker+Hand,13,Poker Hand Data Set,../machine-learning-databases/poker/,Multivariate,1025010,Game,"Categorical, Integer",11,1/1/2007,Classification,No,609688,"Creators: Robert Cattral (cattral '@' gmail.com) Franz Oppacher (oppacher '@' scs.carleton.ca)Carleton University, Department of Computer ScienceIntelligent Systems Research Unit1125 Colonel By Drive, Ottawa, Ontario, Canada, K1S5B6","Each record is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes. There is one Class attribute that describes the ""Poker Hand"". The order of cards is important, which is why there are 480 possible Royal Flush hands as compared to 4 (one for each suit - explained in [Web Link]).","1) S1 ""Suit of card #1""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} 2) C1 ""Rank of card #1""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) 3) S2 ""Suit of card #2""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} 4) C2 ""Rank of card #2""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) 5) S3 ""Suit of card #3""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} 6) C3 ""Rank of card #3""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) 7) S4 ""Suit of card #4""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} 8) C4 ""Rank of card #4""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) 9) S5 ""Suit of card #5""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs} 10) C5 ""Rank of card 5""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King) 11) CLASS ""Poker Hand""    Ordinal (0-9)     0: Nothing in hand; not a recognized poker hand     1: One pair; one pair of equal ranks within five cards    2: Two pairs; two pairs of equal ranks within five cards    3: Three of a kind; three equal ranks within five cards    4: Straight; five cards, sequentially ranked with no gaps    5: Flush; five cards with the same suit    6: Full house; pair + different rank three of a kind    7: Four of a kind; four equal ranks within five cards    8: Straight flush; straight + flush    9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush","R. Cattral, F. Oppacher, D. Deugo. Evolutionary Data Mining with Automatic Rule Generalization. Recent Advances in Computers, Computing and Communications, pp.296-300, WSEAS Press, 2002.Note: This was a slightly different dataset that had more classes, and was considerably more difficult.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Cylinder+Bands,14,Cylinder Bands Data Set,../machine-learning-databases/cylinder-bands/,Multivariate,512,Physical,"Categorical, Integer, Real",39,8/1/1995,Classification,Yes,77223,"Creator:  Bob EvansRR Donnelley & Sons Co.Gallatin Division801 Steam Plant RdGallatin, Tennessee 37066-3396(615) 452-5170 Donor: same","Here's the abstract from the above reference: ABSTRACT: Machine learning tools show significant promise for knowledge acquisition, particularly when human expertise is inadequate. Recently, process delays known as cylinder banding in rotogravure printing were substantially mitigated using control rules discovered by decision tree induction. Our work exemplifies a more general methodology which transforms the knowledge acquisition task from one in which rules are directly elicited from an expert, to one in which a learning system is responsible for rule generation. The primary responsibilities of the human expert are to evaluate the merits of generated rules, and to guide the acquisition and classification of data necessary for machine induction. These responsibilities require the expert to do what an expert does best: to exercise his or her expertise. This seems a more natural fit to an expert's capabilities than the requirements of traditional methodologies that experts explicitly enumerate the rules that they employ.","	 1. timestamp: numeric;19500101 - 21001231 	 2. cylinder number: nominal	 3. customer: nominal; 	 4. job number: nominal; 	 5. grain screened: nominal; yes, no 	 6. ink color: nominal;  key, type 	 7. proof on ctd ink:  nominal;  yes, no  	 8. blade mfg: nominal;  benton, daetwyler, uddeholm 	 9. cylinder division: nominal;  gallatin, warsaw, mattoon 	10. paper type: nominal;  uncoated, coated, super 	11. ink type: nominal;  uncoated, coated, cover 	12. direct steam: nominal; use; yes, no *	13. solvent type: nominal;  xylol, lactol, naptha, line, other 	14. type on cylinder:  nominal;  yes, no  	15. press type: nominal; use; 70 wood hoe, 70 motter, 70 albert, 94 motter 	16. press: nominal;  821, 802, 813, 824, 815, 816, 827, 828 	17. unit number: nominal;  1, 2, 3, 4, 5, 6, 7, 8, 9, 10 	18. cylinder size: nominal;  catalog, spiegel, tabloid 	19. paper mill location: nominal; north us, south us, canadian, scandanavian, mid european	20. plating tank: nominal; 1910, 1911, other 	21. proof cut: numeric;  0-100 	22. viscosity: numeric;  0-100 	23. caliper: numeric;  0-1.0 	24. ink temperature: numeric;  5-30 	25. humifity: numeric;  5-120 	26. roughness: numeric;  0-2 	27. blade pressure: numeric;  10-75 	28. varnish pct: numeric;  0-100 	29. press speed: numeric;  0-4000 	30. ink pct: numeric;  0-100 	31. solvent pct: numeric;  0-100 	32. ESA Voltage: numeric;  0-16 	33. ESA Amperage: numeric;  0-10 	34. wax: numeric ;  0-4.0	35. hardener:  numeric; 0-3.0 	36. roller durometer:  numeric;  15-120 	37. current density:  numeric;  20-50 	38. anode space ratio:  numeric;  70-130 	39. chrome content: numeric; 80-120 	40. band type: nominal; class; band, no band *","Evans, B., and Fisher, D. (1994). Overcoming process delays with decision tree induction. IEEE Expert , Vol. 9, No. 1, 60--66.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Juan J. Rodr##guez and Carlos J. Alonso. Applying Boosting to Similarity Literals for Time Series Classification. Department of Informatics University of Valladolid, Spain. 2000.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso and Henrik Bostrom. Boosting Interval Based Literals. 2000.  [View Context].Juan J Rodríguez Diez and Carlos Alonso González and Henrik Boström. Learning First Order Logic Time Series Classifiers: Rules and Boosting. PKDD. 2000.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso and Henrik Bostrom. Learning First Order Logic Time Series Classifiers: Rules and Boosting. Grupo de Sistemas Inteligentes, Departamento de Inform#atica Universidad de Valladolid, Spain.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context].Carlos J. Alonso Gonzalez and Juan J. Rodr and iguez Diez. Time Series Classification by Boosting Interval Based Literals. Grupo de Sistemas Inteligentes Departamento de Informatica Universidad de Valladolid.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Grammatical+Facial+Expressions,15,Grammatical Facial Expressions Data Set,../machine-learning-databases/00317/,"Multivariate, Sequential",27965,Computer,Real,100,10/6/2014,"Classification, Clustering",N/A,71847,"     (a) Creators: 		Fernando de Almeida Freitas (Freitas, F. A.)		{fernando} at incluirtecnologia.com.br		Felipe VenÃ¢ncio Barbosa (Barbosa, F. V.)		                Sarajane Marques Peres (Peres, S. M.)        	{felipebarbosa, sarajane} at usp.br http://each.uspnet.usp.br/sarajane/       (b) Donor: 		University of SÃ£o Paulo		School of Art, Sciences and Humanities		Sao Paulo, SP, Brazil http://www5.usp.br/en/  		Incluir Tecnologia LTDA ME		ItajubÃ¡, MG, Brazil		www.incluirtecnologia.com.br","   The automated analysis of facial expressions has been widely used in different research areas, such as biometrics or emotional analysis. Special importance is attached to facial expressions in the area of sign language, since they help to form the grammatical structure of the language and allow for the creation of language disambiguation, and thus are called Grammatical Facial Expressions. This dataset was already used in the experiments described in Freitas et al. (2014).    The dataset is composed by eighteen videos recorded using Microsoft Kinect sensor. In each video, a user performs (five times), in front of the sensor, five sentences in Libras (Brazilian Sign Language) that require the use of a grammatical facial expression. By using Microsoft Kinect, we have obtained: (a) a image of each frame, identified by a timestamp; (b) a text file containing one hundred coordinates (x, y, z) of points from eyes, nose, eyebrows, face contour and iris; each line in the file corresponds to points extracted from one frame. The images enabled a manual labeling of each file by a specialist, providing a ground truth for classification.    The dataset is organized in 36 files: 18 datapoint files and 18 target files, one pair for each video which compose the dataset.The name of the file refers to each video: the letter corresponding to the user (A and B), name of grammatical facial expression and a specification (target or datapoints). ","Datapoints files:    Coordinates x and y are given in pixels.   Coordinates z are given in millimetres.    Label of frame   0 - 7	(x,y,z) - left eye   8 - 15 	(x,y,z) - right eye   16 - 25	(x,y,z) - left eyebrow   26 - 35	(x,y,z) - right eyebrow   36 - 47	(x,y,z) - nose   48 - 67	(x,y,z) - mouth   68 - 86	(x,y,z) - face contour   87		(x,y,z) - left iris   88 		(x,y,z) - right iris   89		(x,y,z) - nose tip   90 - 94	(x,y,z) - line above left eyebrow   95 - 99	(x,y,z) - line above right eyebrow","FREITAS, F. A. ; Peres, S. M. ; Lima, C. A. M. ; BARBOSA, F. V. . Grammatical Facial Expressions Recognition with Machine Learning. In: 27th Florida Artificial Intelligence Research Society Conference (FLAIRS), 2014, Pensacola Beach. Proceedings of the 27th Florida Artificial Intelligence Research Society Conference (FLAIRS). Palo Alto: The AAAI Press, 2014. p. 180-185. ","Please refer to the Machine Learning Repository's citation policy. Additionally, the authors request a citation to the paper mentioned here as relevant paper.",
http://archive.ics.uci.edu/ml/datasets/Post-Operative+Patient,16,Post-Operative Patient Data Set,../machine-learning-databases/postoperative-patient-data/,Multivariate,90,Life,"Categorical, Integer",8,6/1/1993,Classification,Yes,106177,"Creators:  Sharon Summers, School of Nursing, University of KansasMedical Center, Kansas City, KS 66160Linda Woolery, School of Nursing, University of Missouri,Columbia, MO 65211 Donor: Jerzy W. Grzymala-Busse (jerzy '@' cs.ukans.edu) (913)864-4488","The classification task of this database is to determine where patients in a postoperative recovery area should be sent to next.  Because hypothermia is a significant concern after surgery (Woolery, L. et. al. 1991), the attributes correspond roughly to body temperature measurements. Results:      -- LERS (LEM2): 48% accuracy","     1. L-CORE (patient's internal temperature in C):              high (> 37), mid (>= 36 and <= 37), low (< 36)     2. L-SURF (patient's surface temperature in C):              high (> 36.5), mid (>= 36.5 and <= 35), low (< 35)     3. L-O2 (oxygen saturation in %):              excellent (>= 98), good (>= 90 and < 98),              fair (>= 80 and < 90), poor (< 80)     4. L-BP (last measurement of blood pressure):              high (> 130/90), mid (<= 130/90 and >= 90/70), low (< 90/70)     5. SURF-STBL (stability of patient's surface temperature):              stable, mod-stable, unstable     6. CORE-STBL (stability of patient's core temperature)              stable, mod-stable, unstable     7. BP-STBL (stability of patient's blood pressure)              stable, mod-stable, unstable     8. COMFORT (patient's perceived comfort at discharge, measured as               an integer between 0 and 20)     9. decision ADM-DECS (discharge decision):              I (patient sent to Intensive Care Unit),              S (patient prepared to go home),              A (patient sent to general hospital floor)","A. Budihardjo, J. Grzymala-Busse, L. Woolery (1991). Program LERS_LB 2.5 as a tool for knowledge acquisition in nursing, Proceedings of the 4th Int. Conference on Industrial & Engineering Applications of AI & Expert Systems, pp. 735-740.[Web Link]  L. Woolery, J. Grzymala-Busse, S. Summers, A. Budihardjo (1991). The use of machine learning program LERS_LB 2.5 in knowledge acquisition for expert system development in nursing. Computers in Nursing 9, pp. 227-234.","Please refer to the Machine Learning
Repository's citation policy","Petri Kontkanen and Jussi Lahtinen and Petri Myllymäki and Henry Tirri. Unsupervised Bayesian visualization of high-dimensional data. KDD. 2000.  [View Context].Art B. Owen. Tubular neighbors for regression and classification. Stanford University. 1999.  [View Context].Glenn Fung and Sathyakama Sandilya and R. Bharat Rao. Rule extraction from Linear Support Vector Machines. Computer-Aided Diagnosis & Therapy, Siemens Medical Solutions, Inc.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+under+dynamic+gas+mixtures,17,Gas sensor array under dynamic gas mixtures Data Set,../machine-learning-databases/00322/,"Multivariate, Time-Series",4178504,Computer,Real,19,3/20/2015,"Classification, Regression",N/A,52895,"Creators: Jordi Fonollosa (fonollosa '@'ucsd.edu) BioCircutis Institute University of California San Diego San Diego, California, USA  Donors of the Dataset:	Jordi Fonollosa (fonollosa '@'ucsd.edu) Ramon Huerta (rhuerta '@' ucsd.edu)","This data set contains the acquired time series from 16 chemical sensors exposed to gas mixtures at varying concentration levels. In particular, we generated two gas mixtures: Ethylene and Methane in air, and Ethylene and CO in air. Each measurement was constructed by the continuous acquisition of the 16-sensor array signals for a duration of about 12 hours without interruption.  The data set was collected in a gas delivery platform facility at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner.  The sensor array included 16 chemical sensors (Figaro Inc., US) of 4 different types: TGS-2600, TGS-2602, TGS-2610, TGS-2620 (4 units of each type). The sensors were integrated with customized signal conditioning and control electronics. The operating voltage of the sensors, which controls the sensorsâ€™ operating temperature, was kept constant at 5 V for the whole duration of the experiments. The sensorsâ€™ conductivities were acquired continuously at a sampling frequency of 100 Hz. The sensor array was placed in a 60 ml measurement chamber, where the gas sample was injected at a constant flow of 300 ml/min. Each measurement was constructed by the continuous acquisition of the 16-sensor array signals while concentration levels changed randomly. For each measurement (each gas mixture), the signals were acquired continuously for about 12 hours without interruption.  The concentration transitions were set at random times (in the interval 80-120s) and to random concentration levels. The data set was constructed such that all possible transitions are present: increasing, decreasing, or setting to zero the concentration of one volatile while the concentration of the other volatile is kept constant (either at a fixed or at zero concentration level). At the beginning, ending, and approximately every 10,000 s, we inserted additional predefined concentration patterns with pure gas mixtures. The concentration ranges for Ethylene, Methane, and CO were selected such that the induced magnitudes of the sensor responses were similar. Moreover, for gas mixtures, lower concentration levels were favored. Therefore, the multivariate response of the sensors to the presented set of stimuli is challenging since none of the configurations (singlegas or mixture presentation) can be easily identified from the magnitude of sensorsâ€™ responses. In particular Ethylene concentration ranges from 0-20 ppm; 0-600 ppm for CO; and 0-300 ppm for Methane. The primary purpose of making this data set freely accessible on-line is to provide extensive and continuous time series acquired from chemical sensors to the sensor and artificial intelligence research communities to develop and test strategies to solve a wide variety of tasks. In particular, the data set may be useful to develop algorithms for continuous monitoring or improve response time of sensory systems. Also, the repetition of the same type of sensors in the array will allow further investigation on sensor variability (reproducibility of sensors of the same kind). Other interesting topics may include sensor failure (to what extent system predictions degrade when sensors start failing) or calibration transfer (whether the model for one sensor can be extended to other sensors). More information on the generated data set can be found in Fonollosa et al. 'Reservoir Computing compensates slow response of chemosensor arrays exposed to fast varying gas concentrations in continuous monitoring'; Sensors and Actuators B, 2015.  The data set can be used exclusively for research purposes. Commercial purposes are fully excluded. ","The data is presented in two different files: Each file contains the data from one mixture. The file ethylene_CO.txt contains the recordings from the sensors when exposed to mixtures of Ethylene and CO in air. The file ethylene_methane.txt contains the acquired time series induced by the mixture of Methane and Ethylene in air. The structure of the files is the same: Data is distributed in 19 columns. First column represents time (in seconds), second column represents Methane (or CO) concentration set point (in ppm), third column details Ethylene concentration set point (in ppm), and the following 16 columns show the recordings of the sensor array.  Files include a header (one line) with the information of each column: Time (seconds), Methane conc (ppm), Ethylene conc (ppm), sensor readings (16 channels) The order of the sensors in the files is as follows:TGS2602; TGS2602; TGS2600; TGS2600; TGS2610; TGS2610; TGS2620; TGS2620; TGS2602; TGS2602; TGS2600; TGS2600; TGS2610; TGS2610; TGS2620; TGS2620 Sensors' readings can be converted to KOhms by 40.000/S_i, where S_i is the value provided in the text files.",N/A,"Citation of Fonollosa et al. 'Reservoir Computing compensates slow response of chemosensor arrays exposed to fast varying gas concentrations in continuous monitoring'; Sensors and Actuators B, 2015 is required.",
http://archive.ics.uci.edu/ml/datasets/3D+Road+Network+%28North+Jutland%2C+Denmark%29,18,"3D Road Network (North Jutland, Denmark) Data Set",../machine-learning-databases/00246/,"Sequential, Text",434874,Computer,Real,4,4/16/2013,"Regression, Clustering",N/A,187989,"Manohar Kaul, Department of Computer Science, Aarhus University, Denmark (mkaul '@' cs.au.dk) ","This dataset was constructed by adding elevation information to a 2D road network in North Jutland, Denmark (covering a region of 185 x 135 km^2). Elevation values where extracted from a publicly available massive Laser Scan Point Cloud for Denmark (available at : [Web Link] (Bottom-most dataset)). This 3D road network was eventually used for benchmarking various fuel and CO2 estimation algorithms. This dataset can be used by any applications that require to know veryaccurate elevation information of a road network to perform more accurate routing for eco-routing, cyclist routes etc. For the data mining and machine learning community, this dataset can be used as 'ground-truth' validation in spatial mining techniques and satellite image processing. It has no class labels, but can be used in unsupervised learning and regression to guess some missing elevation information for some points on the road. The work was supported by the Reduction project that is funded by the European Comission as FP7-ICT-2011-7 STREP project number 288254.","  1. OSM_ID: OpenStreetMap ID for each road segment or edge in the graph.2. LONGITUDE: Web Mercaptor (Google format) longitude 3. LATITUDE: Web Mercaptor (Google format) latitude4. ALTITUDE: Height in meters.  Note: OSM_ID is the ID assigned by OpenStreetMaps ([Web Link]) to the road segments. Each (long,lat,altitude) point on a road segment (with unique OSM ID) is sorted in the same order as they appear on the road. So a 3D-polyline can be drawn by joining points of each row for each OSM_ID road segment.","[1] Chenjuan Guo, Yu Ma, Bin Yang, Christian S. Jensen, Manohar Kaul: EcoMark: evaluating models of vehicular environmental impact. SIGSPATIAL/GIS 2012: 269-278","Use of this dataset in publications must be acknowledged by referencing the following publication:  Building Accurate 3D Spatial Networks to Enable Next Generation Intelligent Transportation Systems (Accepted and to be published in June)Proceedings of International Conference on Mobile Data Management (IEEE MDM), June 3-6 2013, Milan, Italy",
http://archive.ics.uci.edu/ml/datasets/Residential+Building+Data+Set,19,Residential Building Data Set Data Set,../machine-learning-databases/00437/,Multivariate,372,Computer,Real,105,2/19/2018,Regression,N/A,45780,"Donor and Creator:  Mohammad H. Rafiei, Ph.D.        	    Postdoctoral Researcher, The Ohio State University, Columbus, OH 43210 rafiei.4 '@' osu.edu 	 	    www.mhraf.com ",See the tab 'Descriptions' in the Excel file.,"Totally 105: 8 project physical and financial variables, 19 economic variables and indices in 5 time lag numbers (5*19 = 95), and two output variables that are construction costs and sale prices","Rafiei, M.H. and Adeli, H. (2015). â€œA Novel Machine Learning Model for Estimation of Sale Prices of Real Estate Units.â€ ASCE, Journal of Construction Engineering & Management, 142(2), 04015066.Rafiei, M.H. and Adeli, H. (Submitted as of Feb 19, 2018). â€œA Novel Machine Learning Model for Construction Cost Estimation Taking Into Account Economic Variables and Indices.â€ ASCE, Journal of Construction Engineering & Management.","Rafiei, M.H. and Adeli, H. (2015). â€œA Novel Machine Learning Model for Estimation of Sale Prices of Real Estate Units.â€ ASCE, Journal of Construction Engineering & Management, 142(2), 04015066.",
http://archive.ics.uci.edu/ml/datasets/Open+University+Learning+Analytics+dataset,20,Open University Learning Analytics dataset Data Set,../machine-learning-databases/00349/,"Multivariate, Sequential, Time-Series",N/A,Computer,Integer,N/A,12/21/2015,"Classification, Regression, Clustering",Yes,62991,"Jakub Kuzilek (jakub.kuzilek '@' gmail.com)Knowledge Media Institute, The Open UniversityWalton Hall, Milton Keynes, MK7 6AA, UKCIIRC, CTU in PragueZikova 1903/4, Prague, CZMartin Hlosta (martin.hlosta '@' open.ac.uk)Knowledge Media Institute, The Open UniversityWalton Hall, Milton Keynes, MK7 6AA, UKZdenek Zdrahal (zdenek.zdrahal '@' open.ac.uk)Knowledge Media Institute, The Open UniversityWalton Hall, Milton Keynes, MK7 6AA, UKCIIRC, CTU in PragueZikova 1903/4, Prague, CZ","Open University Learning Analytics Dataset (OULAD) contains data about courses, students and their interactions with Virtual Learning Environment (VLE) for seven selected courses (called modules). Presentations of courses start in February and October - they are marked by 'B' and 'J' respectively. The dataset consists of tables connected using unique identifiers. Dataset is stored in several csv files. More information, examples and news can be found at:       [Web Link]",see description file,N/A,"Released under CC-BY 4.0. Please use this paper for your citation: Kuzilek, J., Hlosta, M., Herrmannova, D., Zdrahal, Z. and Wolff, A. OU Analyse: Analysing At-Risk Students at The Open University. Learning Analytics Review, no. LAK15-1, March 2015, ISSN: 2057-7494.",
http://archive.ics.uci.edu/ml/datasets/University+of+Tehran+Question+Dataset+2016+%28UTQD.2016%29,21,University of Tehran Question Dataset 2016 (UTQD.2016) Data Set,../machine-learning-databases/00425/,Text,1175,N/A,N/A,3,9/27/2017,Classification,Yes,12470,"Mohammad Razzaghnoori/Dept. of Mathematics, Statistics and Computer Science, College of Science, University of Tehran/m.razzaghnoori@ut.ac.irHedieh Sajedi/ Dept. of Mathematics, Statistics and Computer Science, College of Science, University of Tehran/hhsajedi '@' ut.ac.ir Iman Khani Jazani/Dept. of Computer Engineering and Information Technology, AmirKabirUniversity of Technology/imankhanijazani '@' aut.ac.ir","The format of each record: Coarse-grained:Fine-grained|Question",N/A,"M. Razzaghnoori, H. Sajedi, I Khani Jazani: 'Question classification in Persian using word vectors and frequencies', Cognitive Systems Research, 2018.","Use of this dataset in publications must be acknowledged by referencing the following publication:  Razzaghnoori, M., Sajedi, H., & Khani Jazani, I. (In Press). Question classification in Persian using word vectors and frequencies. Cognitive Systems Research. doi: 10.1016/j.cogsys.2017.07.002",
http://archive.ics.uci.edu/ml/datasets/Heart+Disease,22,Heart Disease Data Set,../machine-learning-databases/heart-disease/,Multivariate,303,Life,"Categorical, Integer, Real",75,7/1/1988,Classification,Yes,1270649,"Creators:  1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D. Donor:  David W. Aha (aha '@' ics.uci.edu) (714) 856-8779   ","This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to this date.  The ""goal"" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).   The names and social security numbers of the patients were recently removed from the database, replaced with dummy values. One file has been ""processed"", that one containing the Cleveland database.  All four unprocessed files also exist in this directory. To see Test Costs (donated by Peter Turney), please see the folder ""Costs"" ","Only 14 attributes used:      1. #3  (age)             2. #4  (sex)             3. #9  (cp)              4. #10 (trestbps)        5. #12 (chol)            6. #16 (fbs)             7. #19 (restecg)         8. #32 (thalach)         9. #38 (exang)           10. #40 (oldpeak)         11. #41 (slope)           12. #44 (ca)              13. #51 (thal)            14. #58 (num)       (the predicted attribute) Complete attribute documentation:      1 id: patient identification number      2 ccf: social security number (I replaced this with a dummy value of 0)      3 age: age in years      4 sex: sex (1 = male; 0 = female)      5 painloc: chest pain location (1 = substernal; 0 = otherwise)      6 painexer (1 = provoked by exertion; 0 = otherwise)      7 relrest (1 = relieved after rest; 0 = otherwise)      8 pncaden (sum of 5, 6, and 7)      9 cp: chest pain type        -- Value 1: typical angina        -- Value 2: atypical angina        -- Value 3: non-anginal pain        -- Value 4: asymptomatic     10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)     11 htn     12 chol: serum cholestoral in mg/dl     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)     14 cigs (cigarettes per day)     15 years (number of years as a smoker)     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)     17 dm (1 = history of diabetes; 0 = no such history)     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)     19 restecg: resting electrocardiographic results        -- Value 0: normal        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria     20 ekgmo (month of exercise ECG reading)     21 ekgday(day of exercise ECG reading)     22 ekgyr (year of exercise ECG reading)     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)     28 proto: exercise protocol          1 = Bruce               2 = Kottus          3 = McHenry          4 = fast Balke          5 = Balke          6 = Noughton           7 = bike 150 kpa min/min  (Not sure if ""kpa min/min"" is what was written!)          8 = bike 125 kpa min/min            9 = bike 100 kpa min/min         10 = bike 75 kpa min/min         11 = bike 50 kpa min/min         12 = arm ergometer     29 thaldur: duration of exercise test in minutes     30 thaltime: time when ST measure depression was noted     31 met: mets achieved     32 thalach: maximum heart rate achieved     33 thalrest: resting heart rate     34 tpeakbps: peak exercise blood pressure (first of 2 parts)     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)     36 dummy     37 trestbpd: resting blood pressure     38 exang: exercise induced angina (1 = yes; 0 = no)     39 xhypo: (1 = yes; 0 = no)     40 oldpeak = ST depression induced by exercise relative to rest     41 slope: the slope of the peak exercise ST segment        -- Value 1: upsloping        -- Value 2: flat        -- Value 3: downsloping     42 rldv5: height at rest     43 rldv5e: height at peak exercise     44 ca: number of major vessels (0-3) colored by flourosopy     45 restckm: irrelevant     46 exerckm: irrelevant     47 restef: rest raidonuclid (sp?) ejection fraction     48 restwm: rest wall (sp?) motion abnormality        0 = none        1 = mild or moderate        2 = moderate or severe        3 = akinesis or dyskmem (sp?)     49 exeref: exercise radinalid (sp?) ejection fraction     50 exerwm: exercise wall (sp?) motion      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect     52 thalsev: not used     53 thalpul: not used     54 earlobe: not used     55 cmo: month of cardiac cath (sp?)  (perhaps ""call"")     56 cday: day of cardiac cath (sp?)     57 cyr: year of cardiac cath (sp?)     58 num: diagnosis of heart disease (angiographic disease status)        -- Value 0: < 50% diameter narrowing        -- Value 1: > 50% diameter narrowing        (in any major vessel: attributes 59 through 68 are vessels)     59 lmt     60 ladprox     61 laddist     62 diag     63 cxmain     64 ramus     65 om1     66 om2     67 rcaprox     68 rcadist     69 lvx1: not used     70 lvx2: not used     71 lvx3: not used     72 lvx4: not used     73 lvf: not used     74 cathef: not used     75 junk: not used     76 name: last name of patient  (I replaced this with the dummy string ""name"")","Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J., Sandhu, S., Guppy, K., Lee, S., & Froelicher, V. (1989).  International application of a new probability algorithm for the diagnosis of coronary artery disease. American Journal of Cardiology, 64,304--310.[Web Link]  David W. Aha & Dennis Kibler. ""Instance-based prediction of heart-disease presence with the Cleveland database.""[Web Link]  Gennari, J.H., Langley, P, & Fisher, D. (1989). Models of incremental concept formation. Artificial Intelligence, 40, 11--61.[Web Link] ","The authors of the databases have requested that any publications resulting from the use of the data include the names of the principal investigator responsible for the data collection at each institution.  They would be:1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:Robert Detrano, M.D., Ph.D.","Gavin Brown. Diversity in Neural Network Ensembles. The University of Birmingham. 2004.  [View Context].Kaizhu Huang and Haiqin Yang and Irwin King and Michael R. Lyu and Laiwan Chan. Biased Minimax Probability Machine for Medical Diagnosis. AMAI. 2004.  [View Context].Jeroen Eggermont and Joost N. Kok and Walter A. Kosters. Genetic Programming for data classification: partitioning the search space. SAC. 2004.  [View Context].Zhi-Hua Zhou and Yuan Jiang. NeC4.5: Neural Ensemble Based C4.5. IEEE Trans. Knowl. Data Eng, 16. 2004.  [View Context].Remco R. Bouckaert and Eibe Frank. Evaluating the Replicability of Significance Tests for Comparing Learning Algorithms. PAKDD. 2004.  [View Context].Xiaoyong Chai and Li Deng and Qiang Yang and Charles X. Ling. Test-Cost Sensitive Naive Bayes Classification. ICDM. 2004.  [View Context].David Page and Soumya Ray. Skewing: An Efficient Alternative to Lookahead for Decision Tree Induction. IJCAI. 2003.  [View Context].Jinyan Li and Limsoon Wong. Using Rules to Analyse Bio-medical Data: A Comparison between C4.5 and PCL. WAIM. 2003.  [View Context].Yuan Jiang Zhi and Hua Zhou and Zhaoqian Chen. Rule Learning based on Neural Network Ensemble. Proceedings of the International Joint Conference on Neural Networks. 2002.  [View Context].Baback Moghaddam and Gregory Shakhnarovich. Boosted Dyadic Kernel Discriminants. NIPS. 2002.  [View Context].Robert Burbidge and Matthew Trotter and Bernard F. Buxton and Sean B. Holden. STAR - Sparsity through Automated Rejection. IWANN (1). 2001.  [View Context].Peter L. Hammer and Alexander Kogan and Bruno Simeone and Sandor Szedm'ak. R u t c o r Research R e p o r t. Rutgers Center for Operations Research Rutgers University. 2001.  [View Context].Thomas Melluish and Craig Saunders and Ilia Nouretdinov and Volodya Vovk and Carol S. Saunders and I. Nouretdinov V.. The typicalness framework: a comparison with the Bayesian approach. Department of Computer Science. 2001.  [View Context].Petri Kontkanen and Petri Myllym and Tomi Silander and Henry Tirri and Peter Gr. On predictive distributions and Bayesian networks. Department of Computer Science, Stanford University. 2000.  [View Context].Rudy Setiono and Wee Kheng Leow. FERNN: An Algorithm for Fast Extraction of Rules from Neural Networks. Appl. Intell, 12. 2000.  [View Context].Kristin P. Bennett and Ayhan Demiriz and John Shawe-Taylor. A Column Generation Algorithm For Boosting. ICML. 2000.  [View Context].Thomas G. Dietterich. An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization. Machine Learning, 40. 2000.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Improved Generalization Through Explicit Optimization of Margins. Machine Learning, 38. 2000.  [View Context].Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. An Implementation of Logical Analysis of Data. IEEE Trans. Knowl. Data Eng, 12. 2000.  [View Context].Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining. Institute of Information Science. 1999.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Iñaki Inza and Pedro Larrañaga and Basilio Sierra and Ramon Etxeberria and Jose Antonio Lozano and Jos Manuel Peña. Representing the behaviour of supervised classification learning algorithms by Bayesian networks. Pattern Recognition Letters, 20. 1999.  [View Context].Yoav Freund and Lorne Mason. The Alternating Decision Tree Learning Algorithm. ICML. 1999.  [View Context].Jinyan Li and Xiuzhen Zhang and Guozhu Dong and Kotagiri Ramamohanarao and Qun Sun. Efficient Mining of High Confidience Association Rules without Support Thresholds. PKDD. 1999.  [View Context].D. Randall Wilson and Roel Martinez. Machine Learning: Proceedings of the Fourteenth International Conference, Morgan. In Fisher. 1997.  [View Context].Pedro Domingos. Control-Sensitive Feature Selection for Lazy Learners. Artif. Intell. Rev, 11. 1997.  [View Context].Floriana Esposito and Donato Malerba and Giovanni Semeraro. A Comparative Analysis of Methods for Pruning Decision Trees. IEEE Trans. Pattern Anal. Mach. Intell, 19. 1997.  [View Context].Rudy Setiono and Huan Liu. NeuroLinear: From neural networks to oblique decision rules. Neurocomputing, 17. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF. Appl. Intell, 7. 1997.  [View Context].Jan C. Bioch and D. Meer and Rob Potharst. Bivariate Decision Trees. PKDD. 1997.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Ron Kohavi and Dan Sommerfield. Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology. KDD. 1995.  [View Context].Peter D. Turney. Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm. CoRR, csAI/9503102. 1995.  [View Context].Gabor Melli. A Lazy Model-Based Approach to On-Line Classification. University of British Columbia. 1989.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski and Geerd H. F Diercksen. Minimal distance neural methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context].John G. Cleary and Leonard E. Trigg. Experiences with OB1, An Optimal Bayes Decision Tree Learner. Department of Computer Science University of Waikato.  [View Context].Glenn Fung and Sathyakama Sandilya and R. Bharat Rao. Rule extraction from Linear Support Vector Machines. Computer-Aided Diagnosis & Therapy, Siemens Medical Solutions, Inc.  [View Context].Ayhan Demiriz and Kristin P. Bennett and John Shawe and I. Nouretdinov V.. Linear Programming Boosting via Column Generation. Dept. of Decision Sciences and Eng. Systems, Rensselaer Polytechnic Institute.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context].Liping Wei and Russ B. Altman. An Automated System for Generating Comparative Disease Profiles and Making Diagnoses. Section on Medical Informatics Stanford University School of Medicine, MSOB X215.  [View Context].Federico Divina and Elena Marchiori. Handling Continuous Attributes in an Evolutionary Inductive Learner. Department of Computer Science Vrije Universiteit.  [View Context].Ron Kohavi and George H. John. Automatic Parameter Selection by Minimizing Estimated Error. Computer Science Dept. Stanford University.  [View Context].H. -T Lin and C. -J Lin. A Study on Sigmoid Kernels for SVM and the Training of non-PSD Kernels by SMO-type Methods. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. A hybrid method for extraction of logical rules from data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl odzisl/aw Duch and Karol Grudzinski. Search and global minimization in similarity-based methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Rudy Setiono and Wee Kheng Leow. Generating rules from trained network using fast pruning. School of Computing National University of Singapore.  [View Context].Elena Smirnova and Ida G. Sprinkhuizen-Kuyper and I. Nalbantis and b. ERIM and Universiteit Rotterdam. Unanimous Voting using Support Vector Machines. IKAT, Universiteit Maastricht.  [View Context].Krista Lagus and Esa Alhoniemi and Jeremias Seppa and Antti Honkela and Arno Wagner. INDEPENDENT VARIABLE GROUP ANALYSIS IN LEARNING COMPACT REPRESENTATIONS FOR DATA. Neural Networks Research Centre, Helsinki University of Technology.  [View Context].Chiranjib Bhattacharyya and Pannagadatta K. S and Alexander J. Smola. A Second order Cone Programming Formulation for Classifying Missing Data. Department of Computer Science and Automation Indian Institute of Science.  [View Context].Ayhan Demiriz and Kristin P. Bennett. Chapter 1 OPTIMIZATIONAPPROACHESTOSEMI-SUPERVISED LEARNING. Department of Decision Sciences and Engineering Systems & Department of Mathematical Sciences, Rensselaer Polytechnic Institute.  [View Context].Adil M. Bagirov and John Yearwood. A new nonsmooth optimization algorithm for clustering. Centre for Informatics and Applied Optimization, School of Information Technology and Mathematical Sciences, University of Ballarat.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Bruce H. Edmonds. Using Localised `Gossip' to Structure Distributed Learning. Centre for Policy Modelling.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. Geometry in Learning. Department of Mathematical Sciences Rensselaer Polytechnic Institute.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery. CEFET-PR, Curitiba.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Forest+Fires,23,Forest Fires Data Set,../machine-learning-databases/forest-fires/,Multivariate,517,Physical,Real,13,2/29/2008,Regression,N/A,901139,"Paulo Cortez, pcortez '@' dsi.uminho.pt, Department of Information Systems, University of Minho, Portugal.Aníbal Morais, araimorais '@' gmail.com, Department of Information Systems, University of Minho, Portugal.  ","In [Cortez and Morais, 2007], the output 'area' was first transformed with a ln(x+1) function.   Then, several Data Mining methods were applied. After fitting the models, the outputs were   post-processed with the inverse of the ln(x+1) transform. Four different input setups were   used. The experiments were conducted using a 10-fold (cross-validation) x 30 runs. Two   regression metrics were measured: MAD and RMSE. A Gaussian support vector machine (SVM) fed   with only 4 direct weather conditions (temp, RH, wind and rain) obtained the best MAD value:   12.71 +- 0.01 (mean and confidence interval within 95% using a t-student distribution). The   best RMSE was attained by the naive mean predictor. An analysis to the regression error curve   (REC) shows that the SVM model predicts more examples within a lower admitted error. In effect,   the SVM model predicts better small fires, which are the majority. ","For more information, read [Cortez and Morais, 2007].   1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9   2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9   3. month - month of the year: 'jan' to 'dec'    4. day - day of the week: 'mon' to 'sun'   5. FFMC - FFMC index from the FWI system: 18.7 to 96.20   6. DMC - DMC index from the FWI system: 1.1 to 291.3    7. DC - DC index from the FWI system: 7.9 to 860.6    8. ISI - ISI index from the FWI system: 0.0 to 56.10   9. temp - temperature in Celsius degrees: 2.2 to 33.30   10. RH - relative humidity in %: 15.0 to 100   11. wind - wind speed in km/h: 0.40 to 9.40    12. rain - outside rain in mm/m2 : 0.0 to 6.4    13. area - the burned area of the forest (in ha): 0.00 to 1090.84    (this output variable is very skewed towards 0.0, thus it may make    sense to model with the logarithm transform).","[Cortez and Morais, 2007] P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data. In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence, Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December, Guimarães, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9. Available at: [Web Link]","This dataset is public available for research. The details are described in [Cortez and Morais, 2007]. Please include this citation if you plan to use this database:[Cortez and Morais, 2007] P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data. In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence, Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December, Guimarães, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9. Available at: [Web Link]",
http://archive.ics.uci.edu/ml/datasets/Kitsune+Network+Attack+Dataset,24,Kitsune Network Attack Dataset Data Set,../machine-learning-databases/00516/,"Multivariate, Sequential, Time-Series",27170754,Computer,Real,115,10/16/2019,"Classification, Clustering, Causal-Discovery",N/A,114874,"Creators: Yisroel Mirsky, Tomer Doitshman, Yuval Elovici, and Asaf Shabtai.Ben-Gurion University of the Negev, Department of Information Systems Engineering Donor:Yisroel Mirskyyisroel  post.bgu.ac.il16/10/2019","==== Overview ====The are 9 network capture datasets in total, listed below. Viol. is the security violation (Confidentiality, Integrity, and Authenticity).   Attack Type	Attack Name	Tool		Viol.	Description: The attackerRecon.		   -1		OS Scan		Nmap		C	scans the network for hosts, and their operating systems, to reveal possible vulnerabilities.   -2		Fuzzing		SFuzz		C	searches for vulnerabilities in the camera's web servers by sending random commands to their cgis.Man in the Middle	   -3		Video Injection	Video Jack	C,I	injects a recorded video clip into a live video stream.   -4		ARP MitM	Ettercap	C	intercepts all LAN traffic via an ARP poisoning attack.   -5		Active Wiretap	R.PI 3B		C	intercepts all LAN traffic via active wiretap (network bridge) covertly installed on an exposed cable.Denial of Service	   -6		SSDP Flood	Saddam		A	overloads the DVR by causing cameras to spam the server with UPnP advertisements.   -7		SYN DoS		Hping3		A	disables a camera's video stream by overloading its web server.   -8		SSL Reneg.	THC		A	disables a camera's video stream by sending many SSL renegotiation packets to the camera.Botnet Malware	   -9		Mirai		Telnet		C,I	infects IoT with the Mirai malware by exploiting default credentials, and then scans for new vulnerable victims network. -For more details on the attacks themselves, please refer to our paper.  ==== Data Organization ====For each attack (network capture) above we provide (1) a csv of the features used in our paper where each row is a network packet, (2) the corresponding labels [benign, malicious], and (3) the original network capture in truncated pcap format. -Each attack dataset is located in a separate directory-Each directory contains three files: _pcap.pcapng	:	A raw pcap capture of the original N packets. The packets have been truncated to 200 bytes for privacy reasons. _dataset.csv	:	An N-by-M matrix of M-sized feature vectors, each describing the packet and the context of that packet's channel (see our paper for details). _labels.csv	:	An N-by-1 vector of 0-1 values which indicate whether each packet in _pcap.pcapng (and _dataset.csv) is malicious ('1') or not ('0'). For the Man-in-middle-Attacks, all packets which have passed through the MitM are marked as '1'.-Every attack dataset begins with benign traffic, and then at some point (1) the attacker connects to the network and (2) initiates the given attack.   ","=== The features in the csv files ===Each row in the csv is a packet captured (chronologically). More a deep explanation, please see our paper. In general, each row (feature vector) are recent (temporal) statistics which describes the context of the packet's channel and its communicating parties: Whenever a packet arrives, we extract a behavioral snapshot of the hosts and protocols which communicated the given packet. The snapshot consists of 115 traffic statistics capturing a small temporal window into: (1) the packet's sender in general, and (2) the traffic between the packet's sender and receiver. Specifically, the statistics summarize all of the traffic...	 ...originating from this packet's source MAC and IP address (denoted SrcMAC-IP).	 ...originating from this packet's source IP (denoted SrcIP).	 ...sent between this packet's source and destination IPs (denoted Channel). 		 ...sent between this packet's source and destination TCP/UDP Socket (denoted Socket). A total of 23 features (capturing the above) can be extracted from a single time window Î» (see Table II). The FE extracts the same set of features from a total of five time damped windows of approximately: 100ms, 500ms, 1.5sec, 10sec, and 1min into the past (Î» = 5, 3, 1, 0.1, 0.01), thus totaling 115 features. We note that not every packet applies to every channel type (e.g., there is no socket if the packet does not contain a TCP or UDP datagram). In these cases, these features are zeroed. Thus, the final feature vector ~x, which the FE passes to theFM, is always a member of R^n, where n = 115. The feature extraction code (pcap to csv) is available at: [Web Link] ",[Web Link] [Web Link],"If you use this dataset, please cite:Yisroel Mirsky, Tomer Doitshman, Yuval Elovici, and Asaf Shabtai, 'Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection', Network and Distributed System Security Symposium 2018 (NDSS'18)",
http://archive.ics.uci.edu/ml/datasets/TTC-3600%3A+Benchmark+dataset+for+Turkish+text+categorization,25,TTC-3600: Benchmark dataset for Turkish text categorization Data Set,../machine-learning-databases/00407/,Text,3600,Computer,Integer,4814,2/8/2017,"Classification, Clustering",N/A,14579,"Assist.Prof.Dr. Deniz KILINÃ‡, Faculty of Technology, Celal Bayar University, Turkeydrdenizkilinc'@'gmail.com","The dataset consists of a total of 3600 documents including 600 news/texts from six categories â€“ economy, culture-arts, health, politics, sports and technology â€“ obtainedfrom six well-known news portals and agencies (Hurriyet,Posta,Iha,HaberTurk,Radikal and Zaman). Documents of TTC-3600 dataset were collected between May and July 2015 via Rich Site Summary (RSS) feeds from six categories of the respective portals. All java scripts, HTML tags ( < img> , < a > , < p > , < strong> etc.), operators, punctuations, non-printable characters and irrelevant data such as advertising are removed. Three additional dataset versions are created on TTC-3600 by implementing different stemming methods. In all versions of datasets, first, removal-based pre-processing, which is explained in Section 3.2 in detail, is used. Then Turkish stop-words that have no discriminatory power (pronouns, prepositions, conjunctions, etc.) in regard to TC are removedfrom datasets except for the original one. In this study, a semi-automatically constructed stop-words list that contains 147 words is utilized.",ARFF (Attribute-Relation File Format) Weka format ,[Web Link],"KÄ±lÄ±nÃ§, Deniz, et al. 'TTC-3600: A new benchmark dataset for Turkish text categorization.' Journal of Information Science (2015): 0165551515620551.",
http://archive.ics.uci.edu/ml/datasets/Container+Crane+Controller+Data+Set,26,Container Crane Controller Data Set Data Set,../machine-learning-databases/00436/,"Univariate, Domain-Theory",15,Computer,Real,3,1/1/2018,"Classification, Regression",N/A,30460,"Creators original owner and donors: Ricardo Pinto Ferreira (1), Andrea Martiniano (2), Arthur Ferreira (3), Marcio Romero (4) and Renato Jose Sassi (5).  E-mail address: log.kasparov '@' gmail.com (1) - PhD student;andrea.martiniano '@' gmail.com (2) - PhD student;arthur2.ferreira '@' usp.br (3) - Graduation student;mhromero '@' hotmail.com (4) - PhD student;sassi '@' uni9.pro.br (5) - Prof. Doctor Universidade Nove de Julho - Post-Graduation Program in Informatics and Knowledge Management. Address: Rua Vergueiro, 235/249 Liberdade, Sao Paulo â€“ SP, Brazil. Zip code: 01504-001. Website: http://www.uninove.br/curso/informatica-e-gestao-do-conhecimento/  ","Two predictive attributes (Speed and Angle) and one attribute target (Power).A container crane has the function of transporting containers from one point to another point. The difficulty of this task lies in the fact that the container is connected to the bridge crane by cables causing an opening angle while the container is being transported, interfering with the operation at high speeds due to oscillation that occurs at the end point, which could cause accidents.","Speed of moving Container Crane: low, medium and high (low: 1, 2, 3; medium: 6, 7, 8; high: 9, 10).Angle: large negative angle, small negative angle, angle zero, small positive angle and large positive angle.Power: low, medium and high (low: 0.3; medium: 0.5; high: 0.7).for Weka:@relation Container_Crane_Controller@attribute Speed REAL@attribute Angle REAL@attribute Power REAL@data1.0, -5.0, 0.32.0, 5.0, 0.33.0, -2.0, 0.51.0, 2.0, 0.52.0, 0.0, 0.76.0, -5.0, 0.57.0, 5.0, 0.56.0, -2.0, 0.37.0, 2.0, 0.36.0, 0.0, 0.78.0, -5.0, 0.59.0, 5.0, 0.510.0, -2.0, 0.38.0, 2.0, 0.39.0, 0.0, 0.5","Ferreira, R. P., Martiniano, A., Ferreira, A., Romero, M., & Sassi, R. J. (2016). Container Crane Controller with the Use of a NeuroFuzzy Network. In IFIP International Conference on Advances in Production Management Systems (pp. 122-129). Springer, Cham. DOI: 10.1007/978-3-319-51133-7_15.","Ferreira, R. P., Martiniano, A., Ferreira, A., Romero, M., & Sassi, R. J. (2016). Container Crane Controller with the Use of a NeuroFuzzy Network. In IFIP International Conference on Advances in Production Management Systems (pp. 122-129). Springer, Cham. DOI: 10.1007/978-3-319-51133-7_15.",
http://archive.ics.uci.edu/ml/datasets/REALDISP+Activity+Recognition+Dataset,27,REALDISP Activity Recognition Dataset Data Set,../machine-learning-databases/00305/,"Multivariate, Time-Series",1419,Computer,Real,120,7/25/2014,Classification,N/A,44901,"Oresti Banos, Department of Computer Architecture and Computer Technology, University of Granada, oresti '@' ugr.es (oresti.bl '@' gmail.com)Mate Attila Toth, Signal Processing Systems, TU Eindhoven, A.M.Toth '@' tue.nl Oliver Amft, Signal Processing Systems, TU Eindhoven, amft '@' tue.nl ","The REALDISP (REAListic sensor DISPlacement) dataset has been originally collected to investigate the effects of sensor displacement in the activity recognition process in real-world settings. It builds on the concept of ideal-placement, self-placement and induced-displacement. The ideal and mutual-displacement conditions represent extreme displacement variants and thus could represent boundary conditions for recognition algorithms. In contrast, self-placement reflects a users perception of how sensors could be attached, e.g., in a sports or lifestyle application. The dataset includes a wide range of physical activities (warm up, cool down and fitness exercises), sensor modalities (acceleration, rate of turn, magnetic field and quaternions) and participants (17 subjects). Apart from investigating sensor displacement, the dataset lend itself for benchmarking activity recognition techniques in ideal conditions. ----------------------------------------------------------------------------------------------------------------------Dataset summary:#Activities: 33 #Sensors: 9#Subjects: 17#Scenarios: 3---------------------------------------------------------------------------------------------------------------------- ACTIVITY SET:A1: Walking  A2: Jogging  A3: Running  A4: Jump up  A5: Jump front & back  A6: Jump sideways  A7: Jump leg/arms open/closed  A8: Jump rope  A9: Trunk twist (arms outstretched)  A10: Trunk twist (elbows bent)  A11: Waist bends forward  A12: Waist rotation  A13: Waist bends (reach foot with opposite hand)  A14: Reach heels backwards  A15: Lateral bend (10_ to the left + 10_ to the right)A16: Lateral bend with arm up (10_ to the left + 10_ to the right) A17: Repetitive forward stretching A18: Upper trunk and lower body opposite twist A19: Lateral elevation of arms A20: Frontal elevation of arms A21: Frontal hand claps A22: Frontal crossing of arms A23: Shoulders high-amplitude rotation A24: Shoulders low-amplitude rotation A25: Arms inner rotation A26: Knees (alternating) to the breast A27: Heels (alternating) to the backside A28: Knees bending (crouching) A29: Knees (alternating) bending forward A30: Rotation on the knees A31: Rowing A32: Elliptical bike A33: Cycling  SENSOR SETUP:Each sensor provides 3D acceleration (accX,accY,accZ), 3D gyro (gyrX,gyrY,gyrZ), 3D magnetic field orientation (magX,magY,magZ) and 4D quaternions (Q1,Q2,Q3,Q4). The sensors are identified according to the body part on which is placed respectively: S1: right lower arm (RLA)S2: right upper arm (RUA)S3: back (BACK)S4: left upper arm (LUA)S5: left lower arm (LLA)S6: right calf (RC)S7: right thigh (RT)S8: left thigh (LT)S9: left calf (LC) SCENARIOS:The dataset contains information for three different scenarios depending on whether the sensors are positioned on predefined positions or placed by the users themselves.- Ideal-placement or the default scenario. The sensors are positioned by the instructor on predefined locations within each body part. The data stemming from this scenario could be considered as the â€œtraining setâ€ for supervised activity recognition systems.- Self-placement. The user is asked to position a subset of the sensors themselves on the body parts specified by the instructor, but without providing any hint on how the sensors must be exactly placed. This scenario is devised to investigate some of the variability that may occur in the day-to-day usage of an activity recognition system, involving wearable or self-attached sensors. Normally, the self-placement will lead to on-body sensor setups that differ from the ideal-placement. Nevertheless, this difference may be minimal if the subject places the sensor close to the ideal position.- Induced-displacement. An intentional mispositioning of sensors using rotations and translations with respect to the ideal placement is introduced by the instructor. One of the key interests of including this last scenario is to investigate how the performance of a certain method degrades as the system drifts far from the ideal setup. A complete and illustrated description (including table of activities, sensor setup, etc.) of the dataset is provided in the documentation facilitated along with the dataset. Also, the papers presented in the section â€œCitation Requestsâ€ provide an insightful description of the dataset and the underlying theory.  ","The dataset comprises the readings of motion sensors recorded while users executed typical daily activities. The detailed format is described in the package. The attributes correspond to raw sensor readings. There is a total of 120 attributes: Column 1: Timestamp in secondsColumn 2: Timestamp in microsecondsColumn 3-15: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S1Column 16-28: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S2Column 29-41: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S3Column 42-54: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S4Column 55-67: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S5Column 68-80: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S6Column 91-93: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S7Column 94-106: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S8Column 107-119: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S9Column 120: Label (see activity set)","Banos, O., Toth M. A., Damas, M., Pomares, H., Rojas, I. Dealing with the effects of sensor displacement in wearable activity recognition. Sensors vol. 14, no. 6, pp. 9995-10023 (2014).Banos, O., Galvez, J. M., Damas, M., Pomares, H., Rojas, I. Window size impact in activity recognition. Sensors, vol. 14, no. 4, pp. 6474-6499 (2014).Banos, O., Galvez, J. M., Damas, M., Pomares, H., Rojas, I. Evaluating the effects of signal segmentation on activity recognition. Proceedings of the International Work-Conference on Bioinformatics and Biomedical Engineering (IWBBIO 2014), Granada, Spain, April 7-9, (2014).Banos, O., Damas, M., Pomares, H., Rojas, I. Handling displacement effects in on-body sensor-based activity recognition. Proceedings of the 5th International Work-conference on Ambient Assisted Living an Active Ageing (IWAAL 2013), San Jose, Costa Rica, December 2-6, (2013).Banos, O., Damas, M., Pomares, H., Rojas, I. Activity recognition based on a multi-sensor meta-classifier. Proceedings of the International Work Conference on Neural Networks (IWANN 2013), Tenerife, Spain, June 12-14, (2013). Smith, Jeremiah, et al. 'Exploring concept drift using interactive simulations' IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM 2013), San Diego, USA, March 18-22, (2013).Banos, O., Toth, M. A., Damas, M., Pomares, H., Rojas, I., Amft, O. A benchmark dataset to evaluate sensor displacement in activity recognition. Proceedings of the 14th International Conference on Ubiquitous Computing (Ubicomp 2012), Pittsburgh, USA, September 5-8, (2012).Reyes-Ortiz, J.L., Luca Oneto, Albert Samà, Xavier Parra, Davide Anguita, Transition-Aware Human Activity Recognition Using Smartphones, Neurocomputing, (Online) 2015Nguyen, L. T., Zeng, M., Tague, P., Zhang, J. (2015). Recognizing New Activities with Limited Training Data. In IEEE International Symposium on Wearable Computers (ISWC).Wilson, J.; Najjar, N.; Hare, J.; Gupta, S., Human activity recognition using LZW-Coded Probabilistic Finite State Automata. In IEEE International Conference on Robotics and Automation (ICRA), 2015, pp.3018-3023Punchoojit, Lumpapun, and Nuttanont Hongwarittorrn. ""A Comparative Study on Sensor Displacement Effect on Realistic Sensor Displacement Benchmark Dataset."" Recent Advances in Information and Communication Technology 2015. 97-106.","Use of this dataset in publications must be acknowledged by referencing the following publications: Banos, O., Toth M. A., Damas, M., Pomares, H., Rojas, I. Dealing with the effects of sensor displacement in wearable activity recognition. Sensors vol. 14, no. 6, pp. 9995-10023 (2014).Banos, O., Toth, M. A., Damas, M., Pomares, H., Rojas, I., Amft, O. A benchmark dataset to evaluate sensor displacement in activity recognition. Proceedings of the 14th International Conference on Ubiquitous Computing (Ubicomp 2012), Pittsburgh, USA, September 5-8, (2012). We recommend to refer to this dataset as the 'REALDISP dataset' in publications. We would appreciate if you send us an email (oresti.bl '@' gmail.com) to inform us of any publication using this dataset. ",
http://archive.ics.uci.edu/ml/datasets/Condition+Based+Maintenance+of+Naval+Propulsion+Plants,28,Condition Based Maintenance of Naval Propulsion Plants Data Set,../machine-learning-databases/00316/,Multivariate,11934,Computer,Real,16,9/11/2014,Regression,N/A,58896,"Andrea Coraddu(2), Luca Oneto(1), Alessandro Ghio(1), Stefano Savio(2), Davide Anguita(3), Massimo Figari(2)1 - Smartlab - Non-Linear Complex Systems LaboratoryDITEN - UniversitÂˆÃ  degli Studi di Genova, Genoa (I-16145), Italy. 2 - Marine Technology Research TeamDITEN - UniversitÂˆÃ  degli Studi di Genova, Genoa (I-16145), Italy. 3 - Smartlab - Non-Linear Complex Systems LaboratoryDIBRIS - UniversitÂˆÃ  degli Studi di Genova, Genoa (I-16145), Italy. cbm '@' smartlab.ws www.cbm.smartlab.ws","The experiments have been carried out by means of a numerical simulator of a naval vessel (Frigate) characterized by a Gas Turbine (GT) propulsion plant. The different blocks forming the complete simulator (Propeller, Hull, GT, Gear Box and Controller) have been developed and fine tuned over the year on several similar real propulsion plants. In view of these observations the available data are in agreement with a possible real vessel.In this release of the simulator it is also possible to take into account the performance decay over time of the GT components such as GT compressor and turbines.The propulsion system behaviour has been described with this parameters:- Ship speed (linear function of the lever position lp).- Compressor degradation coefficient kMc.- Turbine degradation coefficient kMt.so that each possible degradation state can be described by a combination of this triple (lp,kMt,kMc).The range of decay of compressor and turbine has been sampled with an uniform grid of precision 0.001 so to have a good granularity of representation.In particular for the compressor decay state discretization the kMc coefficient has been investigated in the domain [1; 0.95], and the turbine coefficient in the domain [1; 0.975].Ship speed has been investigated sampling the range of feasible speed from 3 knots to 27 knots with a granularity of representation equal to tree knots.A series of measures (16 features) which indirectly represents of the state of the system subject to performance decay has been acquired and stored in the dataset over the parameter's space.Check the README.txt file for further details about this dataset.","- A 16-feature vector containing the GT measures at steady state of the physical asset:    Lever position (lp) [ ]    Ship speed (v) [knots]    Gas Turbine (GT) shaft torque (GTT) [kN m]    GT rate of revolutions (GTn) [rpm]    Gas Generator rate of revolutions (GGn) [rpm]    Starboard Propeller Torque (Ts) [kN]    Port Propeller Torque (Tp) [kN]    Hight Pressure (HP) Turbine exit temperature (T48) [C]    GT Compressor inlet air temperature (T1) [C]    GT Compressor outlet air temperature (T2) [C]    HP Turbine exit pressure (P48) [bar]    GT Compressor inlet air pressure (P1) [bar]    GT Compressor outlet air pressure (P2) [bar]    GT exhaust gas pressure (Pexh) [bar]    Turbine Injecton Control (TIC) [%]    Fuel flow (mf) [kg/s]- GT Compressor decay state coefficient- GT Turbine decay state coefficient","[2] M. Altosole, G. Benvenuto, M. Figari, U. Campora, Real-time simulation of a cogag naval ship propulsion system, Proceedings of the Institution of Mechanical Engineers, Part M: Journal of Engineering for the Maritime Environment 223 (1) (2009) 47-62.","[1] A. Coraddu, L. Oneto, A. Ghio, S. Savio, D. Anguita, M. Figari, Machine Learning Approaches for Improving Condition?Based Maintenance of Naval Propulsion Plants, Journal of Engineering for the Maritime Environment, 2014, DOI: 10.1177/1475090214540874, (In Press) @article{Coraddu2013Machine,    author={Coraddu, Andrea and Oneto, Luca and Ghio, Alessandro and                  Savio, Stefano and Anguita, Davide and Figari, Massimo},    title={Machine Learning Approaches for Improving Condition?Based Maintenance of Naval Propulsion Plants},    journal={Journal of Engineering for the Maritime Environment},    volume={--},    number={--},    pages={--},    year={2014}}",
http://archive.ics.uci.edu/ml/datasets/Quadruped+Mammals,29,Quadruped Mammals Data Set,../machine-learning-databases/quadrapeds/,"Multivariate, Data-Generator",N/A,Life,Real,72,8/25/1992,Classification,No,66719,"Origin: Gennari, J.~H., Langley, P, \& Fisher, D. (1989). Models of incremental concept formation. {\it Artificial Intelligence\/}, {\it 40\/}, 11--61. Donor:  John H. Gennari (gennari '@' camis.stanford.edu 8/1992)","The file animals.c is a data generator of structured instances representing quadruped animals as used by Gennari, Langley, and Fisher (1989) to evaluate the CLASSIT unsupervised learning algorithm. Instances have 8 components: neck, four legs, torso, head, and tail.  Each component is represented as a simplified/generalized cylinder (i.e., inspired by David Marr's work in ""Vision: A Computational Investigation Into the Human Representation  and Processing of Visual Information"", published by Freeman in 1982). Each cylinder is itself described by 9 attributes: location x 3, axis x 3, height, radius, and texture.  This code generates instances in one of four classes: dogs, cats, horses, and giraffes.  The program generates instances by selecting a class according to a distribution determined by function rand4().  Each class has a prototype; the prototype of the selected class is perturbed according to a distribution described in the code for the four classes (i.e., parameterized means with Guassian distributions are used to represent prototypes and perturbation distributions, where the means are used to distinguish the four classes). From John Gennari: (1990) The only notes I have about it is that I don't use the data format it creates any more. To change this, modify ""printpart()"". Also, it uses a very rough approximation for a bell-shaped distribution. Currently, I use a much more sophisticated random number generator. To fix this, just replace ""bellrand()"" with a real bell shaped distribution.","     A. Eight components per instances/animal:        1. Head        2. Tail        3. 4 legs        4. torso        5. neck        B. Nine attributes per component:        1. Location 1        2. Location 2	3. Location 3	4. Axis 1	5. Axis 2	6. Axis 3	7. Height	8. Radius	9. Texture",N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Air+quality,30,Air Quality Data Set,../machine-learning-databases/00360/,"Multivariate, Time-Series",9358,Computer,Real,15,3/23/2016,Regression,Yes,437733,"Saverio De Vito (saverio.devito '@' enea.it), ENEA - National Agency for New Technologies, Energy and Sustainable Economic Development","The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.This dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.","0 Date	(DD/MM/YYYY)1 Time	(HH.MM.SS)2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)	4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)	7 True hourly averaged NOx concentration  in ppb (reference analyzer)8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) 9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)	10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)	11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)12 Temperature in Â°C	13 Relative Humidity (%) 	14 AH Absolute Humidity","S. De Vito, E. Massera, M. Piga, L. Martinotto, G. Di Francia, On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario, Sensors and Actuators B: Chemical, Volume 129, Issue 2, 22 February 2008, Pages 750-757, ISSN 0925-4005, [Web Link].([Web Link]) Saverio De Vito, Marco Piga, Luca Martinotto, Girolamo Di Francia, CO, NO2 and NOx urban pollution monitoring with on-field calibrated electronic nose by automatic bayesian regularization, Sensors and Actuators B: Chemical, Volume 143, Issue 1, 4 December 2009, Pages 182-191, ISSN 0925-4005, [Web Link].([Web Link]) S. De Vito, G. Fattoruso, M. Pardo, F. Tortorella and G. Di Francia, 'Semi-Supervised Learning Techniques in Artificial Olfaction: A Novel Approach to Classification Problems and Drift Counteraction,' in IEEE Sensors Journal, vol. 12, no. 11, pp. 3215-3224, Nov. 2012.doi: 10.1109/JSEN.2012.2192425","S. De Vito, E. Massera, M. Piga, L. Martinotto, G. Di Francia, On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario, Sensors and Actuators B: Chemical, Volume 129, Issue 2, 22 February 2008, Pages 750-757, ISSN 0925-4005, [Web Link].([Web Link])",
http://archive.ics.uci.edu/ml/datasets/Spoken+Arabic+Digit,31,Spoken Arabic Digit Data Set,../machine-learning-databases/00195/,"Multivariate, Time-Series",8800,N/A,Real,13,9/13/2010,Classification,No,77922,"Data Collected by the Laboratory of Automatic and Signals,University of Badji-MokhtarAnnaba, Algeria. Direction: Prof.Mouldi BeddaParticipants: H.Dahmani, C.Snani, MC.Amara Korba, S.AtouiAdapted and preprocessed by :                        Nacereddine Hammami and Mouldi Bedda                          Faculty of Engineering,                          Al-Jouf UniversitySakaka, Al-JoufKingdom of Saudi Arabia                          e-mail: nacereddine.hammami '@' gmail.com mouldi_bedda '@' yahoo.fr Date: October, 2008","Dataset from 8800(10 digits x 10 repetitions x 88 speakers) time series of 13 Frequency CepstralCoefficients (MFCCs) had taken from 44 males and 44 females Arabic native speakersbetween the ages 18 and 40 to represent ten spoken Arabic digit.","Each line on the data base represents 13 MFCCs coefficients in the increasing order separated byspaces. This corresponds to one analysis frame. The 13 Mel Frequency Cepstral Coefficients(MFCCs) are computed with the followingconditions;Sampling rate: 11025 Hz, 16 bitsWindow applied: hammingFilter pre-emphasized: 1-0.97Z^(-1)","[1] N. Hammami, M. Bedda ,""Improved Tree model for Arabic Speech Recognition"", Proc. IEEEICCSIT10 Conference, 2010.[2] N. Hammami, M. Sellami ,""Tree distribution classifier for automatic spoken Arabic digitrecognition"", Proc. IEEE ICITST09 Conference, 2009 , PP 1-4.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Image+Segmentation,32,Image Segmentation Data Set,../machine-learning-databases/image/,Multivariate,2310,N/A,Real,19,11/1/1990,Classification,No,198808,"Creators:  Vision Group, University of Massachusetts Donor:  Vision Group (Carla Brodley, brodley '@' cs.umass.edu)","The instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.      Each instance is a 3x3 region.","    1.  region-centroid-col:  the column of the center pixel of the region.    2.  region-centroid-row:  the row of the center pixel of the region.    3.  region-pixel-count:  the number of pixels in a region = 9.    4.  short-line-density-5:  the results of a line extractoin algorithm that counts how many lines of length 5 (any orientation) with low contrast, less than or equal to 5, go through the region.    5.  short-line-density-2:  same as short-line-density-5 but counts lines of high contrast, greater than 5.    6.  vedge-mean:  measure the contrast of horizontally adjacent pixels in the region.  There are 6, the mean and standard deviation are given.  This attribute is used as a vertical edge detector.    7.  vegde-sd:  (see 6)    8.  hedge-mean:  measures the contrast of vertically adjacent pixels. Used for horizontal line detection.     9.  hedge-sd: (see 8).    10. intensity-mean:  the average over the region of (R + G + B)/3    11. rawred-mean: the average over the region of the R value.    12. rawblue-mean: the average over the region of the B value.    13. rawgreen-mean: the average over the region of the G value.    14. exred-mean: measure the excess red:  (2R - (G + B))    15. exblue-mean: measure the excess blue:  (2B - (G + R))    16. exgreen-mean: measure the excess green:  (2G - (R + B))    17. value-mean:  3-d nonlinear transformation of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals of Interactive Computer Graphics)    18. saturatoin-mean:  (see 17)    19. hue-mean:  (see 17)",N/A,"Please refer to the Machine Learning
Repository's citation policy","Anthony K H Tung and Xin Xu and Beng Chin Ooi. CURLER: Finding and Visualizing Nonlinear Correlated Clusters. SIGMOD Conference. 2005.  [View Context].Xiaoli Z. Fern and Carla Brodley. Cluster Ensembles for High Dimensional Clustering: An Empirical Study. Journal of Machine Learning Research n, a. 2004.  [View Context].Aristidis Likas and Nikos A. Vlassis and Jakob J. Verbeek. The global k-means clustering algorithm. Pattern Recognition, 36. 2003.  [View Context].Manoranjan Dash and Huan Liu and Peter Scheuermann and Kian-Lee Tan. Fast hierarchical clustering and its validation. Data Knowl. Eng, 44. 2003.  [View Context].Amund Tveit. Empirical Comparison of Accuracy and Performance for the MIPSVM classifier with Existing Classifiers. Division of Intelligent Systems Department of Computer and Information Science, Norwegian University of Science and Technology.  [View Context].Je Scott and Mahesan Niranjan and Richard W. Prager. Realisable Classifiers: Improving Operating Performance on Variable Cost Problems. Cambridge University Department of Engineering.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].K. A. J Doherty and Rolf Adams and Neil Davey. Unsupervised Learning with Normalised Data and Non-Euclidean Norms. University of Hertfordshire.  [View Context].Adil M. Bagirov and John Yearwood. A new nonsmooth optimization algorithm for clustering. Centre for Informatics and Applied Optimization, School of Information Technology and Mathematical Sciences, University of Ballarat.  [View Context].K. A. J Doherty and Rolf Adams and Neil Davey. Non-Euclidean Norms and Data Normalisation. Department of Computer Science, University of Hertfordshire, College Lane.  [View Context].Michael Lindenbaum and Shaul Markovitch and Dmitry Rusakov. Selective Sampling Using Random Field Modelling.  [View Context].James Tin and Yau Kwok. Moderating the Outputs of Support Vector Machine Classifiers. Department of Computer Science Hong Kong Baptist University Hong Kong.  [View Context].Thomas T. Osugi and M. S. EXPLORATION-BASED ACTIVE MACHINE LEARNING. Faculty of The Graduate College at the University of Nebraska In Partial Fulfillment of Requirements.  [View Context].Nikos A. Vlassis and Aristidis Likas. A greedy EM algorithm for Gaussian mixture. Intelligent Autonomous Systems, IAS.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29,33,Breast Cancer Wisconsin (Diagnostic) Data Set,../machine-learning-databases/breast-cancer-wisconsin/,Multivariate,569,Life,Real,32,11/1/1995,Classification,No,1292735,"Creators:  1. Dr. William H. Wolberg, General Surgery Dept. University of Wisconsin,  Clinical Sciences Center Madison, WI 53792wolberg '@' eagle.surgery.wisc.edu  2. W. Nick Street, Computer Sciences Dept. University of Wisconsin, 1210 West Dayton St., Madison, WI 53706street '@' cs.wisc.edu  608-262-6619 3. Olvi L. Mangasarian, Computer Sciences Dept. University of Wisconsin, 1210 West Dayton St., Madison, WI 53706olvi '@' cs.wisc.edu  Donor:  Nick Street","Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]  Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree Construction Via Linear Programming."" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34]. This database is also available through the UW CS ftp server:ftp ftp.cs.wisc.educd math-prog/cpo-dataset/machine-learn/WDBC/","1) ID number2) Diagnosis (M = malignant, B = benign)3-32) Ten real-valued features are computed for each cell nucleus: 	a) radius (mean of distances from center to points on the perimeter)	b) texture (standard deviation of gray-scale values)	c) perimeter	d) area	e) smoothness (local variation in radius lengths)	f) compactness (perimeter^2 / area - 1.0)	g) concavity (severity of concave portions of the contour)	h) concave points (number of concave portions of the contour)	i) symmetry 	j) fractal dimension (""coastline approximation"" - 1)","First Usage: W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.[Web Link]  O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.[Web Link]  Medical literature: W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates.  Cancer Letters 77 (1994) 163-171.[Web Link]  W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Image analysis and machine learning applied to breast cancer diagnosis and prognosis.  Analytical and Quantitative Cytology and Histology, Vol. 17 No. 2, pages 77-87, April 1995.  W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. Computerized breast cancer diagnosis and prognosis from fine needle aspirates.  Archives of Surgery 1995;130:511-516.[Web Link]  W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. Computer-derived nuclear features distinguish malignant from benign breast cytology.  Human Pathology, 26:792--796, 1995.[Web Link]  See also: [Web Link] [Web Link]","Please refer to the Machine Learning
Repository's citation policy","Gavin Brown. Diversity in Neural Network Ensembles. The University of Birmingham. 2004.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. Heterogeneous Forests of Decision Trees. ICANN. 2002.  [View Context].András Antos and Balázs Kégl and Tamás Linder and Gábor Lugosi. Data-dependent margin-based generalization bounds for classification. Journal of Machine Learning Research, 3. 2002.  [View Context].Kristin P. Bennett and Ayhan Demiriz and Richard Maclin. Exploiting unlabeled data in ensemble methods. KDD. 2002.  [View Context].Hussein A. Abbass. An evolutionary artificial neural networks approach for breast cancer diagnosis. Artificial Intelligence in Medicine, 25. 2002.  [View Context].Baback Moghaddam and Gregory Shakhnarovich. Boosted Dyadic Kernel Discriminants. NIPS. 2002.  [View Context].Robert Burbidge and Matthew Trotter and Bernard F. Buxton and Sean B. Holden. STAR - Sparsity through Automated Rejection. IWANN (1). 2001.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. An Implementation of Logical Analysis of Data. IEEE Trans. Knowl. Data Eng, 12. 2000.  [View Context].Yuh-Jeng Lee. Smooth Support Vector Machines. Preliminary Thesis Proposal Computer Sciences Department University of Wisconsin. 2000.  [View Context].Justin Bradley and Kristin P. Bennett and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Improved Generalization Through Explicit Optimization of Margins. Machine Learning, 38. 2000.  [View Context].P. S and Bradley K. P and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining. Institute of Information Science. 1999.  [View Context].Huan Liu and Hiroshi Motoda and Manoranjan Dash. A Monotonic Measure for Optimal Feature Selection. ECML. 1998.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Direct Optimization of Margins Improves Generalization in Combined Classifiers. NIPS. 1998.  [View Context].W. Nick Street. A Neural Network Model for Prognostic Prediction. ICML. 1998.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. A Parametric Optimization Method for Machine Learning. INFORMS Journal on Computing, 9. 1997.  [View Context].Rudy Setiono and Huan Liu. NeuroLinear: From neural networks to oblique decision rules. Neurocomputing, 17. 1997.  [View Context].Erin J. Bredensteiner and Kristin P. Bennett. Feature Minimization within Decision Trees. National Science Foundation. 1996.  [View Context].Ismail Taha and Joydeep Ghosh. Characterization of the Wisconsin Breast cancer Database Using a Hybrid Symbolic-Connectionist System. Proceedings of ANNIE. 1996.  [View Context].Jennifer A. Blue and Kristin P. Bennett. Hybrid Extreme Point Tabu Search. Department of Mathematical Sciences Rensselaer Polytechnic Institute. 1996.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. An Ant Colony Based System for Data Mining: Applications to Medical Data. CEFET-PR, CPGEI Av. Sete de Setembro, 3165.  [View Context].Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. Statistical methods for construction of neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery. CEFET-PR, Curitiba.  [View Context].Adam H. Cannon and Lenore J. Cowen and Carey E. Priebe. Approximate Distance Classification. Department of Mathematical Sciences The Johns Hopkins University.  [View Context].Andrew I. Schein and Lyle H. Ungar. A-Optimality for Active Learning of Logistic Regression Classifiers. Department of Computer and Information Science Levine Hall.  [View Context].Bart Baesens and Stijn Viaene and Tony Van Gestel and J. A. K Suykens and Guido Dedene and Bart De Moor and Jan Vanthienen and Katholieke Universiteit Leuven. An Empirical Assessment of Kernel Type Performance for Least Squares Support Vector Machine Classifiers. Dept. Applied Economic Sciences.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Rudy Setiono and Huan Liu. Neural-Network Feature Selector. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Huan Liu. A Family of Efficient Rule Generators. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Rudy Setiono. Extracting M-of-N Rules from Trained Neural Networks. School of Computing National University of Singapore.  [View Context].Jarkko Salojarvi and Samuel Kaski and Janne Sinkkonen. Discriminative clustering in Fisher metrics. Neural Networks Research Centre Helsinki University of Technology.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. A hybrid method for extraction of logical rules from data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope,34,MAGIC Gamma Telescope Data Set,../machine-learning-databases/magic/,Multivariate,19020,Physical,Real,11,5/1/2007,Classification,No,115046,"Original Owner: R. K. BockMajor Atmospheric Gamma Imaging Cherenkov Telescope project (MAGIC)http://wwwmagic.mppmu.mpg.de rkb '@' mail.cern.ch  Donor: P. SavickyInstitute of Computer Science, AS of CRCzech Republicsavicky '@' cs.cas.cz ","The data are MC generated (see below) to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. Cherenkov gamma telescope observes high energy gamma rays, taking advantage of the radiation emitted by charged particles produced inside the electromagnetic showers initiated by the gammas, and developing in the atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks through the atmosphere and gets recorded in the detector, allowing reconstruction of the shower parameters. The available information consists of pulses left by the incoming Cherenkov photons on the photomultiplier tubes, arranged in a plane, the camera. Depending on the energy of the primary gamma, a total of few hundreds to some 10000 Cherenkov photons get collected, in patterns (called the shower image), allowing to discriminate statistically those caused by primary gammas (signal) from the images of hadronic showers initiated by cosmic rays in the upper atmosphere (background). Typically, the image of a shower after some pre-processing is an elongated cluster. Its long axis is oriented towards the camera center if the shower axis is parallel to the telescope's optical axis, i.e. if the telescope axis is directed towards a point source. A principal component analysis is performed in the camera plane, which results in a correlation axis and defines an ellipse. If the depositions were distributed as a bivariate Gaussian, this would be an equidensity ellipse. The characteristic parameters of this ellipse (often called Hillas parameters) are among the image parameters that can be used for discrimination. The energy depositions are typically asymmetric along the major axis, and this asymmetry can also be used in discrimination. There are, in addition, further discriminating characteristics, like the extent of the cluster in the image plane, or the total sum of depositions. The data set was generated by a Monte Carlo program, Corsika, described in:    D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers,    Forschungszentrum Karlsruhe FZKA 6019 (1998).[Web Link]  The program was run with parameters allowing to observe events with energies down to below 50 GeV.","    1.  fLength:  continuous  # major axis of ellipse [mm]    2.  fWidth:   continuous  # minor axis of ellipse [mm]     3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]    4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]    5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]    6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]    7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm]     8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]    9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]   10.  fDist:    continuous  # distance from origin to center of ellipse [mm]   11.  class:    g,h         # gamma (signal), hadron (background)    g = gamma (signal):     12332   h = hadron (background): 6688    For technical reasons, the number of h events is underestimated. In the real data, the h class represents the majority of the events.    The simple classification accuracy is not meaningful for this data, since classifying a background event as signal is worse than classifying a signal event as background. For comparison of different classifiers an ROC curve has to be used. The relevant points on this curve are those, where the probability of accepting a background event as signal is below one of the following thresholds: 0.01, 0.02, 0.05, 0.1, 0.2 depending on the required quality of the sample of the accepted events for different experiments.","Bock, R.K., Chilingarian, A., Gaug, M., Hakl, F., Hengstebeck, T., Jirina, M., Klaschka, J., Kotrc, E., Savicky, P., Towers, S., Vaicilius, A., Wittek W. (2004).Methods for multidimensional event classification: a case study using images from a Cherenkov gamma-ray telescope.Nucl.Instr.Meth. A, 516, pp. 511-528. P. Savicky, E. Kotrc.Experimental Study of Leaf Confidences for Random Forest.Proceedings of COMPSTAT 2004, In: Computational Statistics. (Ed.: Antoch J.) - Heidelberg, Physica Verlag 2004, pp. 1767-1774. J. Dvorak, P. Savicky.Softening Splits in Decision Trees Using Simulated Annealing.Proceedings of ICANNGA 2007, Warsaw, (Ed.: Beliczynski et. al), Part I, LNCS 4431, pp. 721-729.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Teaching+Assistant+Evaluation,35,Teaching Assistant Evaluation Data Set,../machine-learning-databases/tae/,Multivariate,151,N/A,"Categorical, Integer",5,6/7/1997,Classification,No,161779,"Collector:  Wei-Yin Loh (Department of Statistics, UW-Madison) Donor: Tjen-Sien Lim (limt '@' stat.wisc.edu)","The data consist of evaluations of teaching performance over three regular semesters and two summer semesters of 151 teaching assistant (TA) assignments at the Statistics Department of the University of Wisconsin-Madison. The scores were divided into 3 roughly equal-sized categories (""low"", ""medium"", and ""high"") to form the class variable.","   1. Whether of not the TA is a native English speaker (binary); 1=English speaker, 2=non-English speaker   2. Course instructor (categorical, 25 categories)   3. Course (categorical, 26 categories)   4. Summer or regular semester (binary) 1=Summer, 2=Regular   5. Class size (numerical)   6. Class attribute (categorical) 1=Low, 2=Medium, 3=High","Loh, W.-Y. & Shih, Y.-S. (1997). Split Selection Methods for  Classification Trees, Statistica Sinica 7: 815-840.[Web Link]  Lim, T.-S., Loh, W.-Y. & Shih, Y.-S. (1999). A Comparison of Prediction Accuracy, Complexity, and Training Time of Thirty-three Old and New Classification Algorithms. Machine Learning. ([Web Link] or [Web Link])[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Skin+Segmentation,36,Skin Segmentation Data Set,../machine-learning-databases/00229/,Univariate,245057,Computer,Real,4,7/17/2012,Classification,N/A,203490,"Rajen Bhatt, Abhinav Dhall, rajen.bhatt '@' gmail.com, IIT Delhi.","The skin dataset is collected by randomly sampling B,G,R values from face images of various age groups (young, middle, and old), race groups (white, black, and asian), and genders obtained from FERET database and PAL database. Total learning sample size is 245057; out of which 50859 is the skin samples and 194198 is non-skin samples. Color FERET Image Database: [Web Link], PAL Face Database from Productive Aging Laboratory, The University of Texas at Dallas: [Web Link].   ","This dataset is of the dimension 245057 * 4 where first three columns are B,G,R (x1,x2, and x3 features) values and fourth column is of the class labels (decision variable y). ","1. Rajen B. Bhatt, Gaurav Sharma, Abhinav Dhall, Santanu Chaudhury, â€œEfficient skin region segmentation using low complexity fuzzy decision tree modelâ€, IEEE-INDICON 2009, Dec 16-18, Ahmedabad, India, pp. 1-4.2. Abhinav Dhall, Gaurav Sharma, Rajen Bhatt, Ghulam Mohiuddin Khan, â€œAdaptive Digital Makeupâ€, in Proc. of International Symposium on Visual Computing (ISVC) 2009, Nov. 30 â€“ Dec. 02, Las Vegas, Nevada, USA, Lecture Notes in Computer Science, Vol. 5876, pp. 728-736. ","Rajen Bhatt, Abhinav Dhall, 'Skin Segmentation Dataset', UCI Machine Learning Repository",
http://archive.ics.uci.edu/ml/datasets/Australian+Sign+Language+signs,37,Australian Sign Language signs Data Set,../machine-learning-databases/auslan-mld/,"Multivariate, Time-Series",6650,N/A,"Categorical, Real",15,4/20/1999,Classification,N/A,100030,"Original Owner and Donor: Mohammed Waleed KadousSchool of Computer Science of EngineeringUniversity of New South WalesSydney NSW 2052 Australiawaleed '@' cse.unsw.edu.au ","The source of the data is the raw measurements from a Nintendo PowerGlove. It was interfaced through a PowerGlove Serial Interface to a Silicon Graphics 4D/35G workstation.  This glove definitely falls into the category of ""cheap and nasty"". Position information is calculated on the basis of ultrasound emissions from emitters the glove to a 3-microphone ""L-Bar"" that sits atop a monitor. There are two emitters on the glove; and three receivers. This allows the calculation of 4 pieces of information: x (left/right), y (up/down), z (backward/forward), and roll (is the palm pointing up or down?). x, y and z are measured with 8 bit accuracy. ""x, y, z"" should not be taken to be the normal 3-dimensional orthogonal basis. In particular, 1 unit in the z direction is not of similar distance to 1 unit in the x or y directions. These x, y, z positions are relative to a calibration point which is when the palm is resting on the seated signer's thigh. Roll is 4 bits.  The data is susceptible to occasional ""spikes"" caused by random ultrasound noise. Median filters have been found to be beneficial in solving this problem.  Finger bend is generated by conductive bend sensors on the first four fingers. Values vary between 0 (straight) and 3 (fully bent). Accuracy is 2 bits. The gloves automatically apply a hysteresis filter on these bend sensors. At best, these measurements should be treated sceptically.  See past usage for a more detailed discussion on the data collection methodology.  The data was collected from five signers:  Signer -- Description -- Sessions -- Total samples/sign  Adam -- Sign linguist - PhD completed in area. -- 2 -- 8 Andrew -- Natural signer - signing since youth -- 3 -- 8 John -- Professional Auslan interpreter -- 5 -- 18 Stephen -- Professional Auslan interpreter -- 4  -- 16 Waleed -- The researcher. Novice signer -- 4 -- 20 Each session was taken at a different time, after a break, etc.  The ""adam"" dataset were sampled in a fixed order -- this means that they are subject to fatigue effects, etc. All other datasets were sampled in random order. The ""waleed"" and ""stephen"" datasets contain signs that begin with ""cal-"". These were considered as a means of calibration, but didn't work out too well.  The data presented is the raw data with no filtering.  Occasional dropouts in x, y, z values. These can be easily fixed using a median filter.  Average number of frames per instance is 51, but varies from 30 to 102.  The data is in a comma separated file containing all of the attributes mentioned above. Each sign sample is stored in a single file. The directory hierarchy is as follows: -Each signer is in a separate directory. -Each session from signer is in a subdirectory. Each session is denoted by a number. -Each sample is in a file named by the sample appended with the number of the sample of that sign.  The filenames indicate the class. ","x:  - Continuous.   - Description: x position between -1 and 1. Units are *approximately* metres. y:   - Continuous.   - Description: y position between -1 and 1. Units are approximately metres. z:   - Continuous.   - Description: z position between -1 and 1. Units are not metres.      This space should not really be treated as linear, although it is safe to     treat it as monotonically increasing. roll:        - Continuous.  - Description:  roll with 0 meaning ""palm down"", rotating clcokwise through to a maximum of 1 (not included), which is also ""palm down"".pitch:    - Has a value of -1, indicating that it is not available for this data.    Should be ignored. yaw:    - Has a value of -1, indicating that it is not available for this data.     Should be ignored. thumb:    - Continuous.    - Description: Thumb bend. has a value of 0 (straight) to 1 (fully bent). fore:   - Continuous.    - Description: Forefinger bend. has a value of 0 (straight) to 1 (fully bent). index:   - Continuous.    - Description: Index finger bend. has a value of 0 (straight) to 1 (fully bent). ring:    - Continuous.    - Description: Ring finger bend. has a value of 0 (straight) to 1 (fully bent). little:         - In this case, it is a copy of ring bend. Should be ignored. keycode:    - Indicates which key was pressed on the glove. Should be ignored. gs1:         - glove state 1 Should be ignored. gs2:         - glove state 2 should be ignored. Receiver values:   - Determines if all receivers received values from all transmitters. A value of 0x3F indicates all receivers received information from all transmitters. Other values indicate this is not the case.","M. W. Kadous, GRASP: Recognition of Australian Sign Language using Instrumented Gloves, Honours thesis, School of Computer Science and Engineering, University of New South Wales, 1995. [Web Link]","The data may be used provided that: -The source of the data ([Web Link]) is acknowledged. -If you publish any work using the dataset, please inform the donor. -Use for commercial purposes requires donor permission. ",Mohammed Waleed Kadous and Claude Sammut. The University of New South Wales School of Computer Science and Engineering Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Mobile+Robots,38,Mobile Robots Data Set,../machine-learning-databases/mobile-robots/,Domain-Theory,N/A,Computer,"Categorical, Integer, Real",N/A,7/15/1995,N/A,N/A,73865,"Donors: Volker Klingspor, Katharina J. Morik, Anke D. RiegerComputer Science Dept. LS VIIIUniversity of Dortmund, Germany ",Please view the associated .names file,"   Tr (Trace)           (integer)   T (Time)             (integer)   S (Sensor)           (integer 0-23)   Or (Orientation)     (real 0-360)   Sa (S-Orientation)   (real 0-360)   Gr (Gradient)        (real)   Dist (Distance)      (real)   Sx,Sy   (Sensor-coordinates) (real)   Obj (Object)         (integer)   E (Edge)             (integer)   S_C (Sensorclass)    (set of front_side,right_side,back_side,left_side ...)   Mv (Movement)        (set of parallel, diagonal)   MD (MoveDirection)   (set of forward, backward, right, left)   PD (PerceptionDir.)  (set of front, rear, right, left)   Perc (perceptual features)","Volker Klingspor, Katharina Morik, Anke Rieger. Learning Concepts from Sensor Data of a Mobile Robot. Machine Learning Journal, 1995.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Mohammed Waleed Kadous. Expanding the Scope of Concept Learning Using Metafeatures. School of Computer Science and Engineering, University of New South Wales.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Mammographic+Mass,39,Mammographic Mass Data Set,../machine-learning-databases/mammographic-masses/,Multivariate,961,Life,Integer,6,10/29/2007,Classification,Yes,172853,"Matthias ElterFraunhofer Institute for Integrated Circuits (IIS)Image Processing and Medical Engineering Department (BMT) Am Wolfsmantel 3391058 Erlangen, Germanymatthias.elter '@' iis.fraunhofer.de (49) 9131-7767327  Prof. Dr. Rüdiger Schulz-WendtlandInstitute of Radiology, Gynaecological Radiology, University Erlangen-NurembergUniversitätsstraße 21-2391054 Erlangen, Germany","Mammography is the most effective method for breast cancer screeningavailable today. However, the low positive predictive value of breastbiopsy resulting from mammogram interpretation leads to approximately70% unnecessary biopsies with benign outcomes. To reduce the highnumber of unnecessary breast biopsies, several computer-aided diagnosis(CAD) systems have been proposed in the last years.These systemshelp physicians in their decision to perform a breast biopsy on a suspiciouslesion seen in a mammogram or to perform a short term follow-upexamination instead.This data set can be used to predict the severity (benign or malignant)of a mammographic mass lesion from BI-RADS attributes and the patient's age.It contains a BI-RADS assessment, the patient's age and three BI-RADS attributestogether with the ground truth (the severity field) for 516 benign and445 malignant masses that have been identified on full field digital mammogramscollected at the Institute of Radiology of theUniversity Erlangen-Nuremberg between 2003 and 2006.Each instance has an associated BI-RADS assessment ranging from 1 (definitely benign)to 5 (highly suggestive of malignancy) assigned in a double-review process byphysicians. Assuming that all cases with BI-RADS assessments greater or equala given value (varying from 1 to 5), are malignant and the other cases benign,sensitivities and associated specificities can be calculated. These can be anindication of how well a CAD system performs compared to the radiologists. Class Distribution: benign: 516; malignant: 445","6 Attributes in total (1 goal field, 1 non-predictive, 4 predictive attributes) 1. BI-RADS assessment: 1 to 5 (ordinal, non-predictive!)  2. Age: patient's age in years (integer)3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)6. Severity: benign=0 or malignant=1 (binominal, goal field!)  Missing Attribute Values:    - BI-RADS assessment:    2    - Age:                   5    - Shape:                31    - Margin:               48    - Density:              76    - Severity:              0","M. Elter, R. Schulz-Wendtland and T. Wittenberg (2007)The prediction of breast cancer biopsy outcomes using two CAD approaches that both emphasize an intelligible decision process.Medical Physics 34(11), pp. 4164-4172","M. Elter, R. Schulz-Wendtland and T. Wittenberg (2007)The prediction of breast cancer biopsy outcomes using two CAD approaches that both emphasize an intelligible decision process.Medical Physics 34(11), pp. 4164-4172",
http://archive.ics.uci.edu/ml/datasets/WESAD+%28Wearable+Stress+and+Affect+Detection%29,40,WESAD (Wearable Stress and Affect Detection) Data Set,../machine-learning-databases/00465/,"Multivariate, Time-Series",63000000,Computer,Real,12,9/14/2018,"Classification, Regression",N/A,37700,"Philip Schmidt, Robert Bosch GmbH, Corporate Research, Germany, firstname.lastname '@' de.bosch.com Attila Reiss, Robert Bosch GmbH, Corporate Research, Germany, firstname.lastname '@' de.bosch.com","WESAD is a publicly available dataset for wearable stress and affect detection. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects during a lab study. The following sensor modalities are included: blood volume pulse, electrocardiogram, electrodermal activity, electromyogram, respiration, body temperature, and three-axis acceleration. Moreover, the dataset bridges the gap between previous lab studies on stress and emotions, by containing three different affective states (neutral, stress, amusement). In addition, self-reports of the subjects, which were obtained using several established questionnaires, are contained in the dataset. Details can be found in the dataset's readme-file, as well as in [1].","Raw sensor data was recorded with two devices: a chest-worn device (RespiBAN) and a wrist-worn device (Empatica E4).The RespiBAN device provides the following sensor data: electrocardiogram (ECG), electrodermal activity (EDA), electromyogram (EMG), respiration, body temperature, and three-axis acceleration. All signals are sampled at 700 Hz.The Empatica E4 device provides the following sensor data: blood volume pulse (BVP, 64 Hz), electrodermal activity (EDA, 4 Hz), body temperature (4 Hz), and three-axis acceleration (32 Hz). The dataset's readme-file contains all further details with respect to the dataset structure, data format (RespiBAN device, Empatica E4 device, synchronised data), study protocol, and the self-report questionnaires.","[1] Philip Schmidt, Attila Reiss, Robert Duerichen, Claus Marberger and Kristof Van Laerhoven. 2018. Introducing WESAD, a multimodal dataset for Wearable Stress and Affect Detection. In 2018 International Conference on Multimodal Interaction (ICMI â€™18), October 16â€“20, 2018, Boulder, CO, USA. ACM, New York, NY, USA, 9 pages. [Web Link]","You may use this data for scientific, non-commercial purposes, provided that you give credit to the owners when publishing any work based on this data. Please acknowledge publication [1].We recommend to refer to this dataset as WESAD, or 'Wearable Stress and Affect Detection'.",
http://archive.ics.uci.edu/ml/datasets/KEGG+Metabolic+Relation+Network+%28Directed%29,41,KEGG Metabolic Relation Network (Directed) Data Set,../machine-learning-databases/00220/,"Multivariate, Univariate, Text",53414,Life,"Integer, Real",24,11/28/2011,"Classification, Regression, Clustering",N/A,56566,"1. Muhammad Naeem, Centre of Research in Data Engineering(CORDE) & Department of Computer Science, MAJU Islamabad Pakistan,	(naeems.naeem '@' gmail.com).2. Sohail Asghar, Director/Associate Professor University Institute of IT PMAS-Arid Agriculture University, Rawalpindi, Pakistan Centre of Research in Data Engineering (CORDE), (sohail.asghar '@' gmail.com)","KEGG Metabolic pathways can be realized into network. Two kinds of network / graph can be formed. These include Reaction Network and Relation Network. In Reaction network, Substrate or Product compound are considered as Node and genes are treated as edge. Whereas in the relation network, Substrate and Product componds are considered as Edges while enzyme and genes are placed as nodes. We tool large number of metabolic pathways from KEGG XML. They were modeled into the graph as described above. With the help of Cytoscape tool, variety of network features were compunted. ","a)	Pathway	textb)	Nodes 	integer (min:2, max:116)c)	Edges		integer (min:1, max:606)d)	Connected Components	integer (min:1, max:13)e)	Network Diameter		integer (min:1, max:30)f)	Network Radius	integer (min:1, max:2)g)	Shortest Path	integer (min:1, max:3277)h)	Characteristic Path Length	real (min:1, [Web Link])i)	Avg.num.Neighbours	real (min:1, [Web Link])j)	Isolated Nodes	integer (min:0, max:1)k)	Number of Self Loops	integer (min:0, max:0)l)	Multi-edge Node Pair	integer (min:0, max:57)m)	NeighborhoodConnectivity	real (min:1, [Web Link])n)	Outdegree	real (min:0.5, [Web Link])o)	Stress	real (min:0, [Web Link])p)	SelfLoops	integer (min:0, max:0)q)	PartnerOfMultiEdgedNodePairs	real (min:0, [Web Link])r)	EdgeCount	real (min:1, [Web Link])s)	BetweennessCentrality		real (min:0, [Web Link])t)	Indegree		real (min:0.5, [Web Link])u)	Eccentricity	real ([Web Link], [Web Link])v)	ClosenessCentrality	real ([Web Link], max:1)w)	AverageShortestPathLength	real ([Web Link], [Web Link])x)	ClusteringCoefficient		real (min:0, [Web Link])","Shannon,P., Markiel,A., Ozier,O., Baliga,N.S., Wang,J.T.,Ramage,D., Amin,N., Schwikowski,B. and	Ideker,T. (2003) Cytoscape: a software environment for integrated models of biomolecular interaction networks. Genome Res., 13, 2498â€“2504.","Naeem M,Asghar S, Centre of Research in Data Engineering Islamabad Pakistan, naeems.naeem '@' gmail.com, sohail.asg '@' gmail.com",
http://archive.ics.uci.edu/ml/datasets/PANDOR,42,PANDOR Data Set,../machine-learning-databases/00460/,Multivariate,N/A,Life,Categorical,N/A,10/2/2018,Recommendation,N/A,14453,"Massih-Reza AminiUniv. Grenoble Alpes, CNRS/LIGmassih-reza.amini '@' univ-grenoble-alpes.fr Charlotte LaclauUniv. Grenoble Alpes, CNRS/LIGcharlotte.laclau '@' univ-grenoble-alpes.fr Sumit SidanaUniv. Grenoble Alpes, CNRS/LIGsumit.sidana '@' imag.fr","source, offerId, pageViewId, offerViewId, utcDate, keywords, wasClicked, offerViewCountPerPageView, clickCountPerPageView, userId, productLemmas, productFeatures, url, pageLemmas, pageFeatures # Events: 48,602,664# Users: 5,894,431# Offers: 14,716# Clicks: 337,511# OffersShown: 48,754,927# Max offers shown to 1 user: 2,029# Max clicks done by 1 user: 119 Average # Offers Shown to 1 user: 8.271Average # Clicks done by 1 user: 0.057Average # Clicks done by 1 user (if user did at least 1 click): 1.350616661464461  # Events where user did at least 1 click: 4,544,848# Events which have at least 1 page text words: 1,212,170# Events which have at least 1 product Text words: 450,050# Events which have at least 1 keyword: 4,492,544 page text vocabulary size: 9,111product text vocabulary size: 6,016keyword vocabulary size: 543  Out of 9,847 offers, 2,701 offers have at least 1 text word (27.4%)Out of 7,092 pages, 1,990 pages have at least 1 text word (28.1%)  ",Provide information about each attribute in your data set.,"Sumit Sidana, Charlotte Laclau, Massih-Reza Amini. 'Learning to Recommend Diverse Items over Implicit Feedback on PANDOR',  RecSYS 2018.","If you publish results based on this data set, please acknowledge its use, by referring to:Sumit Sidana, Charlotte Laclau, Massih-Reza Amini. 'Learning to Recommend Diverse Items over Implicit Feedback on PANDOR',  RecSYS 2018.",
http://archive.ics.uci.edu/ml/datasets/US+Census+Data+%281990%29,43,US Census Data (1990) Data Set,../machine-learning-databases/census1990-mld/,Multivariate,2458285,Social,Categorical,68,N/A,Clustering,N/A,156644,"The USCensus1990raw data set was obtained from the (U.S. Department of Commerce) Census Bureau website using the Data Extraction System. This system can be found at http://dataferrett.census.gov/.  Donors: Chris Meek, Microsoft, meek '@' microsoft.com Bo Thiesson, Microsoft, thiesson '@' microsoft.com David Heckerman, Microsoft, heckerma '@' microsoft.com ","The data was collected as part of the 1990 census.  There are 68 categorical attributes. This data set was derived from the USCensus1990raw data set. The attributes are listed in the file USCensus1990.attributes.txt (repeated below) and the coding for the values is described below. Many of the less useful attributes in the original data set have been dropped, the few continuous variables have been discretized and the few discrete variables that have a large number of possible values have been collapsed to have fewer possible values.  More specifically the USCensus1990 data set was obtained from the USCensus1990raw data set by the following sequence of operations;  - Randomization: The order of the cases in the original USCensus1990raw data set were randomly permuted. - Selection of attributes: The 68 attributes included in the data set are given below. In the USCensus1990 data set we have added a single letter prefix to the original name. We add the letter 'i' to indicate that the original attribute values are used and 'd' to indicate that original attribute values for each case have been mapped to new values (the precise mapping is described below).  Hierarchies of values are provided in the file USCensus1990raw.coding.htm and the mapping functions used to transform the USCensus1990raw to the USCensus1990 data sets are giving in the file USCensus1990.mapping.sql.  The data is contained in a file called USCensus1990.data.txt. The first row contains the list of attributes. The first attribute is a caseid and should be ignored during analysis. The data is comma delimited with one case per row. ","      --------------------------------------------------------------        Old Variable        New Variable      --------------------------------------------------------------        Age         dAge        Ancstry1        dAncstry1        Ancstry2        dAncstry2        Avail           iAvail        Citizen         iCitizen        Class           iClass        Depart          dDepart        Disabl1         iDisabl1        Disabl2         iDisabl2        English         iEnglish        Feb55           iFeb55        Fertil          iFertil        Hispanic        dHispanic        Hour89          dHour89        Hours           dHours        Immigr          iImmigr        Income1         dIncome1        Income2         dIncome2        Income3         dIncome3        Income4         dIncome4        Income5         dIncome5        Income6         dIncome6        Income7         dIncome7        Income8         dIncome8        Industry        dIndustry        Korean          iKorean        Lang1           iLang1        Looking         iLooking        Marital         iMarital        May75880        iMay75880        Means           iMeans        Military        iMilitary        Mobility        iMobility        Mobillim        iMobillim        Occup           dOccup        Othrserv        iOthrserv        Perscare        iPerscare        POB         dPOB        Poverty         dPoverty        Pwgt1           dPwgt1        Ragechld        iRagechld        Rearning        dRearning        Relat1          iRelat1        Relat2          iRelat2        Remplpar        iRemplpar        Riders          iRiders        Rlabor          iRlabor        Rownchld        iRownchld        Rpincome        dRpincome        RPOB            iRPOB        Rrelchld        iRrelchld        Rspouse         iRspouse        Rvetserv        iRvetserv        School          iSchool        Sept80          iSept80        Sex         iSex        Subfam1         iSubfam1        Subfam2         iSubfam2        Tmpabsnt        iTmpabsnt        Travtime        dTravtime        Vietnam         iVietnam        Week89          dWeek89        Work89          iWork89        Worklwk         iWorklwk        WWII            iWWII        Yearsch         iYearsch        Yearwrk         iYearwrk        Yrsserv         dYrsserv Mapping: In this step we map all of the old values for variables with prefix 'd' to new values. The mappings for the variables dAncstry1, dAncstry2, dHispanic, dIndustry, dOccup, dPOB were designed to correspond to a natural coarsening of the original values based on the information in the file coding.htm. The remaining variables are continuous valued variables and the mapping for these variables was chosen to make variables that were fairly uniformly distributed across the states (quantiles). The precise mappings are specified in the file USCensus1990.mapping.sql. This file contains all of T-SQL procedures used to map the variables. These procedures can be used directly in SQLServer to map the original values or translated to some other language.       --------------------------------------------------------------        Variable        Procedure      --------------------------------------------------------------        dAge            discAge        dAncstry1       discAncstry1        dAncstry2       discAncstry2        dHispanic       discHispanic        dHour89         discHour89        dHours          discHours        dIncome1        discIncome1        dIncome2        discIncome2to8        dIncome3        discIncome2to8        dIncome4        discIncome2to8        dIncome5        discIncome2to8        dIncome6        discIncome2to8        dIncome7        discIncome2to8        dIncome8        discIncome2to8        dIndustry       discIndustry        dOccup          discOccup        dPOB            discPOB        dPoverty        discPoverty        dPwgt1          discPwgt1        dRearning       discRearning        dRpincome       discRpincome        dTravtime       discTravtime        dWeek89         discWeek89        dYrsserv        discYrsserv ","Meek, Thiesson, and Heckerman (2001), ""The Learning Curve Method Applied to Clustering"", to appear in The Journal of Machine Learning Research. [Web Link]  Also see: [Web Link]","Please refer to the Machine Learning
Repository's citation policy","Zhiyuan Chen and Johannes Gehrke and Flip Korn. Query Optimization In Compressed Database Systems. SIGMOD Conference. 2001.  [View Context].David R. Musicant and Alexander Feinberg. Active Set Support Vector Regression.  [View Context].David R. Musicant. DATA MINING VIA MATHEMATICAL PROGRAMMING AND MACHINE LEARNING. Doctor of Philosophy (Computer Sciences) UNIVERSITY.  [View Context].Chris Giannella and Bassem Sayrafi. An Information Theoretic Histogram for Single Dimensional Selectivity Estimation. Department of Computer Science, Indiana University Bloomington.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/AutoUniv,44,AutoUniv Data Set,../machine-learning-databases/00197/,Multivariate,N/A,N/A,"Categorical, Integer, Real",N/A,11/3/2010,Classification,N/A,58967,AutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com AutoUniv web-site: http://sites.google.com/site/autouniv/.,"The user first creates a classification model and then generates classified examples from it.To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift.  AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl);  a user-friendly statement of the classification rules in an 'if ... then' format (.aurules);  a statistical summary of the main properties of the model, including its Bayes rate (.auprops).","Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... . ","Marrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems.[Web Link]#proc .  Marrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459â€“469.   Hickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Parkinson+Disease+Spiral+Drawings+Using+Digitized+Graphics+Tablet,45,Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet Data Set,../machine-learning-databases/00395/,Multivariate,77,Computer,Integer,7,7/20/2017,"Classification, Regression, Clustering",N/A,44869,"1. M. Erdem ISENKUL, PhD., Istanbul University, Department of Computer Engineering, 34320, Istanbul, Turkey Phone: +90 (212) 473 7070 - 17455 Email: eisenkul '@' istanbul.edu.tr -----------------------------------2. Betul ERDOGDU SAKAR, PhD., Bahcesehir University, Department of Software Engineering, 34381, Istanbul, Turkey Phone: +90 (212) 381 0589 Email: betul.erdogdu '@' eng.bahcesehir.edu.tr","The PD and control handwriting database consists of 62 PWP (People with parkinson) and 15 healthy individuals who appealed at the Department of Neurology in Cerrahpasa Faculty of Medicine, Istanbul University. From all subjects, three types of handwriting recordings (Static Spiral Test (SST), Dynamic Spiral Test (DST) and Stability Test on Certain Point (STCP)) are taken. Also the drawings of spirals belongs to the PWP are included in the dataset as image. Therefore, this dataset can also be used for regression.  Handwriting dataset was constructed using Wacom Cintiq 12WX graphics (Hahne et al., 2009) table. It is basically a graphics tablet and LCD monitor rolled into one. It enables to display a PC's screen on its monitor and only interacts with digitized pens. Special software was designed for recording handwriting drawings and testing the coordination of the PD patients using the recordings. The software uses API functions of the device and was developed in C# platform which can be run on Windows systems You can contact with the authors to request the software which is mentioned [1].  In this study, there are three different kinds of tests developed for the data collection via graphics tablet. The first one isthe Static Spiral Test (SST) which is frequently used for clinical research in the literature for different purposes like determining motor performance (Wang et al., 2008), measuring tremor (Pullman, 1998) and diagnosing PD (Saunders et al., 2008). In this test, three wound Archimedean spirals appears on the graphics tablet using the software and patients were asked to retrace the same spiral as much as they can using the digital pen. During the test, the features which are mentioned above and the other data to specify the patient are recorded to the database.  The second test is the Dynamic Spiral Test (DST). Unlike SST, Archimedean spiral just appears and disappears in certain time intervals, in other words the Archimedean spiral blinks. This forces the patient to keep the pattern in mind and continue to draw. The purpose of this test is to determine the change in patient's drawing performance and pause times since it is more difficult to retrace the Archimedean spiral in this case. As a result of this test, it is observed that most of the patients continued drawing but nearly all of them lost the pattern.  The third test is Stability Test on Certain Point (STCP). In this test, there is a certain red point in the middle of the screen and the subjects are asked to hold the digital pen on the point without touching the screen in a certain time. The purpose of this test is to determine the patient's hand stability or hand tremor level.  Further details are contained in the following reference -- if you use this dataset, please cite:  1.Isenkul, M.E.; Sakar, B.E.; Kursun, O. . 'Improved spiral test using digitized graphics tablet for monitoring Parkinson's disease.' The 2nd International Conference on e-Health and Telemedicine (ICEHTM-2014), pp. 171-175, 2014.2.Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun, O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of Sound Recordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013.",'data' file contains the handwriting dataset. In this file there is two different folder that contains two different groups of handwriting samples which are called PWP (People with Parkinson's) and Healthy.,N/A,"Please cite the following papers if you use this dataset:  1.Isenkul, M.E.; Sakar, B.E.; Kursun, O. . 'Improved spiral test using digitized graphics tablet for monitoring Parkinson's disease.' The 2nd International Conference on e-Health and Telemedicine (ICEHTM-2014), pp. 171-175, 2014.  2.Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun, O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of Sound Recordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013. ",
http://archive.ics.uci.edu/ml/datasets/ICU,46,ICU Data Set,../machine-learning-databases/icu/,"Multivariate, Time-Series",N/A,Life,Real,N/A,N/A,N/A,No,93532,"AIM-94 data set provided by Isaac Kohane, MD, PhD, The Children's Hospital, Boston, MA",Please see documentation,N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/extention+of+Z-Alizadeh+sani+dataset,47,extention of Z-Alizadeh sani dataset Data Set,../machine-learning-databases/00411/,N/A,303,Life,"Integer, Real",59,11/17/2017,Classification,N/A,11366,"Provide the names, email addresses, institutions, and other contact information of the donors and creators of the data set. Name:Dr Zahra Alizadeh Sani,Associate Professor of cardiology,email:Drzas '@' rhc.ac.ir,institution: Cardiovascular Imaging Department, Rajaei Cardiovascular, Medical & Research Center, Iran University , Tehran, Iran.Post code:1996911151website: http://dralizadehsani.rhc.ac.ir/Files/Forms/2016-11-13_01.46.29_dr.alizadeh.CV.pdf  Name:Roohallah Alizadehsani, PhD studentemail: alizadeh_roohallah '@' yahoo.com institution: Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Victoria 3217, Australia.website: http://ce.sharif.ir/~ralizadeh/  Name: Mohamad Roshanzamir, PhD candidateemail: mohamad.roshanzamir '@' ec.iut.ac.ir institution: Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran.","Each patient could be in two possible categories CAD or Normal. A patient is categorized as CAD, if his/her diameter narrowing is greater than or equal to 50%, and otherwise as Normal . Note 1: In this extension LAD, LCX, and RCA features have been added. CAD (Last column in dataset) happens when at least one of these three arteries is stenotic. To use this dataset only one of the LAD, LCX, RCA or Cath (Result of angiography) must be in dataset and the other ones must be eliminated for classification. Note 2: This dataset not only can be used for CAD detection, but also for stenosis diagnosis of each LAD, LCX and RCA arteries. ","The extension of Z-Alizadeh Sani dataset contains the records of 303 patients, each of which have 59 features.The features are arranged in four groups: demographic, symptom and examination, ECG, and laboratory and echo features. Note 1: In this extension LAD, LCX, and RCA features have been added. CAD (Last column in dataset) happens when at least one of these three arteries is stenotic. To use this dataset only one of the LAD, LCX, RCA or Cath (Result of angiography) must be in dataset and the other ones must be eliminated for classification. Note 2: This dataset not only can be used for CAD detection, but also for stenosis diagnosis of each LAD, LCX and RCA arteries. ","R. Alizadehsani, J. Habibi, M. J. Hosseini, H. Mashayekhi, R. Boghrati, A. Ghandeharioun, et al., 'A data mining approach for diagnosis of coronary artery disease,' Computer Methods and Programs in Biomedicine, vol. 111, pp. 52-61, 2013/07/01/ 2013. R. Alizadehsani, J. Habibi, B. Bahadorian, H. Mashayekhi, A. Ghandeharioun, R. Boghrati, et al., 'Diagnosis of Coronary Arteries Stenosis Using Data Mining,' Journal of Medical Signals and Sensors, vol. 2, pp. 153-159, Jul-Sep R. Alizadehsani, M. J. Hosseini, Z. A. Sani, A. Ghandeharioun, and R. Boghrati, 'Diagnosis of Coronary Artery Disease Using Cost-Sensitive Algorithms,' in 2012 IEEE 12th International Conference on Data Mining Workshops, 2012, pp. 9-16. Z. Arabasadi, R. Alizadehsani, M. Roshanzamir, H. Moosaei, and A. A. Yarifard, 'Computer aided decision making for heart disease detection using hybrid neural network-Genetic algorithm,' Computer Methods and Programs in Biomedicine, vol. 141, pp. 19-26, 2017/04/01/ 2017. R. Alizadehsani, J. Habibi, Z. Alizadeh Sani, H. Mashayekhi, R. Boghrati, A. Ghandeharioun, et al., 'Diagnosing Coronary Artery Disease via Data Mining Algorithms by Considering Laboratory and Echocardiography Features,' Research in Cardiovascular Medicine, vol. 2, pp. 133-139, 07/31 R. Alizadehsani, J. Habibi, M. J. Hosseini, R. Boghrati, A. Ghandeharioun, B. Bahadorian, et al., 'Diagnosis of coronary artery disease using data mining techniques based on symptoms and ecg features,' European Journal of Scientific Research, vol. 82, pp. 542-553, 2012. R. Alizadehsani, M. H. Zangooei, M. J. Hosseini, J. Habibi, A. Khosravi, M. Roshanzamir, et al., 'Coronary artery disease detection using computational intelligence methods,' Knowledge-Based Systems, vol. 109, pp. 187-197, 2016/10/01/ 2016. R. Alizadehsani, J. Habibi, Z. A. Sani, H. Mashayekhi, R. Boghrati, A. Ghandeharioun, et al., 'Diagnosis of Coronary Artery Disease Using Data mining based on Lab Data and Echo Features,' Journal of Medical and Bioengineering, vol. 1, 2012. A. Roohallah, H. Mohammad Javad, B. Reihane, G. Asma, K. Fahime, and S. Zahra Alizadeh, 'Exerting Cost-Sensitive and Feature Creation Algorithms for Coronary Artery Disease Diagnosis,' International Journal of Knowledge Discovery in Bioinformatics (IJKDB), vol. 3, pp. 59-79, 2012. R. Alizadehsani, M. J. Hosseini, Z. Alizadehsani, M. H. Mohammadi, O. Barati, and F. Khozeimeh, 'System for determining the need for Angiography in patients with symptoms of Coronary Artery disease,' ed: Google Patents, 2014. F. BabiÄ, J. OlejÃ¡r, Z. VantovÃ¡, and J. ParaliÄ, 'Predictive and Descriptive Analysis for Heart Disease Diagnosis,' presented at the Federated Conference on Computer Science and Information Systems, 2017. LOHITA, Kodali et al. Performance Analysis of Various Data Mining Techniques in the Prediction of Heart Disease. Indian Journal of Science and Technology, [S.l.], dec. 2015. ISSN 0974 -5645. Available at: <[Web Link]>. Date accessed: 17 Nov. 2017. [Web Link]. J. BektaÅŸ, T. IbrikÃ§i, and I. Ã–zcan, 'Classification of Real Imbalanced Cardiovascular Data Using Feature Selection and Sampling Methods: A Case Study with Neural Networks and Logistic Regression,' International Journal on Artificial Intelligence Tools, 2017. C. Yadav, S. Lade, and M. K. Suman, 'Predictive Analysis for the Diagnosis of Coronary Artery Disease using Association Rule Mining,' International Journal of Computer Applications, vol. 87, 2014.  ","Extension of Z-Alizadeh Sani Dataset User Agreement I agree with following items.â€¢	To cite  Z-Alizadeh Sani Dataset in any paper of mine or my collaborators that makes any use of the database. The reference is: 1.	R. Alizadehsani et al., â€œA data mining approach for diagnosis of coronary artery disease,â€ Computer Methods and Programs in Biomedicine, vol.111, no.1, pp.52-61, Jul. 2013.2.	R. Alizadehsani, M.H. Zangooei, M.J. Hosseini, J. Habibi, A. Khosravi, M. Roshanzamir, F. Khozeimeh, N. Sarrafzadegan, S. Nahavandi, Coronary artery disease detection using computational intelligence methods, Knowledge-Based Systems, 109 (2016) 187-197 â€¢	To use the dataset for research purposes only. ",
http://archive.ics.uci.edu/ml/datasets/HIGGS,48,HIGGS Data Set,../machine-learning-databases/00280/,N/A,11000000,Physical,Real,28,2/12/2014,Classification,N/A,149351,"Daniel Whiteson daniel '@' uci.edu, Assistant Professor, Physics & Astronomy, Univ. of California Irvine","The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks are presented in the original paper. The last 500,000 examples are used as a test set.","The first column is the class label (1 for signal, 0 for background), followed by the 28 features (21 low-level features then 7 high-level features): lepton  pT, lepton  eta, lepton  phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb. For more detailed information about each feature see the original paper.","Baldi, P., P. Sadowski, and D. Whiteson. “Searching for Exotic Particles in High-energy Physics with Deep Learning.” Nature Communications 5 (July 2, 2014).","Baldi, P., P. Sadowski, and D. Whiteson. “Searching for Exotic Particles in High-energy Physics with Deep Learning.” Nature Communications 5 (July 2, 2014).",
http://archive.ics.uci.edu/ml/datasets/Hepatitis+C+Virus+%28HCV%29+for+Egyptian+patients,49,Hepatitis C Virus (HCV) for Egyptian patients Data Set,../machine-learning-databases/00503/,Multivariate,1385,Life,"Integer, Real",29,9/30/2019,Classification,N/A,47175,"- Professor: Sanaa Kamal  (Professor of Medicine, Ain Shams University - Faculty of Medicine-Egypt).- Prof. Dr. Khalid Abdelhameed ElBahnasy  (Professor of Information Systems, Faculty of Computer and Information Sciences, Ain Shams University-Egypt).- Dr. Mohamed Hamdy ElEleimy  (Associate Professor at Information Systems Department, Faculty of Computer and Information Sciences, Ain Shams University-Egypt).- Dr. Doaa Hegazy  (Assistant Professor at Information Systems Department, Faculty of Computer and Information Sciences, Ain Shams University-Egypt).- Mr. Mahmoud Nasr (MSc. Faculty of computer and information sciences - Ain Shams University-Egypt).* For any inquiries please contact me at:m.nasr '@' cis.asu.edu.eg",Provide all relevant information about your data set.,"Age	AgeGender	GenderBMI	Body Mass IndexFever	FeverNausea/Vomting	Nausea/VomtingHeadache	HeadacheDiarrhea	DiarrheaFatigue & generalized bone ache	Fatigue & generalized bone acheJaundice	JaundiceEpigastric pain	Epigastric painWBC	White blood cellRBC	red blood cellsHGB	HemoglobinPlat	PlateletsAST 1	aspartate transaminase ratioALT 1	alanine transaminase ratio 1 weekALT 4	alanine transaminase ratio 12 weeksALT 12	alanine transaminase ratio 4 weeksALT 24	alanine transaminase ratio 24 weeksALT 36	alanine transaminase ratio 36 weeksALT 48	alanine transaminase ratio 48 weeksALT after 24 w	alanine transaminase ratio 24 weeksRNA Base	RNA BaseRNA 4	RNA 4RNA 12	RNA 12RNA EOT	RNA end-of-treatment RNA EF	RNA Elongation FactorBaseline histological Grading	Baseline histological GradingBaselinehistological staging	Baselinehistological staging","@INPROCEEDINGS{8289800,author={M. {Nasr} and K. {El-Bahnasy} and M. {Hamdy} and S. M. {Kamal}},booktitle={2017 13th International Computer Engineering Conference (ICENCO)},title={A novel model based on non invasive methods for prediction of liver fibrosis},year={2017},volume={},number={},pages={276-281},keywords={diseases;liver;medical computing;patient diagnosis;physiological models;liver fibrosis progression diagnosis;classification models;liver biopsy;serial liver biopsies;noninvasive methods;Liver;Medical diagnostic imaging;Decision making;XML;Artificial neural networks;Machine learning algorithms;Subsumption;Minimal unique rules;Classification;Knowledge representation},doi={10.1109/ICENCO.2017.8289800},ISSN={},month={Dec},}","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/LED+Display+Domain,50,LED Display Domain Data Set,../machine-learning-databases/led-display-creator/,"Multivariate, Data-Generator",N/A,Computer,Categorical,7,11/10/1988,Classification,No,69411,"Original Source: Breiman,L., Friedman,J.H., Olshen,R.A., & Stone,C.J. (1984).  Classification and Regression Trees.  Wadsworth International Group: Belmont, California.  (see pages 43-49). Donor:  David Aha ","This simple domain contains 7 Boolean attributes and 10 concepts, the set of decimal digits.  Recall that LED displays contain 7 light-emitting diodes -- hence the reason for 7 attributes.  The problem would be easy if not for the introduction of noise.  In this case, each attribute value has the 10% probability of having its value inverted.   It's valuable to know the optimal Bayes rate for these databases. In this case, the misclassification rate is 26% (74% classification accuracy).","   -- All attribute values are either 0 or 1, according to whether the corresponding light is on or not for the decimal digit.   -- Each attribute (excluding the class attribute, which is an integer ranging between 0 and 9 inclusive) has a 10% percent chance of being inverted.","Breiman,L., Friedman,J.H., Olshen,R.A., & Stone,C.J.  Classification and Regression Trees.  Wadsworth International Group: Belmont, California. 1984. (see pages 43-49).[Web Link]  Quinlan,J.R. (1987). Simplifying Decision Trees.  In International Journal of Man-Machine Studies.[Web Link]  Tan,M. & Eshelman,L. (1988). Using Weighted Networks to Represent Classification Knowledge in Noisy Domains.  In Proceedings of the 5th International Conference on Machine Learning, 121-134, Ann Arbor, Michigan: Morgan Kaufmann.  [Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Joao Gama and Ricardo Rocha and Pedro Medas. Accurate decision trees for mining high-speed data streams. KDD. 2003.  [View Context].Tim Leunig and D. Stott Parker. Empirical comparisons of various voting methods in bagging. KDD. 2003.  [View Context].Xavier Llor and David E. Goldberg. Minimal Achievable Error in the LED. Illinois Genetic Algorithms Laboratory University of Illinois at Urbana-Champaign. 2002.  [View Context].Xavier Llor and David E. Goldberg and Ivan Traus and Ester Bernad i Mansilla. Accuracy, Parsimony, and Generality in Evolutionary Learning Systems via Multiobjective Selection. IWLCS. 2002.  [View Context].Huan Liu and Rudy Setiono. Incremental Feature Selection. Appl. Intell, 9. 1998.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Vikas Sindhwani and P. Bhattacharya and Subrata Rakshit. Information Theoretic Feature Crediting in Multiclass Support Vector Machines.  [View Context].Maria Salamo and Elisabet Golobardes. Analysing Rough Sets weighting methods for Case-Based Reasoning Systems. Enginyeria i Arquitectura La Salle.  [View Context].Ramon Sangesa and Ulises Cortes. Possibilistic Conditional Dependency, Similarity and Information Measures: an application to causal network recovery. Departament de Llenguatges i Sistemes Informtics Departament de Llenguatges i Sistemes Informtics Technical University of Catalonia Technical University of Catalonia.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Opinion+Corpus+for+Lebanese+Arabic+Reviews+%28OCLAR%29,51,Opinion Corpus for Lebanese Arabic Reviews (OCLAR) Data Set,../machine-learning-databases/00499/,Text,3916,Computer,Integer,3916,6/17/2019,Classification,N/A,4065,"Marwan Al Omari, Centre for Language Sciences and Communication, Lebanese University, Beirut, Lebanon, marwanalomari '@' yahoo.com Moustafa Al-Hajj, Centre for Language Sciences and Communication, Lebanese University, Beirut, Lebanon, moustafa.alhajj '@' ul.edu.lb Nacereddine Hammami, college of Computer and Information Sciences, Jouf University, Aljouf, KSA, n.hammami '@' ju.edu.sa Amani Sabra, Centre for Language Sciences and Communication, Lebanese University, Beirut, Lebanon, amani.sabra '@' ul.edu.lb","The researchers of OCLAR Marwan et al. (2019), they gathered Arabic costumer reviews from ([Web Link]) and Zomato website ([Web Link]) on wide scope of domain, including restaurants, hotels, hospitals, local shops, etc. The corpus finally contains 3916 reviews in 5-rating scale. For this research purpose, the positive class considers rating stars from 5 to 3 of 3465 reviews, and the negative class is represented from values of 1 and 2 of about 451 texts.","1- 3916 text reviews2- 5-rating scale: 1: 303                   2: 148                   3: 418                   4: 734                   5: 2313Positive class includes rating stars from 5 to 3 of 3465 total.Negative class include rating stars from 1 to 2 of 451 total.","Al Omari, M., Al-Hajj, M., Hammami, N., & Sabra, A. (2019). Sentiment Classifier: Logistic Regression for Arabic Servicesâ€™ Reviews in Lebanon. 2019 International Conference on Computer and Information Sciences (ICCIS), Sakaka, Saudi Arabia, 2019, pp. 1-5. Doi: 10.1109/ICCISci.2019.8716394",Please cite the above paper if you make use of the OCLAR dataset.,
http://archive.ics.uci.edu/ml/datasets/Air+Quality,52,Air Quality Data Set,../machine-learning-databases/00360/,"Multivariate, Time-Series",9358,Computer,Real,15,3/23/2016,Regression,Yes,437734,"Saverio De Vito (saverio.devito '@' enea.it), ENEA - National Agency for New Technologies, Energy and Sustainable Economic Development","The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.This dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.","0 Date	(DD/MM/YYYY)1 Time	(HH.MM.SS)2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)	4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)	7 True hourly averaged NOx concentration  in ppb (reference analyzer)8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) 9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)	10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)	11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)12 Temperature in Â°C	13 Relative Humidity (%) 	14 AH Absolute Humidity","S. De Vito, E. Massera, M. Piga, L. Martinotto, G. Di Francia, On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario, Sensors and Actuators B: Chemical, Volume 129, Issue 2, 22 February 2008, Pages 750-757, ISSN 0925-4005, [Web Link].([Web Link]) Saverio De Vito, Marco Piga, Luca Martinotto, Girolamo Di Francia, CO, NO2 and NOx urban pollution monitoring with on-field calibrated electronic nose by automatic bayesian regularization, Sensors and Actuators B: Chemical, Volume 143, Issue 1, 4 December 2009, Pages 182-191, ISSN 0925-4005, [Web Link].([Web Link]) S. De Vito, G. Fattoruso, M. Pardo, F. Tortorella and G. Di Francia, 'Semi-Supervised Learning Techniques in Artificial Olfaction: A Novel Approach to Classification Problems and Drift Counteraction,' in IEEE Sensors Journal, vol. 12, no. 11, pp. 3215-3224, Nov. 2012.doi: 10.1109/JSEN.2012.2192425","S. De Vito, E. Massera, M. Piga, L. Martinotto, G. Di Francia, On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario, Sensors and Actuators B: Chemical, Volume 129, Issue 2, 22 February 2008, Pages 750-757, ISSN 0925-4005, [Web Link].([Web Link])",
http://archive.ics.uci.edu/ml/datasets/selfBACK,53,selfBACK Data Set,../machine-learning-databases/00521/,Time-Series,26136,Computer,Real,6,6/15/2020,"Classification, Clustering",N/A,2998,"Sadiq Sani, Nirmalie Wiratunga, Kay CooperRobert Gordon UniversityAberdeen, UK","The SELFBACK dataset contains data of 9 activity classes; 6 ambulatory activitiesand 3 sedentary activities, performed by 33 participants.Data are recorded with two tri-axial accelerometers sampling at 100Hz, mounted onthe dominant side wrist and the thigh of the participant. **Application**The dataset can be used for human activity recognition by developing algorithms forpre-processing, feature extraction, sensor fusion, segmentation and classification. ** Data collection method **Each participant performed an activity for approximately 3 minutes.** Sensors**Axivity AX3 3-Axis Logging Accelerometer- sampling frequency -- 100Hz- range -- 8g** Activity Classes**- Walking Upstairs- Walking Downstairs- Walking in slow pace- Walking in medium pace- Walking in fast pace- Jogging- Standing- Sitting- Lying** Data folder ** SELFBACK dataset has three folders, two folders one for each sensor modalitynamed ""w"" for wrist and ""t"" for thigh and an additional folder where two sensormodalities are merged using timestamp named ""wt"" for wrist and thigh.Inside ""w"" and ""t"" folders, 9 folders can be found, one for each activity class, andinside, there are 33 files, one file for each participant.Inside ""wt"" folder, there are 297(33 X 9) files where the file name indicates theperson and the activity.","The 4 columns in the files in t and w folder is organized as follows:1 -- timestamp2 -- x value3 -- y value4 -- z valueMin value = -8Max value = +8The 6 columns in the files in wt folder is organized as follows:1 -- wrist x value2 -- wrist y value3 -- wrist z value4 -- thigh x value5 -- thigh y value6 -- thigh z valueMin value = -8Max value = +8","- Sani, S., Wiratunga, N., Massie, S., & Cooper, K. (2016, December).SELFBACK--activity recognition for self-management of low back pain. InInternational Conference on Innovative Techniques and Applications of ArtificialIntelligence (pp. 281-294). Springer, Cham.- Sani, S., Massie, S., Wiratunga, N., & Cooper, K. (2017, August). Learning deepand shallow features for human activity recognition. In International Conferenceon Knowledge Science, Engineering and Management (pp. 469-482). Springer,Cham.- Sani, S., Wiratunga, N., Massie, S., & Cooper, K. (2017, June). kNN sampling forpersonalised human activity recognition. In International conference on case-based reasoning (pp. 330-344). Springer, Cham.- Sani S, Wiratunga N, Massie S, Cooper K. Personalised human activityrecognition using matching networks. In International Conference on Case-Based Reasoning 2018 Jul 9 (pp. 339-353). Springer, Cham.- Wijekoon, A., Wiratunga, N., Sani, S., Massie, S., & Cooper, K. (2018, July).Improving kNN for Human Activity Recognition with Privileged Learning UsingTranslation Models. In International Conference on Case-Based Reasoning (pp.448-463). Springer, Cham. - Wijekoon, A., Wiratunga, N., Sani, S., & Cooper, K. (2020). A knowledge-lightapproach to personalised and open-ended human activity recognition.Knowledge-Based Systems, 192, 105651.","Sani, S., Wiratunga, N., Massie, S., & Cooper, K. (2016, December).SELFBACK--activity recognition for self-management of low back pain. In International Conferenceon Innovative Techniques and Applications of Artificial Intelligence (pp. 281-294). Springer, Cham.",
http://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization,54,Wireless Indoor Localization Data Set,../machine-learning-databases/00422/,Multivariate,2000,Computer,Real,7,12/4/2017,Classification,N/A,44669,"Rajen Bhatt, rajen.bhatt '@' gmail.com",Collected to perform experimentation on how wifi signal strengths can be used to determine one of the indoor locations.,Each attribute is wifi signal strength observed on smartphone.,"Jayant G Rohra, Boominathan Perumal, Swathi Jamjala Narayanan, Priya Thakur, and Rajen B Bhatt, 'User Localization in an Indoor Environment Using Fuzzy Hybrid of Particle Swarm Optimization & Gravitational Search Algorithm with Neural Networks', in Proceedings of Sixth International Conference on Soft Computing for Problem Solving,2017, pp. 286-295.","1. Rajen Bhatt, 'Fuzzy-Rough Approaches for Pattern Classification: Hybrid measures, Mathematical analysis, Feature selection algorithms, Decision tree algorithms, Neural learning, and Applications', Amazon Books2. Jayant G Rohra, Boominathan Perumal, Swathi Jamjala Narayanan, Priya Thakur, and Rajen B Bhatt, 'User Localization in an Indoor Environment Using Fuzzy Hybrid of Particle Swarm Optimization & Gravitational Search Algorithm with Neural Networks', in Proceedings of Sixth International Conference on Soft Computing for Problem Solving,2017, pp. 286-295.",
http://archive.ics.uci.edu/ml/datasets/Ecoli,55,Ecoli Data Set,../machine-learning-databases/ecoli/,Multivariate,336,Life,Real,8,9/1/1996,Classification,No,233225,"Creator and Maintainer: Kenta NakaiInstitue of Molecular and Cellular BiologyOsaka, University1-3 Yamada-oka, Suita 565 Japannakai '@' imcb.osaka-u.ac.jp http://www.imcb.osaka-u.ac.jp/nakai/psort.html\ Donor:  Paul Horton (paulh '@' cs.berkeley.edu) See also: yeast database","The references below describe a predecessor to this dataset and its development. They also give results (not cross-validated) for classification by a rule-based expert system with that version of the dataset. Reference: ""Expert Sytem for Predicting Protein Localization Sites in Gram-Negative Bacteria"", Kenta Nakai & Minoru Kanehisa,  PROTEINS: Structure, Function, and Genetics 11:95-110, 1991. Reference: ""A Knowledge Base for Predicting Protein Localization Sites in Eukaryotic Cells"", Kenta Nakai & Minoru Kanehisa, Genomics 14:897-911, 1992.","  1.  Sequence Name: Accession number for the SWISS-PROT database  2.  mcg: McGeoch's method for signal sequence recognition.  3.  gvh: von Heijne's method for signal sequence recognition.  4.  lip: von Heijne's Signal Peptidase II consensus sequence score. Binary attribute.  5.  chg: Presence of charge on N-terminus of predicted lipoproteins. Binary attribute.  6.  aac: score of discriminant analysis of the amino acid content of outer membrane and periplasmic proteins.  7. alm1: score of the ALOM membrane spanning region prediction program.  8. alm2: score of ALOM program after excluding putative cleavable signal regions from the sequence.","Paul Horton & Kenta Nakai. ""A Probablistic Classification System for Predicting the Cellular Localization Sites of Proteins"".Intelligent Systems in Molecular Biology, 109-115. St. Louis, USA 1996.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Charles X. Ling and Qiang Yang and Jianning Wang and Shichao Zhang. Decision trees with minimal costs. ICML. 2004.  [View Context].Xiaoyong Chai and Li Deng and Qiang Yang and Charles X. Ling. Test-Cost Sensitive Naive Bayes Classification. ICDM. 2004.  [View Context].Aik Choon Tan and David Gilbert. An Empirical Comparison of Supervised Machine Learning Techniques in Bioinformatics. APBC. 2003.  [View Context].Mukund Deshpande and George Karypis. Evaluation of Techniques for Classifying Biological Sequences. PAKDD. 2002.  [View Context].Huajie Zhang and Charles X. Ling. An Improved Learning Algorithm for Augmented Naive Bayes. PAKDD. 2001.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Paul Horton and Kenta Nakai. Better Prediction of Protein Cellular Localization Sites with the it k Nearest Neighbors Classifier. ISMB. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Andrew Watkins and Jon Timmis and Lois C. Boggess. Artificial Immune Recognition System (AIRS): An ImmuneInspired Supervised Learning Algorithm. (abw5,jt6@kent.ac.uk) Computing Laboratory, University of Kent.  [View Context].Gaurav Marwah and Lois C. Boggess. Artificial Immune Systems for Classification : Some Issues. Department of Computer Science Mississippi State University.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/HCC+Survival,56,HCC Survival Data Set,../machine-learning-databases/00423/,Multivariate,165,Life,"Integer, Real",49,11/29/2017,Classification,Yes,32639,"Donors: Miriam Seoane Santos, Department of Informatics Engineering, Faculty of Sciences and Technology, University of Coimbra (miriams '@' student.dei.uc.pt)Pedro Henriques Abreu, Department of Informatics Engineering, Faculty of Sciences and Technology, University of Coimbra (pha '@' dei.uc.pt)Armando Carvalho, Internal Medicine Service, Hospital and University Centre of Coimbra (aspcarvalho '@' gmail.com)AdÃ©lia SimÃ£o, Internal Medicine Service, Hospital and University Centre of Coimbra (adeliasimao '@' gmail.com)","HCC dataset was obtained at a University Hospital in Portugal and contais several demographic, risk factors, laboratory and overall survival features of 165 real patients diagnosed with HCC. The dataset contains 49 features selected according to the EASL-EORTC (European Association for the Study of the Liver - European Organisation for Research and Treatment of Cancer) Clinical Practice Guidelines, which are the current state-of-the-art on the management of HCC. This is an heterogeneous dataset, with 23 quantitative variables, and 26 qualitative variables. Overall, missing data represents 10.22% of the whole dataset and only eight patients have complete information in all fields (4.85%). The target variables is the survival at 1 year, and was encoded as a binary variable: 0 (dies) and 1 (lives). A certain degree of class-imbalance is also present (63 cases labeled as â€œdiesâ€ and 102 as â€œlivesâ€). A detailed description of the HCC dataset (feature's type/scale, range, mean/mode and missing data percentages) is provided in Santos et al. A new cluster-based oversampling method for improving survival prediction of hepatocellular carcinoma patients, Journal of biomedical informatics, 58, 49-59, 2015.","Gender: nominalSymptoms: nominalAlcohol: nominalHepatitis B Surface Antigen: nominalHepatitis B e Antigen: nominalHepatitis B Core Antibody: nominalHepatitis C Virus Antibody: nominalCirrhosis	: nominal	Endemic Countries: nominalSmoking: nominalDiabetes: nominalObesity: nominalHemochromatosis: nominalArterial Hypertension: nominalChronic Renal Insufficiency: nominalHuman Immunodeficiency Virus: nominalNonalcoholic Steatohepatitis: nominalEsophageal Varices: nominalSplenomegaly: nominalPortal Hypertension: nominalPortal Vein Thrombosis: nominalLiver Metastasis: nominalRadiological Hallmark: nominalAge at diagnosis: integerGrams of Alcohol per day: continuousPacks of cigarets per year: continuousPerformance Status: ordinalEncefalopathy	degree: ordinalAscites degree: ordinalInternational Normalised Ratio: continuousAlpha-Fetoprotein (ng/mL): continuousHaemoglobin (g/dL): continuousMean Corpuscular Volume	 (fl): continuousLeukocytes(G/L): continuousPlatelets	(G/L): continuousAlbumin (mg/dL): continuousTotal Bilirubin(mg/dL): continuousAlanine transaminase (U/L): continuousAspartate transaminase (U/L): continuousGamma glutamyl transferase (U/L): continuousAlkaline phosphatase (U/L): continuousTotal Proteins (g/dL): continuousCreatinine (mg/dL): continuousNumber of Nodules: integerMajor dimension of nodule (cm): continuousDirect Bilirubin (mg/dL): continuousIron	(mcg/dL): continuousOxygen Saturation (%): continuousFerritin (ng/mL): continuousClass: nominal (1 if patient survives, 0 if patient died)","Miriam Seoane Santos, Pedro Henriques Abreu, Pedro J Garcia-Laencina, Adelia Simao, Armando Carvalho, A new cluster-based oversampling method for improving survival prediction of hepatocellular carcinoma patients, Journal of biomedical informatics, 58, 49-59, 2015.","Miriam Seoane Santos, Pedro Henriques Abreu, Pedro J Garcia-Laencina, Adelia Simao, Armando Carvalho, A new cluster-based oversampling method for improving survival prediction of hepatocellular carcinoma patients, Journal of biomedical informatics, 58, 49-59, 2015.",
http://archive.ics.uci.edu/ml/datasets/Hill-Valley,57,Hill-Valley Data Set,../machine-learning-databases/hill-valley/,Sequential,606,N/A,Real,101,3/20/2008,Classification,N/A,71030,"Lee Graham (lee '@' stellaralchemy.com) Franz Oppacher (oppacher '@' scs.carleton.ca)Carleton University, Department of Computer ScienceIntelligent Systems Research Unit1125 Colonel By Drive, Ottawa, Ontario, Canada, K1S5B6","Each record represents 100 points on a two-dimensional graph. When plotted in order (from 1 through 100) as the Y co-ordinate, the points will create either a Hill (a “bump” in the terrain) or a Valley (a “dip” in the terrain). There are six files, as follows: (a) Hill_Valley_without_noise_Training.data(b) Hill_Valley_without_noise_Testing.data These first two datasets (without noise) are a training/testing set pair where the hills or valleys have a smooth transition. (c) Hill_Valley_with_noise_Training.data(d) Hill_Valley_with_noise_Testing.data These next two datasets (with noise) are a training/testing set pair where the terrain is uneven, and the hill or valley is not as obvious when viewed closely.  (e) Hill_Valley_sample_arff.text The sample ARFF file is useful for setting up experiments, but is not necessary. (f) Hill_Valley_visual_examples.jpg This graphic file shows two example instances from the data.","1-100: Labeled “X##”. Floating point values (numeric)101: Labeled “class”. Binary {0, 1} representing {valley, hill}",1. Non-published. Evaluation of dataset by various learning algorithms in the Waikato Environment for Knowledge Analysis (WEKA).,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Reuters+Transcribed+Subset,58,Reuters Transcribed Subset Data Set,../machine-learning-databases/reuters_transcribed/reuters_transcribed.html-mld/,Text,200,Business,N/A,N/A,3/8/2008,Classification,N/A,56978,"Shourya Royshourya.roy '@' gmail.com andShantanu Godboleshantanu '@' godbole.net ","Data Characteristics:--------------------This data was created by selecting 20 files each from the 10 largest classes in the Reuters-21578 collection ([Web Link]). The files were read out by 3 Indian speakers and an Automatic Speech Recognition (ASR) system was used to generate the transcripts. More about the ASR system can be found in [1]. Such a dataset will be really helpful to study the effect of speech recognition noise on text mining algorithms. The first work which refered to this dataset was on noisy text classification[2]. Data Format:----------There are 10 directories labeled by the topic name. Each contains 20 files of transcriptions. References:----------[1] L. R. Bahl, S. Balakrishnan-Aiyer, J. Bellegarda, M. Franz,P. Gopalakrishnan, D. Nahamoo, M. Novak, M. Padmanabhan,M. Picheny, and S. Roukos,Performance of the IBM large vocabulary continuous speech recognition system onthe ARPA wall street journal task. In Proc. of ICASSP ’95,pages 41–44, Detroit, MI, 1995.[2] S. Agarwal, S. Godbole, D. Punjani and S. Roy,How Much Noise is too Much: A Study in Automatic Text Classification',In Proc. of ICDM 2007",Provide information about each attribute in your data set.,"'“How Much Noise in Text is too Much: A Study in Automatic Document Classification”, ICDM 2007, Sumeet Agarwal, Shantanu Godbole, Diwakar Punjani and Shourya Roy","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center,59,Blood Transfusion Service Center Data Set,../machine-learning-databases/blood-transfusion/,Multivariate,748,Business,Real,5,10/3/2008,Classification,N/A,330908,"Original Owner and DonorProf. I-Cheng YehDepartment of Information Management Chung-Hua University, Hsin Chu, Taiwan 30067, R.O.C.e-mail:icyeh '@' chu.edu.tw TEL:886-3-5186511 Date Donated: October 3, 2008","To demonstrate the RFMTC marketing model (a modified version of RFM), this study adopted the donor database of Blood Transfusion Service Center in Hsin-Chu City in Taiwan. The center passes their blood transfusion service bus to one university in Hsin-Chu City to gather blood donated about every three months. To build a FRMTC model, we selected 748 donors at random from the donor database. These 748 donor data, each one included R (Recency - months since last donation), F (Frequency - total number of donation), M (Monetary - total blood donated in c.c.), T (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood). ","Given is the variable name, variable type, the measurement unit and a brief description. The ""Blood Transfusion Service Center"" is a classification problem. The order of this listing corresponds to the order of numerals along the rows of the database.  R (Recency - months since last donation), F (Frequency - total number of donation), M (Monetary - total blood donated in c.c.), T (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood).   Table 1 shows the descriptive statistics of the data. We selected 500 data at random as the training set, and the rest 248 as the testing set. Table 1. Descriptive statistics of the data Variable	Data Type	Measurement	Description	min	max	mean	stdRecency 	quantitative	Months	Input	0.03	74.4	9.74	8.07Frequency 	quantitative	Times	Input	1	50	5.51	5.84Monetary	quantitative	c.c. blood	Input	250	12500	1378.68	1459.83Time 	quantitative	Months	Input	2.27	98.3	34.42	24.32Whether he/she donated blood in March 2007	binary	1=yes 0=no	Output	0	1	1 (24%) 0 (76%)","Yeh, I-Cheng, Yang, King-Jang, and Ting, Tao-Ming, ""Knowledge discovery on RFM model using Bernoulli sequence,"" Expert Systems with Applications, 2008,  [Web Link]","NOTE: Reuse of this database is unlimited with retention of copyright notice for Prof. I-Cheng Yeh and the following published paper: Yeh, I-Cheng, Yang, King-Jang, and Ting, Tao-Ming, ""Knowledge discovery on RFM model using Bernoulli sequence, ""Expert Systems with Applications, 2008,  [Web Link] ",
http://archive.ics.uci.edu/ml/datasets/Character+Trajectories,60,Character Trajectories Data Set,../machine-learning-databases/character-trajectories/,Time-Series,2858,Computer,Real,3,8/20/2008,"Classification, Clustering",N/A,147124,"Ben H Williams School of Informatics,University of Edinburgh,ben.williams '@' ed.ac.uk ","The characters here were used for a PhD study on primitive extraction using HMM based models. The data consists of 2858 character samples, contained in the cell array 'mixout'. The struct variable 'consts' contains a field consts.charlabels which provides ennummerated labels for the characters. consts.key provides the key for each label. The data was captured using a WACOM tablet. 3 Dimensions were kept - x, y, and pen tip force. The data has been numerically differentiated and Gaussian smoothed, with a sigma value of 2. Data was captured at 200Hz. The data was normalised with consts.datanorm. Only characters with a single 'PEN-DOWN' segment were considered. Character segmentation was performed using a pen tip force cut-off point. The characters have also been shifted so that their velocity profiles best match the mean of the set.","Each character sample is a 3-dimensional pen tip velocity trajectory. This is contained in matrix format, with 3 rows and T columns where T is the length of the character sample.","B.H. Williams, M.Toussaint, and A.J. Storkey. Extracting motion primitives from natural handwriting data. In ICANN, volume 2, pages 634–643, 2006. B.H. Williams, M.Toussaint, and A.J. Storkey. A primitive based generative model to infer timing information in unpartitioned handwriting data. In IJCAI, pages 1119–1124, 2007. B.H. Williams, M. Toussaint, and A.J. Storkey. Modelling motion primitives and their timing in biologically executed movements. In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 1609–1616. MIT Press, Cambridge, MA, 2008.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/BLOGGER,61,BLOGGER Data Set,../machine-learning-databases/00255/,Multivariate,100,Computer,N/A,6,7/6/2013,Classification,N/A,81725,http://www.ijcaonline.org/archives/volume47/number18/7291-0509,"In this paper, we look for to recognize the causes of users tendto cyber space in Kohkiloye and Boyer Ahmad Province inIran. Collecting information to form database is done byquestionnaire. This questionnaire is provided as oral, writtenand also programming of a website which includes an internetquestionnaire and the users can answer the questions as theywish. They entered their used websites, blogs and socialnetworks during the day.After collecting questionnaires, the wed addresses aregathered to get expected results. And finally, their trustfulnessis checked by analyzing their used web pages. As the resultswere same, for getting better and noiseless response, they willput in database","We considered the following parameters as questions: age,education, political attitudes, blog topic, and the type of theidentity in internet, the influence of managersâ€™ inefficiency ontendency, the effect of inefficient media on tendency, theeffects of social and political conditions on tendency andfinally the effect of poverty in the province on tendency. Thenoisy or too detailed data in database makes us far from to getproper and suitable answers of algorithms [8]. We preprocessedthe data and eliminated some non-relevant data.Finally the followings are considered as the main fields whichinclude: education, political caprice, topics, local mediaturnover (LMT) and local, political and social space (LPSS).The collected data are shown in Table 1.In order to get correct answer, we classify bloggers to twogroups: professional bloggers and seasonal (temporary)bloggers. Professional bloggers are those who adopt blog asan effective digital media and interested in digital writing incontinuous time intervals. Seasonal (temporary) bloggersarenâ€™t professional and follow blogging in discrete timeperiods. In this study, we review the tendency factorsconsidering whether these people are among professionalbloggers (Pro Bloggers, PB) and then, consider the otherfactors according to it.","F.S GHAREHCHOPOGH, S.R.KHAZE, 'Data Mining Application for Cyber Space Tendency in Blog Writing: A Case Studyâ€, International Journal of Computer Applications (IJCA), Vol: 47, No: 18, pp: 40-46, June 2012.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/MHEALTH+Dataset,62,MHEALTH Dataset Data Set,../machine-learning-databases/00319/,"Multivariate, Time-Series",120,Computer,Real,23,12/7/2014,Classification,N/A,99662,"Oresti Banos, Department of Computer Architecture and Computer Technology, University of Granada Rafael Garcia, Department of Computer Architecture and Computer Technology, University of GranadaAlejandro Saez, Department of Computer Architecture and Computer Technology, University of Granada Email to whom correspondence should be addressed: oresti '@' ugr.es (oresti.bl '@' gmail.com)","The MHEALTH (Mobile HEALTH) dataset comprises body motion and vital signs recordings for ten volunteers of diverse profile while performing several physical activities. Sensors placed on the subject's chest, right wrist and left ankle are used to measure the motion experienced by diverse body parts, namely, acceleration, rate of turn and magnetic field orientation. The sensor positioned on the chest also provides 2-lead ECG measurements, which can be potentially used for basic heart monitoring, checking for various arrhythmias or looking at the effects of exercise on the ECG. ----------------------------------------------------------------------------------------------------------------------DATASET SUMMARY:#Activities: 12 #Sensor devices: 3#Subjects: 10---------------------------------------------------------------------------------------------------------------------- EXPERIMENTAL SETUPThe collected dataset comprises body motion and vital signs recordings for ten volunteers of diverse profile while performing 12 physical activities (Table 1). Shimmer2 [BUR10] wearable sensors were used for the recordings. The sensors were respectively placed on the subject's chest, right wrist and left ankle and attached by using elastic straps (as shown in the figure in attachment). The use of multiple sensors permits us to measure the motion experienced by diverse body parts, namely, the acceleration, the rate of turn and the magnetic field orientation, thus better capturing the body dynamics. The sensor positioned on the chest also provides 2-lead ECG measurements which are not used for the development of the recognition model but rather collected for future work purposes. This information can be used, for example, for basic heart monitoring, checking for various arrhythmias or looking at the effects of exercise on the ECG. All sensing modalities are recorded at a sampling rate of 50 Hz, which is considered sufficient for capturing human activity. Each session was recorded using a video camera. This dataset is found to generalize to common activities of the daily living, given the diversity of body parts involved in each one (e.g., frontal elevation of arms vs. knees bending), the intensity of the actions (e.g., cycling vs. sitting and relaxing) and their execution speed or dynamicity (e.g., running vs. standing still). The activities were collected in an out-of-lab environment with no constraints on the way these must be executed, with the exception that the subject should try their best when executing them. ACTIVITY SETThe activity set is listed in the following:L1: Standing still (1 min) L2: Sitting and relaxing (1 min) L3: Lying down (1 min) L4: Walking (1 min) L5: Climbing stairs (1 min) L6: Waist bends forward (20x) L7: Frontal elevation of arms (20x)L8: Knees bending (crouching) (20x)L9: Cycling (1 min)L10: Jogging (1 min)L11: Running (1 min)L12: Jump front & back (20x)NOTE: In brackets are the number of repetitions (Nx) or the duration of the exercises (min). A complete and illustrated description (including table of activities, sensor setup, etc.) of the dataset is provided in the papers presented in the section â€œCitation Requestsâ€.","The data collected for each subject is stored in a different log file: 'mHealth_subject.log'. Each file contains the samples (by rows) recorded for all sensors (by columns). The labels used to identify the activities are similar to the abovementioned (e.g., the label for walking is '4'). The meaning of each column is detailed next:Column 1: acceleration from the chest sensor (X axis)Column 2: acceleration from the chest sensor (Y axis)Column 3: acceleration from the chest sensor (Z axis)Column 4: electrocardiogram signal (lead 1) Column 5: electrocardiogram signal (lead 2)Column 6: acceleration from the left-ankle sensor (X axis)Column 7: acceleration from the left-ankle sensor (Y axis)Column 8: acceleration from the left-ankle sensor (Z axis)Column 9: gyro from the left-ankle sensor (X axis)Column 10: gyro from the left-ankle sensor (Y axis)Column 11: gyro from the left-ankle sensor (Z axis)Column 13: magnetometer from the left-ankle sensor (X axis)Column 13: magnetometer from the left-ankle sensor (Y axis)Column 14: magnetometer from the left-ankle sensor (Z axis)Column 15: acceleration from the right-lower-arm sensor (X axis)Column 16: acceleration from the right-lower-arm sensor (Y axis)Column 17: acceleration from the right-lower-arm sensor (Z axis)Column 18: gyro from the right-lower-arm sensor (X axis)Column 19: gyro from the right-lower-arm sensor (Y axis)Column 20: gyro from the right-lower-arm sensor (Z axis)Column 21: magnetometer from the right-lower-arm sensor (X axis)Column 22: magnetometer from the right-lower-arm sensor (Y axis)Column 23: magnetometer from the right-lower-arm sensor (Z axis)Column 24: Label (0 for the null class) *Units: Acceleration (m/s^2), gyroscope (deg/s), magnetic field (local), ecg (mV)","Banos, O., Garcia, R., Holgado, J. A., Damas, M., Pomares, H., Rojas, I., Saez, A., Villalonga, C. mHealthDroid: a novel framework for agile development of mobile health applications. Proceedings of the 6th International Work-conference on Ambient Assisted Living an Active Ageing (IWAAL 2014), Belfast, Northern Ireland, December 2-5, (2014).Nguyen, L. T., Zeng, M., Tague, P., Zhang, J. (2015). Recognizing New Activities with Limited Training Data. In IEEE International Symposium on Wearable Computers (ISWC).","Use of this dataset in publications must be acknowledged by referencing the following publications:Banos, O., Garcia, R., Holgado, J. A., Damas, M., Pomares, H., Rojas, I., Saez, A., Villalonga, C. mHealthDroid: a novel framework for agile development of mobile health applications. Proceedings of the 6th International Work-conference on Ambient Assisted Living an Active Ageing (IWAAL 2014), Belfast, Northern Ireland, December 2-5, (2014).Banos, O., Villalonga, C., Garcia, R., Saez, A., Damas, M., Holgado, J. A., Lee, S., Pomares, H., Rojas, I. Design, implementation and validation of a novel open framework for agile development of mobile health applications. BioMedical Engineering OnLine, vol. 14, no. S2:S6, pp. 1-20 (2015).We recommend to refer to this dataset as the 'MHEALTH dataset' in publications. We would appreciate if you send us an email (oresti.bl '@' gmail.com) to inform us of any publication using this dataset.",
http://archive.ics.uci.edu/ml/datasets/Victorian+Era+Authorship+Attribution,63,Victorian Era Authorship Attribution Data Set,../machine-learning-databases/00454/,Text,93600,Computer,N/A,1000,5/31/2018,Classification,N/A,16425,"They're extracted from the GDELT database. The GDELT Project is an open platform for research and analysis of global society and thus all datasets released by the GDELT Project are available for unlimited and unrestricted use for any academic, commercial, or governmental use of any kind without fee.","To decrease the bias and create a reliable authorship attribution dataset the following criteria have been chosen to filter out authors in Gdelt database: English language writing authors, authors that have enough books available (at least 5), 19th century authors. With these criteria 50 authors have been selected and their books were queried through Big Query Gdelt database. The next task has been cleaning the dataset due to OCR reading problems in the original raw form. To achieve that, firstly all books have been scanned through to get the overall number of unique words and each words frequencies. While scanning the texts, the first 500 words and the last 500 words have been removed to take out specific features such as the name of the author, the name of the book and other word specific features that could make the classification task easier. After this step, we have chosen top 10,000 words that occurred in the whole 50 authors text data corpus. The words that are not in top 10,000 words were removed while keeping the rest of the sentence structure intact. The entire book is split into text fragments with 1000 words each. We separately maintained author and book identification number for each one of them in different arrays. Text segments with less than 1000 words were filled with zeros to keep them in the dataset as well. 1000 words make approximately 2 pages of writing, which is long enough to extract a variety of features from the document. Each instance in the training set consists of a text piece of 1000 words and an author id attached. In the testing set, there is only the text piece of 1000 words to do authorship attribution. Training data consists of 45 authors and testing data has 50 information. %34 of testing data is the percentile of unknown authors in the testing set.  ","Each instance consists of 1000 word sequences that are divided from the works of every author's book. In the training, the author id is also provided.  ","E. Stamatatos, A Survey of Modern Authorship Attribution Methods. Journalof the American Society for Information Science and Technology, 2009.","Please site our work : GUNGOR, ABDULMECIT, Benchmarking Authorship Attribution Techniques Using Over A Thousand Books by Fifty Victorian Era Novelists, Purdue Master of Thesis, 2018-04",
http://archive.ics.uci.edu/ml/datasets/Census+Income,64,Census Income Data Set,../machine-learning-databases/adult/,Multivariate,48842,Social,"Categorical, Integer",14,5/1/1996,Classification,Yes,451336,"Donor:  Ronny Kohavi and Barry BeckerData Mining and VisualizationSilicon Graphics.e-mail: ronnyk '@' sgi.com for questions.","Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)) Prediction task is to determine whether a person makes over 50K a year.","Listing of attributes: >50K, <=50K. age: continuous.workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.fnlwgt: continuous.education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.education-num: continuous.marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.sex: Female, Male.capital-gain: continuous.capital-loss: continuous.hours-per-week: continuous.native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.","Ron Kohavi, ""Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid"", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996[Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Rakesh Agrawal and Ramakrishnan ikant and Dilys Thomas. Privacy Preserving OLAP. SIGMOD Conference. 2005.  [View Context].Manuel Oliveira. Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted. University of Alberta Library. 2005.  [View Context].Aristides Gionis and Heikki Mannila and Panayiotis Tsaparas. Clustering Aggregation. ICDE. 2005.  [View Context].Dan Pelleg. Scalable and Practical Probability Density Estimators for Scientific Anomaly Detection. School of Computer Science Carnegie Mellon University. 2004.  [View Context].Ke Wang and Shiyu Zhou and Ada Wai-Chee Fu and Jeffrey Xu Yu. Mining Changes of Classification by Correspondence Tracing. SDM. 2003.  [View Context].Douglas Burdick and Manuel Calimlim and Jason Flannick and Johannes Gehrke and Tomi Yiu. MAFIA: A Performance Study of Mining Maximal Frequent Itemsets. FIMI. 2003.  [View Context].Bart Hamers and J. A. K Suykens. Coupled Transductive Ensemble Learning of Kernel Models. Bart De Moor. 2003.  [View Context].Eibe Frank and Geoffrey Holmes and Richard Kirkby and Mark A. Hall. Racing Committees for Large Datasets. Discovery Science. 2002.  [View Context].James Bailey and Thomas Manoukian and Kotagiri Ramamohanarao. Fast Algorithms for Mining Emerging Patterns. PKDD. 2002.  [View Context].Dennis P. Groth and Edward L. Robertson. An Entropy-based Approach to Visualizing Database Structure. VDB. 2002.  [View Context].Dan Pelleg and Andrew W. Moore. Mixtures of Rectangles: Interpretable Soft Clustering. ICML. 2001.  [View Context].Stephen D. Bay. Multivariate Discretization for Set Mining. Knowl. Inf. Syst, 3. 2001.  [View Context].Zhiyuan Chen and Johannes Gehrke and Flip Korn. Query Optimization In Compressed Database Systems. SIGMOD Conference. 2001.  [View Context].Stephen D. Bay and Michael J. Pazzani. Detecting Group Differences: Mining Contrast Sets. Data Min. Knowl. Discov, 5. 2001.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. DeEPs: A New Instance-based Discovery and Classification System. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001.  [View Context].Jie Cheng and Russell Greiner. Comparing Bayesian Network Classifiers. UAI. 1999.  [View Context].John C. Platt. Using Analytic QP and Sparseness to Speed Training of Support Vector Machines. NIPS. 1998.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Gabor Melli. A Lazy Model-Based Approach to On-Line Classification. University of British Columbia. 1989.  [View Context].David R. Musicant and Alexander Feinberg. Active Set Support Vector Regression.  [View Context].David R. Musicant. DATA MINING VIA MATHEMATICAL PROGRAMMING AND MACHINE LEARNING. Doctor of Philosophy (Computer Sciences) UNIVERSITY.  [View Context].Chris Giannella and Bassem Sayrafi. An Information Theoretic Histogram for Single Dimensional Selectivity Estimation. Department of Computer Science, Indiana University Bloomington.  [View Context].Masahiro Terabe and Takashi Washio and Hiroshi Motoda. The Effect of Subsampling Rate on S 3 Bagging Performance. Mitsubishi Research Institute.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/EEG+Database,65,EEG Database Data Set,../machine-learning-databases/eeg-mld/,"Multivariate, Time-Series",122,Life,"Categorical, Integer, Real",4,10/13/1999,N/A,Yes,211042,"Original Owner: Henri BegleiterNeurodynamics Laboratory, State University of New York Health CenterBrooklyn, New York Donor: Lester IngberPOB 06440 Sears TowerChicago, IL 60606ingber '@' ingber.com http://www.ingber.com/  ","This data arises from a large study to examine EEG correlates of genetic predisposition to alcoholism. It contains measurements from 64 electrodes placed on subject's scalps which were sampled at 256 Hz (3.9-msec epoch) for 1 second.  There were two groups of subjects: alcoholic and control. Each subject was exposed to either a single stimulus (S1) or to two stimuli (S1 and S2) which were pictures of objects chosen from the 1980 Snodgrass and Vanderwart picture set. When two stimuli were shown, they were presented in either a matched condition where S1 was identical to S2 or in a non-matched condition where S1 differed from S2.  Shown here are example plots of a control ([Web Link]) and alcoholic ([Web Link]) subject. The plots indicate voltage, time, and channel and are averaged over 10 trials for the single stimulus condition.  There were 122 subjects and each subject completed 120 trials where different stimuli were shown. The electrode positions were located at standard sites (Standard Electrode Position Nomenclature, American Electroencephalographic Association 1990). Zhang et al. (1995) describes in detail the data collection process.  There are three versions of the EEG data set.  1. The Small Data SetThe small data set (smni97_eeg_data.tar.gz) contains data for the 2 subjects, alcoholic a_co2a0000364 and control c_co2c0000337. For each of the 3 matching paradigms, c_1 (one presentation only), c_m (match to previous presentation) and c_n (no-match to previous presentation), 10 runs are shown.  2.  The Large Data SetThe large data set (SMNI_CMI_TRAIN.tar.gz and SMNI_CMI_TEST.tar.gz) contains data for 10 alcoholic and 10 control subjects, with 10 runs per subject per paradigm. The test data used the same 10 alcoholic and 10 control subjects as with the training data, but with 10 out-of-sample runs per subject per paradigm.  3. The Full Data SetThis data set contains all 120 trials for 122 subjects. The entire set of data is about 700 MBytes.  NOTE: There are 17 trials with empty files in co2c1000367. Some trials have ""err"" notices, e.g., search/grep for ""err"" and see ""S2 match err"" or ""S2 nomatch err"" etc. ","Each trial is stored in its own file and will appear in the following format.  # co2a0000364.rd# 120 trials, 64 chans, 416 samples 368 post_stim samples# 3.906000 msecs uV# S1 obj , trial 0# FP1 chan 00 FP1 0 -8.9210 FP1 1 -8.4330 FP1 2 -2.5740 FP1 3 5.2390 FP1 4 11.5870 FP1 5 14.028     ... The first four lines are header information. Line 1 contains the subject identifier and indicates if the subject was an alcholic (a) or control (c) subject by the fourth letter. Line 4 identifies the matching conditions: a single object shown (S1 obj), object 2 shown in a matching condition (S2 match), and object 2 shown in a non matching condition (S2 nomatch).  Line 5 identifies the start of the data from sensor FP1. The four columns of data are: the trial number, sensor position, sample number (0-255), and sensor value (in micro volts).  ","X.L. Zhang, H. Begleiter, B. Porjesz, W. Wang, and A. Litke. (1995). ""Event related potentials during object recognition tasks"". Brain Research Bulletin. Volume 38. Number 6. Pages 531-538. [Web Link]  L. Ingber. (1997). Statistical mechanics of neocortical interactions: Canonical momenta indicators of electroencephalography. Physical Review E. Volume 55. Number 4. Pages 4578-4593. [Web Link]  L. Ingber. (1998). Statistical mechanics of neocortical interactions: Training and testing canonical momenta indicators of EEG. Mathematical Computer Modelling. Volume 27. Number 3. Pages 33-64. [Web Link]  J. G. Snodgrss and M. Vanderwart. (1980). ""A standardized set of 260 pictures: norms for the naming agreement, familiarity, and visual complexity."" Journal of Experimental Psychology: Human Learning and Memory. Volume 6. Pages 174-215. [Web Link]","There are no usage restrictions on this data.  Acknowledgments for this data should made to Henri Begleiter at the Neurodynamics Laboratory at the State University of New York Health Center at Brooklyn.  Plots are courtesy of Roger Gabriel. ","Peter Sykacek and Stephen J. Roberts. Adaptive Classification by Variational Kalman Filtering. NIPS. 2002.  [View Context].Stephen D. Bay and Dennis F. Kibler and Michael J. Pazzani and Padhraic Smyth. The UCI KDD Archive of Large Data Sets for Data Mining Research and Experimentation. SIGKDD Explorations, 2. 2000.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Knight%29,66,Chess (King-Rook vs. King-Knight) Data Set,../machine-learning-databases/chess/king-rook-vs-king-knight/,"Multivariate, Data-Generator",N/A,Game,"Categorical, Integer",22,10/3/1988,Classification,No,72291,"Database originally described by Ross Quinlan. Donor/Coder:  Jeff Schlimmer (Jeff.Schlimmer '@' cs.cmu.edu)","The companion file is a Common Lisp demonstration file that generates knight-pin Chess end-game samples.  Start up Lisp and load the file. It generates 100 end-games and writes them to a separate file.  Look at the end of the file to see how to change it so that it will produce more end-games, or use the file for output that you wish. The code is released for experimental, confidential use only. See the end of the file for load-time commands that generate a file of examples in Quinlan's format. Note: this program generates duplicates.  In one run, there were about 370 duplicates in the first 1000 instances (i.e., 630 distinct examples).","Attribute Summaries:    Class: knight's side is lost in n-ply (n=2, 3, etc)    1. distance from black king to knight: 		    1, 2, >2    2. distance from black king to rook: 			    1, 2, >2    3. distance from black king to white king: 		    1, 2, >2    4. distance from white king to knight: 		    1, 2, >2    5. distance from white king to rook: 			    1, 2, >2    6. distance from rook to knight (ADDED): 		    1, 2, >2    7. board relationship of black king and knight (ADDED):  diag, rect, other    8. board relationship of black king and rook (ADDED):    diag, rect, other    9. board relationship of black king and white king (ADDED): diag,rect,other   10. board relationship of white king and knight (ADDED):  diag, rect, other   11. board relationship of white king and rook (ADDED):    diag, rect, other   12. board relationship of white rook and knight (ADDED):  diag, rect, other   13. type of black king's initial square:		    corner, edge, open   14. type of black knight's initial square (ADDED):	    corner, edge, open   15. type of white king's initial square (ADDED):	    corner, edge, open   16. type of white rook's initial square (ADDED):	    corner, edge, open   17. rook checks black king (OMITTED, always f):	    t, f   18. rook threatens knight (OMITTED, always t):	    t, f   19. knight threatens rook (OMITTED, always f):	    t, f   20. black king, knight, rook in line (OMITTED, always t) t, f   21. black king can move adjacent to knight (OMITTED)	    t, f   22. knight can interpose adjacent to king (OMITTED)	    t, f","Quinlan, J.R. (1983).  Learning Efficient Classification Procedures and Their Application to Chess End Games.  In R.S. Michalski, J.G. Carbonell, & T.M. Mitchell (Eds.), Machine Learning -- An Artificial Intelligence Approach, 463-482, Palo Alto: Tioga.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Manuel Oliveira. Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted. University of Alberta Library. 2005.  [View Context].Marcus Hutter and Marco Zaffalon. Distribution of Mutual Information from Complete and Incomplete Data. CoRR, csLG/0403025. 2004.  [View Context].Ira Cohen and Fabio Gagliardi Cozman and Nicu Sebe and Marcelo Cesar Cirelo and Thomas S. Huang. Semisupervised Learning of Classifiers: Theory, Algorithms, and Their Application to Human-Computer Interaction. IEEE Trans. Pattern Anal. Mach. Intell, 26. 2004.  [View Context].Douglas Burdick and Manuel Calimlim and Jason Flannick and Johannes Gehrke and Tomi Yiu. MAFIA: A Performance Study of Mining Maximal Frequent Itemsets. FIMI. 2003.  [View Context].Russell Greiner and Wei Zhou. Structural Extension to Logistic Regression: Discriminative Parameter Learning of Belief Net Classifiers. AAAI/IAAI. 2002.  [View Context].Tanzeem Choudhury and James M. Rehg and Vladimir Pavlovic and Alex Pentland. Boosting and Structure Learning in Dynamic Bayesian Networks for Audio-Visual Speaker Detection. ICPR (3). 2002.  [View Context].Marco Zaffalon and Marcus Hutter. Robust Feature Selection by Mutual Information Distributions. CoRR, csAI/0206006. 2002.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].James Bailey and Thomas Manoukian and Kotagiri Ramamohanarao. Fast Algorithms for Mining Emerging Patterns. PKDD. 2002.  [View Context].Jie Cheng and Russell Greiner. Learning Bayesian Belief Network Classifiers: Algorithms and System. Canadian Conference on AI. 2001.  [View Context].Boonserm Kijsirikul and Sukree Sinthupinyo and Kongsak Chongkasemwongse. Approximate Match of Rules Using Backpropagation Neural Networks. Machine Learning, 44. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. DeEPs: A New Instance-based Discovery and Classification System. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao. Instance-Based Classification by Emerging Patterns. PKDD. 2000.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].Adam J. Grove and Dale Schuurmans. Boosting in the Limit: Maximizing the Margin of Learned Ensembles. AAAI/IAAI. 1998.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Brian R. Gaines. Structured and Unstructured Induction with EDAGs. KDD. 1995.  [View Context].Ron Kohavi and Dan Sommerfield. Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology. KDD. 1995.  [View Context].Grigorios Tsoumakas and Ioannis P. Vlahavas. Fuzzy Meta-Learning: Preliminary Results. Greek Secretariat for Research and Technology.  [View Context].Nikunj C. Oza and Stuart J. Russell. Online Bagging and Boosting. Computer Science Division University of California.  [View Context].Hankil Yoon and Khaled A. Alsabti and Sanjay Ranka. Tree-based Incremental Classification for Large Datasets. CISE Department, University of Florida.  [View Context].Omid Madani and David M. Pennock and Gary William Flake. Co-Validation: Using Model Disagreement to Validate Classification Algorithms. Yahoo! Research Labs.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context].BayesianClassifi552 Pat Langley and Wayne Iba. In Proceedings of the Tenth National ConferenceonArtifi256 Intelligence( 42840. Lambda Kevin Thompson.  [View Context].Jerome H. Friedman and Ron Kohavi and Youngkeol Yun. To appear in AAAI-96 Lazy Decision Trees. Statistics Department and Stanford Linear Accelerator Center Stanford University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Heterogeneity+Activity+Recognition,67,Heterogeneity Activity Recognition Data Set,../machine-learning-databases/00344/,"Multivariate, Time-Series",43930257,Computer,Real,16,10/26/2015,"Classification, Clustering",Yes,102017,"Allan Stisen, allans, '@' cs.au.dk, Aarhus University, Denmark Henrik Blunck, blunck '@' cs.au.dk, Aarhus University, Denmark Sourav Bhattacharya, sourav.bhattacharya '@' bell-labs.com, Bell Laboratories, Dublin, Ireland Thor Siiger Prentow, prentow '@' cs.au.dk, Aarhus University, Denmark Mikkel Baun Kjærgaard, mikkelbk '@' cs.au.dk, Aarhus University, Denmark Anind Dey, anind '@' cs.cmu.edu, Carnegie Mellon University, USA Tobias Sonne,tsonne '@' cs.au.dk, Aarhus University, Denmark Mads Møller Jensen, mmjensen '@' cs.au.dk , Aarhus University, Denmark","The Heterogeneity Dataset for Human Activity Recognition from Smartphone and Smartwatch sensors consists of two datasets devised to investigate sensor heterogeneities' impacts on human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc). The datasets were used for the results and analyses produced in [1]. Activity recognition data setThe dataset contains the readings of two motion sensors commonly found in smartphones. Reading were recorded while users executed activities scripted in no specific order carrying smartwatches and smartphones.Activities: ‘Biking’, ‘Sitting’, ‘Standing’, ‘Walking’, ‘Stair Up’ and ‘Stair down’.Sensors: Sensors: Two embedded sensors, i.e., Accelerometer and Gyroscope, sampled at the highest frequency the respective device allows.Devices: 4 smartwatches (2 LG watches, 2 Samsung Galaxy Gears)8 smartphones (2 Samsung Galaxy S3 mini, 2 Samsung Galaxy S3, 2 LG Nexus 4, 2 Samsung Galaxy S+)Recordings: 9 users  Recording scenario===============The activity recognition environment and scenario has been designed to generate many activity primitives, yet in a realistic manner. Users took 2 different routes for the biking and walking, and 2 different set of stairs were used for the stairs up and down. Still experiment data set===================Accelerometer recordings as above but with devices lying still, in 6 different orientations. Devices used comprise 31 smartphones, 4 smartwatches and 1 tablet, representing 13 different models from 4 manufacturers, running variants of Android and iOS.","Activity recognition data set accelerometer Samples ------------ The Phones_accelerometer.csv contains all smartphone accelerometer samples from all devices and users. The csv file consist of the following columns: 'Index', 'Arrival_Time', 'Creation_Time', 'x', 'y', 'z', 'User', 'Model', 'Device', 'gt' All samples from all the experiments is a row in the file containing each column value. ------------- Groundtruths -------------------- The null class is defined as null in the gt (groundtruth) column, whereas the rest of the classes can be seen in the column. ------------- Devices -------------------------- the phones from the still experiment which has been used for activity recognition is the following: â€˜it-116', 'it-133', 'it-108', 'it-103','it-123','3Renault-AH', 'no-name/LG-Nexus4','G-Watch' The device numbering used in the data set is: LG-Nexus 4 'nexus4_1' 'nexus4_2' Saumsung Galaxy S3 's3_1' 's3_2â€™ Samsung Galaxy S3 min: 's3mini_1' 's3mini_2' Samsung Galaxy S+: 'samsungold_1' 'samsungold_2' Still experiment data set This is the Heterogeneity Dataset for Human Activity Recognition, and contains all the samples from the static still experiment. Where the phones where place in the 6 different possible orientation. The data set is structured in the following way: ------------- Static Accelerometer Samples ------------ Each specific device is located in the following way: Orientation/[Web Link] Where the 6 different orientations can be either one of the following: Phoneonback,Phoneonbottom,Phoneonfront,Phoneonleft,Phoneonright,Phoneontop For example to get the samples from the device named 3Renault-AH of the model Samsung-Galaxy-S3 Mini when laying static on the back we get the following structure: Phoneonback/3Renault-AH/Samsung-Galaxy-S3 Mini.csv. Each CSV file consist of 6 columns creation time, sensor time,arrival time,x,y,z. The six axes from the accelerometer is the x,y,z columns. ","[1] Allan Stisen, Henrik Blunck, Sourav Bhattacharya, Thor Siiger Prentow, Mikkel Baun Kjærgaard, Anind Dey, Tobias Sonne, and Mads Møller Jensen ""Smart Devices are Different: Assessing and Mitigating Mobile Sensing Heterogeneities for Activity Recognition"" In Proc. 13th ACM Conference on Embedded Networked Sensor Systems (SenSys 2015), Seoul, Korea, 2015. [Web Link]","Use of this dataset in publications should be acknowledged by referencing publication [1]. We recommend to refer to this dataset as the ""Heterogeneity Human Activity Recognition Dataset"" or HHAR for short in publications. We also appreciate if you drop us an email (allans '@' cs.au.dk or blunck ‘@’ cs.au.dk) to inform us of any publication using this dataset or if you have further question about the dataset and how to make use of it. Reference [1] details the dataset, recording scenarios, multimodality and sensor aspects of the setup as well as quality metrics for evaluating heterogeneities and their impact on HAR.",
http://archive.ics.uci.edu/ml/datasets/Nomao,68,Nomao Data Set,../machine-learning-databases/00227/,Univariate,34465,Computer,Real,120,7/4/2012,Classification,Yes,52075,"(a) Original owner of database (name / phone / snail address / email address)Nomao / 00 33 5 62 48 33 90 / 1 avenue Jean Rieux, 31500 Toulouse / challenge '@' nomao.com (b) Donor of database (name / phone / snail address / email address) Laurent Candillier / - /  1 avenue Jean Rieux, 31500 Toulouse  / laurent '@' nomao.com","The dataset has been enriched during the Nomao Challenge:[Web Link] organized along with the ALRA workshop (Active Learning in Real-world Applications):[Web Link] held at the ECML-PKDD 2012 conference.","120 attributes: 89 continuous, 31 nominal (including the attributes 'label' and 'id').","@inproceedings{nomaochallenge-ecml,  author={Laurent Candillier and Vincent Lemaire},  title={Design and Analysis of the Nomao Challenge - Active Learning in the Real-World},  booktitle={Proceedings of the ALRA : Active Learning in Real-world Applications, Workshop ECML-PKDD 2012, Friday, September 28, 2012, Bristol, UK},  year = 2012,  pages={to appear}}","Thanks to Nomao Labs for opening its data:[Web Link]",
http://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection,69,Reuters-21578 Text Categorization Collection Data Set,../machine-learning-databases/reuters21578-mld/,Text,21578,N/A,Categorical,5,9/26/1997,Classification,N/A,189716,"David D. LewisAT&T Labs - Research     lewis '@' research.att.com  Documents came from Reuters newswire in 1987.","From the original readme file (please consult it for more information):-------------------------The documents in the Reuters-21578 collection appeared on the Reuters newswire in 1987.  The documents were assembled and indexed with categories by personnel from Reuters Ltd. (Sam Dobbins, Mike Topliss, Steve Weinstein) and Carnegie Group, Inc. (Peggy Andersen, Monica Cellio, Phil Hayes, Laura Knecht, Irene Nirenburg) in 1987.   In 1990, the documents were made available by Reuters and CGI for research purposes to the Information Retrieval Laboratory (W.  Bruce Croft, Director) of the Computer and Information Science Department at the University of Massachusetts at Amherst.  Formatting of the documents and production of associated data files was done in 1990 by David D.  Lewis and Stephen Harding at the Information Retrieval Laboratory. Further formatting and data file production was done in 1991 and 1992 by David D. Lewis and Peter Shoemaker at the Center for Information and Language Studies, University of Chicago.  This version of the data was made available for anonymous FTP as ""Reuters-22173, Distribution 1.0"" in January 1993. From 1993 through 1996, Distribution 1.0 was hosted at a succession of FTP sites maintained by the Center for Intelligent Information Retrieval (W. Bruce Croft, Director) of the Computer Science Department at the University of Massachusetts at Amherst. At the ACM SIGIR '96 conference in August, 1996 a group of text categorization researchers discussed how published results on Reuters-22173 could be made more comparable across studies.  It was decided that a new version of collection should be produced with less ambiguous formatting, and including documentation carefully spelling out standard methods of using the collection.  The opportunity would also be used to correct a variety of typographical and other errors in the categorization and formatting of the collection. Steve Finch and David D. Lewis did this cleanup of the collection September through November of 1996, relying heavily on Finch's SGML-tagged version of the collection from an earlier study.  One result of the re-examination of the collection was the removal of 595 documents which were exact duplicates (based on identity of timestamps down to the second) of other documents in the collection. The new collection therefore has only 21,578 documents, and thus is called the Reuters-21578 collection.  This README describes version 1.0 of this new collection, which we refer to as ""Reuters-21578, Distribution 1.0"". In preparing the collection and documentation we have benefited from discussions with Eric Brown, William Cohen, Fred Damerau, Yoram Singer, Amit Singhal, and Yiming Yang, among many others. We thank all the people and organizations listed above for their efforts and support, without which this collection would not exist.","Reuters-21578, Distribution 1.0 includes five files (all-exchanges-strings.lc.txt, all-orgs-strings.lc.txt, all-people-strings.lc.txt, all-places-strings.lc.txt, and all-topics-strings.lc.txt) which list the names of *all* legal categories in each set.  A sixth file, cat-descriptions_120396.txt gives some additional information on the category sets.","Chidanand Apt, Fred Damerau, Sholom M. Weiss. ""Automated Learning of Decision Rules for Text Categorization."" ACM Transactions on Information Systems, 1994.[Web Link]  Chidanand Apt, Fred Damerau, Sholom M. Weiss, ""Toward Language Independent Automated Learning of Text Categorization Models."" SIGIR 1994.[Web Link]  Philip J. Hayes, Peggy M. Anderson, rene B. Nirenburg, Linda M. Schmandt. ""TCS: A Shell for Content-Based Text Categorization."" IEEE Conference on Artificial Intelligence Applications, 1990.[Web Link]  Philip J. Hayes and Steven P. Weinstein. ""CONSTRUE/TIS: A System for Content-Based Indexing of a Database of News Stories.""  Second Annual Conference on Innovative Applications of Artificial Intelligence, 1990.[Web Link]","The copyright for the text of newswire articles and Reuters annotations in the Reuters-21578 collection resides with Reuters Ltd. Reuters Ltd. and Carnegie Group, Inc. have agreed to allow the free distribution of this data *for research purposes only*.   If you publish results based on this data set, please acknowledge its use, refer to the data set by the name ""Reuters-21578, Distribution 1.0"", and inform your readers of the current location of the data set (see ""Availability & Questions"").",Manuel Oliveira. Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted. University of Alberta Library. 2005.  [View Context].David Littau and Daniel Boley. Using Low-Memory Representations to Cluster Very Large Data Sets. SDM. 2003.  [View Context].Bianca Zadrozny and Charles Elkan. Transforming classifier scores into accurate multiclass probability estimates. KDD. 2002.  [View Context].Vijay S. Iyengar and Chidanand Apt and Tong Zhang. Active learning using adaptive resampling. KDD. 2000.  [View Context].Dmitry Pavlov and Jianchang Mao and Byron Dom. Scaling-Up Support Vector Machines Using Boosting Algorithm. ICPR. 2000.  [View Context].Daphne Koller and Mehran Sahami. Toward Optimal Feature Selection. ICML. 1996.  [View Context].Omid Madani and David M. Pennock and Gary William Flake. Co-Validation: Using Model Disagreement to Validate Classification Algorithms. Yahoo! Research Labs.  [View Context].Thomas T. Osugi and M. S. EXPLORATION-BASED ACTIVE MACHINE LEARNING. Faculty of The Graduate College at the University of Nebraska In Partial Fulfillment of Requirements.  [View Context].Vikas Sindhwani and P. Bhattacharya and Subrata Rakshit. Information Theoretic Feature Crediting in Multiclass Support Vector Machines.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Alcohol+QCM+Sensor+Dataset,70,Alcohol QCM Sensor Dataset Data Set,../machine-learning-databases/00496/,Multivariate,125,Computer,Real,8,7/22/2019,"Classification, Regression, Clustering",N/A,44320,"Provide the names, email addresses, institutions, and other contact information of the donors and creators of the data set.M. Fatih ADAK, fatihadak '@' sakarya.edu.tr, Sakarya University, TurkeyPeter Lieberzeit, University of Vienna, AustriaPurim Jarujamrus, Ratchathani University, ThailandNejat Yumusak, Sakarya University, Turkey","In the dataset there are 5 types of dataset.QCM3, QCM6, QCM7, QCM10, QCM12 In each of dataset, There is alcohol classification of five types,1-octanol, 1-propanol, 2-butanol, 2-propanol, 1-isobutanol","The gas sample is passed through the sensor in five different concentrations. These concentrations are, Concentration	Air ratio (ml)	Gas ratio (ml)1       0.799	0.2012	0.700	0.3003	0.600	0.4004	0.501	0.4995	0.400	0.600 There are two channels in the sensor. One of these circles forms channel 1, and the other forms channel 2. MIP and MP ratios used in the QCM sensors are, Sensor name	MIP ratio	NP ratioQCM3	1	1QCM6	1	0QCM7	1	0.5QCM10	1	2QCM12	0	1","M. Fatih Adak, Peter Lieberzeit, Purim Jarujamrus, Nejat Yumusak, Classification of alcohols obtained by QCM sensors with different characteristics using ABC based neural network, Engineering Science and Technology, an International Journal, 2019, , ISSN 2215-0986, [Web Link]. ([Web Link])","M. Fatih Adak, Peter Lieberzeit, Purim Jarujamrus, Nejat Yumusak, Classification of alcohols obtained by QCM sensors with different characteristics using ABC based neural network, Engineering Science and Technology, an International Journal, 2019, , ISSN 2215-0986, [Web Link]. ([Web Link])",
http://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise,71,Airfoil Self-Noise Data Set,../machine-learning-databases/00291/,Multivariate,1503,Physical,Real,6,3/4/2014,Regression,N/A,130841,"Provide the names, email addresses, institutions, and other contact information of the donors and creators of the data set.Donor: Dr Roberto Lopezrobertolopez '@' intelnics.com Intelnics  Creators:Thomas F. Brooks, D. Stuart Pope and Michael A. MarcoliniNASA",The NASA data set comprises different size NACA 0012 airfoils at various wind tunnel speeds and angles of attack. The span of the airfoil and the observer position were the same in all of the experiments. ,"This problem has the following inputs:1. Frequency, in Hertzs. 2. Angle of attack, in degrees. 3. Chord length, in meters.4. Free-stream velocity, in meters per second. 5. Suction side displacement thickness, in meters.  The only output is:6. Scaled sound pressure level, in decibels. ","T.F. Brooks, D.S. Pope, and A.M. Marcolini. Airfoil self-noise and prediction. Technical report, NASA RP-1218, July 1989. K. Lau. A neural networks approach for aerofoil noise prediction. Masterâ€™s thesis, Department of Aeronautics. Imperial College of Science, Technology and Medicine (London, United Kingdom), 2006. R. Lopez.Neural Networks for Variational Problems in Engineering.PhD Thesis, Technical University of Catalonia, 2008. ","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/EBL+Domain+Theories,72,EBL Domain Theories Data Set,../machine-learning-databases/ebl/,N/A,N/A,Computer,N/A,N/A,N/A,N/A,N/A,24237,N/A,N/A,N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Annealing,73,Annealing Data Set,../machine-learning-databases/annealing/,Multivariate,798,Physical,"Categorical, Integer, Real",38,N/A,Classification,Yes,165650,"Donors: David Sterling and Wray Buntine",N/A,"Attribute Listing:    1. family:		--,GB,GK,GS,TN,ZA,ZF,ZH,ZM,ZS    2. product-type:	C, H, G    3. steel:		-,R,A,U,K,M,S,W,V    4. carbon:		continuous    5. hardness:	continuous    6. temper_rolling:	-,T    7. condition:	-,S,A,X    8. formability:	-,1,2,3,4,5    9. strength:	continuous   10. non-ageing:	-,N   11. surface-finish:	P,M,-   12. surface-quality: -,D,E,F,G   13. enamelability:	-,1,2,3,4,5   14. bc:		Y,-   15. bf:		Y,-   16. bt:		Y,-   17. bw/me:		B,M,-   18. bl:		Y,-   19. m:		Y,-   20. chrom:		C,-   21. phos:		P,-   22. cbond:		Y,-   23. marvi:		Y,-   24. exptl:		Y,-   25. ferro:		Y,-   26. corr:		Y,-   27. blue/bright/varn/clean:		B,R,V,C,-   28. lustre:		Y,-   29. jurofm:		Y,-   30. s:		Y,-   31. p:		Y,-   32. shape:		COIL, SHEET   33. thick:		continuous   34. width:		continuous   35. len:		continuous   36. oil:		-,Y,N   37. bore:		0000,0500,0600,0760   38. packing:	-,1,2,3   classes:        1,2,3,4,5,U    -- The '-' values are actually 'not_applicable' values rather than 'missing_values' (and so can be treated as legal discrete values rather than as showing the absence of a discrete value).",N/A,"Please refer to the Machine Learning
Repository's citation policy","Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].Qingping Tao Ph. D. MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004.  [View Context].Jihoon Yang and Rajesh Parekh and Vasant Honavar. DistAl: An inter-pattern distance-based constructive learning algorithm. Intell. Data Anal, 3. 1999.  [View Context].Pedro Domingos. Knowledge Discovery Via Multiple Models. Intell. Data Anal, 2. 1998.  [View Context].James J. Liu and James Tin and Yau Kwok. An Extended Genetic Rule Induction Algorithm. Department of Computer Science Wuhan University.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Devanagari+Handwritten+Character+Dataset,74,Devanagari Handwritten Character Dataset Data Set,../machine-learning-databases/00389/,N/A,92000,Computer,Integer,N/A,9/1/2016,Classification,N/A,27994,"The dataset was created by extraction and manual annotation of thousands of characters from handwritten documents.Creator Name: Shailesh Acharya, Email: sailes437 '@' gmail.com, Institution: University of North Texas, Cell: +19402200157Creator Name: Prashnna Kumar Gyawali, Email: gyawali.prasanna '@' gmail.com, Institution: Rochester Institute of Technology","Data Type: GrayScale Image The image dataset can be used to benchmark classification algorithm for OCR systems. The highest accuracy obtained in the Test set is 98.47%. Model Description is available in the paper [Web Link] More information on the dataset at [Web Link].","Image Format: .pngResolution: 32 by 32Actual character is centered within 28 by 28 pixel, padding of 2 pixel is added on all four sides of actual character.","S. Acharya, A.K. Pant and P.K. Gyawali â€œDeep Learning Based Large Scale Handwritten Devanagari Character Recognitionâ€,In Proceedings of the 9th International Conference on Software, Knowledge, Information Management and Applications (SKIMA), pp. 121-126, 2015.","The material maybe used for free with the following paper cited,S. Acharya, A.K. Pant and P.K. Gyawali â€œDeep Learning Based Large Scale Handwritten Devanagari Character Recognitionâ€,In Proceedings of the 9th International Conference on Software, Knowledge, Information Management and Applications (SKIMA), pp. 121-126, 2015.",
http://archive.ics.uci.edu/ml/datasets/Daily+and+Sports+Activities,75,Daily and Sports Activities Data Set,../machine-learning-databases/00256/,"Multivariate, Time-Series",9120,Computer,Real,5625,7/8/2013,"Classification, Clustering",N/A,188348,"Billur Barshan,Department of Electrical and Electronics Engineering, Bilkent University, TR-06800 Bilkent, Ankara, Turkey    tel: (90-312) 290-2161  fax: (90-312) 266-4192    e-mail : billur`@'ee.bilkent.edu.tr      url: www.ee.bilkent.edu.tr/~billur Kerem Altun, kerem.altun '@' kemerburgaz.edu.tr, kerem.altun '@' gmail.com","Brief Description of the Dataset:---------------------------------Each of the 19 activities is performed by eight subjects (4 female, 4 male, between the ages 20 and 30) for 5 minutes.Total signal duration is 5 minutes for each activity of each subject.The subjects are asked to perform the activities in their own style and were not restricted on how the activities should be performed. For this reason, there are inter-subject variations in the speeds and amplitudes of some activities. The activities are performed at the Bilkent University Sports Hall, in the Electrical and Electronics Engineering Building, and in a flat outdoor area on campus. Sensor units are calibrated to acquire data at 25 Hz sampling frequency. The 5-min signals are divided into 5-sec segments so that 480(=60x8) signal segments are obtained for each activity. The 19 activities are: sitting (A1), standing (A2), lying on back and on right side (A3 and A4), ascending and descending stairs (A5 and A6), standing in an elevator still (A7) and moving around in an elevator (A8), walking in a parking lot (A9), walking on a treadmill with a speed of 4 km/h (in flat and 15 deg inclined positions) (A10 and A11),running on a treadmill with a speed of 8 km/h (A12), exercising on a stepper (A13), exercising on a cross trainer (A14), cycling on an exercise bike in horizontal and vertical positions (A15 and A16),rowing (A17), jumping (A18), and playing basketball (A19). File structure: 19 activities (a) (in the order given above) 8 subjects   (p)60 segments   (s) 5 units on torso (T), right arm (RA), left arm (LA), right leg (RL), left leg (LL) 9 sensors on each unit (x,y,z accelerometers, x,y,z gyroscopes, x,y,z magnetometers) Folders a01, a02, ..., a19 contain data recorded from the 19 activities. For each activity, the subfolders p1, p2, ..., p8 contain data from each of the 8 subjects. In each subfolder, there are 60 text files s01, s02, ..., s60, one for each segment. In each text file, there are 5 units x 9 sensors = 45 columns and 5 sec x 25 Hz = 125 rows.Each column contains the 125 samples of data acquired from one of the sensors of one of the units over a period of 5 sec.Each row contains data acquired from all of the 45 sensor axes at a particular sampling instant separated by commas. Columns 1-45 correspond to:   T_xacc,  T_yacc,  T_zacc,  T_xgyro, ...,  T_ymag,  T_zmag,RA_xacc, RA_yacc, RA_zacc, RA_xgyro, ..., RA_ymag, RA_zmag,LA_xacc, LA_yacc, LA_zacc, LA_xgyro, ..., LA_ymag, LA_zmag,RL_xacc, RL_yacc, RL_zacc, RL_xgyro, ..., RL_ymag, RL_zmag,LL_xacc, LL_yacc, LL_zacc, LL_xgyro, ..., LL_ymag, LL_zmag. Therefore,columns  1-9  correspond to the sensors in unit 1 (T), columns 10-18 correspond to the sensors in unit 2 (RA), columns 19-27 correspond to the sensors in unit 3 (LA), columns 28-36 correspond to the sensors in unit 4 (RL), columns 37-45 correspond to the sensors in unit 5 (LL). ",Please see the detailed description above.,The papers listed under `Citation Requests' use this dataset.,"K. Altun, B. Barshan, and O. Tunçel,``Comparative study on classifying human activities with miniature inertial and magnetic sensors,''Pattern Recognition, 43(10):3605-3620, October 2010.B. Barshan and M. C. Yüksek, ``Recognizing daily and sports activities in two open source machine learning environments using body-worn sensor units,'' The Computer Journal, 57(11):1649--1667, November 2014.K. Altun and B. Barshan,``Human activity recognition using inertial/magnetic sensor units,'' Proceedings First International Workshop on Human Behavior Understanding (in conjunction with the 20th Int. Conf. on Pattern Recognition), 22 August 2010, Istanbul, Turkey,A. A. Salah, T. Gevers, N. Sebe, A. Vinciarelli (editors), HBU 2010, LNCS 6219, pp.38-51, Springer: Berlin, Heidelberg, 2010.",
http://archive.ics.uci.edu/ml/datasets/Document+Understanding,76,Document Understanding Data Set,../machine-learning-databases/document-understanding,N/A,N/A,N/A,N/A,N/A,11/1/1994,N/A,No,44459,"Owner: Donato MalerbaDipartimento di InformaticaUniversity of Barivia Orabona 470126 Bari - Italyphone: +39 - 80 - 5443269fax: +39 - 80 - 5443196malerbad '@' vm.csata.it  Donor:  Donato Malerba","In the experimentation, 30 single page documents were considered.  They are copies of letters sent by Olivetti. Six trials were performed by randomly selecting 20 documents for the training set and 10 for the test set. Each document is identified by a letter (A to Z) or a pair of letters (AA, AB, AC, AD).    Trial  Training documents     1    A B C D E F G H I J K L M N O P Q R S T     2    C D E F G H I M P R S V X Y W Z AA AB AC AD     3    C D E F G H I J K P R S T U V Y W AA AB AC     4    A B C D E F G J L M N O P Q T V X Z AB AD     5    A B E F G I J K M N O P Q R T V X Z AA AD     6    A B C D E F G I J M Q S T X Y Z AA AB AC AD",N/A,"Malerba D. Document Understanding: A Machine Learning Approach. Technical Report, Esprit Project 5203 INTREPID, 4 March 1993.[Web Link]  Esposito F., Malerba D., Semeraro G., & Pazzani M. A Machine Learning Approach to Document Understanding. Proc. 2nd Int. Workshop on Multistrategy Learning, Harpers Ferry, WV, pp. 276-292, May 1993.[Web Link]  Esposito F., Malerba D., & Semeraro G. Learning Contextual Rules in First-Order Logic. Proc. 4th Italian Workshop on Machine Learning (GAA93), Milan, Italy, pp. 111-127, June 1993. Esposito F., Malerba D., & Semeraro G. Automated Acquisition of Rules for Document Understanding. Proc. of the 2nd Int. Conf. on Document Analysis and Recognition, Tsukuba Science City, Japan, pp. 650-654, October 1993.[Web Link]  Semeraro G., Esposito F., & Malerba D. Learning Contextual Rules for Document Understanding. Proc. 10th IEEE Conf. on Artificial Intelligence for Applications. San Antonio, Texas, pp. 108-115, March 1994.[Web Link]  Esposito F., Malerba D., & Semeraro G. Multistrategy Learning for Document Recognition. Applied Artificial Intelligence, 8, pp. 33-84, 1994[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Tarvel+Review+Ratings,77,Tarvel Review Ratings Data Set,../machine-learning-databases/00485/,"Multivariate, Text",5456,N/A,Real,25,12/19/2018,"Classification, Clustering",N/A,51016,"Shini Renjith, shinirenjith '@' gmail.com",This data set is populated by capturing user ratings from Google reviews. Reviews on attractions from 24 categories across Europe are considered. Google user rating ranges from 1 to 5 and average user rating per category is calculated. ,"Attribute 1 : Unique user idAttribute 2 : Average ratings on churchesAttribute 3 : Average ratings on resortsAttribute 4 : Average ratings on beachesAttribute 5 : Average ratings on parksAttribute 6 : Average ratings on theatresAttribute 7 : Average ratings on museumsAttribute 8 : Average ratings on mallsAttribute 9 : Average ratings on zooAttribute 10 : Average ratings on restaurantsAttribute 11 : Average ratings on pubs/barsAttribute 12 : Average ratings on local servicesAttribute 13 : Average ratings on burger/pizza shopsAttribute 14 : Average ratings on hotels/other lodgingsAttribute 15 : Average ratings on juice barsAttribute 16 : Average ratings on art galleriesAttribute 17 : Average ratings on dance clubsAttribute 18 : Average ratings on swimming poolsAttribute 19 : Average ratings on gymsAttribute 20 : Average ratings on bakeriesAttribute 21 : Average ratings on beauty & spasAttribute 22 : Average ratings on cafesAttribute 23 : Average ratings on view pointsAttribute 24 : Average ratings on monumentsAttribute 25 : Average ratings on gardens","Renjith, Shini, A. Sreekumar, and M. Jathavedan. 2018. â€œEvaluation of Partitioning Clustering Algorithms for Processing Social Media Data in Tourism Domainâ€. In 2018 IEEE Recent Advances in Intelligent Computational Systems (RAICS), 127â€“31. IEEE.","Renjith, Shini, A. Sreekumar, and M. Jathavedan. 2018. â€œEvaluation of Partitioning Clustering Algorithms for Processing Social Media Data in Tourism Domainâ€. In 2018 IEEE Recent Advances in Intelligent Computational Systems (RAICS), 127â€“31. IEEE.",
http://archive.ics.uci.edu/ml/datasets/Arrhythmia,78,Arrhythmia Data Set,../machine-learning-databases/arrhythmia/,Multivariate,452,Life,"Categorical, Integer, Real",279,1/1/1998,Classification,Yes,315309,"Original Owners of Database: 1. H. Altay Guvenir, PhD., Bilkent University,Department of Computer Engineering and Information Science,06533 Ankara, TurkeyPhone: +90 (312) 266 4133Email: guvenir '@' cs.bilkent.edu.tr  2. Burak Acar, M.S.,Bilkent University, EE Eng. Dept. 06533 Ankara, TurkeyEmail: buraka '@' ee.bilkent.edu.tr  3. Haldun Muderrisoglu, M.D., Ph.D., Baskent University, School of MedicineAnkara, Turkey Donor:  H. Altay GuvenirBilkent University,Department of Computer Engineering and Information Science,06533 Ankara, TurkeyPhone: +90 (312) 266 4133Email: guvenir '@' cs.bilkent.edu.tr","This database contains 279 attributes, 206 of which are linear valued and the rest are nominal.  Concerning the study of H. Altay Guvenir: ""The aim is to distinguish between the presence and absence of cardiac arrhythmia and to classify it in one of the 16 groups. Class 01 refers to 'normal' ECG classes 02 to 15 refers to different classes of arrhythmia and class 16 refers to the rest of unclassified ones. For the time being, there exists a computer program that makes such a classification. However there are differences between the cardiolog's and the programs classification. Taking the cardiolog's as a gold standard we aim to minimise this difference by means of machine learning tools."" The names and id numbers of the patients were recently removed from the database. ","   -- Complete attribute documentation:      1 Age: Age in years , linear      2 Sex: Sex (0 = male; 1 = female) , nominal      3 Height: Height in centimeters , linear      4 Weight: Weight in kilograms , linear      5 QRS duration: Average of QRS duration in msec., linear      6 P-R interval: Average duration between onset of P and Q waves in msec., linear      7 Q-T interval: Average duration between onset of Q and offset of T waves in msec., linear      8 T interval: Average duration of T wave in msec., linear      9 P interval: Average duration of P wave in msec., linear      Vector angles in degrees on front plane of:, linear     10 QRS     11 T     12 P     13 QRST     14 J      15 Heart rate: Number of heart beats per minute ,linear      Of channel DI:      Average width, in msec., of: linear      16 Q wave      17 R wave      18 S wave      19 R' wave, small peak just after R      20 S' wave       21 Number of intrinsic deflections, linear       22 Existence of ragged R wave, nominal      23 Existence of diphasic derivation of R wave, nominal      24 Existence of ragged P wave, nominal      25 Existence of diphasic derivation of P wave, nominal      26 Existence of ragged T wave, nominal      27 Existence of diphasic derivation of T wave, nominal      Of channel DII:       28 .. 39 (similar to 16 .. 27 of channel DI)     Of channels DIII:      40 .. 51     Of channel AVR:      52 .. 63     Of channel AVL:      64 .. 75     Of channel AVF:      76 .. 87     Of channel V1:      88 .. 99     Of channel V2:      100 .. 111     Of channel V3:      112 .. 123     Of channel V4:      124 .. 135     Of channel V5:      136 .. 147     Of channel V6:      148 .. 159      Of channel DI:      Amplitude , * 0.1 milivolt, of      160 JJ wave, linear      161 Q wave, linear      162 R wave, linear      163 S wave, linear      164 R' wave, linear      165 S' wave, linear      166 P wave, linear      167 T wave, linear       168 QRSA , Sum of areas of all segments divided by 10, ( Area= width * height / 2 ), linear      169 QRSTA = QRSA + 0.5 * width of T wave * 0.1 * height of T wave. (If T is diphasic then the bigger segment is considered), linear      Of channel DII:      170 .. 179     Of channel DIII:      180 .. 189     Of channel AVR:      190 .. 199     Of channel AVL:      200 .. 209     Of channel AVF:      210 .. 219     Of channel V1:      220 .. 229     Of channel V2:      230 .. 239     Of channel V3:      240 .. 249     Of channel V4:      250 .. 259     Of channel V5:      260 .. 269     Of channel V6:      270 .. 279","H. Altay Guvenir, Burak Acar, Gulsen Demiroz, Ayhan Cekin ""A Supervised Machine Learning Algorithm for Arrhythmia Analysis.""  Proceedings of the Computers in Cardiology Conference, Lund, Sweden, 1997.[Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Krista Lagus and Esa Alhoniemi and Jeremias Seppa and Antti Honkela and Arno Wagner. INDEPENDENT VARIABLE GROUP ANALYSIS IN LEARNING COMPACT REPRESENTATIONS FOR DATA. Neural Networks Research Centre, Helsinki University of Technology.  [View Context].Gisele L. Pappa and Alex Alves Freitas and Celso A A Kaestner. AMultiobjective Genetic Algorithm for Attribute Selection. Computing Laboratory Pontificia Universidade Catolica do Parana University of Kent at Canterbury.  [View Context].Shay Cohen and Eytan Ruppin and Gideon Dror. Feature Selection Based on the Shapley Value. School of Computer Sciences Tel-Aviv University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29,79,Statlog (Australian Credit Approval) Data Set,../machine-learning-databases/statlog/australian/,Multivariate,690,Financial,"Categorical, Integer, Real",14,N/A,Classification,Yes,168169,"(confidential) Submitted by quinlan '@' cs.su.oz.au","This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.","There are 6 numerical and 8 categorical attributes.  The labels have been changed for the convenience of the statistical algorithms.  For example, attribute 4 originally had 3 labels p,g,gg and these have been changed to labels 1,2,3. A1: 0,1    CATEGORICAL (formerly: a,b)A2: continuous.A3: continuous.A4: 1,2,3    CATEGORICAL  (formerly: p,g,gg)A5: 1, 2,3,4,5, 6,7,8,9,10,11,12,13,14    CATEGORICAL (formerly: ff,d,i,k,j,aa,m,c,w, e, q, r,cc, x)A6: 1, 2,3, 4,5,6,7,8,9    CATEGORICAL (formerly: ff,dd,j,bb,v,n,o,h,z)A7: continuous.A8: 1, 0    CATEGORICAL (formerly: t, f)A9: 1, 0	CATEGORICAL (formerly: t, f)A10:  continuous.A11:  1, 0	    CATEGORICAL (formerly t, f)A12:  1, 2, 3    CATEGORICAL (formerly: s, g, p) A13:  continuous.A14:  continuous.A15:   1,2  class attribute (formerly: +,-) ","Ross Quinlan. ""Simplifying decision trees"", Int J Man-Machine Studies 27, Dec 1987, pp. 221-234.[Web Link]  Ross Quinlan. ""C4.5: Programs for Machine Learning"", Morgan Kaufmann, Oct 1992[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Jeroen Eggermont and Joost N. Kok and Walter A. Kosters. Genetic Programming for data classification: partitioning the search space. SAC. 2004.  [View Context].Bart Hamers and J. A. K Suykens. Coupled Transductive Ensemble Learning of Kernel Models. Bart De Moor. 2003.  [View Context].Xiaoming Huo. FBP: A Frontier-Based Tree-Pruning Algorithm. Seoung Bum Kim. 2002.  [View Context].Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. An Implementation of Logical Analysis of Data. IEEE Trans. Knowl. Data Eng, 12. 2000.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Rudy Setiono and Huan Liu. NeuroLinear: From neural networks to oblique decision rules. Neurocomputing, 17. 1997.  [View Context].Wl/odzisl/aw Duch and Karol Grudzi nski and Grzegorz Stawski. SYMBOLIC FEATURES IN NEURAL NETWORKS. Department of Computer Methods, Nicolaus Copernicus University.  [View Context].Hussein A. Abbass. Pareto Neuro-Evolution: Constructing Ensemble of Neural Networks Using Multi-objective Optimization. Artificial Life and Adaptive Robotics (A.L.A.R.) Lab, School of Information Technology and Electrical Engineering, Australian Defence Force Academy.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. THE SEPARABILITY OF SPLIT VALUE CRITERION. Department of Computer Methods, Nicolaus Copernicus University.  [View Context].Bart Baesens and Stijn Viaene and Tony Van Gestel and J. A. K Suykens and Guido Dedene and Bart De Moor and Jan Vanthienen and Katholieke Universiteit Leuven. An Empirical Assessment of Kernel Type Performance for Least Squares Support Vector Machine Classifiers. Dept. Applied Economic Sciences.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Promoter+Gene+Sequences%29,80,Molecular Biology (Promoter Gene Sequences) Data Set,../machine-learning-databases/molecular-biology/promoter-gene-sequences/,"Sequential, Domain-Theory",106,Life,Categorical,58,6/30/1990,Classification,No,78137,"Creators:  1.  promoter instances: C. Harley (CHARLEY '@' McMaster.CA) and R. Reynolds  2. non-promoter instances and domain theory: M. Noordewier-- (non-promoters derived from work of lab of Prof. Tom Record, University of Wisconsin Biochemistry Department) Donor:  M. Noordewier and J. Shavlik, {noordewi,shavlik}@cs.wisc.edu","This dataset has been developed to help evaluate a ""hybrid"" learning algorithm (""KBANN"") that uses examples to inductively refine preexisting knowledge.  Using a ""leave-one-out"" methodology, the following errors were produced by various ML algorithms.  (See Towell, Shavlik, & Noordewier, 1990, for details.) System -- Errors -- Comments ----------------------------------------------------------------KBANN -- 4/106 -- a hybrid ML systemBP --  8/106 -- std backprop with one hidden layerO'Neill -- 12/106  -- ad hoc technique from the bio. lit.Near-Neigh -- 13/106 -- a nearest-neighbor algo (k=3)ID3 -- 19/106 -- Quinlan's decision-tree builder Type of domain: non-numeric, nominal (one of A, G, T, C)  Note: DNA nucleotides can be grouped into a hierarchy, as shown below: 		      X (any)		    /   \	  (purine) R     Y (pyrimidine)		  / \   / \		 A   G T   C  Here is that hierachy in a text-friendly format: X (any). R (purine). . A. . G. Y (pyrimidine). . T. . C","1.   One of {+/-}, indicating the class (""+"" = promoter).2.   The instance name (non-promoters named by position in the 1500-long nucleotide sequence provided by T. Record).3-59.   The remaining 57 fields are the sequence, starting at position -50 (p-50) and ending at position +7 (p7). Each of these fields is filled by one of {a, g, t, c}.","Harley, C. and Reynolds, R. 1987.  ""Analysis of E. Coli Promoter Sequences."" Nucleic Acids Research, 15:2343-2361.[Web Link]  Towell, G., Shavlik, J. and Noordewier, M. 1990. ""Refinement of Approximate Domain Theories by Knowledge-Based Artificial Neural Networks."" In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI-90).[Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.  [View Context].Wei-Chun Kao and Kai-Min Chung and Lucas Assun and Chih-Jen Lin. Decomposition Methods for Linear Support Vector Machines. Neural Computation, 16. 2004.  [View Context].Aik Choon Tan and David Gilbert. An Empirical Comparison of Supervised Machine Learning Techniques in Bioinformatics. APBC. 2003.  [View Context].Giorgio Valentini. Ensemble methods based on bias--variance analysis Theses Series DISI-TH-2003. Dipartimento di Informatica e Scienze dell'Informazione . 2003.  [View Context].Zoubin Ghahramani and Hyun-Chul Kim. Bayesian Classifier Combination. Gatsby Computational Neuroscience Unit University College London. 2003.  [View Context].Jinyan Li and Limsoon Wong. Using Rules to Analyse Bio-medical Data: A Comparison between C4.5 and PCL. WAIM. 2003.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].Mukund Deshpande and George Karypis. Evaluation of Techniques for Classifying Biological Sequences. PAKDD. 2002.  [View Context].Takashi Matsuda and Hiroshi Motoda and Tetsuya Yoshida and Takashi Washio. Mining Patterns from Structured Data by Beam-Wise Graph-Based Induction. Discovery Science. 2002.  [View Context].Marina Meila and Michael I. Jordan. Learning with Mixtures of Trees. Journal of Machine Learning Research, 1. 2000.  [View Context].Mark A. Hall and Lloyd A. Smith. Feature Selection for Machine Learning: Comparing a Correlation-Based Filter Approach to the Wrapper. FLAIRS Conference. 1999.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Jie Cheng and Russell Greiner. Comparing Bayesian Network Classifiers. UAI. 1999.  [View Context].Ismail Taha and Joydeep Ghosh. Symbolic Interpretation of Artificial Neural Networks. IEEE Trans. Knowl. Data Eng, 11. 1999.  [View Context].Cesar Guerra-Salcedo and L. Darrell Whitley. Genetic Approach to Feature Selection for Ensemble Creation. GECCO. 1999.  [View Context].Foster J. Provost and Tom Fawcett and Ron Kohavi. The Case against Accuracy Estimation for Comparing Induction Algorithms. ICML. 1998.  [View Context].Andreas L. Prodromidis. On the Management of Distributed Learning Agents Ph.D. Thesis Proposal CUCS-032-97. Department of Computer Science Columbia University. 1998.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Daphne Koller and Mehran Sahami. Toward Optimal Feature Selection. ICML. 1996.  [View Context].Ron Kohavi and Dan Sommerfield. Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology. KDD. 1995.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Ron Kohavi and Dan Sommerfield. To Appear in KDD-98 Targeting Business Users with Decision Table Classifiers. Data Mining and Visualization Silicon Graphics, Inc.  [View Context].Warodom Geamsakul and Takashi Matsuda and Tetsuya Yoshida and Hiroshi Motoda and Takashi Washio. Constructing a Decision Tree for Graph Structured Data. Institute of Scientific and Industrial Research, Osaka University.  [View Context].Ivor W. Tsang and James T. Kwok. Distance Metric Learning with Kernels. Department of Computer Science Hong Kong University of Science and Technology Clear Water Bay Hong Kong.  [View Context].Norbert Jankowski. Survey of Neural Transfer Functions. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Ron Kohavi and George H. John. Automatic Parameter Selection by Minimizing Estimated Error. Computer Science Dept. Stanford University.  [View Context].Ron Kohavi and Barry G. Becker and Dan Sommerfield. Improving Simple Bayes. Data Mining and Visualization Group Silicon Graphics, Inc.  [View Context].Vikas Sindhwani and P. Bhattacharya and Subrata Rakshit. Information Theoretic Feature Crediting in Multiclass Support Vector Machines.  [View Context].C. esar and Cesar Guerra-Salcedo and Darrell Whitley. Feature Selection Mechanisms for Ensemble Creation : A Genetic Search Perspective. Department of Computer Science Colorado State University.  [View Context].Alain Rakotomamonjy. Analysis of SVM regression bounds for variable ranking. P.S.I CNRS FRE 2645, INSA de Rouen Avenue de l'Universite.  [View Context].Cesar Guerra-Salcedo and Stephen Chen and Darrell Whitley and Sarah Smith. Fast and Accurate Feature Selection Using Hybrid Genetic Strategies. Department of Computer Science Colorado State University.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context].Kuan-ming Lin and Chih-Jen Lin. A Study on Reduced Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Chih-Wei Hsu and Cheng-Ru Lin. A Comparison of Methods for Multi-class Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Rudy Setiono. Extracting M-of-N Rules from Trained Neural Networks. School of Computing National University of Singapore.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Online+Handwritten+Assamese+Characters+Dataset,81,Online Handwritten Assamese Characters Dataset Data Set,../machine-learning-databases/00208/,"Multivariate, Sequential",8235,Computer,Integer,N/A,4/1/2011,Classification,N/A,47303,"Creators: Udayan BaruahÂ¹ Â² and Shyamanta M HazarikaÂ¹ 1.	Department of Computer Science and Engineering	Tezpur University	Assam, India, 784028. udayanbaruah '@' yahoo.co.in  shyamanta '@' ieee.org  2.	Department of Information Technology        Sikkim Manipal Institute of Technology        Sikkim, India, 737136. udayanbaruah '@' yahoo.co.in  Donor:  Udayan BaruahDepartment of Information TechnologySikkim Manipal Institute of TechnologySikkim, India, 737136.udayanbaruah '@' yahoo.co.in ","A dataset of online handwritten assamese characters by collecting samples from 45 writers is created. Each writer contributed 52 basic characters, 10 numerals and 121 assamese conjunct consonants. The total number of entries corresponding to each writer is 183 (= 52 characters + 10 numerals + 121 conjunct consonants). The total number of samples in the dataset is 8235 ( = 45 Ã— 183 ). The handwriting samples were collected on an iball 8060U external digitizing tablet connected to a laptop using its cordless digital stylus pen. The data acquisition program consists of a GUI which shows a box on the screen along with other controls. The writers are instructed to write only inside the acquisition box. The acquisition program records the handwriting as a stream of (X, Y) coordinate points using the appropriate pen position sensor along with the pen-up/pen-down switching. No pressure level was recorded.  The distribution of the dataset consists of 45 folders (one for each writer) and a â€œData_Table.pdfâ€ file. This file contains information about the character id (ID), character name (Label) and actual shape of the character (Char).   Each folder contains 183 text files corresponding to the 183 characters written by a single writer. Each file is named based on the pair (M, N). The text file â€œM.N.txtâ€ represents the character with ID â€œMâ€ written by the writer with ID â€œNâ€. For instance the file â€œ132.10.txtâ€ represents the character with ID â€œ132â€ written by the writer with ID â€œ10â€.  ","1.	Character Name: The first line of each sample is â€œCHARACTER_NAME: Characterâ€. The â€œCharacterâ€ is the Name of any one of the 183 characters listed below:  Here â€œID [i]â€ represents the name of the character with the ID â€œiâ€. ID [1]     = â€œAâ€ID [2]     = â€œAAâ€ID [3]     = â€œEâ€ID [4]     = â€œEEâ€ID [5]     = â€œUâ€ID [6]     = â€œUUâ€ID [7]     = â€œREEâ€ID [8]     = â€œAEâ€ID [9]     = â€œOIâ€ID [10]   = â€œOâ€ID [11]   = â€œOUâ€ID [12]   = â€œKAâ€ID [13]   = â€œKHAâ€ID [14]   = â€œGAâ€ID [15]   = â€œGHAâ€ID [16]   = â€œNGâ€ID [17]   = â€œCAâ€ID [18]   = â€œCCAâ€ID [19]   = â€œJAâ€ID [20]   = â€œJHAâ€ID [21]   = â€œNIYAâ€ID [22]   = â€œMTAâ€ID [23]   = â€œMTHAâ€ID [24]   = â€œMDAâ€ID [25]   = â€œMDHAâ€ID [26]   = â€œMNAâ€ID [27]   = â€œTAâ€ID [28]   = â€œTHAâ€ID [29]   = â€œDAâ€ID [30]   = â€œDHAâ€ID [31]   = â€œNAâ€ID [32]   = â€œPAâ€ID [33]   = â€œPHAâ€ID [34]   = â€œBAâ€ID [35]   = â€œBHAâ€ID [36]   = â€œMAâ€ID [37]   = â€œAJAâ€ID [38]   = â€œRAâ€ID [39]   = â€œLAâ€ID [40]   = â€œWAâ€ID [41]   = â€œTXAâ€ID [42]   = â€œMXAâ€ID [43]   = â€œDXAâ€ID [44]   = â€œHAâ€ID [45]   = â€œKHYAâ€ID [46]   = â€œAYAâ€ID [47]   = â€œDRAâ€ID [48]   = â€œDHRAâ€ID [49]   = â€œKTAâ€ID [50]   = â€œANSRâ€ID [51]   = â€œBXGâ€ID [52]   = â€œCBNâ€ID [53]   = â€œKKâ€ID [54]   = â€œKTâ€ID [55]   = â€œKTTâ€ID [56]   = â€œKSâ€ID [57]   = â€œKLâ€ID [58]   = â€œKMâ€ID [59]   = â€œGLâ€ID [60]   = â€œCCâ€ID [61]   = â€œCCCâ€ID [62]   = â€œJJâ€ID [63]   = â€œJBâ€ID [64]   = â€œBJâ€ID [65]   = â€œGNâ€ID [66]   = â€œTNâ€ID [67]   = â€œJJBâ€ID [68]   = â€œLGâ€ID [69]   = â€œTTâ€ID [70]   = â€œGDHâ€ID [71]   = â€œGMâ€ID [72]   = â€œGHNâ€ID [73]   = â€œMDDâ€ID [74]   = â€œNTâ€ID [75]   = â€œNNâ€ID [76]   = â€œNMMâ€ID [77]   = â€œTTTâ€ID [78]   = â€œTTBâ€ID [79]   = â€œTMâ€ID [80]   = â€œTRâ€ID [81]   = â€œNTTâ€ID [82]   = â€œRRGâ€ID [83]   = â€œNDDâ€ID [84]   = â€œNTHâ€ID [85]   = â€œNDHâ€ID [86]   = â€œNNNâ€ID [87]   = â€œNBâ€ID [88]   = â€œNSâ€ID [89]   = â€œNMâ€ID [90]   = â€œDBâ€ID [91]   = â€œQJâ€ID [92]   = â€œPTTâ€ID [93]   = â€œPLâ€ID [94]   = â€œDVâ€ID [95]   = â€œBLâ€ID [96]   = â€œBDâ€ID [97]   = â€œTBâ€ID [98]   = â€œMMâ€ID [99]   = â€œMVâ€ID [100] = â€œMPâ€ID [101] = â€œMNâ€ID [102] = â€œNTRâ€ID [103] = â€œMBâ€ID [104] = â€œLKâ€ID [105] = â€œMNDâ€ID [106] = â€œFKâ€ID [107] = â€œLDâ€ID [108] = â€œLLâ€ID [109] = â€œLPâ€ID [110] = â€œLTâ€ID [111] = â€œSNâ€ID [112] = â€œSCâ€ID [113] = â€œSMâ€ID [114] = â€œSBâ€ID [115] = â€œFNâ€ID [116] = â€œFTâ€ID [117] = â€œSKâ€ID [118] = â€œSSTHâ€ID [119] = â€œSSMâ€ID [120] = â€œSSNâ€ID [121] = â€œSSBâ€ID [122] = â€œSTâ€ID [123] = â€œSPâ€ID [124] = â€œSPHâ€ID [125] = â€œSTHâ€ID [126] = â€œSKHâ€ID [127] = â€œNGGâ€ID [128] = â€œNGCâ€ID [129] = â€œFPâ€ID [130] = â€œNGNâ€ID [131] = â€œXMâ€ID [132] = â€œNGJâ€ID [133] = â€œMNTHâ€ID [134] = â€œNGKâ€ID [135] = â€œKRâ€ID [136] = â€œTRUâ€ID [137] = â€œBHRâ€ID [138] = â€œTHBâ€ID [139] = â€œDGâ€ID [140] = â€œDGHâ€ID [141] = â€œDDâ€ID [142] = â€œDDHâ€ID [143] = â€œHRâ€ID [144] = â€œGGUâ€ID [145] = â€œGGNâ€ID [146] = â€œNKHâ€ID [147] = â€œNGHâ€ID [148] = â€œNGKHâ€ID [149] = â€œTTHâ€ID [150] = â€œPNâ€ID [151] = â€œHNâ€ID [152] = â€œXNâ€ID [153] = â€œMFâ€ID [154] = â€œBBâ€ID [155] = â€œLBâ€ID [156] = â€œLMâ€ID [157] = â€œBHMâ€ID [158] = â€œMLâ€ID [159] = â€œSLâ€ID [160] = â€œPSâ€ID [161] = â€œKHRâ€ID [162] = â€œGRâ€ID [163] = â€œGHRâ€ID [164] = â€œJRâ€ID [165] = â€œTRRâ€ID [166] = â€œDRRâ€ID [167] = â€œDHRRâ€ID [168] = â€œPRRâ€ID [169] = â€œBRRâ€ID [170] = â€œMRRâ€ID [171] = â€œTSRâ€ID [172] = â€œDSRâ€ID [173] = â€œHRRâ€ID [174] = â€œSUNYAâ€ID [175] = â€œEKâ€ID [176] = â€œDUIâ€ID [177] = â€œTINIâ€ID [178] = â€œCARIâ€ID [179] = â€œPACâ€ID [180] = â€œCAYâ€ID [181] = â€œXATâ€ID [182] = â€œATHâ€ID [183] = â€œNAAâ€ 2.	The total number of strokes in the sample: The total number of strokes used to write a character is represented by the line â€œSTROKE_COUNT: Numberâ€, where â€œNumberâ€ is an integer value. 3.	Sequence of Strokes: Each stroke begins with the â€œPEN_DOWNâ€ information and there is a â€œPEN_UPâ€ information followed by the â€œPEN_DOWNâ€ information between two consecutive strokes. The end of a sample is represented by the â€œPEN_UPâ€ information followed by the â€œEND_CHARACTER: Characterâ€ information. Each stroke consists of a sequence of X and Y coordinates values which are given in the first and the second columns respectively. Corresponding to each pair of values of X and Y coordinates, there are â€œSTYLUS_STATEâ€ and â€œSTROKEâ€ information given in the third and the fourth columns respectively. â€œSTYLUS_STATEâ€ is either 1 or 0. Corresponding to each recorded (X, Y) point, â€œSTYLUS_STATEâ€ is 1 and corresponding to the â€œPEN_UPâ€ information â€œSTYLUS_STATEâ€ is 0. â€œSTYLUS_STATEâ€ is kept blank corresponding to each â€œPEN_DOWNâ€ information. The â€œSTROKEâ€ information represents the serial number of a constituent stroke of a sample. The value of X grows left-to-right and that of Y grows downwards. Coordinates are integer numbers ranging from 0 to 4392 for X and 0 to 4868 for Y respectively. ",Provide references to papers that have cited this data set in the past (if any).,"U. Baruah, S. M. Hazarika, ""A Dataset of Online Handwritten Assamese Characters"", Journal of Information Processing Systems, vol. 11, no. 3, pp. 325-341, 2015.",
http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized,82,Communities and Crime Unnormalized Data Set,../machine-learning-databases/00211/,Multivariate,2215,Social,Real,147,3/2/2011,Regression,Yes,145708,"  -- Creator: Michael Redmond (redmond 'at' lasalle.edu); Computer Science; La Salle University; Philadelphia, PA, 19141, USA    -- culled from 1990 US Census, 1995 US FBI Uniform Crime Report, 1990 US Law Enforcement Management and Administrative Statistics Survey, available from ICPSR at U of Michigan.  -- Donor: Michael Redmond (redmond 'at' lasalle.edu); Computer Science; La Salle University; Philadelphia, PA, 19141, USA","The source datasets needed to be combined via programming. Many variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=125), plus the crime variables which are potential dependent variables. The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units. The crime attributes (N=18) that could be predicted are the 8 crimes considered 'Index Crimes' by the FBI)(Murders, Rape, Robbery, .... ), per capita (actually per 100,000 population) versions of each, and Per Capita Violent Crimes and Per Capita Nonviolent Crimes).  A limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data. The per capita crimes variables were calculated using population values included in the 1995 FBI data (which differ from the 1990 Census values).  The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in missing values for per capita violent crime. Many of these omitted communities were from the midwestern USA (Minnesota, Illinois, and Michigan have many of these).   The per capita nonviolent crime variable was calculated using the sum of crime variables considered non-violent crimes in the United States: burglaries, larcenies, auto thefts and arsons. (There are many other types of crimes, these only include FBI 'Index Crimes') Some further pre-processing of the dataset must be done. Choose the desirable dependent variable from among the 18 possible. It would not be interesting or appropriate to predict total crime (e.g. violent crime) while including subtotals (e.g. murders) as independent variables. There are also identifying variables (community name, county code, community code) that are not predictive, and would get in the way of some algorithms. Weka's Unsupervised Attribute Remove Filter can be used to remove unwanted attributes. The FBI notes that use of this data to evaluate communities is over-simplistic, as many relevant factors are not included. For one example, communities with large numbers of visitors will have higher per capita crime (measured by residents) than communities with fewer visitors, other things being equal. ","(125 predictive, 4 non-predictive, 18 potential goal)  -- communityname: Community name - not predictive - for information only (string)  -- state: US state (by 2 letter postal abbreviation)(nominal)   -- countyCode: numeric code for county - not predictive, and many missing values (numeric)  -- communityCode: numeric code for community - not predictive and many missing values (numeric)   -- fold: fold number for non-random 10 fold cross validation, potentially useful for debugging, paired tests - not predictive (numeric - integer)   -- population: population for community: (numeric - expected to be integer)  -- householdsize: mean people per household (numeric - decimal)  -- racepctblack: percentage of population that is african american (numeric - decimal)  -- racePctWhite: percentage of population that is caucasian (numeric - decimal)  -- racePctAsian: percentage of population that is of asian heritage (numeric - decimal)  -- racePctHisp: percentage of population that is of hispanic heritage (numeric - decimal)  -- agePct12t21: percentage of population that is 12-21 in age (numeric - decimal)  -- agePct12t29: percentage of population that is 12-29 in age (numeric - decimal)  -- agePct16t24: percentage of population that is 16-24 in age (numeric - decimal)  -- agePct65up: percentage of population that is 65 and over in age (numeric - decimal)  -- numbUrban: number of people living in areas classified as urban (numeric - expected to be integer)  -- pctUrban: percentage of people living in areas classified as urban (numeric - decimal)  -- medIncome: median household income (numeric - may be integer)  -- pctWWage: percentage of households with wage or salary income in 1989 (numeric - decimal)  -- pctWFarmSelf: percentage of households with farm or self employment income in 1989 (numeric - decimal)  -- pctWInvInc: percentage of households with investment / rent income in 1989 (numeric - decimal)  -- pctWSocSec: percentage of households with social security income in 1989 (numeric - decimal)  -- pctWPubAsst: percentage of households with public assistance income in 1989 (numeric - decimal)  -- pctWRetire: percentage of households with retirement income in 1989 (numeric - decimal)  -- medFamInc: median family income (differs from household income for non-family households) (numeric - may be integer)  -- perCapInc: per capita income (numeric - decimal)  -- whitePerCap: per capita income for caucasians (numeric - decimal)  -- blackPerCap: per capita income for african americans (numeric - decimal)  -- indianPerCap: per capita income for native americans (numeric - decimal)  -- AsianPerCap: per capita income for people with asian heritage (numeric - decimal)  -- OtherPerCap: per capita income for people with 'other' heritage (numeric - decimal)  -- HispPerCap: per capita income for people with hispanic heritage (numeric - decimal)  -- NumUnderPov: number of people under the poverty level (numeric - expected to be integer)  -- PctPopUnderPov: percentage of people under the poverty level (numeric - decimal)  -- PctLess9thGrade: percentage of people 25 and over with less than a 9th grade education (numeric - decimal)  -- PctNotHSGrad: percentage of people 25 and over that are not high school graduates (numeric - decimal)  -- PctBSorMore: percentage of people 25 and over with a bachelors degree or higher education (numeric - decimal)  -- PctUnemployed: percentage of people 16 and over, in the labor force, and unemployed (numeric - decimal)  -- PctEmploy: percentage of people 16 and over who are employed (numeric - decimal)  -- PctEmplManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)  -- PctEmplProfServ: percentage of people 16 and over who are employed in professional services (numeric - decimal)  -- PctOccupManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)   #### No longer sure of difference from PctEmplManu - may include unemployed manufacturing workers ####  -- PctOccupMgmtProf: percentage of people 16 and over who are employed in management or professional occupations (numeric - decimal)  -- MalePctDivorce: percentage of males who are divorced (numeric - decimal)  -- MalePctNevMarr: percentage of males who have never married (numeric - decimal)  -- FemalePctDiv: percentage of females who are divorced (numeric - decimal)  -- TotalPctDiv: percentage of population who are divorced (numeric - decimal)  -- PersPerFam: mean number of people per family (numeric - decimal)  -- PctFam2Par: percentage of families (with kids) that are headed by two parents (numeric - decimal)  -- PctKids2Par: percentage of kids in family housing with two parents (numeric - decimal)  -- PctYoungKids2Par: percent of kids 4 and under in two parent households (numeric - decimal)  -- PctTeen2Par: percent of kids age 12-17 in two parent households (numeric - decimal)  -- PctWorkMomYoungKids: percentage of moms of kids 6 and under in labor force (numeric - decimal)  -- PctWorkMom: percentage of moms of kids under 18 in labor force (numeric - decimal)  -- NumKidsBornNeverMar: number of kids born to never married (numeric - expected to be integer)  -- PctKidsBornNeverMar: percentage of kids born to never married (numeric - decimal)  -- NumImmig: total number of people known to be foreign born (numeric - expected to be integer)  -- PctImmigRecent: percentage of _immigrants_ who immigated within last 3 years (numeric - decimal)  -- PctImmigRec5: percentage of _immigrants_ who immigated within last 5 years (numeric - decimal)  -- PctImmigRec8: percentage of _immigrants_ who immigated within last 8 years (numeric - decimal)  -- PctImmigRec10: percentage of _immigrants_ who immigated within last 10 years (numeric - decimal)  -- PctRecentImmig: percent of _population_ who have immigrated within the last 3 years (numeric - decimal)  -- PctRecImmig5: percent of _population_ who have immigrated within the last 5 years (numeric - decimal)  -- PctRecImmig8: percent of _population_ who have immigrated within the last 8 years (numeric - decimal)  -- PctRecImmig10: percent of _population_ who have immigrated within the last 10 years (numeric - decimal)  -- PctSpeakEnglOnly: percent of people who speak only English (numeric - decimal)  -- PctNotSpeakEnglWell: percent of people who do not speak English well (numeric - decimal)  -- PctLargHouseFam: percent of family households that are large (6 or more) (numeric - decimal)  -- PctLargHouseOccup: percent of all occupied households that are large (6 or more people) (numeric - decimal)  -- PersPerOccupHous: mean persons per household (numeric - decimal)  -- PersPerOwnOccHous: mean persons per owner occupied household (numeric - decimal)  -- PersPerRentOccHous: mean persons per rental household (numeric - decimal)  -- PctPersOwnOccup: percent of people in owner occupied households (numeric - decimal)  -- PctPersDenseHous: percent of persons in dense housing (more than 1 person per room) (numeric - decimal)  -- PctHousLess3BR: percent of housing units with less than 3 bedrooms (numeric - decimal)  -- MedNumBR: median number of bedrooms (numeric - decimal)  -- HousVacant: number of vacant households (numeric - expected to be integer)  -- PctHousOccup: percent of housing occupied (numeric - decimal)  -- PctHousOwnOcc: percent of households owner occupied (numeric - decimal)  -- PctVacantBoarded: percent of vacant housing that is boarded up (numeric - decimal)  -- PctVacMore6Mos: percent of vacant housing that has been vacant more than 6 months (numeric - decimal)  -- MedYrHousBuilt: median year housing units built (numeric - may be integer)  -- PctHousNoPhone: percent of occupied housing units without phone (in 1990, this was rare!) (numeric - decimal)  -- PctWOFullPlumb: percent of housing without complete plumbing facilities (numeric - decimal)  -- OwnOccLowQuart: owner occupied housing - lower quartile value (numeric - decimal)  -- OwnOccMedVal: owner occupied housing - median value (numeric - decimal)  -- OwnOccHiQuart: owner occupied housing - upper quartile value (numeric - decimal)  -- OwnOccQrange: owner occupied housing - difference between upper quartile and lower quartile values (numeric - decimal)  -- RentLowQ: rental housing - lower quartile rent (numeric - decimal)  -- RentMedian: rental housing - median rent (Census variable H32B from file STF1A) (numeric - decimal)  -- RentHighQ: rental housing - upper quartile rent (numeric - decimal)  -- RentQrange: rental housing - difference between upper quartile and lower quartile rent (numeric - decimal)  -- MedRent: median gross rent (Census variable H43A from file STF3A - includes utilities) (numeric - decimal)  -- MedRentPctHousInc: median gross rent as a percentage of household income (numeric - decimal)  -- MedOwnCostPctInc: median owners cost as a percentage of household income - for owners with a mortgage (numeric - decimal)  -- MedOwnCostPctIncNoMtg: median owners cost as a percentage of household income - for owners without a mortgage (numeric - decimal)  -- NumInShelters: number of people in homeless shelters (numeric - expected to be integer)  -- NumStreet: number of homeless people counted in the street (numeric - expected to be integer)  -- PctForeignBorn: percent of people foreign born (numeric - decimal)  -- PctBornSameState: percent of people born in the same state as currently living (numeric - decimal)  -- PctSameHouse85: percent of people living in the same house as in 1985 (5 years before) (numeric - decimal)  -- PctSameCity85: percent of people living in the same city as in 1985 (5 years before) (numeric - decimal)  -- PctSameState85: percent of people living in the same state as in 1985 (5 years before) (numeric - decimal)  -- LemasSwornFT: number of sworn full time police officers (numeric - expected to be integer)  -- LemasSwFTPerPop: sworn full time police officers per 100K population (numeric - decimal)  -- LemasSwFTFieldOps: number of sworn full time police officers in field operations (on the street as opposed to administrative etc) (numeric - expected to be integer)  -- LemasSwFTFieldPerPop: sworn full time police officers in field operations (on the street as opposed to administrative etc) per 100K population (numeric - decimal)  -- LemasTotalReq: total requests for police (numeric - expected to be integer)  -- LemasTotReqPerPop: total requests for police per 100K popuation (numeric - decimal)  -- PolicReqPerOffic: total requests for police per police officer (numeric - decimal)  -- PolicPerPop: police officers per 100K population (numeric - decimal)  -- RacialMatchCommPol: a measure of the racial match between the community and the police force. High values indicate proportions in community and police force are similar (numeric - decimal)  -- PctPolicWhite: percent of police that are caucasian (numeric - decimal)  -- PctPolicBlack: percent of police that are african american (numeric - decimal)  -- PctPolicHisp: percent of police that are hispanic (numeric - decimal)  -- PctPolicAsian: percent of police that are asian (numeric - decimal)  -- PctPolicMinor: percent of police that are minority of any kind (numeric - decimal)  -- OfficAssgnDrugUnits: number of officers assigned to special drug units (numeric - expected to be integer)  -- NumKindsDrugsSeiz: number of different kinds of drugs seized (numeric - expected to be integer)  -- PolicAveOTWorked: police average overtime worked (numeric - decimal)  -- LandArea: land area in square miles (numeric - decimal)  -- PopDens: population density in persons per square mile (numeric - decimal)  -- PctUsePubTrans: percent of people using public transit for commuting (numeric - decimal)  -- PolicCars: number of police cars (numeric - expected to be integer)  -- PolicOperBudg: police operating budget (numeric - may be integer)  -- LemasPctPolicOnPatr: percent of sworn full time police officers on patrol (numeric - decimal)  -- LemasGangUnitDeploy: gang unit deployed (numeric - integer - but really nominal - 0 means NO, 10 means YES,  5 means Part Time)  -- LemasPctOfficDrugUn: percent of officers assigned to drug units (numeric - decimal)  -- PolicBudgPerPop: police operating budget per population (numeric - decimal)   -- murders: number of murders in 1995 (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- murdPerPop: number of murders per 100K population (numeric - decimal) potential GOAL attribute (to be predicted)  -- rapes: number of rapes in 1995 (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- rapesPerPop: number of rapes per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- robberies: number of robberies in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- robbbPerPop: number of robberies per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- assaults: number of assaults in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- assaultPerPop: number of assaults per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- burglaries: number of burglaries in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- burglPerPop: number of burglaries per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- larcenies: number of larcenies in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- larcPerPop: number of larcenies per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- autoTheft: number of auto thefts in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- autoTheftPerPop: number of auto thefts per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- arsons: number of arsons in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- arsonsPerPop: number of arsons per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- ViolentCrimesPerPop: total number of violent crimes per 100K popuation (numeric - decimal) GOAL attribute (to be predicted)  -- nonViolPerPop: total number of non-violent crimes per 100K popuation (numeric - decimal) potential GOAL attribute (to be predicted) Summary Statistics:variable,Minimum,Maximum,Mean,Standard Deviation,Correlation w/ ViolPerPop,Median,Mode,Missingpop,10005,7322564,53117.9842,204620.2529,0.212353809,22792,12361,0perHoush,1.6,5.28,2.707327314,0.334119654,-0.020110177,2.66,2.6,0pctBlack,0,96.67,9.33510158,14.2471563,0.628367756,2.87,0.24,0pctWhite,2.68,99.63,83.97981941,16.41908022,-0.676848823,90.35,98.04,0pctAsian,0.03,57.46,2.67020316,4.473843444,0.031949477,1.23,0.41,0pctHisp,0.12,95.29,7.950176072,14.58983204,0.253596415,2.18,0.78,0pct12-21,4.58,54.4,14.44583747,4.518622844,0.023535103,13.62,13.62,0pct12-29,9.38,70.51,27.64483973,6.181517075,0.105908765,26.78,26.78,0pct16-24,4.64,63.62,13.97514221,5.970746729,0.045251915,12.54,11.61,0pct65up,1.66,52.77,11.83639278,4.777565216,0.055637064,11.73,11.06,0persUrban,0,7322564,47734.72009,205606.6933,0.21384036,18041,0,0pctUrban,0,100,70.46530926,44.08027532,0.086294263,100,100,0medIncome,8866,123625,33984.69616,13424.68001,-0.397407452,31441,27095,0pctWwage,31.68,96.76,78.31275847,7.950672435,-0.289829747,78.61,85.12,0pctWfarm,0,6.53,0.881841986,0.689005635,-0.148357317,0.69,0.54,0pctWdiv,5.81,89.04,43.75093454,12.78792465,-0.557786505,42.88,41.65,0pctWsocsec,4.81,76.39,26.40941761,8.295604161,0.107881101,26.59,21.51,0pctPubAsst,0.18,44.82,6.801444695,4.700334848,0.563107116,5.61,2.27,0pctRetire,3.46,45.51,15.96900226,4.622553011,-0.098964807,15.65,13.14,0medFamIncome,10447,139008,39857.05508,14251.20603,-0.411864109,36678,30546,0perCapInc,5237,63302,15603.5246,6281.558523,-0.315255977,14101,11252,0whitePerCap,5472,68850,16567.69842,6346.840251,-0.185898177,15073,12735,0blackPerCap,0,212120,11541.74944,9232.102062,-0.209243037,9777,0,0NAperCap,0,480000,12229.19142,14853.83618,-0.060250637,9895,0,0asianPerCap,0,106165,14227.98962,9881.266395,-0.128086386,12250,0,0otherPerCap,0,137000,9442.765131,7926.466713,-0.103288444,8186,0,1hispPerCap,0,54648,11018.99819,5884.063446,-0.219349786,9721,0,0persPoverty,78,1384994,7590.853273,39361.46001,0.240253072,2142,470,0pctPoverty,0.64,58,11.62053725,8.600352277,0.505349223,9.33,3.26,0pctLowEdu,0.2,49.89,9.186645598,6.66670296,0.371421768,7.74,5.78,0pctNotHSgrad,1.46,73.66,22.30511964,10.98951654,0.46759552,21.38,11.27,0pctCollGrad,1.63,79.18,23.05687585,12.68721342,-0.299897539,19.65,14.2,0pctUnemploy,1.32,31.23,6.045241535,2.89561824,0.483440771,5.45,4.36,0pctEmploy,24.82,84.67,62.02161174,8.31204498,-0.31764382,62.44,62.6,0pctEmployMfg,2.05,50.03,18.22890745,8.099280979,-0.04712343,17.3,25.38,0pctEmployProfServ,8.69,62.67,24.53229797,6.659470242,-0.064554813,23.39,21.52,0pctOccupManu,1.37,44.27,13.81916479,6.430263859,0.283898507,13.15,16.52,0pctOccupMgmt,6.48,64.97,28.2092009,9.326123364,-0.324430512,26.24,28.31,0pctMaleDivorc,2.13,20.08,9.12758465,2.802747328,0.510455756,9.15,10.82,0pctMaleNevMar,12.06,76.6,30.68351693,8.127990901,0.271229742,29,26.78,0pctFemDivorc,3.35,23.92,12.32530023,3.262612867,0.537302801,12.52,14.36,0pctAllDivorc,2.83,22.23,10.81251467,3.000883481,0.536548564,10.9,11.77,0persPerFam,2.29,4.64,3.129697517,0.240742507,0.149955382,3.1,3.13,0pct2Par,22.97,93.6,74.05912867,10.52595184,-0.698640874,75.03,72.16,0pctKids2Par,18.3,92.58,71.22725508,12.04504833,-0.728058986,72.53,63.25,0pctKids-4w2Par,8.7,100,81.86542212,12.26373565,-0.658436367,83.99,100,0pct12-17w2Par,20.2,97.34,75.52178781,10.36526212,-0.655627787,76.92,77.49,0pctWorkMom-6,24.42,87.97,60.54264108,8.008936744,-0.02162507,60.71,63.48,0pctWorkMom-18,41.95,89.37,68.85479458,6.679959744,-0.146173218,69.23,65.64,0kidsBornNevrMarr,0,527557,2141.418962,14692.58284,0.240337327,352,139,0pctKidsBornNevrMarr,0,27.35,3.115498871,3.127681493,0.738089083,2.04,0.97,0numForeignBorn,20,2082931,6277.273589,55419.65383,0.144585649,1024,147,0pctFgnImmig-3,0,64.29,13.525693,9.780097693,0.156688654,12.26,0,0pctFgnImmig-5,0,76.16,20.42128668,12.41035515,0.201445794,19.08,0,0pctFgnImmig-8,0,80.81,27.54418059,14.36881288,0.236607959,26.72,0,0pctFgnImmig-10,0,88,34.73392777,16.32732237,0.281536984,34.79,0,0pctImmig-3,0,13.71,1.099124153,1.595766262,0.215616823,0.5,0,0pctImmig-5,0,19.93,1.697462754,2.46105956,0.232900674,0.75,0,0pctImmig-8,0,25.34,2.307503386,3.286647928,0.23889175,1.04,0,0pctImmig-10,0,32.63,2.943760722,4.246468259,0.250865298,1.31,0,0pctSpeakOnlyEng,6.15,98.98,87.07499323,14.07608745,-0.219031839,92.18,93.57,0pctNotSpeakEng,0,38.33,2.405792325,4.210367661,0.27243614,0.92,0.44,0pctLargHousFam,0.96,34.87,5.38661851,3.794309411,0.341601121,4.28,3.71,0pctLargHous,0.44,30.87,3.91578781,3.175770454,0.257215583,3.05,2.98,0persPerOccupHous,1.58,4.52,2.615841986,0.315646341,-0.017700909,2.57,2.44,0persPerOwnOccup,1.61,4.48,2.74048307,0.297420849,-0.099169625,2.71,2.65,0persPerRenterOccup,1.55,4.73,2.367137698,0.391805778,0.240564095,2.29,2.17,0pctPersOwnOccup,13.93,97.24,66.36945372,14.18258845,-0.507329566,65.91,63.79,0pctPopDenseHous,0.05,59.49,4.132437923,5.599131346,0.395855647,2.34,1.31,0pctSmallHousUnits,3.06,95.34,45.40534086,13.77834736,0.454469731,46.39,53.15,0medNumBedrm,1,4,2.640632054,0.512686001,-0.347149961,3,3,0houseVacant,36,172768,1748.368849,6503.866478,0.289690649,558,246,0pctHousOccup,37.47,99,92.93397291,5.04073584,-0.256836226,94.21,95.38,0pctHousOwnerOccup,16.86,96.49,63.36829797,13.9700567,-0.45535904,62.83,56.17,0pctVacantBoarded,0,39.89,2.778523702,3.592396207,0.479910148,1.66,0,0pctVacant6up,3.12,82.13,34.77388713,13.91146771,0.030768767,34.1,37.5,0medYrHousBuilt,1939,1987,1962.623476,11.16655501,-0.111201128,1964,1939,0pctHousWOphone,0,23.88,4.289823928,4.088174777,0.473717673,2.85,0,0pctHousWOplumb,0,5.33,0.425273138,0.426188232,0.311226836,0.32,0,0ownHousLowQ,14999,500001,88695.80226,66670.78153,-0.194912005,65500,34000,0ownHousMed,19500,500001,113097.5233,81906.36228,-0.17822542,82800,500001,0ownHousUperQ,28200,500001,145318.2578,99030.91382,-0.166029142,106700,500001,0ownHousQrange,0,331000,56622.45553,39106.49804,-0.086578248,43400,28100,0rentLowQ,99,1001,329.9665914,144.1384609,-0.245708342,307,252,0rentMed,120,1001,428.537246,170.7066437,-0.232797807,397,316,0rentUpperQ,182,1001,527.2528217,199.29078,-0.223893683,486,1001,0rentQrange ,0,803,197.2862302,85.20568803,-0.110281171,171,139,0medGrossRent,192,1001,501.4663657,169.2717347,-0.231754244,467,1001,0medRentpctHousInc,14.9,35.1,26.29810384,2.979297132,0.315536838,26.1,24.7,0medOwnCostpct,14,32.7,20.99015801,2.987621666,0.061058949,21,22.6,0medOwnCostPctWO,10.1,23.4,13.01020316,1.419678674,0.063296009,12.8,11.8,0persEmergShelt,0,23383,66.95349887,564.253149,0.19494198,0,0,0persHomeless,0,10447,17.8234763,245.4525529,0.136446046,0,0,0pctForeignBorn,0.18,60.4,7.340302483,8.418475989,0.193229615,4.31,2.97,0pctBornStateResid,6.75,93.14,61.5396298,16.75006116,-0.070943862,64.49,74.45,0pctSameHouse-5,11.83,78.56,51.53859594,10.51792598,-0.14008735,52.17,54.85,0pctSameCounty-5,27.95,96.59,77.41107901,10.87818569,0.082634597,79.49,81.47,0pctSameState-5,32.83,99.9,88.11186456,7.287836465,-0.006663834,90.03,92.69,0numPolice,65,25655,499.1982507,1681.472251,0.194219827,173,100,1872policePerPop,29.4,3437.23,246.4909621,273.7991617,0.073197363,196.01,#N/A,1872policeField,14,22496,432.5597668,1493.708385,0.186477279,152,94,1872policeFieldPerPop,19.21,3290.62,210.8447813,235.4788145,0.065928304,170.27,183.22,1872policeCalls,2100,8328470,252404.9883,689449.7817,0.230023206,90000,50000,1872policCallPerPop,2704.8,1926281.5,120651.7189,148211.3422,0.14854896,91034.6,#N/A,1872policCallPerOffic,20.8,2162.5,523.658309,307.8390067,0.145798061,443.2,422.6,1872policePerPop2,29.4,3437.2,246.493586,273.7984086,0.073203166,196,171.5,1872racialMatch,42.15,100,85.4996793,10.94131216,-0.469374164,87.93,100,1872pctPolicWhite,1.6,100,82.5158309,15.33261214,-0.392584252,86.18,100,1872pctPolicBlack,0,67.31,9.263294461,11.02142376,0.513568853,5,0,1872pctPolicHisp,0,98.4,5.459766764,10.60453332,0.056080974,2.04,0,1872pctPolicAsian,0,18.57,0.681282799,1.706344058,0.072778715,0,0,1872pctPolicMinority,0,98.4,15.2422449,14.82675626,0.416418453,11.37,0,1872officDrugUnits,0,1773,26.28862974,100.8219209,0.166934688,12,6,1872numDiffDrugsSeiz,1,15,8.816326531,2.836390802,0.115940631,9,9,1872policAveOT,0,634.7,119.1142857,92.49518559,0.010162351,98.7,0,1872landArea,0.9,3569.8,27.41995485,109.8226001,0.075697852,13.7,4.9,0popDensity,10,44229.9,2783.835034,2828.993341,0.256966815,2027.3,3217.7,0pctUsePubTrans,0,54.33,3.041124153,4.91291686,0.190478991,1.22,0,0policCarsAvail,20,3187,185.4781341,318.5428335,0.313164478,86,55,1872policOperBudget,2380215,1617293056,32176019.34,110456627.5,0.195267289,11164110,8000000,1872pctPolicPatrol,10.85,99.94,87.13093294,10.34961235,-0.093114808,89.58,93.07,1872gangUnit,0,10,4.285714286,4.064537838,0.109156269,5,0,1872pctOfficDrugUnit,0,48.44,0.980162528,2.877127691,0.318474028,0,0,0policBudgetPerPop,15260.4,2422367,153577.8712,203040.8861,0.056100531,114582,#N/A,1872murders,0,1946,7.764785553,58.16646847,0.248259306,1,0,0murdPerPop,0,91.09,5.859295711,9.156828742,0.671541352,2.17,0,0rapes,0,2818,28.04633782,105.6161353,0.336087881,7,0,208rapesPerPop,0,401.35,36.25848032,34.23974957,0.581533276,26.92,0,208robberies,0,86001,237.9521229,2250.720788,0.208547391,19,1,1robbbPerPop,0,2264.13,162.6125971,234.4866243,0.828574083,74.8,0,1assaults,0,62778,326.5281562,1987.947941,0.301016534,56,12,13assaultPerPop,0,4932.5,378.0046049,438.2385994,0.945565838,226.525,0,13burglaries,2,99207,761.2368897,3111.702756,0.316504514,205,79,3burglPerPop,16.92,11881.02,1033.430203,763.3544416,0.698552626,822.715,728.93,3larcenies,10,235132,2137.629295,7600.573464,0.2950221,747,547,3larcPerPop,77.86,25910.55,3372.97915,1901.316145,0.509410495,3079.51,4631.1,3autoTheft,1,112464,516.6925859,3258.164244,0.244925811,75,16,3autoTheftPerPop,6.55,4968.59,473.9656284,504.6660256,0.636484339,302.355,213.62,3arsons,0,5119,30.90772128,180.1252481,0.232824758,5,0,91arsonsPerPop,0,436.37,32.15368173,39.24090028,0.416718515,21.08,0,91violentPerPop,0,4877.06,589.0789218,614.7845182,1,374.06,223.06,221nonViolPerPop,116.79,27119.76,4908.241804,2739.708901,0.675374243,4425.45,4295.96,97 Statistics for nominal State variable:State,CountAK,3AL,43AR,25AZ,20CA,279CO,25CT,71DC,1DE,1FL,90GA,37IA,20ID,7IL,40IN,48KS,1KY,26LA,22MA,123MD,12ME,17MI,108MN,66MO,42MS,20NC,46ND,8NH,21NJ,211NM,10NV,5NY,46OH,111OK,36OR,31PA,101RI,26SC,28SD,9TN,35TX,162UT,24VA,33VT,4WA,40WI,60WV,14WY,7 Distribution of the main Goal Variable (Violent Crimes per Population): Range	Frequency (On boundary goes in the lower bin; e.g. exactly 200 goes in 100-200) 0,11-100,285100-200,306200-300,265300-400,185400-500,151500-600,131600-700,100700-800,77800-900,72900-1000,611000-1100,381100-1200,331200-1300,501300-1400,351400-1500,301500-1600,281600-1700,281700-1800,141800-1900,121900-2000,14More,78  .arff header for weka: @relation crimeunnormalized @attribute communityname string@attribute State {AK,AL,AR,AZ,CA,CO,CT,DC,DE,FL,GA,IA,ID,IL,IN,KS,KY,LA,MA,MD,ME,MI,MN,MO,MS,NC,ND,NH,NJ,NM,NV,NY,OH,OK,OR,PA,RI,SC,SD,TN,TX,UT,VA,VT,WA,WI,WV,WY}@attribute countyCode numeric@attribute communityCode numeric@attribute fold numeric@attribute pop numeric @attribute perHoush numeric @attribute pctBlack numeric @attribute pctWhite numeric @attribute pctAsian numeric @attribute pctHisp numeric @attribute pct12-21 numeric @attribute pct12-29 numeric @attribute pct16-24 numeric @attribute pct65up numeric @attribute persUrban numeric @attribute pctUrban numeric @attribute medIncome numeric @attribute pctWwage numeric @attribute pctWfarm numeric @attribute pctWdiv numeric @attribute pctWsocsec numeric @attribute pctPubAsst numeric @attribute pctRetire numeric @attribute medFamIncome numeric @attribute perCapInc numeric @attribute whitePerCap numeric @attribute blackPerCap numeric @attribute NAperCap numeric @attribute asianPerCap numeric @attribute otherPerCap numeric @attribute hispPerCap numeric @attribute persPoverty numeric @attribute pctPoverty numeric @attribute pctLowEdu numeric @attribute pctNotHSgrad numeric @attribute pctCollGrad numeric @attribute pctUnemploy numeric @attribute pctEmploy numeric @attribute pctEmployMfg numeric @attribute pctEmployProfServ numeric @attribute pctOccupManu numeric @attribute pctOccupMgmt numeric @attribute pctMaleDivorc numeric @attribute pctMaleNevMar numeric @attribute pctFemDivorc numeric @attribute pctAllDivorc numeric @attribute persPerFam numeric @attribute pct2Par numeric @attribute pctKids2Par numeric @attribute pctKids-4w2Par numeric @attribute pct12-17w2Par numeric @attribute pctWorkMom-6 numeric @attribute pctWorkMom-18 numeric @attribute kidsBornNevrMarr numeric @attribute pctKidsBornNevrMarr numeric @attribute numForeignBorn numeric @attribute pctFgnImmig-3 numeric @attribute pctFgnImmig-5 numeric @attribute pctFgnImmig-8 numeric @attribute pctFgnImmig-10 numeric @attribute pctImmig-3 numeric @attribute pctImmig-5 numeric @attribute pctImmig-8 numeric @attribute pctImmig-10 numeric @attribute pctSpeakOnlyEng numeric @attribute pctNotSpeakEng numeric @attribute pctLargHousFam numeric @attribute pctLargHous numeric @attribute persPerOccupHous numeric @attribute persPerOwnOccup numeric @attribute persPerRenterOccup numeric @attribute pctPersOwnOccup numeric @attribute pctPopDenseHous numeric @attribute pctSmallHousUnits numeric @attribute medNumBedrm numeric @attribute houseVacant numeric @attribute pctHousOccup numeric @attribute pctHousOwnerOccup numeric @attribute pctVacantBoarded numeric @attribute pctVacant6up numeric @attribute medYrHousBuilt numeric @attribute pctHousWOphone numeric @attribute pctHousWOplumb numeric @attribute ownHousLowQ numeric @attribute ownHousMed numeric @attribute ownHousUperQ numeric @attribute ownHousQrange numeric @attribute rentLowQ numeric @attribute rentMed numeric @attribute rentUpperQ numeric @attribute rentQrange numeric @attribute medGrossRent numeric @attribute medRentpctHousInc numeric @attribute medOwnCostpct numeric @attribute medOwnCostPctWO numeric @attribute persEmergShelt numeric @attribute persHomeless numeric @attribute pctForeignBorn numeric @attribute pctBornStateResid numeric @attribute pctSameHouse-5 numeric @attribute pctSameCounty-5 numeric @attribute pctSameState-5 numeric @attribute numPolice numeric @attribute policePerPop numeric @attribute policeField numeric @attribute policeFieldPerPop numeric @attribute policeCalls numeric @attribute policCallPerPop numeric @attribute policCallPerOffic numeric @attribute policePerPop2 numeric @attribute racialMatch numeric @attribute pctPolicWhite numeric @attribute pctPolicBlack numeric @attribute pctPolicHisp numeric @attribute pctPolicAsian numeric @attribute pctPolicMinority numeric @attribute officDrugUnits numeric @attribute numDiffDrugsSeiz numeric @attribute policAveOT numeric @attribute landArea numeric @attribute popDensity numeric @attribute pctUsePubTrans numeric @attribute policCarsAvail numeric @attribute policOperBudget numeric @attribute pctPolicPatrol numeric @attribute gangUnit numeric @attribute pctOfficDrugUnit numeric @attribute policBudgetPerPop numeric @attribute murders numeric @attribute murdPerPop numeric @attribute rapes numeric @attribute rapesPerPop numeric @attribute robberies numeric @attribute robbbPerPop numeric @attribute assaults numeric @attribute assaultPerPop numeric @attribute burglaries numeric @attribute burglPerPop numeric @attribute larcenies numeric @attribute larcPerPop numeric @attribute autoTheft numeric @attribute autoTheftPerPop numeric @attribute arsons numeric @attribute arsonsPerPop numeric @attribute violentPerPop numeric @attribute nonViolPerPop numeric  @data","Past Usage  1. [Redmond and Highley 2009] Redmond, M., and Highley, T., Empirical Analysis of Case-Editing Approaches for Numeric Prediction. In International Joint Conference on Computer, Information, and Systems Sciences and Engineering (CISSE) subconference International Conference on Systems, Computing Sciences and Software Engineering (SCSS). University of Bridgeport, CT, December 2009.     -- All numeric data was normalized (0-1), ViolentCrimesPerPop was predicted (all other crime attributes were eliminated)    -- Best mean absolute error obtained was .096 (on normalized data)  2. [Buczak and Gifford 2010] Buczak, A. L. and Gifford, C. M., Fuzzy Association Rule Mining for Community Crime Pattern Discovery. In Workshop on Intelligence and Security Informatics at 16th Conference on Knowledge Discovery and Data Mining (ISI-KDD-2010). Washington DC. July 2010.    -- Data was further processed ","Please cite the UCI Machine Learning Repository and my sources:   U. S. Department of Commerce, Bureau of the Census, Census Of Population And Housing 1990 United States: Summary Tape File 1a & 3a (Computer Files),    U.S. Department Of Commerce, Bureau Of The Census Producer, Washington, DC and Inter-university Consortium for Political and Social Research Ann Arbor, Michigan. (1992)    U.S. Department of Justice, Bureau of Justice Statistics, Law Enforcement Management And Administrative Statistics (Computer File) U.S. Department Of Commerce, Bureau Of The Census Producer, Washington, DC and Inter-university Consortium for Political and Social Research Ann Arbor, Michigan. (1992)    U.S. Department of Justice, Federal Bureau of Investigation, Crime in the United States (Computer File) (1995) ",
http://archive.ics.uci.edu/ml/datasets/Volcanoes+on+Venus+-+JARtool+experiment,83,Volcanoes on Venus - JARtool experiment Data Set,../machine-learning-databases/volcanoes-mld/,Image,N/A,Physical,N/A,N/A,N/A,Classification,Yes,48318,"Michael C. BurlMS 126-347, JPL4800 Oak Grove DrivePasadena, CA 91109(818) 393-5345Michael.C.Burl '@' jpl.nasa.gov http://www-aig.jpl.nasa.gov/mls/home/burl/","The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at  JPL's Magellan webpage. There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system.  The image files are in a format called VIEW. This format consists of two files, a binary file with extension .sdt (the image data) and an ascii file with extension .spr (header information). There is a MATLAB utility function included in the data package that can be used to read the data. If you want to use something other than Matlab, you are on your own, but the format is fairly simple and can be understood by looking at the Matlab code. The labeling files are provided in two forms. The .lxyr files are simple space-separated ascii containing label, x-location of center, y-location of center, and radius. ","The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.","G.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, ""Magellan: Radar Performance and Data Products"", Science, 252:260-265 (1991).[Web Link]  R.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, ""Magellan Mission Summary"", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992).[Web Link]  M.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, ""Learning to Recognize Volcanoes on Venus"", Machine Learning, (March 1998).[Web Link]  P. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: ""Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth"", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995). [Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29,84,Drug consumption (quantified) Data Set,../machine-learning-databases/00373/,Multivariate,1885,Social,Real,32,10/17/2016,Classification,N/A,128556,"Original Owners of Database:  1. Elaine Fehrman,Men's Personality Disorder and National Women's Directorate, Rampton Hospital, Retford, Nottinghamshire, DN22 0PD, UK, Elaine.Fehrman '@' nottshc.nhs.uk  2. Vincent Egan,Department of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, NG8 1BB, UK, Vincent.Egan '@' nottingham.ac.uk  3. Evgeny M. MirkesDepartment of Mathematics, University of Leicester, Leicester, LE1 7RH, UK, em322 '@' le.ac.uk  Donor:Evgeny M. MirkesDepartment of Mathematics, University of Leicester, Leicester, LE1 7RH, UK, em322 '@' le.ac.uk ","Database contains records for 1885 respondents. For each respondent 12 attributes are known: Personality measurements which include NEO-FFI-R (neuroticism, extraversion, openness to experience, agreeableness, and conscientiousness), BIS-11 (impulsivity), and ImpSS (sensation seeking), level of education, age, gender, country of residence and ethnicity. All input attributes are originally categorical and are quantified. After quantification values of all input features can be considered as real-valued. In addition, participants were questioned concerning their use of 18 legal and illegal drugs (alcohol, amphetamines, amyl nitrite, benzodiazepine, cannabis, chocolate, cocaine, caffeine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine and volatile substance abuse and one fictitious drug (Semeron) which was introduced to identify over-claimers. For each drug they have to select one of the answers: never used the drug, used it over a decade ago, or in the last decade, year, month, week, or day.Database contains 18 classification problems. Each of independent label variables contains seven classes: ""Never Used"", ""Used over a Decade Ago"", ""Used in Last Decade"", ""Used in Last Year"", ""Used in Last Month"", ""Used in Last Week"", and ""Used in Last Day"".Problem which can be solved:* Seven class classifications for each drug separately.* Problem can be transformed to binary classification by union of part of classes into one new class. For example, ""Never Used"", ""Used over a Decade Ago"" form class ""Non-user"" and all other classes form class ""User"".* The best binarization of classes for each attribute.* Evaluation of risk to be drug consumer for each drug.Detailed description of database and process of data quantification are presented in E. Fehrman, A. K. Muhammad, E. M. Mirkes, V. Egan and A. N. Gorban, ""The Five Factor Model of personality and evaluation of drug consumption risk.,"" arXiv [Web Link], 2015Paper above solve binary classification problem for all drugs. For most of drugs sensitivity and specificity are greater than 75%.","1. ID is number of record in original database. Cannot be related to participant. It can be used for reference only. 2. Age (Real) is age of participant and has one of the values:     Value    Meaning Cases Fraction     -0.95197 18-24   643   34.11%     -0.07854 25-34   481   25.52%      0.49788 35-44   356   18.89%      1.09449 45-54   294   15.60%      1.82213 55-64    93    4.93%      2.59171 65+      18    0.95%     Descriptive statistics     Min      Max     Mean    Std.dev.     -0.95197 2.59171 0.03461 0.87813 3. Gender (Real) is gender of participant:     Value    Meaning Cases Fraction      0.48246 Female  942   49.97%     -0.48246 Male    943   50.03%     Descriptive statistics     Min      Max     Mean     Std.dev.     -0.48246 0.48246 -0.00026 0.48246 4. Education (Real) is level of education of participant and has one of the values:     Value    Meaning                                              Cases Fraction     -2.43591 Left school before 16 years                           28    1.49%     -1.73790 Left school at 16 years                               99    5.25%     -1.43719 Left school at 17 years                               30    1.59%     -1.22751 Left school at 18 years                              100    5.31%     -0.61113 Some college or university, no certificate or degree 506   26.84%     -0.05921 Professional certificate/ diploma                    270   14.32%      0.45468 University degree                                    480   25.46%      1.16365 Masters degree                                       283   15.01%      1.98437 Doctorate degree                                      89    4.72%     Descriptive statistics     Min      Max     Mean     Std.dev.     -2.43591 1.98437 -0.00379 0.95004 5. Country (Real) is country of current residence of participant and has one of the values:     Value    Meaning             Cases Fraction     -0.09765 Australia             54   2.86%      0.24923 Canada                87   4.62%     -0.46841 New Zealand            5   0.27%     -0.28519 Other                118   6.26%      0.21128 Republic of Ireland   20   1.06%      0.96082 UK                  1044  55.38%     -0.57009 USA                  557  29.55%     Descriptive statistics     Min      Max     Mean    Std.dev.     -0.57009 0.96082 0.35554 0.70015 6. Ethnicity (Real) is ethnicity of participant and has one of the values:     Value    Meaning           Cases Fraction     -0.50212 Asian               26   1.38%     -1.10702 Black               33   1.75%      1.90725 Mixed-Black/Asian    3   0.16%      0.12600 Mixed-White/Asian   20   1.06%     -0.22166 Mixed-White/Black   20   1.06%      0.11440 Other               63   3.34%     -0.31685 White             1720  91.25%     Descriptive statistics     Min      Max     Mean     Std.dev.     -1.10702 1.90725 -0.30958 0.16618 7. Nscore (Real) is NEO-FFI-R Neuroticism. Possible values are presented in table below:     Nscore Cases Value         Nscore Cases Value         Nscore Cases Value     12      1    -3.46436      29     60    -0.67825      46     67    1.02119     13      1    -3.15735      30     61    -0.58016      47     27    1.13281     14      7    -2.75696      31     87    -0.46725      48     49    1.23461     15      4    -2.52197      32     78    -0.34799      49     40    1.37297     16      3    -2.42317      33     68    -0.24649      50     24    1.49158     17      4    -2.34360      34     76    -0.14882      51     27    1.60383     18     10    -2.21844      35     69    -0.05188      52     17    1.72012     19     16    -2.05048      36     73     0.04257      53     20    1.83990     20     24    -1.86962      37     67     0.13606      54     15    1.98437     21     31    -1.69163      38     63     0.22393      55     11    2.12700     22     26    -1.55078      39     66     0.31287      56     10    2.28554     23     29    -1.43907      40     80     0.41667      57      6    2.46262     24     35    -1.32828      41     61     0.52135      58      3    2.61139     25     56    -1.19430      42     77     0.62967      59      5    2.82196     26     57    -1.05308      43     49     0.73545      60      2    3.27393     27     65    -0.92104      44     51     0.82562     28     70    -0.79151      45     37     0.91093     Descriptive statistics     Min      Max     Mean    Std.dev.     -3.46436 3.27393 0.00004 0.99808 8. Escore (Real) is NEO-FFI-R Extraversion. Possible values are presented in table below:     Escore Cases Value         Escore Cases Value         Escore Cases Value     16      2    -3.27393      31      55   -1.23177      45     91    0.80523     18      1    -3.00537      32      52   -1.09207      46     69    0.96248     19      6    -2.72827      33      77   -0.94779      47     64    1.11406     20      3    -2.53830      34      68   -0.80615      48     62    1.28610     21      3    -2.44904      35      58   -0.69509      49     37    1.45421     22      8    -2.32338      36      89   -0.57545      50     25    1.58487     23      5    -2.21069      37      90   -0.43999      51     34    1.74091     24      9    -2.11437      38     106   -0.30033      52     21    1.93886     25      4    -2.03972      39     107   -0.15487      53     15    2.12700     26     21    -1.92173      40     130    0.00332      54     10    2.32338     27     23    -1.76250      41     116    0.16767      55      9    2.57309     28     23    -1.63340      42     109    0.32197      56      2    2.85950     29     32    -1.50796      43     105    0.47617      58      1    3.00537     30     38    -1.37639      44     103    0.63779      59      2    3.27393     Descriptive statistics     Min      Max     Mean     Std.dev.     -3.27393 3.27393 -0.00016 0.99745 9. Oscore (Real) is NEO-FFI-R Openness to experience. Possible values are presented in table below:     Oscore Cases Value         Oscore Cases Value         Oscore Cases Value     24      2    -3.27393      38      64   -1.11902      50     83    0.58331     26      4    -2.85950      39      60   -0.97631      51     87    0.72330     28      4    -2.63199      40      68   -0.84732      52     87    0.88309     29     11    -2.39883      41      76   -0.71727      53     81    1.06238     30      9    -2.21069      42      87   -0.58331      54     57    1.24033     31      9    -2.09015      43      86   -0.45174      55     63    1.43533     32     13    -1.97495      44     101   -0.31776      56     38    1.65653     33     23    -1.82919      45     103   -0.17779      57     34    1.88511     34     25    -1.68062      46     134   -0.01928      58     19    2.15324     35     26    -1.55521      47     107    0.14143      59     13    2.44904     36     39    -1.42424      48     116    0.29338      60      7    2.90161     37     51    -1.27553      49      98    0.44585     Descriptive statistics     Min      Max     Mean     Std.dev.     -3.27393 2.90161 -0.00053 0.99623 10. Ascore (Real) is NEO-FFI-R Agreeableness. Possible values are presented in table below:     Ascore Cases Value         Ascore Cases Value         Ascore Cases Value     12      1    -3.46436      34      42   -1.34289      48     104   0.76096     16      1    -3.15735      35      45   -1.21213      49      85   0.94156     18      1    -3.00537      36      62   -1.07533      50      68   1.11406     23      1    -2.90161      37      83   -0.91699      51      58   1.2861     24      2    -2.78793      38      82   -0.76096      52      39   1.45039     25      1    -2.70172      39     102   -0.60633      53      36   1.61108     26      7    -2.53830      40      98   -0.45321      54      36   1.81866     27      7    -2.35413      41     114   -0.30172      55      16   2.03972     28      8    -2.21844      42     101   -0.15487      56      14   2.23427     29     13    -2.07848      43     105   -0.01729      57       8   2.46262     30     18    -1.92595      44     118    0.13136      58       7   2.75696     31     24    -1.77200      45     112    0.28783      59       1   3.15735     32     30    -1.62090      46     100    0.43852      60       1   3.46436     33     34    -1.47955      47     100    0.59042                       Descriptive statistics     Min      Max     Mean     Std.dev.     -3.46436 3.46436 -0.00024 0.99744 11. Cscore (Real) is NEO-FFI-R Conscientiousness. Possible values are presented in table below:     Cscore Cases Value         Cscore Cases Value         Cscore Cases Value     17      1    -3.46436      32       39  -1.25773      46     113   0.58489     19      1    -3.15735      33       49  -1.13788      47      95   0.7583     20      3    -2.90161      34       55  -1.01450      48      95   0.93949     21      2    -2.72827      35       55  -0.89891      49      76   1.13407     22      5    -2.57309      36       69  -0.78155      50      47   1.30612     23      5    -2.42317      37       81  -0.65253      51      43   1.46191     24      6    -2.30408      38       77  -0.52745      52      34   1.63088     25      9    -2.18109      39       87  -0.40581      53      28   1.81175     26     13    -2.04506      40       97  -0.27607      54      27   2.04506     27     13    -1.92173      41       99  -0.14277      55      13   2.33337     28     25    -1.78169      42      105  -0.00665      56       8   2.63199     29     24    -1.64101      43       90   0.12331      57       3   3.00537     30     29    -1.51840      44      111   0.25953      59       1   3.46436     31     41    -1.38502      45      111   0.41594                       Descriptive statistics     Min      Max     Mean     Std.dev.     -3.46436 3.46436 -0.00039 0.99752 12. Impulsive (Real) is impulsiveness measured by BIS-11. Possible values are presented in table below:     Impulsiveness Cases Fraction     -2.55524       20    1.06%     -1.37983      276   14.64%     -0.71126      307   16.29%     -0.21712      355   18.83%      0.19268      257   13.63%      0.52975      216   11.46%      0.88113      195   10.34%      1.29221      148    7.85%      1.86203      104    5.52%      2.90161        7    0.37%     Descriptive statistics     Min      Max     Mean    Std.dev.     -2.55524 2.90161 0.00721 0.95446 13. SS (Real) is sensation seeing measured by ImpSS. Possible values are presented in table below:     SS       Cases Fraction     -2.07848  71    3.77%     -1.54858  87    4.62%     -1.18084 132    7.00%     -0.84637 169    8.97%     -0.52593 211   11.19%     -0.21575 223   11.83%      0.07987 219   11.62%      0.40148 249   13.21%      0.76540 211   11.19%      1.22470 210   11.14%      1.92173 103    5.46%     Descriptive statistics     Min      Max     Mean     Std.dev.     -2.07848 1.92173 -0.00329 0.96370 14. Alcohol is class of alcohol consumption. It is output attribute with following distribution of classes. 15. Amphet is class of amphetamines consumption. It is output attribute with following distribution of classes. 16. Amyl is class of amyl nitrite consumption. It is output attribute with following distribution of classes. 17. Benzos is class of benzodiazepine consumption. It is output attribute with following distribution of classes:     Value Class                     Alcohol        Amphet          Amyl          Benzos                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used              34    1.80%   976   51.78%   1305  69.23%   1000  53.05%     CL1   Used over a Decade Ago  34    1.80%   230   12.20%    210  11.14%    116   6.15%     CL2   Used in Last Decade     68    3.61%   243   12.89%    237  12.57%    234  12.41%     CL3   Used in Last Year      198   10.50%   198   10.50%     92   4.88%    236  12.52%     CL4   Used in Last Month     287   15.23%    75    3.98%     24   1.27%    120   6.37%     CL5   Used in Last Week      759   40.27%    61    3.24%     14   0.74%     84   4.46%     CL6   Used in Last Day       505   26.79%   102    5.41%      3   0.16%     95   5.04% 18. Caff is class of caffeine consumption. It is output attribute with following distribution of classes. 19. Cannabis is class of cannabis consumption. It is output attribute with following distribution of classes. 20. Choc is class of chocolate consumption. It is output attribute with following distribution of classes. 21. Coke is class of cocaine consumption. It is output attribute with following distribution of classes:     Value Class                      Caff         Cannabis         Choc           Coke                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used               27   1.43%   413   21.91%    32    1.70%   1038  55.07%     CL1   Used over a Decade Ago   10   0.53%   207   10.98%     3    0.16%    160   8.49%     CL2   Used in Last Decade      24   1.27%   266   14.11%    10    0.53%    270  14.32%     CL3   Used in Last Year        60   3.18%   211   11.19%    54    2.86%    258  13.69%     CL4   Used in Last Month      106   5.62%   140    7.43%   296   15.70%     99   5.25%     CL5   Used in Last Week       273  14.48%   185    9.81%   683   36.23%     41   2.18%     CL6   Used in Last Day       1385  73.47%   463   24.56%   807   42.81%     19   1.01% 22. Crack is class of crack consumption. It is output attribute with following distribution of classes. 23. Ecstasy is class of ecstasy consumption. It is output attribute with following distribution of classes. 24. Heroin is class of heroin consumption. It is output attribute with following distribution of classes. 25. Ketamine is class of ketamine consumption. It is output attribute with following distribution of classes:     Value Class                     Crack         Ecstasy         Heroin        Ketamine                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             1627  86.31%   1021  54.16%   1605  85.15%   1490  79.05%     CL1   Used over a Decade Ago   67   3.55%    113   5.99%     68   3.61%     45   2.39%     CL2   Used in Last Decade     112   5.94%    234  12.41%     94   4.99%    142   7.53%     CL3   Used in Last Year        59   3.13%    277  14.69%     65   3.45%    129   6.84%     CL4   Used in Last Month        9   0.48%    156   8.28%     24   1.27%     42   2.23%     CL5   Used in Last Week         9   0.48%     63   3.34%     16   0.85%     33   1.75%     CL6   Used in Last Day          2   0.11%     21   1.11%     13   0.69%      4   0.21% 26. Legalh is class of legal highs consumption. It is output attribute with following distribution of classes 27. LSD is class of alcohol consumption. It is output attribute with following distribution of classes 28. Meth is class of methadone consumption. It is output attribute with following distribution of classes. 29. Mushrooms is class of magic mushrooms consumption. It is output attribute with following distribution of classes:     Value Class                     Legalh          LSD            Meth         Mushrooms                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             1094  58.04%   1069  56.71%   1429  75.81%   982   52.10%     CL1   Used over a Decade Ago   29   1.54%    259  13.74%     39   2.07%   209   11.09%     CL2   Used in Last Decade     198  10.50%    177   9.39%     97   5.15%   260   13.79%     CL3   Used in Last Year       323  17.14%    214  11.35%    149   7.90%   275   14.59%     CL4   Used in Last Month      110   5.84%     97   5.15%     50   2.65%   115    6.10%     CL5   Used in Last Week        64   3.40%     56   2.97%     48   2.55%    40    2.12%     CL6   Used in Last Day         67   3.55%     13   0.69%     73   3.87%     4    0.21% 30. Nicotine is class of nicotine consumption. It is output attribute with following distribution of classes. 31. Semer is class of fictitious drug Semeron consumption. It is output attribute with following distribution of classes. 32. VSA is class of volatile substance abuse consumption. It is output attribute with following distribution of classes:     Value Class                    Nicotine        Semer           VSA                                  Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             428   22.71%   1877  99.58%   1455  77.19%     CL1   Used over a Decade Ago 193   10.24%      2   0.11%    200  10.61%     CL2   Used in Last Decade    204   10.82%      3   0.16%    135   7.16%     CL3   Used in Last Year      185    9.81%      2   0.11%     61   3.24%     CL4   Used in Last Month     108    5.73%      1   0.05%     13   0.69%     CL5   Used in Last Week      157    8.33%      0   0.00%     14   0.74%     CL6   Used in Last Day       610   32.36%      0   0.00%      7   0.37%","E. Fehrman, A. K. Muhammad, E. M. Mirkes, V. Egan and A. N. Gorban, ""The Five Factor Model of personality and evaluation of drug consumption risk.,"" arXiv [Web Link], 2015 E. Fehrman,  V. Egan, A. N. Gorban, J. Levesley, E. M. Mirkes, A. K. Muhammad, ""Personality Traits and Drug Consumption. A Story Told by Data."" Springer, Cham, 2019. [Web Link]. ISBN 978-3-030-10441-2 [a book of Original Owners of Database] D. Kumari, S. Kilam, P. Nath, et al. ""Prediction of alcohol abused individuals using artificial neural network."" Int. J. Inf. Tecnol. 10, 233–237 2018. [Web Link]  P. Nath, S. Kilam and A. Swetapadma, A machine learning approach to predict volatile substance abuse for drug risk analysis,  2017 Third International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN), Kolkata, 2017, pp. 255-258.   IEEE. [Web Link]  M. L. Eric, ""Predicting illicit drug use with artificial neural network."" European Journal of Humanities and Social Sciences, (3), 131-137, 2019. [Web Link]  X. Luo, Y. Li, W. Wang,  et al. ""A robust multilayer extreme learning machine using kernel risk-sensitive loss criterion."" Int. J. Mach. Learn. & Cyber. 11, 197–216, 2020. [Web Link]  K. I. Adenuga, I. O. Muniru, F. I. Sadiq, et al.  ""Big Data in Healthcare: Are we getting useful insights from this avalanche of data?."" In  ICSIE '19: Proceedings of the 2019 8th International Conference on Software and Information Engineering, April 2019 Pages 196–199, 2019.  IEEE.  [Web Link]  A. Sies, I. Van Mechelen, ""C443: a Methodology to See a Forest for the Trees."" J Classif (2020). [Web Link]  S. Adinugroho, Y. A. Sari and N. Hidayat, ""Drug usage duration classification using Extreme Learning Machine based on personality features,"" 2019 International Conference on Sustainable Information Engineering and Technology (SIET), Lombok, Indonesia, 2019, pp. 33-37.  IEEE. [Web Link]  Z. T. Qiao, Q. Chai, X. Zhang, et al. ""Predicting potential drug abusers using machine learning techniques,"" 2019 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS), Shanghai, China, 2019, pp. 283-286.  IEEE.  [Web Link]  B. Trevizan, J. Chamby-Diaz, A. L. Bazzan, M. Recamonde-Mendoza,   ""A comparative evaluation of aggregation methods for machine learning over vertically partitioned data."" Expert Systems with Applications, 113406, 2020. [Web Link]  D. Benkeser, M. Petersen, M. J. van der Laan, ""Improved small-sample estimation of nonlinear cross-validated prediction metrics."" Journal of the American Statistical Association, 1-16,  21 Oct 2019. [Web Link]  A. Shahriar, F. Faisal, S. U. Mahmud, et al. ""A Machine Learning Approach to Predict Vulnerability to Drug Addiction."" In 2019 22nd International Conference on Computer and Information Technology (ICCIT) (pp. 1-7) 2019. IEEE. [Web Link]  R. Sen, K. Shanmugam, S. Shakkottai, ""Contextual bandits with stochastic experts."" arXiv preprint [Web Link], 2018. [Web Link]  S. Garg, Z. Ghodsi, C. Hazay, et al. ""Outsourcing private machine learning via lightweight secure arithmetic computation."" arXiv preprint [Web Link], 2018. [Web Link]","E. Fehrman, A. K. Muhammad, E. M. Mirkes, V. Egan and A. N. Gorban, ""The Five Factor Model of personality and evaluation of drug consumption risk.,"" arXiv [Web Link], 2015",
http://archive.ics.uci.edu/ml/datasets/StoneFlakes,85,StoneFlakes Data Set,../machine-learning-databases/00299/,Multivariate,79,N/A,Real,8,5/20/2014,"Classification, Clustering, Causal-Discovery",Yes,62631,"Owner: Thomas Weber       Landesamt fÃ¼r Denkmalpflege und ArchÃ¤ologie Sachsen-Anhalt       Richard-Wagner-Str. 9       06114 Halle/Germany tweber '@' lda.mk.sachsen-anhalt.de  Donor: Gunter Ritter       University of Passau       94030 Passau/Germany ritter '@' fim.uni-passau.de","Background information: The data set concerns the earliest historyof mankind. Prehistoric men created the desired shape of a stone toolby striking on a raw stone, thus splitting off flakes, the wasteproducts of the crafting process. Archaelogists do not find many tools,but they do find flakes. The data set is about these flakes. Its rows donot stand for single flakes but for whole inventories of them. The givenfeatures are relative frequencies of binary, and mean values of numericalcharacteristics taken over all pieces found in the inventory. A questionrelated to the data set is: Does the data reflect the technologicalprogress during several hundred thousand years? Annotation:The columns below stand for the identifier of the inventory, a groupdefined by the archaeologists mainly by age and hominid type (1=LowerPaleolithic, Homo ergaster?, oldest; 2=Levallois technique; 3=MiddlePaleolithic, probably Neanderthals; 4=Homo sapiens, youngest), age ofthe stone artefacts (millennia, not to be taken too seriously), mode ofdating (geological=more accurate, typological), stone material (1=flint,2=other), region (mit=Central Germany, d=Non-Central Germany, eur=Europewithout Germany), site (1=gravel pit, 0=other), number of finds ininventory. ID  group age dating mat region site number-------------------------------------------ar    3  -120  geo    2   d      0    34arn   2  -200  typo   1   mit    1     5be    2  -200  typo   1   mit    1   331bi1   1  -300  geo    1   mit    0  4111bi2   1  -300  geo    2   mit    0    77bie   2  -200  geo    1   mit    1     8bn    2  -200  typo   1   mit    1    25bo    2  -200  geo    1   d      1   211by    2  -200  typo   1   mit    1     8c     3   -80  geo    1   mit    1    50   cl    1  -300  geo    1   eur    1   134d     2  -200  geo    1   mit    1   104   e1    3  -120  geo    1   mit    0   772e2    3  -120  geo    2   mit    0   215ey    2  -200  geo    1   mit    1   356fli   1    ?    ?     1   mit    ?   119   g10   3   -80  geo    1   d      0    38g11   3   -80  geo    1   d      0   122g2    3   -80  geo    1   d      0   614g4    3   -80  geo    1   d      0    60g5    3   -80  geo    1   d      0    57g6    3   -80  geo    1   d      0   104ga1   3   -80  geo    1   mit    0   418ga2   3   -80  geo    2   mit    0    44goe   3  -120  geo    1   mit    0    21   gra   3  -120  geo    1   mit    0     7   gro   1  -300  geo    1   mit    1    11gue   2  -200  typo   1   mit    1    95hey   2  -200  typo   1   mit    1    56hu    2  -200  geo    1   mit    1    71hx    2  -200  geo    1   eur    0   135ka    3   -80  geo    1   mit    0   270kb    3   -80  geo    1   mit    0   506kc    3   -80  geo    1   mit    0   190l     3  -120  geo    1   mit    0    20   li    3   -80  geo    1   mit    0   140lue   2  -200  geo    1   mit    1   651   m     2  -200  geo    1   mit    1  2717mar   1  -300  geo    1   mit    1    16ml    1  -300  typo   1   mit    1    62mr    2  -200  typo   1   mit    1   107ms    2  -200  typo   1   mit    1    17n     3  -120  geo    1   mit    0   256   nie   2  -200  typo   1   mit    1    55pb    3   -80  geo    1   mit    0   291r     3  -120  geo    1   mit    0   102r1    3   -80  typo   1   d      1   270r3    3   -80  typo   1   d      1   315reh   2  -200  geo    1   mit    1    36   roe   3   -80  geo    1   mit    1   104   s1    3   -80  geo    1   d      0   159s2    3   -80  geo    1   d      0   299s4    3   -80  geo    1   d      0   153s5    3   -80  geo    1   d      0   100sa1   4   -40  geo    1   eur    0    65   sa2   4   -40  geo    1   eur    0   370   sa3   4   -40  geo    1   eur    0   430   san   1    ?    ?     1   mit    ?   103   sk    2  -200  geo    2   d      0   126sm    3   -80  geo    1   d      0   180so    3   -80  geo    1   d      0   366sz    2  -200  typo   1   d      1   308t1    3  -120  geo    1   mit    0   395t2    3  -120  geo    2   mit    0    58ta    2  -130  geo    2   d      0    59tb    3   -80  geo    1   d      0    42v1    1  -400  geo    1   eur    0   120v2    1  -400  geo    2   eur    0   208va    2  -200  geo    1   mit    1     5w1    3  -120  geo    1   mit    0   537w2    3  -120  geo    2   mit    0    24wd    1  -300  geo    1   mit    1   727we    3   -80  geo    1   mit    0   338   wl    2  -200  typo   2   mit    1   315   wn    1  -300  geo    1   mit    1    39woe   1  -300  geo    1   mit    1    20wol   2  -200  geo    1   mit    1   218wst   2  -200  typo   2   mit    1    69z     2  -200  geo    1   mit    0   214","LBI: Length-breadth index of the striking platformRTI: Relative-thickness index of the striking platformWDI: Width-depth index of the striking platformFLA: Flaking angle (the angle between the striking platform and the splitting surface)PSF: platform primery (yes/no, relative frequency)FSF: Platform facetted (yes/no, relative frequency)ZDF1: Dorsal surface totally worked (yes/no, relative frequency)PROZD: Proportion of worked dorsal surface (continuous) LBI, RTI, WDI, FLA, and PROZD are averages, PSF, FSF, and ZDF1 arerelative frequencies ","Thomas Weber (2009): The Lower/middle palaeolithic transition - is          there a Lower/middle palaeolithic transition?          Preistoria Alpina 44: 1-6. D. SchÃ¤fer (1993): GrundzÃ¼ge der technologischen Entwicklung und          Klassifikation vorjungpalÃ¤olithischer Steinartefakte in          Mitteleuropa. Berichte der RÃ¶misch-Germanischen Kommission,          74: 49-193. Gunter Ritter (2014): Robust Cluster Analysis and Variable Selection,          Chapman and Hall/CRC.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Relative+location+of+CT+slices+on+axial+axis,86,Relative location of CT slices on axial axis Data Set,../machine-learning-databases/00206/,Domain-Theory,53500,Computer,Real,386,7/7/2011,Regression,N/A,56666,"F. Graf, H.-P. Kriegel, M. Schubert, S. Poelsterl, A. Cavallaro Ludwig-Maximilians-UniversitÃ¤t MunichDatabase Systems GroupOettingenstraÃŸe 6780538 Munich, Germany","The data was retrieved from a set of 53500 CT images from 74 differentpatients (43 male, 31 female). Each CT slice is described by two histograms in polar space.The first histogram describes the location of bone structures in the image,the second the location of air inclusions inside of the body.Both histograms are concatenated to form the final feature vector.Bins that are outside of the image are marked with the value -0.25. The class variable (relative location of an image on the axial axis) wasconstructed by manually annotating up to 10 different distinct landmarks ineach CT Volume with known location. The location of slices in betweenlandmarks was interpolated.","1. patientId:      Each ID identifies a different patient2. - 241.:         Histogram describing bone structures242. - 385.:       Histogram describing air inclusions386. reference:    Relative location of the image on the axial axis (class	      value). Values are in the range [0; 180] where 0 denotes	      the top of the head and 180 the soles of the feet.","1. F. Graf, H.-P. Kriegel, M. Schubert, S. Poelsterl, A. Cavallaro2D Image Registration in CT Images using Radial Image DescriptorsIn Medical Image Computing and Computer-Assisted Intervention (MICCAI),Toronto, Canada, 2011.The data was used to predict the relative location of CT slices onthe axial axis using k-nearest neighbor search.2. F. Graf, H.-P. Kriegel, S. PÃ¶lsterl, M. Schubert, A. CavallaroPosition Prediction in CT Volume ScansIn Proceedings of the 28th International Conference on MachineLearning (ICML) Workshop on Learning for Global Challenges,Bellevue, Washington, WA, 2011.Here, the data was used to apply weighted combinations of image features for the localization of small sub volumes in CT scans.3. Cheng, Ming-Yen, and Hau-tieng Wu. ""Local Linear Regression on Manifolds and its Geometric Interpretation."" arXiv preprint  (2012).","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Insurance+Company+Benchmark+%28COIL+2000%29,87,Insurance Company Benchmark (COIL 2000) Data Set,../machine-learning-databases/tic-mld/,Multivariate,9000,Social,"Categorical, Integer",86,7/3/2000,"Regression, Description",No,154830,"Original Owner and Donor: Peter van der PuttenSentient Machine ResearchBaarsjesweg 2241058 AA AmsterdamThe Netherlands+31 20 6186927pvdputten '@' hotmail.com, putten '@' liacs.nl  TIC Benchmark Homepage: http://www.liacs.nl/~putten/library/cc2000/ ","Information about customers consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was supplied by the Dutch data mining company Sentient Machine Research and is based on a real world business problem. The training set contains over 5000 descriptions of customers, including the information of whether or not they have a caravan insurance policy. A test set contains 4000 customers of whom only the organisers know if they have a caravan insurance policy.  The data dictionary ([Web Link]) describes the variables used and their values.  Note: All the variables starting with M are zipcode variables. They give information on the distribution of that variable, e.g. Rented house, in the zipcode area of the customer.  One instance per line with tab delimited fields.  TICDATA2000.txt: Dataset to train and validate prediction models and build a description (5822 customer records). Each record consists of 86 attributes, containing sociodemographic data (attribute 1-43) and product ownership (attributes 44-86).The sociodemographic data is derived from zip codes. All customers living in areas with the same zip code have the same sociodemographic attributes. Attribute 86, ""CARAVAN:Number of mobile home policies"", is the target variable.  TICEVAL2000.txt: Dataset for predictions (4000 customer records). It has the same format as TICDATA2000.txt, only the target is missing. Participants are supposed to return the list of predicted targets only. All datasets are in tab delimited format. The meaning of the attributes and attribute values is given below.  TICTGTS2000.txt Targets for the evaluation set. ",N/A,"P. van der Putten and M. van Someren (eds). CoIL Challenge 2000: The Insurance Company Case. Published by Sentient Machine Research, Amsterdam. Also a Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22, 2000. [Web Link]","Data is (c) Sentient Machine Research 2000 This dataset is owned and supplied by the Dutch datamining company Sentient Machine Research, and is based on real world business data. You are allowed to use this dataset and accompanying information for non commercial research and education purposes only. It is explicitly not allowed to use this dataset for commercial education or demonstration purposes.  Please cite/acknowledge:  P. van der Putten and M. van Someren (eds) . CoIL Challenge 2000: The Insurance Company Case. Published by Sentient Machine Research, Amsterdam. Also a Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22, 2000. [Web Link]","Bianca Zadrozny and Charles Elkan. Transforming classifier scores into accurate multiclass probability estimates. KDD. 2002.  [View Context].Stephen D. Bay and Dennis F. Kibler and Michael J. Pazzani and Padhraic Smyth. The UCI KDD Archive of Large Data Sets for Data Mining Research and Experimentation. SIGKDD Explorations, 2. 2000.  [View Context].Stefan R uping. A Simple Method For Estimating Conditional Probabilities For SVMs. CS Department, AI Unit Dortmund University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records,88,Congressional Voting Records Data Set,../machine-learning-databases/voting-records/,Multivariate,435,Social,Categorical,16,4/27/1987,Classification,Yes,221074,"Origin: Congressional Quarterly Almanac, 98th Congress,  2nd session 1984, Volume XL: Congressional Quarterly Inc. Washington, D.C., 1985. Donor:  Jeff Schlimmer (Jeffrey.Schlimmer '@' a.gp.cs.cmu.edu)","This data set includes votes for each of the U.S. House of Representatives Congressmen on the 16 key votes identified by the CQA.  The CQA lists nine different types of votes: voted for, paired for, and announced for (these three simplified to yea), voted against, paired against, and announced against (these three simplified to nay), voted present, voted present to avoid conflict of interest, and did not vote or otherwise make a position known (these three simplified to an unknown disposition).","   1. Class Name: 2 (democrat, republican)   2. handicapped-infants: 2 (y,n)   3. water-project-cost-sharing: 2 (y,n)   4. adoption-of-the-budget-resolution: 2 (y,n)   5. physician-fee-freeze: 2 (y,n)   6. el-salvador-aid: 2 (y,n)   7. religious-groups-in-schools: 2 (y,n)   8. anti-satellite-test-ban: 2 (y,n)   9. aid-to-nicaraguan-contras: 2 (y,n)  10. mx-missile: 2 (y,n)  11. immigration: 2 (y,n)  12. synfuels-corporation-cutback: 2 (y,n)  13. education-spending: 2 (y,n)  14. superfund-right-to-sue: 2 (y,n)  15. crime: 2 (y,n)  16. duty-free-exports: 2 (y,n)  17. export-administration-act-south-africa: 2 (y,n)","Schlimmer, J. C. (1987).  Concept acquisition through representational adjustment.  Doctoral dissertation, Department of Information and Computer Science, University of California, Irvine, CA.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Aristides Gionis and Heikki Mannila and Panayiotis Tsaparas. Clustering Aggregation. ICDE. 2005.  [View Context].Julie Greensmith. New Frontiers For An Artificial Immune System. Digital Media Systems Laboratory HP Laboratories Bristol. 2003.  [View Context].Daniel J. Lizotte and Omid Madani and Russell Greiner. Budgeted Learning of Naive-Bayes Classifiers. UAI. 2003.  [View Context].Robert M French and Nick Chater. Using Noise to Compute Error Surfaces in Connectionist Networks: A Novel Means of Reducing Catastrophic Forgetting. Neural Computation. 2002.  [View Context].Jonathan Eckstein and Peter L. Hammer and Ying Liu and Mikhail Nediak and Bruno Simeone. The Maximum Box Problem and its Application to Data Analysis. RUTCOR Rutgers Center for Operations Research Rutgers University. 2002.  [View Context].Daniel Barbar and Yi Li and Julia Couto. COOLCAT: an entropy-based algorithm for categorical clustering. CIKM. 2002.  [View Context].Federico Divina and Elena Marchiori. Evolutionary Concept Learning. GECCO. 2002.  [View Context].Gary M. Weiss and Haym Hirsh. A Quantitative Study of Small Disjuncts: Experiments and Results. Department of Computer Science Rutgers University. 2000.  [View Context].Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining. Institute of Information Science. 1999.  [View Context].Huan Liu and Rudy Setiono. Incremental Feature Selection. Appl. Intell, 9. 1998.  [View Context].Blai Bonet and Hector Geffner. Learning Sorting and Decision Trees with POMDPs. ICML. 1998.  [View Context].Eui-Hong Han and George Karypis and Vipin Kumar and Bamshad Mobasher. Clustering Based On Association Rule Hypergraphs. DMKD. 1997.  [View Context].Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF. Appl. Intell, 7. 1997.  [View Context].Erin J. Bredensteiner and Kristin P. Bennett. Feature Minimization within Decision Trees. National Science Foundation. 1996.  [View Context].Ron Kohavi and George H. John and Richard Long and David Manley and Karl Pfleger. MLC++: A Machine Learning Library in C. ICTAI. 1994.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Rudy Setiono and Huan Liu. Neural-Network Feature Selector. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Igor Kononenko and Edvard Simec. Induction of decision trees using RELIEFF. University of Ljubljana, Faculty of electrical engineering & computer science.  [View Context].Daniel J. Lizotte. Library Release Form Name of Author. Budgeted Learning of Naive Bayes Classifiers.  [View Context].Daniel J. Lizotte and Omid Madani and Russell Greiner. Budgeted Learning, Part II: The Na#ve-Bayes Case. Department of Computing Science University of Alberta.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29,89,Drug Review Dataset (Drugs.com) Data Set,../machine-learning-databases/00462/,"Multivariate, Text",215063,Life,Integer,6,10/4/2018,"Classification, Regression, Clustering",N/A,74826,"Surya KallumadiKansas State UniversityManhattan, Kansas, USAsurya '@' ksu.edu  Felix GräßerInstitut für Biomedizinische TechnikTechnische Universität DresdenDresden, Germanyfelix.graesser '@' tu-dresden.de","The dataset provides patient reviews on specific drugs along with related conditions and a 10 star patient rating reflecting overall patient satisfaction. The data was obtained by crawling online pharmaceutical review sites. The intention was to study  (1) sentiment analysis of drug experience over multiple facets, i.e. sentiments learned on specific aspects such as effectiveness and side effects,(2) the transferability of models among domains, i.e. conditions, and (3) the transferability of models among different data sources (see 'Drug Review Dataset (Druglib.com)'). The data is split into a train (75%) a test (25%) partition (see publication) and stored in two .tsv (tab-separated-values) files, respectively.  Important notes: When using this dataset, you agree that you1) only use the data for research purposes2) don't use the data for any commerical purposes3) don't distribute the data to anyone else4) cite us","1. drugName (categorical): name of drug2. condition (categorical): name of condition3. review (text): patient review4. rating (numerical): 10 star patient rating5. date (date): date of review entry6. usefulCount (numerical): number of users who found review useful","Felix Gräßer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018. Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-Domain and Cross-Data Learning. In Proceedings of the 2018 International Conference on Digital Health (DH '18). ACM, New York, NY, USA, 121-125. DOI: [Web Link] ","Felix Gräßer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018. Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-Domain and Cross-Data Learning. In Proceedings of the 2018 International Conference on Digital Health (DH '18). ACM, New York, NY, USA, 121-125. DOI: [Web Link] ",
http://archive.ics.uci.edu/ml/datasets/Yacht+Hydrodynamics,90,Yacht Hydrodynamics Data Set,../machine-learning-databases/00243/,Multivariate,308,Physical,Real,7,1/3/2013,Regression,N/A,95331,"Creator:  Ship Hydromechanics Laboratory, Maritime and Transport Technology Department, Technical University of Delft.  Donor:  Dr Roberto LopezE-mail: roberto-lopez '@' users.sourceforge.net ","Prediction of residuary resistance of sailing yachts at the initial design stage is of a great value for evaluating the shipâ€™s performance and for estimating the required propulsive power. Essential inputs include the basic hull dimensions and the boat velocity.  The Delft data set comprises 308 full-scale experiments, which were performed at the Delft Ship Hydromechanics Laboratory for that purpose. These experiments include 22 different hull forms, derived from a parent form closely related to the â€˜Standfast 43â€™ designed by Frans Maas.","Variations concern hull geometry coefficients and the Froude number: 1. Longitudinal position of the center of buoyancy, adimensional.2. Prismatic coefficient, adimensional.3. Length-displacement ratio, adimensional.4. Beam-draught ratio, adimensional.5. Length-beam ratio, adimensional.6. Froude number, adimensional. The measured variable is the residuary resistance per unit weight of displacement: 7. Residuary resistance per unit weight of displacement, adimensional.","J. Gerritsma, R. Onnink, and A. Versluis. Geometry, resistance and stability of the delft systematic yacht hull series. In International ShipbuildingProgress, volume 28, pages 276â€“297, 1981. I. Ortigosa, R. Lopez and J. Garcia. A neural networks approach to residuary resistance of sailingyachts prediction. In Proceedings of the International Conference on Marine Engineering MARINE2007, 2007.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/OCT+data+%26+Color+Fundus+Images+of+Left+%26+Right+Eyes,91,OCT data & Color Fundus Images of Left & Right Eyes Data Set,../machine-learning-databases/00430/,Multivariate,50,Computer,Real,2,11/1/2016,Classification,N/A,15547,Tahereh Mahmudi; Rahele Kafieh; Hossein Rabbani; Alireza Mehri dehnavi; Mohammadreza Akhlagi,OCT data & Color Fundus Images of Left & Right Eyes : This dataset contains OCT data (in mat format) and color fundus data (in jpg format) of left & right eyes of 50 healthy persons. Each volunteer's folder includes color fundus images (.jpg) and OCT data (.mat) of the right and left eyes.,OCT data & Color Fundus Images of Left & Right Eyes : This dataset contains OCT data (in mat format) and color fundus data (in jpg format) of left & right eyes of 50 healthy persons. Each volunteer's folder includes color fundus images (.jpg) and OCT data (.mat) of the right and left eyes.,"* T. Mahmudi, R. Kafieh, H. Rabbani, â€œComparison of macular OCTs in right andleft eyes of normal peopleâ€, in Proc. SPIE 9038, Medical Imaging 2014: Biomedical Applications in Molecular, Structural, and Functional Imaging, 90381K, San Diego, California, United States Feb. 15-20, 2014. doi: 10.1117/12.2044046","* T. Mahmudi, R. Kafieh, H. Rabbani, â€œComparison of macular OCTs in right andleft eyes of normal peopleâ€, in Proc. SPIE 9038, Medical Imaging 2014: Biomedical Applications in Molecular, Structural, and Functional Imaging, 90381K, San Diego, California, United States Feb. 15-20, 2014. doi: 10.1117/12.2044046To download more free dataset in different medical applications, please visit [Web Link]  ",
http://archive.ics.uci.edu/ml/datasets/Water+Treatment+Plant,92,Water Treatment Plant Data Set,../machine-learning-databases/water-treatment/,Multivariate,527,Physical,"Integer, Real",38,6/1/1993,Clustering,N/A,145232,"Creators:  Manel Poch (igte2 '@' cc.uab.es)Unitat d'Enginyeria QuimicaUniversitat Autonoma de Barcelona. Bellaterra. Barcelona; Spain Donor:  Javier Bejar and Ulises Cortes (bejar '@' lsi.upc.es)Dept. Llenguatges i Sistemes Informatics;Universitat Politecnica de Catalunya. Barcelona; Spain",This dataset comes from the daily measures of sensors in a urban waste water treatment plant. The objective is to classify the operational state of the plant in order to predict faults through the state variables of the plant at each of the stages of the treatment process.  This domain has been stated as an ill-structured domain. ," All atrributes are numeric and continuous N.  Attrib.     1  Q-E        (input flow to plant)   2  ZN-E       (input Zinc to plant) 3  PH-E       (input pH to plant)  4  DBO-E      (input Biological demand of oxygen to plant)  5  DQO-E      (input chemical demand of oxygen to plant) 6  SS-E       (input suspended solids to plant)   7  SSV-E      (input volatile supended solids to plant) 8  SED-E      (input sediments to plant)  9  COND-E     (input conductivity to plant) 10  PH-P       (input pH to primary settler)11  DBO-P      (input Biological demand of oxygen to primary settler)12  SS-P       (input suspended solids to primary settler)13  SSV-P      (input volatile supended solids to primary settler)14  SED-P      (input sediments to primary settler) 15  COND-P     (input conductivity to primary settler)16  PH-D       (input pH to secondary settler) 17  DBO-D      (input Biological demand of oxygen to secondary settler)18  DQO-D      (input chemical demand of oxygen to secondary settler)19  SS-D       (input suspended solids to secondary settler)20  SSV-D      (input volatile supended solids to secondary settler)21  SED-D      (input sediments to secondary settler)  22  COND-D     (input conductivity to secondary settler) 23  PH-S       (output pH)   24  DBO-S      (output Biological demand of oxygen)25  DQO-S      (output chemical demand of oxygen)26  SS-S       (output suspended solids)27  SSV-S      (output volatile supended solids) 28  SED-S      (output sediments) 29  COND-S     (output conductivity)30  RD-DBO-P   (performance input Biological demand of oxygen in primary settler)31  RD-SS-P    (performance input suspended solids to primary settler)32  RD-SED-P   (performance input sediments to primary settler)33  RD-DBO-S   (performance input Biological demand of oxygen to secondary settler)34  RD-DQO-S   (performance input chemical demand of oxygen to secondary settler)35  RD-DBO-G   (global performance input Biological demand of oxygen)36  RD-DQO-G   (global performance input chemical demand of oxygen)37  RD-SS-G    (global performance input suspended solids) 38  RD-SED-G   (global performance input sediments)","J. De Gracia. ``Avaluacio de tecniques de classificacio per a la gestio de Bioprocessos: Aplicacio a un reactor de fangs activats'' Master Thesis. Dept. de Quimica. Unitat d'Enginyeria Quimica. Universitat Autonoma de Barcelona. Bellaterra (Barcelona). 1993. J. Bejar, U. Cort\'es and M. Poch. ""LINNEO+: A Classification Methodology for Ill-structured Domains''.  Research report RT-93-10-R. Dept. Llenguatges i Sistemes Informatics. Barcelona. 1993.[Web Link]  Ll. Belanche, U. Cortes and M. S\`anchez. ""A knowledge-based system for the diagnosis of waste-water treatment plant''. Proceedings of the 5th international conference of industrial and engineering applications of AI and Expert Systems IEA/AIE-92. Ed Springer-Verlag. Paderborn, Germany, June 92.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29,93,Statlog (Heart) Data Set,../machine-learning-databases/statlog/heart/,Multivariate,270,Life,"Categorical, Real",13,N/A,Classification,No,222889,N/A,"Cost Matrix _______	 abse  presabsence	 0	1presence  5	0 where the rows represent the true values and the columns the predicted."," Attribute Information:------------------------      -- 1. age             -- 2. sex             -- 3. chest pain type  (4 values)             -- 4. resting blood pressure        -- 5. serum cholesterol in mg/dl            -- 6. fasting blood sugar > 120 mg/dl             -- 7. resting electrocardiographic results  (values 0,1,2)       -- 8. maximum heart rate achieved        -- 9. exercise induced angina          -- 10. oldpeak = ST depression induced by exercise relative to rest         -- 11. the slope of the peak exercise ST segment           -- 12. number of major vessels (0-3) colored by flourosopy              -- 13.  thal: 3 = normal; 6 = fixed defect; 7 = reversable defect      Attributes types----------------- Real: 1,4,5,8,10,12Ordered:11,Binary: 2,6,9Nominal:7,3,13 Variable to be predicted------------------------Absence (1) or presence (2) of heart disease",N/A,"Please refer to the Machine Learning
Repository's citation policy","Gavin Brown. Diversity in Neural Network Ensembles. The University of Birmingham. 2004.  [View Context].Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF. Appl. Intell, 7. 1997.  [View Context].Elena Smirnova and Ida G. Sprinkhuizen-Kuyper and I. Nalbantis and b. ERIM and Universiteit Rotterdam. Unanimous Voting using Support Vector Machines. IKAT, Universiteit Maastricht.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/BLE+RSSI+Dataset+for+Indoor+localization+and+Navigation,94,BLE RSSI Dataset for Indoor localization and Navigation Data Set,../machine-learning-databases/00435/,"Multivariate, Sequential, Time-Series",6611,Computer,Integer,15,1/25/2018,"Classification, Clustering",Yes,30121,"Mehdi Mohammadi and Ala Al-Fuqaha, {mehdi.mohammadi, ala-alfuqaha}@wmich.eduDepartment of Computer ScienceWestern Michigan University","The dataset was created using the RSSI readings of an array of 13 ibeacons in the first floor of Waldo Library, Western Michigan University. Data was collected using iPhone 6S. The dataset contains two sub-datasets: a labeled dataset (1420 instances) and an unlabeled dataset (5191 instances). The recording was performed during the operational hours of the library. For the labeled dataset, the input data contains the location (label column), a timestamp, followed by RSSI readings of 13 iBeacons. RSSI measurements are negative values. Bigger RSSI values indicate closer proximity to a given iBeacon (e.g., RSSI of -65 represent a closer distance to a given iBeacon compared to RSSI of -85). For out-of-range iBeacons, the RSSI is indicated by -200. The locations related to RSSI readings are combined in one column consisting a letter for the column and a number for the row of the position. The attached figure depicts the layout of the iBeacons as well as the arrange of locations.   ","location: The location of receiving RSSIs from ibeacons b3001 to b3013; symbolic values showing the column and row of the location on the map (e.g., A01 stands for column A, row 1). Date: Datetime in the format of â€˜d-m-yyyy hh:mm:ssâ€™ b3001 - b3013: RSSI readings corresponding to the iBeacons; numeric, integers only.","M. Mohammadi and A. Al-Fuqaha, 'Enabling Cognitive Smart Cities Using Big Data and Machine Learning: Approaches and Challenges,' IEEE Communications Magazine, vol. 56, no. 2, 2018.","@article{mohammadi2017semi, author={M. Mohammadi and A. Al-Fuqaha and M. Guizani and J. S. Oh}, journal={IEEE Internet of Things Journal}, title={{Semi-supervised Deep Reinforcement Learning in Support of IoT and Smart City Services}}, year={2017}, pages={1-12}, publisher={IEEE},doi={10.1109/JIOT.2017.2712560}, ISSN={2327-4662}, }",
http://archive.ics.uci.edu/ml/datasets/Audit+Data,95,Audit Data Data Set,../machine-learning-databases/00475/,Multivariate,777,N/A,Real,18,7/14/2018,Classification,Yes,38552,"Nishtha Hooda, CSED, TIET, Patiala","The goal of the research is to help the auditors by building a classification model that can predict the fraudulent firm on the basis the present and historical risk factors. The information about the sectors and the counts of firms are listed respectively as Irrigation (114), Public Health (77), Buildings and Roads (82), Forest (70), Corporate (47), Animal Husbandry (95), Communication (1), Electrical (4), Land (5), Science and Technology (3), Tourism (1), Fisheries (41), Industries (37), Agriculture (200).","Many risk factors are examined from various areas like past records of audit office, audit-paras, environmental conditions reports, firm reputation summary, on-going issues report, profit-value records, loss-value records, follow-up reports etc. After in-depth interview with the auditors, important risk factors are evaluated and their probability of existence is calculated from the present and past records.","Hooda, Nishtha, Seema Bawa, and Prashant Singh Rana. 'Fraudulent Firm Classification: A Case Study of an External Audit.' Applied Artificial Intelligence 32.1 (2018): 48-64.","This research work is supported by Ministry of Electronics and Information Technology (MEITY), Govt.of India",
http://archive.ics.uci.edu/ml/datasets/SPECT+Heart,96,SPECT Heart Data Set,../machine-learning-databases/spect/,Multivariate,267,Life,Categorical,22,10/1/2001,Classification,No,204736,"Original Owners:  Krzysztof J. Cios, Lukasz A. KurganUniversity of Colorado at Denver, Denver, CO 80217, U.S.A.Krys.Cios '@' cudenver.edu Lucy S. GoodendayMedical College of Ohio, OH, U.S.A. Donors:  Lukasz A.Kurgan, Krzysztof J. Cios","The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The pattern was further processed to obtain 22 binary feature patterns. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 84.0% accurate (as compared with cardilogists' diagnoses). SPECT is a good data set for testing ML algorithms; it has 267 instances that are descibed by 23 binary attributes","   1.  OVERALL_DIAGNOSIS: 0,1 (class attribute, binary)   2.  F1:  0,1 (the partial diagnosis 1, binary)   3.  F2:  0,1 (the partial diagnosis 2, binary)   4.  F3:  0,1 (the partial diagnosis 3, binary)   5.  F4:  0,1 (the partial diagnosis 4, binary)   6.  F5:  0,1 (the partial diagnosis 5, binary)   7.  F6:  0,1 (the partial diagnosis 6, binary)   8.  F7:  0,1 (the partial diagnosis 7, binary)   9.  F8:  0,1 (the partial diagnosis 8, binary)   10. F9:  0,1 (the partial diagnosis 9, binary)   11. F10: 0,1 (the partial diagnosis 10, binary)   12. F11: 0,1 (the partial diagnosis 11, binary)   13. F12: 0,1 (the partial diagnosis 12, binary)   14. F13: 0,1 (the partial diagnosis 13, binary)   15. F14: 0,1 (the partial diagnosis 14, binary)   16. F15: 0,1 (the partial diagnosis 15, binary)   17. F16: 0,1 (the partial diagnosis 16, binary)   18. F17: 0,1 (the partial diagnosis 17, binary)   19. F18: 0,1 (the partial diagnosis 18, binary)   20. F19: 0,1 (the partial diagnosis 19, binary)   21. F20: 0,1 (the partial diagnosis 20, binary)   22. F21: 0,1 (the partial diagnosis 21, binary)   23. F22: 0,1 (the partial diagnosis 22, binary)   - dataset is divided into:	-- training data (""SPECT.train"" 80 instances)	-- testing data (""SPECT.test"" 187 instances)","Kurgan, L.A., Cios, K.J., Tadeusiewicz, R., Ogiela, M. & Goodenday, L.S. ""Knowledge Discovery Approach to Automated Cardiac SPECT Diagnosis"" Artificial Intelligence in Medicine, vol. 23:2, pp 149-169, Oct 2001[Web Link]  Cios, K.J., Wedding, D.K. & Liu, N. CLIP3: cover learning using integer programming. Kybernetes, 26:4-5, pp 513-536, 1997 Cios K. J. & Kurgan L. Hybrid Inductive Machine Learning: An Overview of CLIP Algorithms,  In: Jain L.C., and Kacprzyk J. (Eds). New Learning Paradigms in Soft Computing, Physica-Verlag (Springer), 2001[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Rich Caruana and Alexandru Niculescu-Mizil. An Empirical Evaluation of Supervised Learning for ROC Area. ROCAI. 2004.  [View Context].Lukasz A. Kurgan and Waldemar Swiercz and Krzysztof J. Cios. Semantic Mapping of XML Tags Using Inductive Machine Learning. ICMLA. 2002.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Entree+Chicago+Recommendation+Data,97,Entree Chicago Recommendation Data Data Set,../machine-learning-databases/entree-mld/,"Transactional, Sequential",50672,N/A,Categorical,N/A,3/9/2000,Recommender-Systems,Yes,93464,"Original Owner and Donor: Robin BurkeUniversity of California, IrvineDepartment of Information and Computer ScienceIrvine, CA 92697 Now here:http://josquin.cti.depaul.edu/~rburke/","This data records interactions with Entree Chicago restaurant recommendation system (originally [Web Link]) from September, 1996 to April, 1999. The data is organized into files roughly spanning a quarter year -- with Q3 1996 and Q2 1999 each only containing one month.  Each line in a session file represents a session of user interaction with the system. The (tab-separated) fields are as follows:       Date, IP, Entry point, Rated restaurant1, ..., Rated restaurantN, End point 1. Entry point: Users can use a restaurant from any city as a entry point, but they always get recommendations for Chicago restaurants. The entry point therefore draws from a larger universe of restaurants than the rest of the data. Entry points have the form nnnX, where nnn is a numeric restaurant ID and X is a character A-H that encodes the city.       A = Atlanta     B = Boston     C = Chicago     D = Los Angeles     E = New Orleans     F = New York     G = San Francisco     H = Washington DC 2. Rated Restaurant: These are all Chicago restaurants. These entries have the form nnnX, where nnn is a numeric restaurant ID and X is a character L-T that encodes the navigation operation.       L = browse (move from one restaurant in a list of recommendations to another)     M = cheaper (search for a restaurant like this one, but cheaper)     N = nicer   (         ""               ""           , but nicer)     O = closer  (unused in the production version of the system)     P = more traditional (search for a restaurant like this, but serving more traditional cuisine)     Q = more creative (search for a restaurant serving more creative cuisine)     R = more lively (search for a restaurant with a livelier atmosphere)     S = quieter (search for a restaurant with a quieter atmosphere)     T = change cuisine (search for a restaurant like this, but serving a different kind of food) Note that with this tweak, we would ideally like to know what cuisine the user wanted to change to, but this information was not recorded. 3. End point: Just the numeric id for the (Chicago) restaurant that the user saw last. In our experiments, we are assuming that this was a good suggestion, but it is also possible that user just gives up. Some potentially useful data is missing. In many cases, we don't know the starting point because the user input a set of selection criteria (such as ""inexpensive traditional Mexican"") using a form submission, rather than starting from a known restaurant. These queries were not recorded. This is denoted by a 0 in the entry point field. Some sessions do not have a known end point. This is marked by -1 in the end point field.   In addition to the user's interactions, there is also data linking the restaurant ID with its name and features such as ""fabulous wine lists"", ""good for younger kids"", and ""Ethopian"" cuisine. This data is stored by city (e.g. Atlanta, Boston, etc.) and is in the following format:      restaurant id [tab] restaurant name [tab] restaurant features (3 digits ids separated by spaces) ",N/A,"Burke, R. The Wasabi Personal Shopper: A Case-Based Recommender System. In Proceedings of the 11th National Conference on Innovative Applications of Artificial Intelligence, pages 844-849. AAAI, 1999. [Web Link]  Burke, R. Knowledge-based Recommender Systems. To appear in the Encyclopedia of Library and Information Science. ","Please refer to the Machine Learning
Repository's citation policy","Zoran Obradovic and Slobodan Vucetic. Challenges in Scientific Data Mining: Heterogeneous, Biased, and Large Samples. Center for Information Science and Technology Temple University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Nursery,98,Nursery Data Set,../machine-learning-databases/nursery/,Multivariate,12960,Social,Categorical,8,6/1/1997,Classification,No,199758,"Creator:  Vladislav Rajkovic et al. (13 experts) Donors:  Marko Bohanec   (marko.bohanec '@' ijs.si)Blaz Zupan      (blaz.zupan '@' ijs.si)","Nursery Database was derived from a hierarchical decision model originally developed to rank applications for nursery schools. It was used during several years in 1980's when there was excessive enrollment to these schools in Ljubljana, Slovenia, and the rejected applications frequently needed an objective explanation. The final decision depended on three subproblems: occupation of parents and child's nursery, family structure and financial standing, and social and health picture of the family. The model was developed within expert system shell for decision making DEX (M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The hierarchical model ranks nursery-school applications according to the following concept structure:  NURSERY            Evaluation of applications for nursery schools . EMPLOY           Employment of parents and child's nursery . . parents        Parents' occupation . . has_nurs       Child's nursery . STRUCT_FINAN     Family structure and financial standings . . STRUCTURE      Family structure . . . form         Form of the family . . . children     Number of children . . housing        Housing conditions . . finance        Financial standing of the family . SOC_HEALTH       Social and health picture of the family . . social         Social conditions . . health         Health conditions Input attributes are printed in lowercase. Besides the target concept (NURSERY) the model includes four intermediate concepts: EMPLOY, STRUCT_FINAN, STRUCTURE, SOC_HEALTH. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see [Web Link]). The Nursery Database contains examples with the structural information removed, i.e., directly relates NURSERY to the eight input attributes: parents, has_nurs, form, children, housing, finance, social, health. Because of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.","   parents:        usual, pretentious, great_pret   has_nurs:       proper, less_proper, improper, critical, very_crit   form:           complete, completed, incomplete, foster   children:       1, 2, 3, more   housing:        convenient, less_conv, critical   finance:        convenient, inconv   social:         non-prob, slightly_prob, problematic   health:         recommended, priority, not_recom","M. Olave, V. Rajkovic, M. Bohanec: An application for admission in public school systems. In (I. Th. M. Snellen and W. B. H. J. van de Donk and J.-P. Baquiast, editors) Expert Systems in Public Administration, pages 145-160. Elsevier Science Publishers (North Holland), 1989.[Web Link]  B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by function decomposition. ICML-97, Nashville, TN. 1997[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Daniel J. Lizotte and Omid Madani and Russell Greiner. Budgeted Learning of Naive-Bayes Classifiers. UAI. 2003.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].Marina Meila and Michael I. Jordan. Learning with Mixtures of Trees. Journal of Machine Learning Research, 1. 2000.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao. Instance-Based Classification by Emerging Patterns. PKDD. 2000.  [View Context].Jie Cheng and Russell Greiner. Comparing Bayesian Network Classifiers. UAI. 1999.  [View Context].Gustavo E. A and Gustavo E A P A Batista and Ronaldo C. Prati and Maria Carolina Monard. A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data. Instituto de Ci ^ encias Matem aticas e de Computac~ ao.  [View Context].Nikunj C. Oza and Stuart J. Russell. Online Bagging and Boosting. Computer Science Division University of California.  [View Context].Daniel J. Lizotte and Omid Madani and Russell Greiner. Budgeted Learning, Part II: The Na#ve-Bayes Case. Department of Computing Science University of Alberta.  [View Context].Shi Zhong and Weiyu Tang and Taghi M. Khoshgoftaar. Boosted Noise Filters for Identifying Mislabeled Data. Department of Computer Science and Engineering Florida Atlantic University.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context].Daniel J. Lizotte. Library Release Form Name of Author. Budgeted Learning of Naive Bayes Classifiers.  [View Context].Jinyan Li and Kotagiri Ramamohanarao and Guozhu Dong. ICML2000 The Space of Jumping Emerging Patterns and Its Incremental Maintenance Algorithms. Department of Computer Science and Software Engineering, The University of Melbourne, Parkville.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Lenses,99,Lenses Data Set,../machine-learning-databases/lenses/,Multivariate,24,N/A,Categorical,4,8/1/1990,Classification,No,173869,"Original Source: Cendrowska, J. ""PRISM: An algorithm for inducing modular rules"", International Journal of Man-Machine Studies, 1987, 27, 349-370 Donor:  Benoit Julien (Julien '@' ce.cmu.edu)","The examples are complete and noise free. The examples highly simplified the problem. The attributes do not fully describe all the factors affecting the decision as to which type, if any, to fit.  Notes:   --This database is complete (all possible combinations of attribute-value pairs are represented). --Each instance is complete and correct. --9 rules cover the training set.","    -- 3 Classes     1 : the patient should be fitted with hard contact lenses,     2 : the patient should be fitted with soft contact lenses,     3 : the patient should not be fitted with contact lenses.     1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic    2. spectacle prescription:  (1) myope, (2) hypermetrope    3. astigmatic:     (1) no, (2) yes    4. tear production rate:  (1) reduced, (2) normal","Witten, I. H. & MacDonald, B. A. (1988). Using concept learning for knowledge acquisition. International Journal of Man-Machine Studies, 27, (pp. 349-370).[Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Bob Ricks and Dan Ventura. Training a Quantum Neural Network. NIPS. 2003.  [View Context].Jeremy Kubica and Andrew Moore. Probabilistic Noise Identification and Data Cleaning. ICDM. 2003.  [View Context].Ke Wang and Shiyu Zhou and Ada Wai-Chee Fu and Jeffrey Xu Yu. Mining Changes of Classification by Correspondence Tracing. SDM. 2003.  [View Context].Jim Prentzas and Ioannis Hatzilygeroudis and Athanasios K. Tsakalidis. Updating a Hybrid Rule Base with New Empirical Source Knowledge. ICTAI. 2002.  [View Context].Pedro Domingos. Knowledge Discovery Via Multiple Models. Intell. Data Anal, 2. 1998.  [View Context].J. Kent Martin and Daniel S. Hirschberg. Small Sample Statistics for Classification Error Rates I: Error Rate Measurements. Department of Information and Computer Science University of California, Irvine. 1996.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Christophe Giraud and Tony Martinez and Christophe G. Giraud-Carrier. University of Bristol Department of Computer Science ILA: Combining Inductive Learning with Prior Knowledge and Reasoning. 1995.  [View Context].Christophe G. Giraud-Carrier and Tony Martinez. AN INCREMENTAL LEARNING MODEL FOR COMMONSENSE REASONING. Department of Computer Science Brigham Young University.  [View Context].Anthony D. Griffiths and Derek Bridge. A Yardstick for the Evaluation of Case-Based Classifiers. Department of Computer Science, University of York.  [View Context].Mehmet Dalkilic and Arijit Sengupta. A Logic-theoretic classifier called Circle. School of Informatics Center for Genomics and BioInformatics Indiana University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/BAUM-2,100,BAUM-2 Data Set,../machine-learning-databases/00474/,Time-Series,1047,Computer,N/A,N/A,11/9/2018,Classification,N/A,10518,"C. E. Erdem, C. Turan, Z. AydÄ±n, 'BAUM-2: a multilingual audio-visual affecive face database', Multimedia Tools and Applications, vol.74, pp. 7429-7459, 2015. DOI 10.1007/s11042-014-1986-2   ","A multilingual audio-visual affective face database consisting of 1047 video clips of 286 subjects. The collected clips simulate real-world conditions by containing various head poses, illumination conditions, accessories, temporary occlusions and subjects with a wide range of ages. In order to download the database please send an e-mail to cigdem.turan '@' connect.polyu.hk or cigdem.erogluerdem '@' gmail.com",The readme file contains more information about the format of the database. ," Histogram-based local descriptors for facial expression recognition (FER): A comprehensive studyBy: Turan, Cigdem; Lam, Kin-ManJOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION  Volume: 55   Pages: 331-341   Published: AUG 2018  BAUM-1: A Spontaneous Audio-Visual Face Database of Affective and Mental StatesBy: Zhalehpour, Sara; Onder, Onur; Akhtar, Zahid; et al.IEEE TRANSACTIONS ON AFFECTIVE COMPUTING  Volume: 8   Issue: 3   Pages: 300-313   Published: JUL-SEP 2017  Affect Recognition using Key Frame Selection based on Minimum Sparse ReconstructionBy: Kayaoglu, Mehmet; Erdem, Cigdem ErogluConference: 2015 ACM International Conference on Multimodal Interaction Location: Seattle, WA Date: NOV 09-13, 2015Sponsor(s): ACM SIGCHIICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION  Pages: 519-524   Published: 2015","C. E. Erdem, C. Turan, Z. AydÄ±n, 'BAUM-2: a multilingual audio-visual affective face database', Multimedia Tools and Applications, vol.74, pp. 7429-7459, 2015. DOI 10.1007/s11042-014-1986-2",
http://archive.ics.uci.edu/ml/datasets/Reuters+RCV1+RCV2+Multilingual%2C+Multiview+Text+Categorization+Test+collection,101,"Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection Data Set",../machine-learning-databases/00259/,Multivariate,111740,Life,Real,N/A,9/6/2013,Classification,N/A,59985,"Massih-Reza AminiUniversitÃ© Joseph FourierLaboratoire d'Informatique de GrenobleEmail : Massih-Reza.Amini '@' imag.fr  Cyril GoutteNational Research Council CanadaInteractive Language Technology groupEmail : Cyril.Goutte '@' nrc.ca","Uncompressing rcv1rcv2aminigoutte.tar.bz2 will create a directory  that contains 5 subdirectories EN, FR, GR, IT and SP, corresponding to the 5 languages. Each subdirectory in {EN, FR, GR, IT, SP} contains 5 files, each containing indexes of the documents written or translated in that language.  For example, EN contains files: - Index_EN-EN : Original English documents - Index_FR-EN : French documents translated to English - Index_GR-EN : German documents translated to English - Index_IT-EN : Italian documents translated to English - Index_SP-EN : Spanish documents translated to English And similarly for the 4 other languages. Each file contains one indexed document per line, in a format similar to SVM_light.  Each line is of the form:  : : ... where  is the category label, ie one of C15, CCAT, E21, ECAT, GCAT or M11. : is the feature, value pair, in ascending order of feature index. The order of documents is maintained in corresponding files, for example, FR/Index_EN-FR and EN/Index_EN-EN have the same number of documents (and therefore the same number of lines), in the same order. ","We focused on six relatively populous categories: C15, CCAT, E21, ECAT, GCAT, M11. For each language and each class, we sampled up to 5000 documents from the RCV1 (for English) or RCV2 (for other languages). Documents belonging to more than one of our 6 classes were assigned the label of their smallest class.  This resulted in 12-30K documents per language, and 11-34K documents per class. The distribution of documents over languages and classes are:               Number of                   VocabularyLanguage      documents     percentage       size************  **********   ************  ************ English        18,758         16.78        21,531French         26,648         23.45        24,893German         29,953         26.80        34,279Italian        24,039         21.51        15,506Spanish        12,342         11.46        11,547-------Total         111,740 The distribution of classes in the whole collection is           Number of                 Class      documents     percentage  *********  **********   ************ C15          18,816         16.84     CCAT         21,426         19.17     E21          13,701         12.26        ECAT         19,198         17.18        GCAT         19,178         17.16        M11          19,421         17.39  In experiments that we conducted in cite{AUG09}, we considered each document available in a given language as the observed view for an example and all translated documents were used as the other views for that example, generated using Machine Translation. Results shown in this study were averaged over 10 random samples of 10 labeled examples per view for training, and 20% of the collection for testing. ","Massih-Reza Amini, Nicolas Usunier and Cyril Goutte. Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization. Advances in Neural Information Processing Systems 22, pp. 28-36, 2009 Massih-Reza Amini and Cyril Goutte. A Co-classification Approach to Learning from Multilingual Corpora. Machine Learning Journal Springer, 79(1-2):105-121, 2010 Abhishek Kumar, Hal DaumÃ© III. A co-training approach for multi-view spectral clustering. International Conference on Machine Learning, pp. 393-400. 2011","If you publish results based on this data set, please acknowledge its use, by referring to: M.-R. Amini, N. Usunier, C. Goutte. Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization. Advances in Neural Information Processing Systems 22, p. 28-36, 2009",
http://archive.ics.uci.edu/ml/datasets/NIPS+Conference+Papers+1987-2015,102,NIPS Conference Papers 1987-2015 Data Set,../machine-learning-databases/00371/,Text,11463,Computer,Integer,5812,11/23/2016,Clustering,N/A,50319,"Valerio Perronev.perrone '@' warwick.ac.uk Department of StatisticsUniversity of WarwickCoventry (UK)","The dataset is in the form of a 11463 x 5812 matrix of word counts, containing 11463 words and 5811 NIPS conference papers (the first column contains the list of words). Each column contains the number of times each word appears in the corresponding document. The names of the columns give information about each document and its timestamp in the following format: Xyear_paperID.  The matrix of word counts was obtained using the R package 'tmâ€ to process the raw .txt files of the full text of the NIPS conference papers published between 1987 and 2015. The document-term matrix was constructed after tokenization, removal of stopwords and truncation of the vocabulary by only keeping words occurring more than 50 times.","Column 1: 'X' (list of words)Columns 2-5812: 'Xyear_ID' (timestamp and paper ID)","Perrone V., Jenkins P. A., Spano D., Teh Y. W. (2016). Poisson Random Fields for Dynamic Feature Models. [Web Link] ([Web Link]).","If you use this data please cite 'Poisson Random Fields for Dynamic Feature Models'. Perrone V., Jenkins P. A., Spano D., Teh Y. W. (2016). [Web Link] ([Web Link]).",
http://archive.ics.uci.edu/ml/datasets/Japanese+Vowels,103,Japanese Vowels Data Set,../machine-learning-databases/JapaneseVowels-mld/,"Multivariate, Time-Series",640,N/A,Real,12,N/A,Classification,N/A,108408,"Original Owner and Donor: Mineichi Kudo, Jun Toyama, Masaru ShimboInformation Processing LaboratoryDivision of Systems and Information EngineeringGraduate School of EngineeringHokkaido University, Sapporo 060-8628, JAPAN{mine,jun,shimbo}@main.eng.hokudai.ac.jp","The data was collected for examining our newly developed classifier for multidimensional curves (multidimensional time series). Nine male speakers uttered two Japanese vowels /ae/ successively. For each utterance, with the analysis parameters described below, we applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 LPC cepstrum coefficients. This means that one utterance by a speaker forms a time series whose length is in the range 7-29 and each point of a time series is of 12 features (12 coefficients). The number of the time series is 640 in total. We used one set of 270 time series for training and the other set of 370 time series for testing. Number of Instances (Utterances):     * Training: 270 (30 utterances by 9 speakers. See file 'size_ae.train'.)    * Testing: 370 (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.)  Length of Time Series:     * 7 - 29 depending on utterances  Analysis parameters:     * Sampling rate : 10kHz    * Frame length : 25.6 ms    * Shift length : 6.4ms    * Degree of LPC coefficients : 12  Files:     * Training file: ae.train    * Testing file: ae.test  Format: Each line in ae.train or ae.test represents 12 LPC coefficients in the increasing order separated by spaces. This corresponds to one analysis frame. Lines are organized into blocks, which are a set of 7-29 lines separated by blank lines and corresponds to a single speech utterance of /ae/ with 7-29 frames. Each speaker is a set of consecutive blocks. In ae.train there are 30 blocks for each speaker. Blocks 1-30 represent speaker 1, blocks 31-60 represent speaker 2, and so on up to speaker 9. In ae.test, speakers 1 to 9 have the corresponding number of blocks: 31 35 88 44 29 24 40 50 29. Thus, blocks 1-31 represent speaker 1 (31 utterances of /ae/), blocks 32-66 represent speaker 2 (35 utterances of /ae/), and so on.",12 Real Attributes,"M. Kudo, J. Toyama and M. Shimbo. (1999). ""Multidimensional Curve Classification Using Passing-Through Regions"". Pattern Recognition Letters, Vol. 20, No. 11--13, pages 1103--1111.[Web Link]","If you publish any work using the dataset, please inform the donor. Use for commercial purposes requires donor permission.",
http://archive.ics.uci.edu/ml/datasets/Gas+sensors+for+home+activity+monitoring,104,Gas sensors for home activity monitoring Data Set,../machine-learning-databases/00362/,"Multivariate, Time-Series",919438,Computer,Real,11,7/15/2016,Classification,N/A,81785,"Creators:Flavia HuertaRamon Huerta, University of California San Diego, USA Donors:Flavia HuertaRamon Huerta, University of California San Diego, USA (rhuerta â€˜@â€™ ucsd.edu)Thiago Mosqueiro, University of California San Diego, USA (thmosqueiro â€˜@â€™ ucsd.edu)Jordi Fonollosa, Institute for Bioengineering of Catalunya, Spain (jfonollosa â€˜@â€™ ibecbarcelona.eu)Nikolai Rulkov, University of California San Diego, USA ( nrulkov â€˜@â€™ ucsd.edu )Irene Rodriguez-Lujan, Universidad Autonoma de Madrid, Spain ( Irene.rodriguez â€˜@â€™ uam.es )","This dataset has recordings of a gas sensor array composed of 8 MOX gas sensors, and a temperature and humidity sensor. This sensor array was exposed to background home activity while subject to two different stimuli: wine and banana. The responses to banana and wine stimuli were recorded by placing the stimulus close to the sensors. The duration of each stimulation varied from 7min to 2h, with an average duration of 42min. This dataset contains a set of time series from three different conditions: wine, banana and background activity. There are 36 inductions with wine, 33 with banana and 31 recordings of background activity. One possible application is to discriminate among background, wine and banana. This dataset is composed of two files: HT_sensor_dataset.dat (zipped), where the actual time series are stored, and the HT_Sensor_metadata.dat, where metadata for each induction is stored. Each induction is uniquely identified by an id in both files. Thus, metadata for a particular induction can be easily found by matching columns id from each file.  We also made available python scripts to exemplify how to import, organize and plot our data. The scripts are available on GitHub:[Web Link]  For each induction, we include one hour of background activity prior to and after the stimulus presentation. Time series were recorded at one sample per second, with minor variations at some data points due to issues in the wireless communication. For details on which sensors were used and how the time series is organized, see Attribute Information below. The metadata stored in file HT_Sensor_metadata.dat is divided in the following columns: * id: identification of the induction, to be matched with id in file HT_Sensor_dataset.dat;* date: day, month and year when this induction was recorded;* class: what was used to generate this induction (wine, banana or background);* t0: time in hours in which the induction started (represents the time zero in file HT_Sensor_dataset.dat);* dt: interval that this induction lasted.","The dataset is composed of 100 snippets of time series, each being a single induction or background activity. On total, there are 919438 points. For each induction, the time when the stimulus was presented is set to zero. For the actual time, see column t0 of the metadata file. In file HT_Sensor_dataset.dat, each column has a title according to the following  * id: identification of the induction, to be matched with id in file HT_Sensor_metadata.dat;* time: time in hours, where zero is the start of the induction;* R1 â€“ R8: value of each of the 8 MOX sensors resistance at that time;* Temp.: measurement of temperature in Celsius at that time;* Humidity: measurement of humidity in percent at that time.  Temperature and humidity were measured using the Sensirion SHT75. The 8 MOX sensors are commercially available from Figaro, and are detailed below:R1: TGS2611R2: TGS2612R3: TGS2610R4: TGS2600R5: TGS2602R6: TGS2602R7: TGS2620R8: TGS2620 ","Ramon Huerta, Thiago Mosqueiro, Jordi Fonollosa, Nikolai Rulkov, Irene Rodriguez-Lujan. Online Decorrelation of Humidity and Temperature in Chemical Sensors for Continuous Monitoring. Chemometrics and Intelligent Laboratory Systems 2016.","Ramon Huerta, Thiago Mosqueiro, Jordi Fonollosa, Nikolai Rulkov, Irene Rodriguez-Lujan. Online Decorrelation of Humidity and Temperature in Chemical Sensors for Continuous Monitoring. Chemometrics and Intelligent Laboratory Systems 2016.",
http://archive.ics.uci.edu/ml/datasets/CMU+Face+Images,105,CMU Face Images Data Set,../machine-learning-databases/faces-mld/,Image,640,N/A,Integer,N/A,6/24/1999,Classification,Yes,148034,"Original Owner and Donor: Tom MitchellSchool of Computer Science Carnegie Mellon Universitytom.mitchell '@' cmu.edu http://www.cs.cmu.edu/~tom/ ","Each image can be characterized by the pose, expression, eyes, and size. There are 32 images for each person capturing every combination of features.  To view the images, you can use the program xv.  The image data can be found in /faces. This directory contains 20 subdirectories, one for each person, named by userid. Each of these directories contains several different face images of the same person.  You will be interested in the images with the following naming convention:      .pgm  is the user id of the person in the image, and this field has 20 values: an2i, at33, boland, bpm, ch4f, cheyer, choon, danieln, glickman, karyadi, kawamura, kk49, megak, mitchell, night, phoebe, saavik, steffi, sz24, and tammo.  is the head position of the person, and this field has 4 values: straight, left, right, up.  is the facial expression of the person, and this field has 4 values: neutral, happy, sad, angry.  is the eye state of the person, and this field has 2 values: open, sunglasses.  is the scale of the image, and this field has 3 values: 1, 2, and 4. 1 indicates a full-resolution image (128 columns by 120 rows); 2 indicates a half-resolution image (64 by 60); 4 indicates a quarter-resolution image (32 by 30). If you've been looking closely in the image directories, you may notice that some images have a .bad suffix rather than the .pgm suffix. As it turns out, 16 of the 640 images taken have glitches due to problems with the camera setup; these are the .bad images. Some people had more glitches than others, but everyone who got ``faced'' should have at least 28 good face images (out of the 32 variations possible, discounting scale).  More information and C code for loading the images is available here: [Web Link]. ",N/A,"T. Mitchell. Machine Learning, McGraw Hill, 1997.  ","You may use this material free of charge for any educational purpose, provided attribution is given in any lectures or publications that make use of this material. ","Xiaofeng He and Partha Niyogi. Locality Preserving Projections. NIPS. 2003.  [View Context].Marina Meila and Michael I. Jordan. Learning with Mixtures of Trees. Journal of Machine Learning Research, 1. 2000.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Musk+%28Version+1%29,106,Musk (Version 1) Data Set,../machine-learning-databases/musk/,Multivariate,476,Physical,Integer,168,9/12/1994,Classification,No,66919,"Creators:   AI Group at Arris Pharmaceutical Corporationcontact:  David Chapman or Ajay JainArris Pharmaceutical Corporation385 Oyster Point Blvd.South San Francisco, CA 94080415-737-8600zvona '@' arris.com, jain '@' arris.com  Donor:      Tom DietterichDepartment of Computer ScienceOregon State UniversityCorvallis, OR 97331503-737-5559tgd '@' cs.orst.edu","This dataset describes a set of 92 molecules of which 47 are judged by human experts to be musks and the remaining 45 molecules are judged to be non-musks.  The goal is to learn to predict whether new molecules will be musks or non-musks.  However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule.  Because bonds can rotate, a single molecule can adopt many different shapes.  To generate this data set, the low-energy conformations of the molecules were generated and then filtered to remove highly similar conformations. This left 476 conformations.  Then, a feature vector was extracted that describes each conformation. This many-to-one relationship between feature vectors and molecules is called the ""multiple instance problem"".  When learning a classifier for this data, the classifier should classify a molecule as ""musk"" if ANY of its conformations is classified as a musk.  A molecule should be classified as ""non-musk"" if NONE of its conformations is classified as a musk.","   molecule_name:       Symbolic name of each molecule.  Musks have names such as MUSK-188.  Non-musks have names such as NON-MUSK-jp13.   conformation_name:   Symbolic name of each conformation.  These have the format MOL_ISO+CONF, where MOL is the molecule number, ISO is the stereoisomer number (usually 1), and CONF is the conformation number.    f1 through f162:     These are ""distance features"" along rays (see paper cited above).  The distances are measured in hundredths of Angstroms.  The distances may be negative or positive, since they are actually measured relative to an origin placed along each ray.  The origin was defined by a ""consensus musk"" surface that is no longer used.  Hence, any experiments with the data should treat these feature values as lying on an arbitrary continuous scale.  In particular, the algorithm should not make any use of the zero point or the sign of each feature value.    f163:                This is the distance of the oxygen atom in the molecule to a designated point in 3-space. This is also called OXY-DIS.   f164:                OXY-X: X-displacement from the designated point.   f165:                OXY-Y: Y-displacement from the designated point.   f166:                OXY-Z: Z-displacement from the designated point.    class:               0 => non-musk, 1 => musk    Please note that the molecule_name and conformation_name attributes should not be used to predict the class.","Dietterich, T. G., Lathrop, R. H., Lozano-Perez, T. Solving the multiple-instance problem with axis-parallel rectangles.  Artificial Intelligence.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Qingping Tao Ph. D. MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004.  [View Context].Qingping Tao and Stephen Scott and N. V. Vinodchandran and Thomas T. Osugi. SVM-based generalized multiple-instance learning via approximate box counting. ICML. 2004.  [View Context].Giorgio Valentini. Random Aggregated and Bagged Ensembles of SVMs: An Empirical Bias?Variance Analysis. Multiple Classifier Systems. 2004.  [View Context].Giorgio Valentini. Ensemble methods based on bias--variance analysis Theses Series DISI-TH-2003. Dipartimento di Informatica e Scienze dell'Informazione . 2003.  [View Context].Zhi-Hua Zhou and Min-Ling Zhang. Ensembles of Multi-instance Learners. ECML. 2003.  [View Context].Giorgio Valentini and Thomas G. Dietterich. Low Bias Bagged Support Vector Machines. ICML. 2003.  [View Context].Stephen D. Bay. Combining Nearest Neighbor Classifiers Through Multiple Feature Subsets. ICML. 1998.  [View Context].Hendrik Blockeel and Luc De Raedt. Lookahead and Discretization in ILP. ILP. 1997.  [View Context].Zhi-Hua Zhou and Hua Zhou. Multi-Instance Learning: A Survey. National Laboratory for Novel Software Technology.  [View Context].Zhi-Hua Zhou and Min-Ling Zhang. Neural Networks for Multi-Instance Learning. National Laboratory for Novel Software Technology, Nanjing University.  [View Context].Giorgio Valentini. An experimental bias--variance analysis of SVM ensembles based on resampling techniques.  [View Context].Zhi-Hua Zhou and Min-Ling Zhang. Solving Multi-Instance Problems with Classifier Ensemble Based on Constructive Clustering. National Laboratory for Novel Software Technology.  [View Context].Hendrik Blockeel and Luc De Raedt. Top-down Induction of Logical Decision Trees. Katholieke Universiteit Leuven Department of Computer Science.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/EEG+Steady-State+Visual+Evoked+Potential+Signals,107,EEG Steady-State Visual Evoked Potential Signals Data Set,../machine-learning-databases/00457/,"Multivariate, Time-Series",9200,Life,Integer,16,7/13/2018,"Classification, Regression",N/A,33481,"This database was obtained by performing the experiments using a commercial device for 30 subjects in order to partially fulfill the requirements for the Ph.D. candidate in Computer Science: Fernandez-Fraga S.M. and was supervised by Dr. M. A. Aceves-Fernandez, Ph.D. from the Autonomous University of Queretaro, Mexico (UAQ). The experiments were carried out complying with the highest ethical standards both locally (Bioethical standards provided by our University) and internationally (documents provided by the World Health Organization) and supervised by an expert physician at all time.","The tests are explained in more detail in the articles attached to the databases. The tests are visual experiments, so the signal you may be more interested in are the electrodes O1 and O2 (Columns I and J) according to the extensive literature review and international standards. Each subject performed different tests which are provided in .csv format as follows: suppose you have a .csv which name is A001SB1_1 This means the data corresponds to group A (only Group A is provided at present), subject 001, Test SB1 (Five Box Visual Test), and first experiment (_1, there could be a repetition of the experiment which will be _2, _3, etc). The different tests are as follows: SB1 - Five Box Visual Test 1, SB2 - Five Box Visual Test 2, SB3 - Five Box Visual Test 3 (There are three different Five Box tests, these are not repetitions of the same test), SV1 - Visual Image Search, SM1 - Motor Images (Hand Shake Experiment). Since these experiments are visual tests, you may be interested in the electrodes O1 and O2. A file named Signal Database.xlsx is provided with a list of every experiment carried out and the subjects for each experiment. The real name of each subject are not provided due to confidentiality issues.","There are 16 attributes, of which the last 14 are the signals coming from the electrodes. They are named according to international standards (see the references). The first two are the time-domain and a signal called interpolated which is normally 0.","Please e-mail to marco.aceves '@' gmail.com for the full article and/or information on where to fetch the paper(s).*Fernandez-Fraga, S. M., Aceves-Fernandez, M. A., Pedraza-Ortega, J. C. (2018). Feature Extraction of EEG Signal upon BCI Systems Based on Steady-State Visual Evoked Potentials Using the Ant Colony Optimization Algorithm. Discrete Dynamics in Nature and Society, 2018.*S. M. Fernandez-Fraga, M. A. Aceves-Fernande, J. C. Pedraza-Ortega & J. M. Ramos-ArreguÃ­n (2018). Screen Task Experiments for EEG Signals Based on SSVEP Brain Computer Interface. International Journal of Advanced Research, 2018.","Please if you use the database for any purpose, include one (or more) of the provided references and acknowledge the corresponding author (Aceves-Fernandez).",
http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups,108,Twenty Newsgroups Data Set,../machine-learning-databases/20newsgroups-mld/,Text,20000,N/A,N/A,N/A,9/9/1999,N/A,No,114232,"Original Owner and Donor: Tom MitchellSchool of Computer Science Carnegie Mellon Universitytom.mitchell '@' cmu.edu http://www.cs.cmu.edu/~tom/",N/A,N/A,"T. Mitchell. Machine Learning, McGraw Hill, 1997.  T. Joachims (1996). A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization, Computer Science Technical Report CMU-CS-96-118. Carnegie Mellon University. [Web Link]","You may use this material free of charge for any educational purpose, provided attribution is given in any lectures or publications that make use of this material. ",
http://archive.ics.uci.edu/ml/datasets/Glass+Identification,109,Glass Identification Data Set,../machine-learning-databases/glass/,Multivariate,214,Physical,Real,10,9/1/1987,Classification,No,348898,"Creator:  B. GermanCentral Research EstablishmentHome Office Forensic Science ServiceAldermaston, Reading, Berkshire RG7 4PN Donor:  Vina Spiehler, Ph.D., DABFTDiagnostic Products Corporation(213) 776-0180 (ext 3014)","Vina conducted a comparison test of her rule-based system, BEAGLE, the nearest-neighbor algorithm, and discriminant analysis.  BEAGLE is a product available through VRS Consulting, Inc.; 4676 Admiralty Way, Suite 206; Marina Del Ray, CA 90292 (213) 827-7890 and FAX: -3189. In determining whether the glass was a type of ""float"" glass or not, the following results were obtained (# incorrect answers): Type of Sample  -- Beagle -- NN -- DAWindows that were float processed (87)  -- 10 -- 12 -- 21Windows that were not:            (76) -- 19 -- 16 -- 22 The study of classification of types of glass was motivated by criminological investigation.  At the scene of the crime, the glass left can be used as evidence...if it is correctly identified!","1. Id number: 1 to 2142. RI: refractive index3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)4. Mg: Magnesium5. Al: Aluminum6. Si: Silicon7. K: Potassium8. Ca: Calcium9. Ba: Barium10. Fe: Iron11. Type of glass: (class attribute)     -- 1 building_windows_float_processed     -- 2 building_windows_non_float_processed     -- 3 vehicle_windows_float_processed     -- 4 vehicle_windows_non_float_processed (none in this database)     -- 5 containers     -- 6 tableware     -- 7 headlamps","Ian W. Evett and Ernest J. Spiehler. Rule Induction in Forensic Science. Central Research Establishment. Home Office Forensic Science Service. Aldermaston, Reading, Berkshire RG7 4PN[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Ping Zhong and Masao Fukushima. A Regularized Nonsmooth Newton Method for Multi-class Support Vector Machines. 2005.  [View Context].Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].S. Augustine Su and Jennifer G. Dy. Automated hierarchical mixtures of probabilistic principal component analyzers. ICML. 2004.  [View Context].Xiaoli Z. Fern and Carla Brodley. Solving cluster ensemble problems by bipartite graph partitioning. ICML. 2004.  [View Context].Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Francesco Masulli. An experimental analysis of the dependence among codeword bit errors in ECOC learning machines. and Giorgio Valentini b,c. 2003.  [View Context].Krzysztof Krawiec. Genetic Programming-based Construction of Features for Machine Learning and Knowledge Discovery Tasks. Institute of Computing Science, Poznan University of Technology. 2002.  [View Context].Michail Vlachos and Carlotta Domeniconi and Dimitrios Gunopulos and George Kollios and Nick Koudas. Non-linear dimensionality reduction techniques for classification and visualization. KDD. 2002.  [View Context].Giorgio Valentini and Francesco Masulli. NEURObjects: an object-oriented library for neural network development. Neurocomputing, 48. 2002.  [View Context].D. I. S I and Francesco Masulli and Giorgio Valentini and D. I. S. Universit#a di Genova. Dipartimento di Informatica e Scienze dell' Informazione. 2001.  [View Context].Petri Kontkanen and Petri Myllym and Tomi Silander and Henry Tirri and Peter Gr. On predictive distributions and Bayesian networks. Department of Computer Science, Stanford University. 2000.  [View Context].Thierry Denoeux. A neural network classifier based on Dempster-Shafer theory. IEEE Transactions on Systems, Man, and Cybernetics, Part A, 30. 2000.  [View Context].Francesco Masulli and Giorgio Valentini. Effectiveness of Error Correcting Output Codes in Multiclass Learning Problems. Multiple Classifier Systems. 2000.  [View Context].Nir Friedman and Iftach Nachman. Gaussian Process Networks. UAI. 2000.  [View Context].Carlotta Domeniconi and Jing Peng and Dimitrios Gunopulos. An Adaptive Metric Machine for Pattern Classification. NIPS. 2000.  [View Context].Mark A. Hall. Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning. ICML. 2000.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Christopher J. Merz. Using Correspondence Analysis to Combine Classifiers. Machine Learning, 36. 1999.  [View Context].Eibe Frank and Ian H. Witten. Generating Accurate Rule Sets Without Global Optimization. ICML. 1998.  [View Context].Georg Thimm and E. Fiesler. Optimal Setting of Weights, Learning Rate, and Gain. E S E A R C H R E P R O R T I D I A P. 1997.  [View Context].Richard Maclin and David W. Opitz. An Empirical Evaluation of Bagging and Boosting. AAAI/IAAI. 1997.  [View Context].Ethem Alpaydin. Voting over Multiple Condensed Nearest Neighbors. Artif. Intell. Rev, 11. 1997.  [View Context].Jan C. Bioch and D. Meer and Rob Potharst. Bivariate Decision Trees. PKDD. 1997.  [View Context].D. Greig and Hava T. Siegelmann and Michael Zibulevsky. A New Class of Sigmoid Activation Functions That Don't Saturate. 1997.  [View Context].Christopher J. Merz. Combining Classifiers Using Correspondence Analysis. NIPS. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Ron Kohavi and Mehran Sahami. Error-Based and Entropy-Based Discretization of Continuous Features. KDD. 1996.  [View Context].Aynur Akkus and H. Altay Güvenir. K Nearest Neighbor Classification on Feature Projections. ICML. 1996.  [View Context].Thomas G. Dietterich and Ghulum Bakiri. Solving Multiclass Learning Problems via Error-Correcting Output Codes. CoRR, csAI/9501101. 1995.  [View Context].Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. Exploiting Upper Approximation in the Rough Set Methodology. KDD. 1995.  [View Context].Rong-En Fan and P. -H Chen and C. -J Lin. Working Set Selection Using the Second Order Information for Training SVM. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Yin Zhang and W. Nick Street. Bagging with Adaptive Costs. Management Sciences Department University of Iowa Iowa City.  [View Context].Ping Zhong and Masao Fukushima. Second Order Cone Programming Formulations for Robust Multi-class Classification.  [View Context].Karthik Ramakrishnan. UNIVERSITY OF MINNESOTA.  [View Context].Pramod Viswanath and M. Narasimha Murty and Shalabh Bhatnagar. A pattern synthesis technique to reduce the curse of dimensionality effect. E-mail.  [View Context].Erin J. Bredensteiner and Kristin P. Bennett. Multicategory Classification by Support Vector Machines. Department of Mathematics University of Evansville.  [View Context].Pramod Viswanath and M. Narasimha Murty and Shalabh Bhatnagar. Partition Based Pattern Synthesis Technique with Efficient Algorithms for Nearest Neighbor Classification. Department of Computer Science and Automation, Indian Institute of Science.  [View Context].Federico Divina and Elena Marchiori. Handling Continuous Attributes in an Evolutionary Inductive Learner. Department of Computer Science Vrije Universiteit.  [View Context].James J. Liu and James Tin and Yau Kwok. An Extended Genetic Rule Induction Algorithm. Department of Computer Science Wuhan University.  [View Context].Francesco Masulli and Giorgio Valentini. Comparing Decomposition Methods for Classification. Istituto Nazionale per la Fisica della Materia DISI - Dipartimento di Informatica e Scienze dell'Informazione.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].H. Altay G uvenir and Aynur Akkus. WEIGHTED K NEAREST NEIGHBOR CLASSIFICATION ON FEATURE PROJECTIONS. Department of Computer Engineering and Information Science Bilkent University.  [View Context].Ron Kohavi and Brian Frasca. Useful Feature Subsets and Rough Set Reducts. the Third International Workshop on Rough Sets and Soft Computing.  [View Context].H. Altay Guvenir. A Classification Learning Algorithm Robust to Irrelevant Features. Bilkent University, Department of Computer Engineering and Information Science.  [View Context].Suresh K. Choubey and Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. A comparison of feature selection algorithms in the context of rough classifiers.  [View Context].Stefan Aeberhard and Danny Coomans and De Vel. THE PERFORMANCE OF STATISTICAL PATTERN RECOGNITION METHODS IN HIGH DIMENSIONAL SETTINGS. James Cook University.  [View Context].Chih-Wei Hsu and Cheng-Ru Lin. A Comparison of Methods for Multi-class Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context].. Eectiveness of Error Correcting Output Coding methods in ensemble and monolithic learning machines. Dipartimento di Informatica, Universitdi Pisa.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context].Aynur Akku and H. Altay Guvenir. Weighting Features in k Nearest Neighbor Classification on Feature Projections. Department of Computer Engineering and Information Science Bilkent University.  [View Context].Francesco Masulli and Giorgio Valentini. Quantitative Evaluation of Dependence among Outputs in ECOC Classifiers Using Mutual Information Based Measures. Universitdi Genova DISI - Dipartimento di Informatica e Scienze dell'Informazione INFM - Istituto Nazionale per la Fisica della Materia.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Protein+Secondary+Structure%29,110,Molecular Biology (Protein Secondary Structure) Data Set,../machine-learning-databases/molecular-biology/protein-secondary-structure/,Sequential,128,Life,Categorical,N/A,N/A,Classification,N/A,55986,"The data set was contributed to the benchmark collection by Terry Sejnowski, now at the Salk Institute and the University of California at San Deigo.  The data set was developed in collaboration with Ning Qian of Johns-Hopkins University.","This is a data set used by Ning Qian and Terry Sejnowski in their study using a neural net to predict the secondary structure of certain globular proteins [1].  The idea is to take a linear sequence of amino acids and to predict, for each of these amino acids, what secondary structure it is a part of within the protein.  There are three choices: alpha-helix, beta-sheet, and random-coil.  The data set contains both a large set of training data and a distinct set of data that can be used for testing the resulting network.  Qian and Sejnowski use a Nettalk-like approach and report an accuracy of 64.3% on the test set, and they speculate that this is about the best that can be done using only local context. There is also a domain theory in the folder, donated and created by Jude Shavlik & Rich Maclin",N/A,"Ning Qian and Terrnece J. Sejnowski (1988), ""Predicting the Secondary Structure of Globular Proteins Using Neural Network Models"" in Journal of Molecular Biology 202, 865-884.  Academic Press.[Web Link]","Copyright (C) 1988 by Terrence J. Sejnowski.  Permission is hereby given to use the included data for non-commercial research purposes.  Contact the John Hopkins University, Cognitive Science Center, Baltimore MD, USA for information on commercial use.","Jianbin Tan and David L. Dowe. MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes. Australian Conference on Artificial Intelligence. 2003.  [View Context].Mukund Deshpande and George Karypis. Evaluation of Techniques for Classifying Biological Sequences. PAKDD. 2002.  [View Context].Steven Eschrich and Nitesh V. Chawla and Lawrence O. Hall. Generalization Methods in Bioinformatics. BIOKDD. 2002.  [View Context].Andreas L. Prodromidis. On the Management of Distributed Learning Agents Ph.D. Thesis Proposal CUCS-032-97. Department of Computer Science Columbia University. 1998.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Kuan-ming Lin and Chih-Jen Lin. A Study on Reduced Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling,111,User Knowledge Modeling Data Set,../machine-learning-databases/00257/,Multivariate,403,Computer,Integer,5,6/26/2013,"Classification, Clustering",N/A,126250,"-- Creators: Hamdi Tolga Kahraman (htolgakahraman '@' yahoo.com)   -- Institution: Faculty of Technology, Department of Software Engineering, Karadeniz Technical University, Trabzon, Turkiye -- Creators: Ilhami Colak (icolak '@' gazi.edu.tr)-- Institution: Faculty of Technology, Department of Electrical and Electronics Engineering, Gazi University, Ankara, Turkiye-- Creators: Seref Sagiroglu (ss '@' gazi.edu.tr)-- Institution: Faculty of Technology, Department of Computer Engineering, Gazi University, Ankara, Turkiye    -- Donor: undergraduate students of Department of Electrical Education of Gazi University in the  2009 semester   -- Date: October, 2009"," -- The users' knowledge class were classified by the authors      using intuitive knowledge classifier (a hybrid ML technique of k-NN and meta-heuristic exploring methods), k-nearest neighbor algorithm.       See article for more details on how the users' data was collected and evaluated by the user modeling server. 	H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,         Knowledge Based Systems, vol. 37, pp. 283-295, 2013. ","STG (The degree of study time for goal object materails), (input value) SCG (The degree of repetition number of user for goal object materails) (input value) STR (The degree of study time of user for related objects with goal object) (input value) LPR (The exam performance of user for related objects with goal object) (input value) PEG (The exam performance of user for goal objects) (input value) UNS (The knowledge level of user) (target value) Very Low: 50Low:129Middle: 122High 130","1. H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,        Knowledge Based Systems, vol. 37, pp. 283-295, 2013.2. Kahraman, H. T. (2009). Designing and Application of Web-Based Adaptive Intelligent Education System. Gazi University Ph. D. Thesis, Turkey, 1-156.","H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web, Knowledge Based Systems, vol. 37, pp. 283-295, 2013.",
http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits,112,Optical Recognition of Handwritten Digits Data Set,../machine-learning-databases/optdigits/,Multivariate,5620,Computer,Integer,64,7/1/1998,Classification,No,276536,"E. Alpaydin, C. KaynakDepartment of Computer EngineeringBogazici University, 80815 Istanbul Turkeyalpaydin '@' boun.edu.tr","We used preprocessing programs made available by NIST to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions. For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469, 1994.","All input attributes are integers in the range 0..16.The last attribute is the class code 0..9","C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their Applications to Handwritten Digit Recognition, MSc Thesis, Institute of Graduate Studies in Science and Engineering, Bogazici University.[Web Link]  E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika. [Web Link] [Web Link]","Please refer to the Machine Learning
Repository's citation policy","Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.  [View Context].Claudio Gentile. A New Approximate Maximal Margin Classification Algorithm. NIPS. 2000.  [View Context].Ethem Alpaydin. Combined 5 x 2 cv F Test for Comparing Supervised Classification Learning Algorithms. Neural Computation, 11. 1999.  [View Context].Stephen D. Bay. Nearest neighbor classification from multiple feature subsets. Intell. Data Anal, 3. 1999.  [View Context].Erick Cantú-Paz and Chandrika Kamath. Using Evolutionary Algorithms to Induce Oblique Decision Trees. Center for Applied Scientific Computing Lawrence Livermore National Laboratory.  [View Context].Ayhan Demiriz and Kristin P. Bennett and John Shawe and I. Nouretdinov V.. Linear Programming Boosting via Column Generation. Dept. of Decision Sciences and Eng. Systems, Rensselaer Polytechnic Institute.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption,113,Individual household electric power consumption Data Set,../machine-learning-databases/00235/,"Multivariate, Time-Series",2075259,Physical,Real,9,8/30/2012,"Regression, Clustering",Yes,366946,"Georges Hebrail (georges.hebrail '@' edf.fr), Senior Researcher, EDF R&D, Clamart, FranceAlice Berard, TELECOM ParisTech Master of Engineering Internship at EDF R&D, Clamart, France","This archive contains 2075259 measurements gathered in a house located in Sceaux (7km of Paris, France) between December 2006 and November 2010 (47 months).Notes: 1.(global_active_power*1000/60 - sub_metering_1 - sub_metering_2 - sub_metering_3) represents the active energy consumed every minute (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3.2.The dataset contains some missing values in the measurements (nearly 1,25% of the rows). All calendar timestamps are present in the dataset but for some timestamps, the measurement values are missing: a missing value is represented by the absence of value between two consecutive semi-colon attribute separators. For instance, the dataset shows missing values on April 28, 2007.","1.date: Date in format dd/mm/yyyy2.time: time in format hh:mm:ss3.global_active_power: household global minute-averaged active power (in kilowatt)4.global_reactive_power: household global minute-averaged reactive power (in kilowatt)5.voltage: minute-averaged voltage (in volt)6.global_intensity: household global minute-averaged current intensity (in ampere)7.sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered).8.sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.9.sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner.",N/A,This dataset is made available under the “Creative Commons Attribution 4.0 International (CC BY 4.0)” license,
http://archive.ics.uci.edu/ml/datasets/Primary+Tumor,114,Primary Tumor Data Set,../machine-learning-databases/primary-tumor/,Multivariate,339,Life,Categorical,17,11/1/1988,Classification,Yes,132154,"Donors:  1. Igor Kononenko, University E.KardeljFaculty for electrical engineeringTrzaska 2561000 Ljubljana (tel.: (38)(+61) 265-161 2. Bojan CestnikJozef Stefan InstituteJamova 3961000 LjubljanaYugoslavia (tel.: (38)(+61) 214-399 ext.287) ","This is one of three domains provided by the Oncology Institutenthat has repeatedly appeared in the machine learning literature. (See also breast-cancer and lymphography.)","--- NOTE: All attribute values in the database have been entered as numeric values corresponding to their index in the list of attribute values for that attribute domain as given below.   1. class: lung, head & neck, esophasus, thyroid, stomach, duoden & sm.int, colon, rectum, anus, salivary glands, pancreas, gallblader, liver, kidney, bladder, testis, prostate, ovary, corpus uteri, cervix uteri, vagina, breast   2. age:   <30, 30-59, >=60   3. sex:   male, female   4. histologic-type: epidermoid, adeno, anaplastic   5. degree-of-diffe: well, fairly, poorly   6. bone: yes, no   7. bone-marrow: yes, no   8. lung: yes, no   9. pleura: yes, no  10. peritoneum: yes, no  11. liver: yes, no  12. brain: yes, no  13. skin: yes, no  14. neck: yes, no  15. supraclavicular: yes, no  16. axillar: yes, no  17. mediastinum: yes, no  18. abdominal: yes, no","Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.[Web Link]  Clark,P. & Niblett,T. (1987). Induction in Noisy Domains.  In I.Bratko & N.Lavrac (Eds.) Progress in Machine Learning, 11-30, Sigma Press.[Web Link]  Michalski,R., Mozetic,I. Hong,J., & Lavrac,N. (1986).  The Multi-Purpose Incremental Learning System AQ15 and its Testing Applications to Three Medical Domains.  In Proceedings of the Fifth National Conference on Artificial Intelligence, 1041-1045. Philadelphia, PA: Morgan Kaufmann.[Web Link]","This primary tumor domain was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and M. Soklic for providing the data.  Please include this citation if you plan to use this database.","Xavier Llor and David E. Goldberg and Ivan Traus and Ester Bernad i Mansilla. Accuracy, Parsimony, and Generality in Evolutionary Learning Systems via Multiobjective Selection. IWLCS. 2002.  [View Context].Remco R. Bouckaert. Accuracy bounds for ensembles under 0 { 1 loss. Xtal Mountain Information Technology & Computer Science Department, University of Waikato. 2002.  [View Context].Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF. Appl. Intell, 7. 1997.  [View Context].Pedro Domingos. Control-Sensitive Feature Selection for Lazy Learners. Artif. Intell. Rev, 11. 1997.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Geoffrey I Webb. Learning Decision Lists by Prepending Inferred Rules. School of Computing and Mathematics Deakin University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/EMG+data+for+gestures,115,EMG data for gestures Data Set,../machine-learning-databases/00481/,Time-Series,30000,Life,Real,6,1/7/2019,Classification,N/A,48587,"Creators:Lobov S.(1), Krilova N.(2), Kastalskiy I.(3), Kazantsev V.(4), Makarov V.A.(5, 6) 1 Lobachevsky State University of Nizhny Novgorod, Gagarin Ave. 23, 603950 Nizhny Novgorod, Russia. lobov '@' neuro.nnov.ru. 2 Lobachevsky State University of Nizhny Novgorod, Gagarin Ave. 23, 603950 Nizhny Novgorod, Russia. k-nadezhda-k '@' yandex.ru. 3 Lobachevsky State University of Nizhny Novgorod, Gagarin Ave. 23, 603950 Nizhny Novgorod, Russia. kastalskiy '@' neuro.nnov.ru. 4 Lobachevsky State University of Nizhny Novgorod, Gagarin Ave. 23, 603950 Nizhny Novgorod, Russia. kazantsev '@' neuro.nnov.ru. 5 Lobachevsky State University of Nizhny Novgorod, Gagarin Ave. 23, 603950 Nizhny Novgorod, Russia. vmakarov '@' ucm.es. 6 Department of Applied Mathematics, Instituto de MatemÃ¡tica Interdisciplinar, Universidad Complutense de Madrid, 28040 Madrid, Spain. vmakarov '@' ucm.es. ","For recording patterns, we used a MYO Thalmic bracelet worn on a userâ€™s forearm, and a PC with a Bluetooth receiver. The bracelet is equipped with eight sensors equally spaced around the forearm that simultaneously acquire myographic signals. The signals are sent through a Bluetooth interface to a PC. We present raw EMG data for 36 subjects while they performed series of static hand gestures.The subject performs two series, each of which consists of six (seven) basic gestures. Each gesture was performed for 3 seconds with a pause of 3 seconds between gestures. Number of Instances is about 40000-50000 recordings in each column (30000 listed as guaranteed)","Description of raw_data _*** fileEach file consist of 10 columns:1) Time - time in ms;2-9) Channel - eightEMG channels of MYO Thalmic bracelet;10) Class  â€“thelabel of gestures: 0 - unmarked data,1 - hand at rest, 2 - hand clenched in a fist, 3 - wrist flexion,4 â€“ wrist extension,5 â€“ radial deviations,6 - ulnar deviations,7 - extended palm (the gesture was not performed by all subjects).","Relevant Paper:Lobov S., Krilova N., Kastalskiy I., Kazantsev V., Makarov V.A. Latent Factors Limiting the Performance of sEMG-Interfaces. Sensors. 2018;18(4):1122. doi: 10.3390/s18041122","Supported by the Ministry of Education and Science of the Russian Federation in the framework of megagrant allocation in accordance with the decree of the government of the Russian Federation â„–220, project â„– 14.Y26.31.0022",
http://archive.ics.uci.edu/ml/datasets/Hepatitis,116,Hepatitis Data Set,../machine-learning-databases/hepatitis/,Multivariate,155,Life,"Categorical, Integer, Real",19,11/1/1988,Classification,Yes,256793,"Creator: unknown Donor:  G.Gong  (Carnegie-Mellon University) via Bojan CestnikJozef Stefan InstituteJamova 3961000 LjubljanaYugoslavia (tel.: (38)(+61) 214-399 ext.287) }",Please ask Gail Gong for further information on this database.,"     1. Class: DIE, LIVE     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80     3. SEX: male, female     4. STEROID: no, yes     5. ANTIVIRALS: no, yes     6. FATIGUE: no, yes     7. MALAISE: no, yes     8. ANOREXIA: no, yes     9. LIVER BIG: no, yes    10. LIVER FIRM: no, yes    11. SPLEEN PALPABLE: no, yes    12. SPIDERS: no, yes    13. ASCITES: no, yes    14. VARICES: no, yes    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00        -- see the note below    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250    17. SGOT: 13, 100, 200, 300, 400, 500,     18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90    20. HISTOLOGY: no, yes The BILIRUBIN attribute appears to be continuously-valued.  I checked this with the donater, Bojan Cestnik, who replied:  About the hepatitis database and BILIRUBIN problem I would like to say the following: BILIRUBIN is continuous attribute (= the number of it's ""values"" in the ASDOHEPA.DAT file is negative!!!); ""values"" are quoted because when speaking about the continuous attribute there is no such thing as all possible values. However, they represent so called ""boundary"" values; according to these ""boundary"" values the attribute can be discretized. At the same time, because of the continious attribute, one can perform some other test since the continuous information is preserved. I hope that these lines have at least roughly answered your question. ","Diaconis,P. & Efron,B. (1983).  Computer-Intensive Methods in Statistics.  Scientific American, Volume 248.[Web Link]  Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Amaury Habrard and Marc Bernard and Marc Sebban. IOS Press Detecting Irrelevant Subtrees to Improve Probabilistic Learning from Tree-structured Data. Fundamenta Informaticae. 2004.  [View Context].Michael L. Raymer and Travis E. Doom and Leslie A. Kuhn and William F. Punch. Knowledge discovery in medical and biological datasets using a hybrid Bayes classifier/evolutionary algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B, 33. 2003.  [View Context].Zhi-Hua Zhou and Yuan Jiang and Shifu Chen. Extracting symbolic rules from trained neural network ensembles. AI Commun, 16. 2003.  [View Context].Xiaoli Z. Fern and Carla Brodley. Boosting Lazy Decision Trees. ICML. 2003.  [View Context].Jinyan Li and Limsoon Wong. Using Rules to Analyse Bio-medical Data: A Comparison between C4.5 and PCL. WAIM. 2003.  [View Context].Takashi Matsuda and Hiroshi Motoda and Tetsuya Yoshida and Takashi Washio. Mining Patterns from Structured Data by Beam-Wise Graph-Based Induction. Discovery Science. 2002.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski. Ensembles of Similarity-based Models. Intelligent Information Systems. 2001.  [View Context].Petri Kontkanen and Petri Myllym and Tomi Silander and Henry Tirri and Peter Gr. On predictive distributions and Bayesian networks. Department of Computer Science, Stanford University. 2000.  [View Context].Gary M. Weiss and Haym Hirsh. A Quantitative Study of Small Disjuncts: Experiments and Results. Department of Computer Science Rutgers University. 2000.  [View Context].David W. Opitz and Richard Maclin. Popular Ensemble Methods: An Empirical Study. J. Artif. Intell. Res. (JAIR, 11. 1999.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].Floriana Esposito and Donato Malerba and Giovanni Semeraro. A Comparative Analysis of Methods for Pruning Decision Trees. IEEE Trans. Pattern Anal. Mach. Intell, 19. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Peter D. Turney. Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm. CoRR, csAI/9503102. 1995.  [View Context].Christophe Giraud and Tony Martinez and Christophe G. Giraud-Carrier. University of Bristol Department of Computer Science ILA: Combining Inductive Learning with Prior Knowledge and Reasoning. 1995.  [View Context].Gabor Melli. A Lazy Model-Based Approach to On-Line Classification. University of British Columbia. 1989.  [View Context].Elena Smirnova and Ida G. Sprinkhuizen-Kuyper and I. Nalbantis and b. ERIM and Universiteit Rotterdam. Unanimous Voting using Support Vector Machines. IKAT, Universiteit Maastricht.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. An Ant Colony Based System for Data Mining: Applications to Medical Data. CEFET-PR, CPGEI Av. Sete de Setembro, 3165.  [View Context].Suresh K. Choubey and Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. A comparison of feature selection algorithms in the context of rough classifiers.  [View Context].Takao Mohri and Hidehiko Tanaka. An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes. Information Engineering Course, Faculty of Engineering The University of Tokyo.  [View Context].Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. Statistical methods for construction of neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Chris Drummond and Robert C. Holte. C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling. Institute for Information Technology, National Research Council Canada.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Ida G. Sprinkhuizen-Kuyper and Elena Smirnova and I. Nalbantis. Reliability yields Information Gain. IKAT, Universiteit Maastricht.  [View Context].Christophe Giraud and Tony Martinez. ADYNAMIC INCREMENTAL NETWORK THAT LEARNS BY DISCRIMINATION. AA.  [View Context].Federico Divina and Elena Marchiori. Handling Continuous Attributes in an Evolutionary Inductive Learner. Department of Computer Science Vrije Universiteit.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery. CEFET-PR, Curitiba.  [View Context].Wl/odzisl/aw Duch and Rafal Adamczak and Geerd H. F Diercksen. Neural Networks from Similarity Based Perspective. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski and Geerd H. F Diercksen. Minimal distance neural methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski. Optimization of Logical Rules Derived by Neural Procedures. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl/odzisl/aw Duch and Rafal Adamczak and Geerd H. F Diercksen. Classification, Association and Pattern Completion using Neural Similarity Based Methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Syskill+and+Webert+Web+Page+Ratings,117,Syskill and Webert Web Page Ratings Data Set,../machine-learning-databases/SyskillWebert-mld/,"Multivariate, Text",332,Computer,Categorical,5,10/20/1998,Classification,N/A,67595,"Michael PazzaniDepartment of Information and Computer Science,University of California, IrvineIrvine, CA 92697-3425 pazzani '@' ics.uci.edu http://www.ics.uci.edu/~pazzani","The HTML source of a web page is given. Users looked at each web page and inidated on a 3 point scale (hot medium cold) 50-100 pages per domain. However, this is realistic because we want to learn user profiles from as few examples as possible so that users have an incentitive to rate pages.","Each subject is in a separate directory. Within each directory, there is an file named ""index"". The index contains information on the other files. Each entry is a line of the form:  file-name  |  rating  |  url  |  date-rated  |  title  where file-name is the name of a file (usually an integer), rating is hot, medium, or cold. There are so few medium's that mediums are usually merged with cold in experiments. The other fields aren't used in learning, but they are collected by the interface for other purposes. They are the url of the html source, the date rated and the title of the web oage. ","Pazzani M., Billsus, D. (1997). Learning and Revising User Profiles: The identification of interesting web sites. Machine Learning 27, 313-331[Web Link]  Pazzani, M., Muramatsu J., Billsus, D. (1996). Syskill & Webert: Identifying interesting web sites. Proceedings of the National Conference on Artificial Intelligence, Portland, OR. PDF [Web Link]","Please refer to the Machine Learning
Repository's citation policy","Stephen D. Bay and Dennis F. Kibler and Michael J. Pazzani and Padhraic Smyth. The UCI KDD Archive of Large Data Sets for Data Mining Research and Experimentation. SIGKDD Explorations, 2. 2000.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Australian+Sign+Language+signs+%28High+Quality%29,118,Australian Sign Language signs (High Quality) Data Set,../machine-learning-databases/auslan2-mld/,"Multivariate, Time-Series",2565,N/A,Real,22,2/26/2002,Classification,N/A,112305,"Original Owner and Donor: Mohammed Waleed KadousSchool of Computer Science of EngineeringUniversity of New South WalesSydney NSW 2052 AustraliaTel: 61 2 9385 6922waleed '@' cse.unsw.edu.au ","Data was captured using a setup that consisted of:  - Two Fifth Dimension Technologies (5DT) gloves, one right and one left - Two Ascension Flock-of-Birds magnetic position trackers, one attached to each hand - A four-port serial card to cope with four data sources - A PC (128MB RAM, Intel Pentium II 266MHz) was used  In terms of the quality of the data, the Flock system was far superior to the Nintendo system also available from the same donor. Firstly, this was a two-hand system. Secondly, each position tracker provided 6 degrees of freedom - i.e. roll, pitch and yaw as well as x, y and z. The gloves also provided a full five fingers of data. But the big improvements were in resolution - both accuracy and temporal. Position and orientation were defined to 14-bit accuracy, giving position information with a typical positional error less than one centimetre and angle error less than one half of a degree. Finger bend was measured with 8 bits per finger, of which probably 6 bits were usable once the glove was calibrated. The refresh rate of the complete system was close to 100 frames per second; and all signals had significantly less noise than the Nintendo data.  Samples from a single signer (a native Auslan signer) were collected over a period of nine weeks. In total, 27 samples per sign, and a total of 2565 signs were collected. The average length of each sign was approximately 57 frames.  The data was collected from a volunteer native Auslan signer  The data presented is the raw data with no filtering.  The file consists of 9 subdirectories tctodd1-9. Each directory consists of 3 samples of each sign, captured on a different day. In total there are 95 different signs, with 27 samples per sign. Signs were provided by a native signer volunteer.  Each file consists of a sequence of lines. Each line consists of 22 whitespace-separated numbers representing the 22 channels of information. The list of channels can be found in the domain description file. It also lists the classes. More information can be found here: [Web Link].   ","The following data were recorded for each hand: * x position expressed relative to a zero point set slightly below the chin. Expressed in meters. * y position expressed relative to a zero point set slightly below the chin. Expressed in meters. * z position expressed relative to a zero point set slightly below the chin. Expressed in meters. * roll expressed as a value between -0.5 and 0.5 with 0 being palm down. Positive means the palm is rolled clockwise from the perspective of the signer. To get degrees, multiply by 180. * pitch expressed as a value between -0.5 and 0.5 with 0 being palm flat (horizontal). Positive means the palm is pointing up. To get degrees, multiply by 180. * yaw expressed a value between -1.0 and 1.0 with 0 being palm straight ahead from the perspective of the signer. Positive means clockwise from the perspective above the signer. To get degrees, multiply by 180. * Thumb bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact. * Forefinger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact. * Middle finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact. * Ring finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact. * Little finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.","Kadous, M. W., ""Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series"", PhD Thesis (draft), School of Computer Science and Engineering, University of New South Wales, 2002.[Web Link]  Also available from: [Web Link] ","Please cite the PhD thesis above as the data source:  Kadous, M. W., ""Temporal Classification: Extending the ClassificationParadigm to Multivariate Time Series"", PhD Thesis (draft), School ofComputer Science and Engineering, University of New South Wales, 2002. ",Mohammed Waleed Kadous and Claude Sammut. The University of New South Wales School of Computer Science and Engineering Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series.  [View Context].
http://archive.ics.uci.edu/ml/datasets/CalIt2+Building+People+Counts,119,CalIt2 Building People Counts Data Set,../machine-learning-databases/event-detection/,"Multivariate, Time-Series",10080,N/A,"Categorical, Integer",4,12/1/2006,N/A,No,53914,"Creator and Maintainer:Jon HutchinsUCIjohutchi '@' uci.edu","Observations come from 2 data streams (people flow in and out of the building),  over 15 weeks, 48 time slices per day (half hour count aggregates).  The purpose is to predict the presence of an event such as a conference in the building that is reflected by unusually high people counts for that day/time period.  ","1.  Flow ID: 7 is out flow, 9 is in flow2.  Date: MM/DD/YY3.  Time: HH:MM:SS4.  Count: Number of counts reported for the previous half hour Rows: Each half hour time slice is represented by 2 rows: one row for the out flow during that time period (ID=7) and one row for the in flow during that time period (ID=9) Attributes in .events file (""ground truth"")1.  Date: MM/DD/YY2.  Begin event time: HH:MM:SS (military) 3.  End event time: HH:MM:SS (military)4.  Event name (anonymized)","""Adaptive event detection with time-varying Poisson processes""A. Ihler, J. Hutchins, and P. SmythProceedings of the 12th ACM SIGKDD Conference (KDD-06), August 2006.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/HEPMASS,120,HEPMASS Data Set,../machine-learning-databases/00347/,Multivariate,10500000,Physical,Real,28,1/28/2016,Classification,N/A,63325,"Daniel Whiteson daniel '@' uci.edu, Assistant Professor, Physics & Astronomy, Univ. of California Irvine","Machine learning is used in high-energy physics experiments to search for the signatures of exotic particles. These signatures are learned from Monte Carlo simulations of the collisions that produce these particles and the resulting decay products. In each of the three data sets here, the goal is to separate particle-producing collisions from a background source.  The mass of the new particle is unknown, so three separate data sets are provided. In each data set, 50% of the data is from a signal process, while 50% is from the background process. The data is separated into a training set of 7 million examples and a test set of 3.5 million for each. 1) In the '1000' dataset, the signal particle has mass=1000. (Note: this dataset does not include a mass feature since all signal examples have the same mass.) 2) In the 'not1000' dataset, the signal particle's mass is drawn uniformly from the set {500, 750, 1250, 1500}. The mass is included as an input feature; for the background examples, the mass is selected randomly from this same set. 3) In the 'all' dataset, the signal particle's mass is drawn uniformly from the set {500, 750, 1000, 1250, 1500}. The mass is included as an input feature; for the background examples, the mass is selected randomly from this same set.","The first column is the class label (1 for signal, 0 for background), followed by the 27 normalized features (22 low-level features then 5 high-level features), and a 28th mass feature for datasets 2 and 3. See the original paper for more detailed information.  There is a header line in each file. ","Pierre Baldi, Kyle Cranmer, Taylor Faucett, Peter Sadowski, and Daniel Whiteson. 'Parameterized Machine Learning for High-Energy Physics.' In submission.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Statlog+%28Shuttle%29,121,Statlog (Shuttle) Data Set,../machine-learning-databases/statlog/shuttle/,Multivariate,58000,Physical,Integer,9,N/A,Classification,N/A,138580,"Donor: Jason Catlett Basser Department of Computer Science, University of Sydney, N.S.W., Australia  ","Approximately 80% of the data belongs to class 1. Therefore the default accuracy is about 80%. The aim here is to obtain an accuracy of 99 - 99.9%. The examples in the original dataset were in time order, and this time order could presumably be relevant in classification.   However, this was not deemed relevant for StatLog purposes, so the order of the examples in the original dataset was randomised, and a portion of the original dataset removed for validation purposes.","The shuttle dataset contains 9 attributes all of which are numerical. The first one being time.  The last column is the class which has been coded as follows :        1       Rad Flow        2       Fpv Close        3       Fpv Open        4       High        5       Bypass        6       Bpv Close        7       Bpv Open",N/A,"Thanks to NASA for allowing us to use the shuttle datasets.","Ira Cohen and Fabio Gagliardi Cozman and Nicu Sebe and Marcelo Cesar Cirelo and Thomas S. Huang. Semisupervised Learning of Classifiers: Theory, Algorithms, and Their Application to Human-Computer Interaction. IEEE Trans. Pattern Anal. Mach. Intell, 26. 2004.  [View Context].Richard Nock. Inducing Interpretable Voting Classifiers without Trading Accuracy for Simplicity: Theoretical Results, Approximation Algorithms, and Experiments. J. Artif. Intell. Res. (JAIR, 17. 2002.  [View Context].Grigorios Tsoumakas and Ioannis P. Vlahavas. Effective Stacking of Distributed Classifiers. ECAI. 2002.  [View Context].Jun Wang and Bin Yu and Les Gasser. Concept Tree Based Clustering Visualization with Shaded Similarity Matrices. ICDM. 2002.  [View Context].Jochen Garcke and Michael Griebel and Michael Thess. Data Mining with Sparse Grids. Computing, 67. 2001.  [View Context].Stephen D. Bay. Multivariate Discretization for Set Mining. Knowl. Inf. Syst, 3. 2001.  [View Context].Haixun Wang and Carlo Zaniolo. CMP: A Fast Decision Tree Classifier Using Multivariate Predictions. ICDE. 2000.  [View Context].Khaled A. Alsabti and Sanjay Ranka and Vineet Singh. CLOUDS: A Decision Tree Classifier for Large Datasets. KDD. 1998.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Pedro Domingos. Linear-Time Rule Induction. KDD. 1996.  [View Context].Nir Friedman and Moisés Goldszmidt. Discretizing Continuous Attributes While Learning Bayesian Networks. ICML. 1996.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Ron Kohavi. A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection. IJCAI. 1995.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski. Optimization of Logical Rules Derived by Neural Procedures. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Chih-Wei Hsu and Cheng-Ru Lin. A Comparison of Methods for Multi-class Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Jeffrey P. Bradford and Clayton Kunz and Ron Kohavi and Clifford Brunk and Carla Brodley. Appears in ECML-98 as a research note Pruning Decision Trees with Misclassification Costs. School of Electrical Engineering.  [View Context].Jun Wang. Classification Visualization with Shaded Similarity Matrix. Bei Yu Les Gasser Graduate School of Library and Information Science University of Illinois at Urbana-Champaign.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. THE SEPARABILITY OF SPLIT VALUE CRITERION. Department of Computer Methods, Nicolaus Copernicus University.  [View Context].Mohammed Waleed Kadous and Claude Sammut. The University of New South Wales School of Computer Science and Engineering Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series.  [View Context].Adil M. Bagirov and Julien Ugon. An algorithm for computation of piecewise linear function separating two sets. CIAO, School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Ron Kohavi and George H. John. Automatic Parameter Selection by Minimizing Estimated Error. Computer Science Dept. Stanford University.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].Chris Giannella and Bassem Sayrafi. An Information Theoretic Histogram for Single Dimensional Selectivity Estimation. Department of Computer Science, Indiana University Bloomington.  [View Context].Christophe Giraud and Tony Martinez. ADYNAMIC INCREMENTAL NETWORK THAT LEARNS BY DISCRIMINATION. AA.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Paper+Reviews,122,Paper Reviews Data Set,../machine-learning-databases/00410/,Text,405,Computer,Integer,10,10/23/2017,"Classification, Regression",Yes,50255,"Brian Keith, Exequiel Fuentes and Claudio Meneses. Department of Computing & Systems Engineering, Universidad CatÃ³lica del Norte.brian.keith '@' ucn.cl, exequiel.fuentes '@' ucn.cl, cmeneses '@' ucn.cl","The data set consists of paper reviews sent to an international conference mostly in Spanish (some are in English). It has a total of N = 405 instances evaluated with a 5-point scale ('-2': very negative, '-1': negative, '0': neutral, '1': positive, '2': very positive), expressing the reviewer's opinion about the paper and the orientation perceived by a reader who does not know the reviewer's evaluation (more details in the attributes' section). The distribution of the original scores is more uniform in comparison to the revised scores. This difference is assumed to come from a discrepancy between the way the paper is evaluated and the way the review is written by the original reviewer. The data set is stored in JSON format, the structure is as follows:Paper: { papers have an associated timespan and a paper ID, each paper contains some reviews. The reviews have their own ID, the review text, the remarks (which can be empty), the language of the review, its orientation and evaluation. Some relevant statistics (excluding reviews in English and empty reviews):- Number of words:Min: 3 Max: 530 Avg: 88.64 Stdev: 69.76- Number of sentences:Min: 1 Max: 47 Avg: 8.91 Stdev: 7.54","1. Timespan (datetime): A date associated with the year of conference, which in turn corresponds with the time the review was written. The data set includes four years of reviews worth of conferences.2. Paper ID (integer):  This number identifies each individual paper from a given conference. The data set has 172 different papers.3. Preliminary decision (label): The preliminary decision of acceptance or rejection of a paper taken by the conference committee.4. Review ID (integer: A serial number identifier for each review as a correlative with respect to each individual paper. (e.g. the second review of some paper would correspond to the number $2$). The data set has a total of 405 reviews. Most papers have 2 reviews each.5. Text (text): Comments and detailed review of the paper. This is read by the authors and the editing commission of the conference. The editors determine if the paper should be published or not depending on the reviews. There are $6$ instances of empty reviews.6. Remarks (text): Additional comments that can be read only by the editing commission of the conference. This is used in conjunction with the previous attribute to determine if the paper should be published. This is an optional attribute. Whenever it is possible it is concatenated at the end of the main body of the review. Some reviews do not have remarks, this is indicated with an empty string ''.7. Language (text): Language corresponding to the review (it may be English or Spanish). In this case the majority of the reviews are in Spanish, with only $17$ instances of English reviews.8. Orientation (integer from -2 to 2): Review classification defined by the authors of this study, according to the 5-point scale previously described, obtained through the authors' systematic judgement of each review. This attribute represents the subjective perception of each review (i.e. how negative or positive the review is perceived when someone reads it).9. Evaluation (integer from -2 to 2): Review classification as defined by the reviewer, according to the 5-point scale previously described. This attribute represents the real evaluation given to the paper, as determined by the reviewers.10. Confidence (integer from 1 to 5): Value describing the confidence of the reviewer, a higher value denotes more confidence, while a lower value indicates less confidence.","Keith, B., Fuentes, E., & Meneses, C. (2017). A Hybrid Approach for Sentiment Analysis Applied to Paper Reviews. Available at: [Web Link]","Please cite the following paper when using this data set.- APA: Keith, B., Fuentes, E., & Meneses, C. (2017). A Hybrid Approach for Sentiment Analysis Applied to Paper Reviews. Available at: [Web Link] - BibTeX:@article{keith2017hybrid,  title={A Hybrid Approach for Sentiment Analysis Applied to Paper Reviews},  author={Keith, Brian and Fuentes, Exequiel and Meneses, Claudio},  year={2017}}",
http://archive.ics.uci.edu/ml/datasets/Prodigy,123,Prodigy Data Set,http://www.ics.uci.edu/~mlearn/databases/prodigy/,Domain-Theory,N/A,N/A,N/A,N/A,N/A,N/A,N/A,33933,N/A,"Here is a summary of the domains that can be used currently with Prodigy.  Each one is described briefly. For more information in any of them, read the README file in the directory corresponding to the domain.   * stripsworld: There are several directories related to this domain:        -- stripsworld: the domain for STRIPS.        -- extended-strips: an extension to the STRIPS domain where doors can be locked and there are keys for the locks.        -- multirobot: the STRIPS domain with two or more robots.    * blocksworld: There are several directories related to this domain:        -- blocksworld: the domain as was built initially.        -- frozenblocksworld: a stable version. Used for the manual.        -- extended-bw: an extension to blocksworld that deals with  the weight and location of the blocks.      (See also gridworld)   * eightpuzzle: a domain for solving the eight puzzle.   * grammar: a simple grammar.   * gridworld: a 3-D version of blocksworld.   * jupiter: Prodigy interacts with an external world, via the World Modelers.   * logic: a simple logic domain.   * matrix-algebra: gaussian elimination in matrices.   * r1: VAX configuration domain (a simplification of R1).   * rocket: chinese rocket domain.   * schedworld:  a machine shop scheduling domain.   * telescope: a domain for building telescope mirrors.  ",N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Demospongiae,124,Demospongiae Data Set,../machine-learning-databases/demospongiae,Multivariate,503,Life,Integer,N/A,1/21/2010,Classification,Yes,55325,"Creator: Eva Armengol, Enric Plaza, Marta Domingo and Iosune Uriz Donor: Santiago Ontanon (santi '@' iiia.csic.es)","This dataset contains 503 sponges belonging to the Demospongiae class collected from the Mediterranean (451 sponges) and Atlantic oceans (52 sponges). Each sponge is classified according to a hierarchy formed by: order, family, genus and specie. Each order is subdivided in several families. Each family is also divided in several genus, and each genus in several species:- There are 7 different orders (between 42 to 117 sponges per order)- 42 different families (1 to 43 sponges per family)- 114 different genus (1 to 34 sponges per genus)- 230 different species (1 to 15 sponges per specie) Although classification at all these levels can be attempted, it has traditionally been used as a classification dataset, using 'order' as the target class. Moreover, a subset consisting of 280 sponges (orders astrophoricda, axinellida and hadromerida) is also commonly used. The data set is relational and is provided in two alternative formats (which are equivalent):- NOOS: NOOS is a lisp-like language to represent data as feature-terms. The following files contain the dataset in this format:	- sponge-ontology.noos: this defines the ontology (sorts and features)	- sponge-dm.noos: this file defines the different constants used in the examples	- sponge-cases-503.noos: this file contains the actual dataset- Horn Clauses: the dataset is also provided as a set of prolog clauses, equivalent to the feature-term representation in NOOS. The file sponges-503.pl contains the dataset in this format. Each predicate with head 'sponge-problem' defines a different sponge.","Each sponge defines 2 attributes:- description: which in itself defines up to 6 attributes (external-features, ecological-features, spikulate-skeleton, fibrous-skeleton, tracts-skeleton, and anatomy). Each of those attributes has additional attributes defined, and so on, forming a tree structure. The leaves of the tree contain both categorial as well as numerical features. Moreover, some features are multi-valued (i.e. a feature can contain more than one value)- solution: this attribute has 4 additional attributes defined (order, family, genus and specie), which are the target attributes. As explained above, typically 'order' is used as the target class, since there are not enough examples to predict family, genus and specie accurately. The trees representing the sponges vary in size: their depth varies form 5 to 8, and their number of leaves from 17 to 51. A graphical representation of a sponge is shown in the file sponge-220.pdf as an example.","Santiago Ontanon and Enric Plaza (2009) On Similarity Measures based on a Refinement Lattice. in ICCBR 2009, LNAI 5650, pp 240 - 255. Eva Armengol, Enric Plaza: Lazy Induction of Descriptions for Relational Case-Based Learning. ECML 2001: 13-24 Eva Armengol, Enric Plaza: Similarity Assessment for Relational CBR. ICCBR 2001: 44-58","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Roman+Urdu+Data+Set,125,Roman Urdu Data Set Data Set,../machine-learning-databases/00458/,Text,20000,Computer,N/A,2,8/29/2018,Classification,N/A,20633,"Zareen Sharf, zareensharf76 '@' gmail.com, Shaheed Zulfiqar Ali Bhutto Institute of Science and Technology (SZABIST).","Tagged for Sentiment (Positive, Negative, Neutral)",Each record comprises of two string datatype values. One for Comment/Review and the second for sentiment.,"Sharf, Zareen, and Saif Ur Rahman. 'Lexical normalization of roman Urdu text.' IJCSNS 17.12 (2017): 213.Sharf, Zareen, and Saif Ur Rahman. â€œPerforming Natural Language Processing On Roman Urdu Datasets.' IJCSNS (January 2018 Volume)",To be cited whenever accessed or downloaded.,
http://archive.ics.uci.edu/ml/datasets/URL+Reputation,126,URL Reputation Data Set,../machine-learning-databases/url/,"Multivariate, Time-Series",2396130,Computer,"Integer, Real",3231961,10/15/2009,Classification,N/A,138461,"'Identifying Malicious URLs: An Application of Large-Scale Online Learning' (ICML-09)Justin Ma, Lawrence K. Saul, Stefan Savage, Geoffrey M. Voelker Please visit [http://sysnet.ucsd.edu/projects/url/] for more information.","Uncompressing the archive url_svmlight.tar.gz will yield a directory url_svmlight/ containing the following files:    * FeatureTypes --- A text file list of feature indices that correspond to real-valued features.    * DayX.svm (where X is an integer from 0 to 120) --- The data for day X in SVM-light format. A label of +1 corresponds to a malicious URL and -1 corresponds to a benign URL.","Attributes are anonymized, but correspond to lexical and host-based features gathered for each URL.",N/A,"If you use this data set in published work, please cite the ICML-09 paper in which it was first introduced and described: Justin Ma, Lawrence K. Saul, Stefan Savage, and Geoffrey M. Voelker,Identifying Suspicious URLs: An Application of Large-Scale Online LearningProceedings of the International Conference on Machine Learning (ICML), pages 681-688, Montreal, Quebec, June 2009. ",
http://archive.ics.uci.edu/ml/datasets/Dorothea,127,Dorothea Data Set,../machine-learning-databases/dorothea/,Multivariate,1950,Life,Integer,100000,2/29/2008,Classification,N/A,109176,"a.	Original ownersThe dataset with which DOROTHEA was created is one of the KDD (Knowledge Discovery in Data Mining) Cup 2001. The original dataset and papers of the winners of the competition are available at: http://www.cs.wisc.edu/~dpage/kddcup2001/. DuPont Pharmaceuticals graciously provided this data set for the KDD Cup 2001 competition. All publications referring to analysis of this data set should acknowledge DuPont Pharmaceuticals Research Laboratories and KDD Cup 2001. b.	Donor of databaseThis version of the database was prepared for the NIPS 2003 variable and feature selection benchmark by Isabelle Guyon, 955 Creston Road, Berkeley, CA 94708, USA (isabelle '@' clopinet.com).","Drugs are typically small organic molecules that achieve their desired activity by binding to a target site on a receptor. The first step in the discovery of a new drug is usually to identify and isolate the receptor to which it should bind, followed by testing many small molecules for their ability to bind to the target site. This leaves researchers with the task of determining what separates the active (binding) compounds from the inactive (non-binding) ones. Such a determination can then be used in the design of new compounds that not only bind, but also have all the other properties required for a drug (solubility, oral absorption, lack of side effects, appropriate duration of action, toxicity, etc.). The original data were modified for the purpose of the feature selection challenge. In particular, we added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. DOROTHEA -- Positive ex. -- Negative ex. -- Total		   Training set -- 78 -- 722 -- 800		   Validation set -- 34 -- 316 -- 350		   Test set -- 78 -- 722 -- 800		   All -- 190 -- 1760 -- 1950		 We mapped Active compounds to the target value +1 (positive examples) and Inactive compounds to the target value –1 (negative examples). Number of variables/features/attributes:Real: 50000Probes: 50000Total: 100000	  This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link]. All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge. The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link]. The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a sparse binary matrix, patterns in lines, features in columns: the number of the non-zero features are provided).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).",We do not provide attribute information to avoid biasing feature selection.,"The best challenge entrants wrote papers collected in the book:Isabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer. [Web Link]  See also:Isabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 1438–1444.and the associated technical report:Isabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report. [Web Link].","Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge. In: NIPS. [Web Link].",
http://archive.ics.uci.edu/ml/datasets/UJI+Pen+Characters,128,UJI Pen Characters Data Set,../machine-learning-databases/uji-penchars/version1/,"Multivariate, Sequential",1364,Computer,Integer,N/A,6/1/2007,Classification,No,97231,"D. Llorens, F. Prat, A. Marzal, J. M. VilarDepartamento de Lenguajes y Sistemas InformáticosUniversitat Jaume I, 12071 Castellón (SPAIN)fprat '@' lsi.uji.es","We create a character database by collecting samples from 11 writers.  Each writer contributed with letters (lower and uppercase), digits, and other characters (Spanish diacritics and punctuation marks) that we have not employed in our experiments and are not included in this database version. Two samples have been collected for each pair writer/character, so the total number of samples in this database version is 1364:           11 writers x 2 repetitions x (2x26 letters + 10 digits) The proposed task is a writer-independent one consisting of 11 leaving-one-writer-out tests, so the effective training set size (for each one of the 1364 test samples) is 1240:           10 writers x 2 repetitions x (2x26 letters + 10 digits) Moreover, this classification task is a 35-class one because we have not considered a different class for each different character: each one of the 26 letters is considered as a case-independent class, there are 9 additional clases for non-zero digits, and the zero is included in the same class as o's. This database is available in a UNIPEN-like format, trying to mimic the original Pendigits database. Two versions of that database are available; see folder: [Web Link]  The distribution of our database consists of 12 files:           uji.names          One file ""UJIpenchars-wNN"" per writer, where NN = ""01"", ""02""... ""11"" The handwriting samples were collected on a Toshiba Portégé M400 Tablet PC using its cordless stylus. Each one of the 11 writers completed 2 non-consecutive sessions. In each session, the corresponding writer was asked to write one exemplar for each character in a fixed set including lowercase letters, uppercase ones, and digits, along with other characters omitted from this database version. The acquisition program shows a set of boxes on the screen, a different one for each required character, and writers are told to write only inside those boxes. If they make a mistake or are unhappy with a character writing, they are instructed to clear the content of the corresponding box by using an on-screen button and try again. Subjects are monitored only when writing their first exemplars and every sample considered OK by its writer was accepted as such. Only X and Y coordinate information was recorded along the strokes by the acquisition program, without, for instance, pressure level values or timing information. Thus, in multi-stroke samples, no information at all was recorded between strokes; however, in this database version we have included a "".DT 100"" line in sample files after each stroke, following the Pendigits database criterion. We have observed that runs of consecutive points with identical coordinates were frequently acquired inside strokes; such runs were preserved in this database version, so each database user must decide whether to avoid them by an appropriate preprocessing step or not.","For each sample, you can find: a. The character it represents.b. The class it belongs to.c. The sequence of strokes it consists of. When testing, you are only allowed to read the sequence of strokes of a sample in order to predict its class. For Each Attribute: As said before, this database is available in a UNIPEN-like format, trying to mimic the original Pendigits database.  A definition of UNIPEN format can be found in [Web Link]  Regarding the attributes of a sample, you can find them in the file format as follows: a. Character name: Each sample begins with a "".SEGMENT"" line. The last component of that line shows the character name, one out of 62 possibilities. The complete set of possibilities is shown in the first line of each file, a "".LEXICON"" line. Those possibilities are repeated here: ""a"" ""b"" ""c"" ""d"" ""e"" ""f"" ""g"" ""h"" ""i"" ""j"" ""k"" ""l"" ""m""""n"" ""o"" ""p"" ""q"" ""r"" ""s"" ""t"" ""u"" ""v"" ""w"" ""x"" ""y"" ""z""""A"" ""B"" ""C"" ""D"" ""E"" ""F"" ""G"" ""H"" ""I"" ""J"" ""K"" ""L"" ""M""""N"" ""O"" ""P"" ""Q"" ""R"" ""S"" ""T"" ""U"" ""V"" ""W"" ""X"" ""Y"" ""Z""""0"" ""1"" ""2"" ""3"" ""4"" ""5"" ""6"" ""7"" ""8"" ""9"" b. Class name: The class name of a sample appears in the "".COMMENT"" line that follows its "".SEGMENT"" line. This name is one out of 35 possibilities. In each file, the complete set of possibilities is shown in "".COMMENT"" lines between the "".LEXICON"" line and a "".HIERARCHY"" one. Those class definitions are repeated here:                [A] = { ""a"" , ""A"" }               [B] = { ""b"" , ""B"" }               [C] = { ""c"" , ""C"" }               [D] = { ""d"" , ""D"" }               [E] = { ""e"" , ""E"" }               [F] = { ""f"" , ""F"" }               [G] = { ""g"" , ""G"" }               [H] = { ""h"" , ""H"" }               [I] = { ""i"" , ""I"" }               [J] = { ""j"" , ""J"" }               [K] = { ""k"" , ""K"" }               [L] = { ""l"" , ""L"" }               [M] = { ""m"" , ""M"" }               [N] = { ""n"" , ""N"" }               [O] = { ""o"" , ""O"" , ""0"" }               [P] = { ""p"" , ""P"" }               [Q] = { ""q"" , ""Q"" }               [R] = { ""r"" , ""R"" }               [S] = { ""s"" , ""S"" }               [T] = { ""t"" , ""T"" }               [U] = { ""u"" , ""U"" }               [V] = { ""v"" , ""V"" }               [W] = { ""w"" , ""W"" }               [X] = { ""x"" , ""X"" }               [Y] = { ""y"" , ""Y"" }               [Z] = { ""z"" , ""Z"" }               [1] = { ""1"" }               [2] = { ""2"" }               [3] = { ""3"" }               [4] = { ""4"" }               [5] = { ""5"" }               [6] = { ""6"" }               [7] = { ""7"" }               [8] = { ""8"" }               [9] = { ""9"" } c. Sequence of strokes: After the "".SEGMENT"" and "".COMMENT"" lines of a sample, a sequence of one or more strokes follows until the beginning of a new sample or the end of the file.  Each stroke begins with a "".PEN_DOWN"" line and ends with a sequence "".PEN_UP"", "".DT 100""; in between, a sequence of lines, each one representing X and Y coordinates of a point, where X grows left-to-right and Y grows downwards. Coordinates are integer numbers.","  R. Ramos-Garijo, S. Martín, A. Marzal, F. Prat, J.M. Vilar, and D. Llorens:  ""An Input Panel and Recognition Engine for On-Line Handwritten Text Recognition""  Artificial Intelligence Research and Development, pp. 223-232, IOS Press, 2007.   F. Prat, A. Marzal, S. Martín, and R. Ramos-Garijo:  ""A Two-Stage Template-Based Recognition Engine for On-Line Handwritten Characters""  Proceeding of the Asia-Pacific Workshop 2007 on Visual Information Processing, pp. 77-82, 2007.    D. Llorens et al.:  ""The UJIpenchars Database: A Pen-Based Database of Isolated Handwritten Characters""      Proc. of the 6th International Conference on Language Resources and Evaluation. 2008. ","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover,129,Urban Land Cover Data Set,../machine-learning-databases/00295/,Multivariate,168,Physical,N/A,148,3/27/2014,Classification,N/A,46854,"Brian Johnson; Institute for Global Environmental Strategies; 2108-11 Kamiyamaguchi, Hayama, Kanagawa,240-0115 Japan; Email: Johnson '@' iges.or.jp ","Contains training and testing data for classifying a high resolution aerial image into 9 types of urban land cover. Multi-scale spectral, size, shape, and texture information are used for classification. There are a low number of training samples for each class (14-30) and a high number of classification variables (148), so it may be an interesting data set for testing feature selection methods. The testing data set is from a random sampling of the image. Class is the target classification variable. The land cover classes are: trees, grass, soil, concrete, asphalt, buildings, cars, pools, shadows.","LEGENDClass: Land cover class (nominal)BrdIndx: Border Index (shape variable)Area: Area in m2 (size variable)Round: Roundness (shape variable)Bright: Brightness (spectral variable)Compact: Compactness (shape variable)ShpIndx: Shape Index (shape variable)Mean_G: Green (spectral variable)Mean_R: Red (spectral variable)Mean_NIR: Near Infrared (spectral variable)SD_G: Standard deviation of Green (texture variable)SD_R: Standard deviation of Red (texture variable)SD_NIR: Standard deviation of Near Infrared (texture variable)LW: Length/Width (shape variable)GLCM1: Gray-Level Co-occurrence Matrix [i forget which type of GLCM metric this one is] (texture variable)Rect: Rectangularity (shape variable)GLCM2: Another Gray-Level Co-occurrence Matrix attribute (texture variable)Dens: Density (shape variable)Assym: Assymetry (shape variable)NDVI: Normalized Difference Vegetation Index (spectral variable)BordLngth: Border Length (shape variable)GLCM3: Another Gray-Level Co-occurrence Matrix attribute (texture variable) Note: These variables repeat for each coarser scale (i.e. variable_40, variable_60, ...variable_140).","1. Johnson, B., Xie, Z., 2013. Classifying a high resolution image of an urban area using super-object information. ISPRS Journal of Photogrammetry and Remote Sensing, 83, 40-49. 2. Johnson, B., 2013. High resolution urban land cover classification using a competitive multi-scale object-based approach. Remote Sensing Letters, 4 (2), 131-140. ","Please cite: 1. Johnson, B., Xie, Z., 2013. Classifying a high resolution image of an urban area using super-object information. ISPRS Journal of Photogrammetry and Remote Sensing, 83, 40-49. 2. Johnson, B., 2013. High resolution urban land cover classification using a competitive multi-scale object-based approach. Remote Sensing Letters, 4 (2), 131-140.",
http://archive.ics.uci.edu/ml/datasets/Bias+correction+of+numerical+prediction+model+temperature+forecast,130,Bias correction of numerical prediction model temperature forecast Data Set,../machine-learning-databases/00514/,Multivariate,7750,Physical,Real,25,2/18/2020,Regression,Yes,14124,"Dongjin Cho, djcho '@' unist.ac.kr, School of Urban and Environmental Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, South KoreaCheolhee Yoo, yoclhe '@' unist.ac.kr, School of Urban and Environmental Engineering, Ulsan National Institute of Science and Technology (UNIST), Ulsan, South Korea","This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017.","For more information, read [Cho et al, 2020].1. station - used weather station number: 1 to 252. Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')3. Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Â°C): 20 to 37.64. Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Â°C): 11.3 to 29.95. LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.56. LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 1007. LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Â°C): 17.6 to 38.58. LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Â°C): 14.3 to 29.69. LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.910. LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.411. LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.9712. LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.9713. LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.9814. LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.9715. LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.716. LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.617. LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.818. LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.719. lat - Latitude (Â°): 37.456 to 37.64520. lon - Longitude (Â°): 126.826 to 127.13521. DEM - Elevation (m): 12.4 to 212.322. Slope - Slope (Â°): 0.1 to 5.223. Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.924. Next_Tmax - The next-day maximum air temperature (Â°C): 17.4 to 38.925. Next_Tmin - The next-day minimum air temperature (Â°C): 11.3 to 29.8","Cho, D., Yoo, C., Im, J., & Cha, D. (2020). Comparative assessment of various machine learning-based bias correction methods for numerical weather prediction model forecasts of extreme air temperatures in urban areas. Earth and Space Science. (Accepted)","Cho, D., Yoo, C., Im, J., & Cha, D. (2020). Comparative assessment of various machine learning-based bias correction methods for numerical weather prediction model forecasts of extreme air temperatures in urban areas. Earth and Space Science. (Accepted)Please include this citation if you plan to use this database:",
http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra,131,Breast Cancer Coimbra Data Set,../machine-learning-databases/00451/,Multivariate,116,Life,Integer,10,3/6/2018,Classification,N/A,88384,"Miguel Patrício(miguelpatricio '@' gmail.com), José Pereira (jafcpereira '@' gmail.com), Joana Crisóstomo (joanacrisostomo '@' hotmail.com), Paulo Matafome (paulomatafome '@' gmail.com), Raquel Seiça (rmfseica '@' gmail.com), Francisco Caramelo (fcaramelo '@' fmed.uc.pt), all from the Faculty of Medicine of the University of Coimbra and also Manuel Gomes (manuelmgomes '@' gmail.com) from the University Hospital Centre of Coimbra","There are 10 predictors, all quantitative, and a binary dependent variable, indicating the presence or absence of breast cancer. The predictors are anthropometric data and parameters which can be gathered in routine blood analysis. Prediction models based on these predictors, if accurate, can potentially be used as a biomarker of breast cancer.","Quantitative Attributes: Age (years)BMI (kg/m2)Glucose (mg/dL)Insulin (µU/mL)HOMALeptin (ng/mL)Adiponectin (µg/mL)Resistin (ng/mL)MCP-1(pg/dL) Labels:1=Healthy controls2=Patients",[Web Link] [Web Link],"This dataset is publicly available for research. The details are described in [Patricio, 2018] - [Web Link]. Please include this citation if you plan to use this database: [Patricio, 2018] Patrício, M., Pereira, J., Crisóstomo, J., Matafome, P., Gomes, M., Seiça, R., & Caramelo, F. (2018). Using Resistin, glucose, age and BMI to predict the presence of breast cancer. BMC Cancer, 18(1). [Web Link]",
http://archive.ics.uci.edu/ml/datasets/Firm-Teacher_Clave-Direction_Classification,132,Firm-Teacher_Clave-Direction_Classification Data Set,../machine-learning-databases/00324/,Multivariate,10800,N/A,N/A,20,4/24/2015,Classification,N/A,28904,"Name: Mehmet VurkaÃ§, Ph.D.E-mail address: mehmet.vurkac '@' gmail.com, mehmet.vurkac '@' oit.edu, engineer '@' fastmail.com Institutions: Oregon Institute of Technology (current), Portland State University (where data were obtained)Other contact information: Daytime phone: 1-541-885-1258","The data consist of 16 binary inputs and one 'four-bit' one-hot classification output. The 16-bit inputs are binary-valued attack-point vectors. 1 indicates the substantial presence (0, absence) of an onset (note start) in a certain time window during one bar of 4/4 time music (not limited to percussion, hence *onset* vectors without duration) quantized to 16th-note subdivisions. Each vector has 16 positions in which there may be or not be an onset. The output classes (left to right: neutral, reverse clave, forward clave, and incoherent) were determined through the music-theoretic/ethnomusicological portion of the my dissertation studies, based on both double-blind listening tests and informal interviews with with four professional master-musicians, as well as decades of studying the music. Future uploads (subject only to formatting) can include an additional column of fuzzy descriptors (of the degree of match to the output class).","In terms of divisive rhythm counting, the first 16 attributes (input bits) correspond to a significant onset at:1 e & a 2 e & a 3 e & a 4 e & a of one bar of 4/4 time. The last four are the output classes (3 - neutral, 2 - reverse clave, 1 - forward clave, 0 - incoherent) in one-hot (one-up) encoding.","A Cross-Cultural Grammar for Temporal Harmony in Afro-Latin Musics: Clave, Partido-Alto and Other Timelines (Current Musicology, No. 94, 2014 with Fall 2012 imprint: [Web Link]:180566)On the Need for Clave-Direction Analysis: A New Arena for Educational and Creative Applications of Music Technology (Journal of Music, Technology and Education, Vol. 4, No. 1, August 2011: [Web Link])BalanÃ§o: the Contour of Selective Offbeatness (Bridges 2012: Mathematics, Music, Art, Architecture, Culture: [Web Link])Workshop: Make Your Own MP3 with â€œAlgorhythmicâ€ Generation and Aksakâ€“Euclidean Synthesis (2013 for 2015 Presentation, Bridges 2013: Mathematics, Music, Art, Architecture, Culture: archive.bridgesmathart.org/2013/bridges2013-593.pdf)",Please refer to Machine Learning Repository's citation policy.,
http://archive.ics.uci.edu/ml/datasets/PMU-UD,133,PMU-UD Data Set,../machine-learning-databases/00469/,Univariate,5180,Computer,N/A,9,8/5/2018,Classification,N/A,10405,"Ghazanfar Latif, College of Computer Engineering and Sciences, Prince Mohammad bin Fahd University, Al Khobar, Saudi Arabia. glatif '@' pmu.edu.sa",The dataset contains handwritten Urdu/Arabic numerals from 0 to 9,The participants were asked to write the numerals from 0-9 five times each. Participants age ranged from 25-55 years old.,"Multi-Language Handwritten Digits Recognition based on Novel Structural FeaturesJaafar M. Alghazo, Ghazanfar Latif, Loay Alzubaidi1, Ammar Elhassan","Multi-Language Handwritten Digits Recognition based on Novel Structural FeaturesJaafar M. Alghazo, Ghazanfar Latif, Loay Alzubaidi1, Ammar Elhassan, JIST, 2018.",
http://archive.ics.uci.edu/ml/datasets/Real-time+Election+Results%3A+Portugal+2019,134,Real-time Election Results: Portugal 2019 Data Set,../machine-learning-databases/00513/,"Multivariate, Time-Series, Text",21643,Social,"Integer, Real",29,12/5/2019,Regression,N/A,11800,"Nuno MonizLIAAD - INESC Tec; Sciences College, University of PortoEmail: nmmoniz '@' inesctec.pt","A data set describing the evolution of results in the Portuguese Parliamentary Elections of October 6th 2019. The data spans a time interval of 4 hours and 25 minutes, in intervals of 5 minutes, concerning the results of the 27 parties involved in the electoral event. The data set is tailored for predictive modelling tasks, mostly focused on numerical forecasting tasks. Regardless, it allows for other tasks such as ordinal regression or learn-to-rankProvide a short description of your data set (less than 200 characters). Additional (and updated) information may be found in [Web Link] :- Raw data sets- R code to build the final data set- Basic operations to build predictive modelling tasks using this data set","TimeElapsed (Numeric): Time (minutes) passed since the first data acquisitiontime (timestamp): Date and time of the data acquisitionterritoryName (string): Short name of the location (district or nation-wide)totalMandates (numeric): MP's elected at the momentavailableMandates (numeric): MP's left to elect at the momentnumParishes (numeric): Total number of parishes in this locationnumParishesApproved (numeric): Number of parishes approved in this locationblankVotes (numeric): Number of blank votesblankVotesPercentage (numeric): Percentage of blank votesnullVotes (numeric): Number of null votesnullVotesPercentage (numeric): Percentage of null votesvotersPercentage (numeric): Percentage of voterssubscribedVoters (numeric): Number of subscribed voters in the locationtotalVoters (numeric): Percentage of blank votespre.blankVotes (numeric): Number of blank votes (previous election)pre.blankVotesPercentage (numeric): Percentage of blank votes (previous election)pre.nullVotes (numeric): Number of null votes (previous election)pre.nullVotesPercentage (numeric): Percentage of null votes (previous election)pre.votersPercentage (numeric): Percentage of voters (previous election)pre.subscribedVoters (numeric): Number of subscribed voters in the location (previous election)pre.totalVoters (numeric): Percentage of blank votes (previous election)Party (string): Political PartyMandates (numeric): MP's elected at the moment for the party in a given districtPercentage (numeric): Percentage of votes in a partyvalidVotesPercentage (numeric): Percentage of valid votes in a partyVotes (numeric): Percentage of party votesHondt (numeric): Number of MP's according to the distribution of votes nowFinalMandates (numeric): Target: final number of elected MP's in a district/national-level","Nuno Moniz (2019) Real-time 2019 Portuguese Parliament Election Results Dataset. arXiv Code + Data in [Web Link]",Nuno Moniz (2019) Real-time 2019 Portuguese Parliament Election Results Dataset. arXiv,
http://archive.ics.uci.edu/ml/datasets/Turkiye+Student+Evaluation,136,Turkiye Student Evaluation Data Set,../machine-learning-databases/00262/,Multivariate,5820,N/A,N/A,33,9/1/2013,"Classification, Clustering",N/A,99876,"Ernest FokoueCenter for Quality and Applied StatisticsRochester Institute of Technology98 Lomb Memorial DriveRochester, NY 14623, USA eMaÄ±l: epfeqa '@' rit.edu  Necla GunduzDepartment of Statistics Faculty of Science, Gazi UniversityTeknikokullar,06500 Ankara, Turkey eMail: ngunduz '@' gazi.edu.tr gunduznecla '@' yahoo.com ",N/A,"   instr: Instructor's identifier; values taken from {1,2,3}   class: Course code (descriptor); values taken from {1-13}   repeat: Number of times the student is taking this course; values taken from {0,1,2,3,...}   attendance: Code of the level of attendance; values from {0, 1, 2, 3, 4}   difficulty: Level of difficulty of the course as perceived by the student; values taken from {1,2,3,4,5}   Q1:  The semester course content, teaching method and evaluation system were provided at the start.   Q2:  The course aims and objectives were clearly stated at the beginning of the period.   Q3:  The course was worth the amount of credit assigned to it.   Q4:  The course was taught according to the syllabus announced on the first day of class.   Q5:	The class discussions, homework assignments, applications and studies were satisfactory.   Q6:  The textbook and other courses resources were sufficient and up to date.				   Q7:  The course allowed field work, applications, laboratory, discussion and other studies.   Q8:  The quizzes, assignments, projects and exams contributed to helping the learning.	   Q9:  I greatly enjoyed the class and was eager to actively participate during the lectures.   Q10: My initial expectations about the course were met at the end of the period or year.   Q11: The course was relevant and beneficial to my professional development.   Q12: The course helped me look at life and the world with a new perspective.   Q13: The Instructor's knowledge was relevant and up to date.   Q14: The Instructor came prepared for classes.   Q15: The Instructor taught in accordance with the announced lesson plan.   Q16: The Instructor was committed to the course and was understandable.   Q17: The Instructor arrived on time for classes.   Q18: The Instructor has a smooth and easy to follow delivery/speech.   Q19: The Instructor made effective use of class hours.   Q20: The Instructor explained the course and was eager to be helpful to students.   Q21: The Instructor demonstrated a positive approach to students.   Q22: The Instructor was open and respectful of the views of students about the course.   Q23: The Instructor encouraged participation in the course.   Q24: The Instructor gave relevant homework assignments/projects, and helped/guided students.   Q25: The Instructor responded to questions about the course inside and outside of the course.   Q26: The Instructor's evaluation system (midterm and final questions, projects, assignments, etc.) effectively measured the course objectives.   Q27: The Instructor provided solutions to exams and discussed them with students.   Q28: The Instructor treated all students in a right and objective manner.    Q1-Q28 are all Likert-type, meaning that the values are taken from {1,2,3,4,5}",N/A,"If you publish material based on databases obtained from this repository, then, in your acknowledgements, please note the assistance you received by using this repository. This will help others to obtain the same data sets and replicate your experiments. We suggest the following pseudo-APA reference format for referring to this repository: Gunduz, G. & Fokoue, E. (2013). UCI Machine Learning Repository [[Web Link]]. Irvine, CA: University of California, School of Information and Computer Science. Here is a BiBTeX citation as well: @misc{GunduzFokoue:2013 ,author = 'Gunduz, N. and Fokoue, E.',year = '2013',title = '{UCI} Machine Learning Repository',url = '[Web Link]',institution = 'University of California, Irvine, School of Information and Computer Sciences' }",
http://archive.ics.uci.edu/ml/datasets/Online+Retail+II,137,Online Retail II Data Set,../machine-learning-databases/00502/,"Multivariate, Sequential, Time-Series, Text",1067371,Business,"Integer, Real",8,9/21/2019,"Classification, Regression, Clustering",Yes,71232,"Dr. Daqing Chen, Course Director: MSc Data Science. chend '@' lsbu.ac.uk, School of Engineering, London South Bank University, London SE1 0AA, UK.","This Online Retail II data set contains all the transactions occurring for a UK-based and registered, non-store online retail between 01/12/2009 and 09/12/2011.The company mainly sells unique all-occasion gift-ware. Many customers of the company are wholesalers.","InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation. StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product. Description: Product (item) name. Nominal. Quantity: The quantities of each product (item) per transaction. Numeric.	InvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated. UnitPrice: Unit price. Numeric. Product price per unit in sterling (Â£). CustomerID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer. Country: Country name. Nominal. The name of the country where a customer resides.","Chen, D. Sain, S.L., and Guo, K. (2012), Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining, Journal of Database Marketing and Customer Strategy Management, Vol. 19, No. 3, pp. 197-208. doi: [Web Link].Chen, D., Guo, K. and Ubakanma, G. (2015), Predicting customer profitability over time based on RFM time series, International Journal of Business Forecasting and Marketing Intelligence, Vol. 2, No. 1, pp.1-18. doi: [Web Link].Chen, D., Guo, K., and Li, Bo (2019), Predicting Customer Profitability Dynamically over Time: An Experimental Comparative Study, 24th Iberoamerican Congress on Pattern Recognition (CIARP 2019), Havana, Cuba, 28-31 Oct, 2019.Laha Ale, Ning Zhang, Huici Wu, Dajiang Chen, and Tao Han, Online Proactive Caching in Mobile Edge Computing Using Bidirectional Deep Recurrent Neural Network, IEEE Internet of Things Journal, Vol. 6, Issue 3, pp. 5520-5530, 2019.Rina Singh, Jeffrey A. Graves, Douglas A. Talbert, William Eberle, Prefix and Suffix Sequential Pattern Mining, Industrial Conference on Data Mining 2018: Advances in Data Mining. Applications and Theoretical Aspects, pp. 309-324. 2018.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset,138,Bike Sharing Dataset Data Set,../machine-learning-databases/00275/,Univariate,17389,Social,"Integer, Real",16,12/20/2013,Regression,N/A,491007,"Hadi Fanaee-T Laboratory of Artificial Intelligence and Decision Support (LIAAD), University of PortoINESC Porto, Campus da FEUPRua Dr. Roberto Frias, 3784200 - 465 Porto, Portugal Original Source: http://capitalbikeshare.com/system-data Weather Information: http://www.freemeteo.com Holiday Schedule: http://dchr.dc.gov/page/holiday-schedule","Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.  Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.","Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv 	- instant: record index	- dteday : date	- season : season (1:winter, 2:spring, 3:summer, 4:fall)	- yr : year (0: 2011, 1:2012)	- mnth : month ( 1 to 12)	- hr : hour (0 to 23)	- holiday : weather day is holiday or not (extracted from [Web Link])	- weekday : day of the week	- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.	+ weathersit : 		- 1: Clear, Few clouds, Partly cloudy, Partly cloudy		- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist		- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds		- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog	- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)	- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)	- hum: Normalized humidity. The values are divided to 100 (max)	- windspeed: Normalized wind speed. The values are divided to 67 (max)	- casual: count of casual users	- registered: count of registered users	- cnt: count of total rental bikes including both casual and registered","[1] Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg, [Web Link].","Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg, [Web Link]. @article{	year={2013},	issn={2192-6352},	journal={Progress in Artificial Intelligence},	doi={10.1007/s13748-013-0040-3},	title={Event labeling combining ensemble detectors and background knowledge},	url={[Web Link]},	publisher={Springer Berlin Heidelberg},	keywords={Event labeling; Event detection; Ensemble learning; Background knowledge},	author={Fanaee-T, Hadi and Gama, Joao},	pages={1-15}}",
http://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+under+flow+modulation,139,Gas sensor array under flow modulation Data Set,../machine-learning-databases/00308/,"Multivariate, Time-Series",58,Computer,Real,120432,9/10/2014,"Classification, Regression",N/A,38476,"Creators:Andrey Ziyatdinov (andrey.ziyatdinov '@' upc.edu)Department of ESAII, Universitat Politenica de Catalunya, Pau Gargallo 5, Barcelona, SpainCentro de Investigacion Biomedica en Red en BioingenierÄ±a, Biomateriales y Nanomedicina (CIBER-BBN), Barcelona, Spain Jordi Fonollosa (fonollosa '@' ucsd.edu)BioCircuits Institute, University of California, San Diego, La Jolla, CA 92093, USA Donors: Luis Fernandez (lfernandez '@' el.ub.es)Agustin Gutierrez-Galvez (agutierrez '@' el.ub.es)Santiago Marco (smarco '@' el.ub.es)Signal and Information Processing for Sensing Systems Institute for Bioengineering of Catalonia (IBEC), Baldiri Reixac, 4-8, 08028 Barcelona, SpainDepartament dElectronica, Universitat de Barcelona, Marti i Franques 1, 08028 Barcelona, Spain Alexandre Perera (Alexandre.Perera '@' upc.edu)Department of ESAII, Universitat Politenica de Catalunya, Pau Gargallo 5, Barcelona, SpainCentro de Investigacion Biomedica en Red en BioingenierÄ±a, Biomateriales y Nanomedicina (CIBER-BBN), Barcelona, Spain","The measured data was collected using a chemical sensing system based on an array of 16 metal-oxide gas sensors and an external mechanical ventilator to simulate the biological respiration cycle. The tested gas classes (12 in total) formed a relatively broad combination of two analytes, acetone and ethanol, in binary mixtures. Both, raw data set and feature data set, are available. In particular, two sets of low-frequency and high-frequency features are provided for a comparison study. The primary data analysis is supposed to be a multivariate regression with multiple responses (two responses), where the predictors were the features extracted from the sensor signals and the responses were the concentrations of two analytes, acetone and ethanol. This task is also known as a mixture quantification problem of two analytes. Please see the article (Ziyatdinov et al., 2014, Section 3.2) for such regression analysis based on partial least squares (PLS). A classification task is also possible given that a small number of samples per class is available, if all the 12 classes are used. Another classification problem can be stated to distinguish two pure analytes and mixtures of them. Three concentrations doses 0.1, 0.3 and 1 vol.% were used to prepare the dilutions in water for the pure analytes. The same dilutions were used to generate gas mixtures. The gas classes included samples of pure ethanol ('lab' attribute eth-0.1, eth-0.3 and eth-1), samples of pure acetone (ace-0.1, ace-0.3 and ace-1), samples of binary mixtures of ethanol and acetone (ace-0.1-eth-0.1, ace-0.1-eth-0.3, ace-0.3-eth-0.1, ace-0.1-eth-1 and ace-1-eth-0.1) and samples of water dilutions without any analyte (air) giving a total number of 12 classes. The choice of these analytes and concentrations was not affected by any particular application constraint, except that the sensors of selected models show consistent and diverse responses among the gas classes. The statistics on class distribution among 58 samples: eth-0.1: 6eth-0.3: 4eth-1: 5ace-0.1: 6ace-0.3: 6ace-1: 3ace-0.1-eth-0.1: 4ace-0.1-eth-0.3: 5ace-0.3-eth-0.1: 5ace-0.1-eth-1: 3ace-1-eth-0.1: 3air: 8 The measurements were split into 5 batches ('batch' attribute), where each batch contained records approximately for all gas classes given in a random order. All the batches were collected in a time period of 4 days to minimize the effect of the long-term internal and environmental noise in the system. The statistics on batch distribution among 58 samples: day-1-morning: 19day-2-afternoon: 10day-2-morning: 10day-3-morning: 11day-4-afternoon: 8 The array was composed of 16 metal-oxide gas sensors of 5 different TGS models from Figaro Inc. The sensors were configured for 10 different sensor conditioning profiles based on the combination of 5 TGS models and 2 sensor operating temperatures. The circuit board with the gas sensor array was placed in a 70 ml inner volume chamber connected to the mechanical ventilator. The device of the mechanical ventilator was made commercially available from Harvard Apparatus (Harvard Apparatus, Harvard Inspira Advanced Safety Ventilator Manual, Tech. rep., 2003). The mechanical ventilator includes a cylinder of volume 63.44 cm3 and a mechanical pump that takes air from the outlet 'Source' and pushes the air sample through the outlet 'To Animal'. The system also receives the sample again in the outlet 'From Animal' to close the loop, control the air pressure decay, and collect the exhaled air. The cylinder of the ventilator was fixed to a frequency of 5 breaths per minute, approximately equivalent to 0.08 Hz for all the measurements. See the article (Ziyatdinov et al., 2014, Section 2.1) for a detailed description of the experimental set up. The measurement protocol was the following: using a micropipette we delivered 10 Î¼l of the corresponding dilution to the vessel, which in turn was connected to the apparatus 'Source' channel to expose the sensor array to the generated gas sample. After 3 min of exposition, the source of the gas vapour was removed from the vessel to start the recovery phase. During the recovery phase, the system was sampling room air for 2 additional minutes to record the decay in the sensors signals. The recorded time-series signal for each sensor was acquired at the sampling frequency of 25 Hz during 5 min, resulting in 7500 data points per time-series of a single sensor. Note that 2 minutes of recovery phase was not sufficient to recover the sensors baseline and re-establish again the initial conditions in the gas chamber. Hence, although we acquired 2 minutes of recovery phase, the system was pumping air until the sensors recovered the baseline and the whole gas sample was exhausted from the gas chamber. The readout data was the output voltage of the sensor stored as resistance values according to the voltage-divider scheme and using the value of the load resistor. Hence, each data point in the array described the resistance of a sensor R(t) at a certain time of measurement t. The resistancevalues in the data set were normalized by subtracting the baseline value R0 = R(t0) at thestarting point of the measurement t0 and scaling by factor R0, (R(t) âˆ’ R0)/R0. Note that such format of the measured raw data allows for comparison of responses among different sensors. Previously to computing the low-frequency and high-frequency features, the raw data were pre-processed by a set of digital filters. A median filter was used to remove the spikes in the signals. Then we employed two Butterworth filters of 3rd order: a low-pass filter (cut-off frequency 0.01 Hz) and a high-pass filter (pass-frequency 0.07 Hz) to generate the low/high frequency signals, respectively. Note that these low/high frequency signals (output of the two Butterworth filters) are not distributed within the data set. For feature extraction, both low-frequency and high-frequency sensor signals were divided by respiratory cycles, where each cycle was processed independently. Thus, a feature is referred to as a feature by respiratory cycle. Since high-frequency signals showed oscillatory behavior similar to a sine wave curve, we decided to follow a straightforward strategy for feature extraction in this case. We used amplitude of the high-frequency signal (oscillation) at every respiratory cycle as a feature. Low-frequency trajectories had a monotonic behaviour, and we used the magnitude of the low-frequency signal as a feature at every respiratory cycle. The magnitude value was taken at the same time of oscillation, where the amplitude of the high-frequency signal was measured. Note that the low-frequency and high-frequency features were computed only for the first 13 respiration cycles. In addition to the low/high frequency features, we also introduced a cycle-independent feature persingle measurement, defined as the maximum of the low-frequency signal over the course ofthe measurement. The first data analysis of the data set was presented in (Ziyatdinov et al., 2014), and the results reported there should be considered as a reference. The study aimed to characterize and explore the sensor signals in response to the modulated gas flow at a fixed respiration frequency. It was expected to confirm a superior performance of the proposed system under the gas flow modulation on the early detection scenario. The acquired modulated signals were decomposed into low-frequency and high-frequency components, and the resulted feature sets were compared in terms of the discrimination performance. Note that it was assumed that the low-frequency part of the modulated signals approximate the signals that would be measured under the standard constant flow rate mode (such assumption was empirically confirmed by observing the transient dynamics). The strategy in signal- and data-processing applied in (Ziyatdinov et al., 2014) was straightforward, and the analysis can be improved in a number of ways, on the stages of feature extraction and/or pattern recognition. Hence, the raw data stored in 'rawdata.csv.gz' file is intended for testing feature extraction methods, while the features computed in (Ziyatdinov et al., 2014) and stored in 'features.csv' can be readily used in testing pattern recognition methods. Additional links:1. Data vizualization of time series in the data set: [Web Link].2. Code repository for reproducible analysis applied to the data set: [Web Link].","The data set is organized in two 'csv' files, 'rawdata.csv.gz' (4.5 MB) and 'features.csv' (200 kB). The raw data are stored in the first file 'rawdata.csv.gz', where each line represents a single measurement per sensor. Consequently, one needs to read specific 16 consecutive lines to get a single measurement from 16 sensors. The features extracted in (Ziyatdinov et al., 2014) are provided in the second file 'features.csv', where each line represents features extracted from all 16 time-series of the sensors (a single measurement). Raw data of each sample contains 16 time-series (one time-series per sensor). Each time-series was recorded during 5 min at a sample rate of 25 Hz (samples per second), providing 7500 data points per time-series. The total number of attributes per sample in raw data is 120000. Feature data set includes three types of features extracted from each time-series. Each time-series (one time-series per sensor) is associated with 1 maximum features, 13 high-frequency features and 13 low-frequency features (the features correspond to the first 13 respiration cycles, respectively). The total number of attributes per sample in feature data set is 432. Both tables of the raw data and features have common attributes:'exp': integer (range 100-181); represents the experiment number registered in the laboratory.'batch': string (5 values); represents the batch identificator of the measurements;'ace_conc': float (range 0-1); the concentration of the acetone analyte given in vol.%;'eth_conc': float (range 0-1); the concentration of the ethanol analyte given in vol.%;'lab': string (12 values); the class label of the gas;'gas': string (4 values); another class label that encodes either pure analytes, mixture or air;'col': string (12 values); the color code for better plotting among the class labels. The table of the raw data has specific attributes:'sensor': integer (range 1-16); the sensor number;'sample': integer (range 1-58); the sample number;'dR_t': float; represents the value of the time series for a given sensor and for a given sample, which were measured at the time instant , where  takes the value from 1 to 7500. The table of the features has specific attributes:'S_max': float; represents the value of the maximum feature extracted from the time-series of sensor ;'S_r_Alf': float; represents the low-frequency feature extracted from the time-series of sensor  at the respiration , where  takes the value from 1 to 16,  takes the value from 1 to 13;'S_r_Ahf': float; represents the high-frequency feature extracted from the time-series of sensor  at the respiration , where  takes the value from 1 to 16,  takes the value from 1 to 13.",N/A,"Please cite the following paper if you use this data set:A Ziyatdinov, J Fonollosa, L Fernandez, A Gutierrez-Galvez, S Marco, A Perera. ""Bioinspired early detection through gas flow modulation in chemo-sensory systems."" Sensors and Actuators B: Chemical 206 (2015): 538-547.This work was funded from the European Community's Seventh Framework Programme (FP7/2007-2013) under grant agreement no. 216916: Biologically inspired computation for chemical sensing (NEUROChem).",
http://archive.ics.uci.edu/ml/datasets/Tamilnadu+Electricity+Board+Hourly+Readings,140,Tamilnadu Electricity Board Hourly Readings Data Set,../machine-learning-databases/00290/,Multivariate,45781,Life,Real,5,12/22/2013,"Classification, Regression, Clustering",N/A,74033,"K.Kalyani ,kkalyanims '@' gmail.com,T.U.K Arts College,Karanthai,Thanjavur.","Collect the real time readings for residential,commercial,industrial,agriculure,to find the accuracy consumption in Tamil Nadu Around Thanajvur","forkva,forkw,type,sector,service",Efficient Electricity Utilization By IHBMO,"If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection,141,YouTube Spam Collection Data Set,../machine-learning-databases/00380/,Text,1956,Computer,N/A,5,3/26/2017,Classification,N/A,81581,This corpus has been collected using the YouTube Data API v3.,"The table below lists the datasets, the YouTube video ID, the amount of samples in each class and the total number of samples per dataset. Dataset --- YouTube ID -- # Spam - # Ham - TotalPsy ------- 9bZkp7q19f0 --- 175 --- 175 --- 350KatyPerry - CevxZvSJLk8 --- 175 --- 175 --- 350LMFAO ----- KQ6zr6kCPj8 --- 236 --- 202 --- 438Eminem ---- uelHwf8o7_U --- 245 --- 203 --- 448Shakira --- pRpeEdMmmQ0 --- 174 --- 196 --- 370 Note: the chronological order of the comments were kept.","The collection is composed by one CSV file per dataset, where each line has the following attributes: COMMENT_ID,AUTHOR,DATE,CONTENT,TAG We offer one example bellow: z12oglnpoq3gjh4om04cfdlbgp2uepyytpw0k,Francisco Nora,2013-11-28T19:52:35,please like :D [Web Link],1","Alberto, T.C., Lochter J.V., Almeida, T.A. TubeSpam: Comment Spam Filtering on YouTube. Proceedings of the 14th IEEE International Conference on Machine Learning and Applications (ICMLA'15), 1-6, Miami, FL, USA, December, 2015. T.A. ALMEIDA, T.P. SILVA, I. SANTOS and J.M. GOMEZ HIDALGO. Text Normalization and Semantic Indexing to Enhance Instant Messaging and SMS Spam Filtering. Knowledge-Based Systems, Elsevier, 108(2016), 25-32, 2016.","We would appreciate: 1. If you find this collection useful, make a reference to the paper below and the web page: [Web Link].2. Send us a message either to talmeida < AT > ufscar.br or tuliocasagrande < AT > acm.org in case you make use of the corpus.",
http://archive.ics.uci.edu/ml/datasets/Bag+of+Words,142,Bag of Words Data Set,../machine-learning-databases/bag-of-words/,Text,8000000,N/A,Integer,100000,3/12/2008,Clustering,N/A,311733,"David Newmannewman '@' uci.edu University of California, Irvine ","For each text collection, D is the number of documents, W is thenumber of words in the vocabulary, and N is the total number of wordsin the collection (below, NNZ is the number of nonzero counts in thebag-of-words).  After tokenization and removal of stopwords, thevocabulary of unique words was truncated by only keeping words thatoccurred more than ten times.  Individual document names (i.e. aidentifier for each docID) are not provided for copyright reasons. These data sets have no class labels, and for copyright reasons nofilenames or other document-level metadata.  These data sets are idealfor clustering and topic modeling experiments. For each text collection we provide docword.*.txt (the bag of wordsfile in sparse format) and vocab.*.txt (the vocab file). Enron Emails:orig source: www.cs.cmu.edu/~enronD=39861W=28102N=6,400,000 (approx) NIPS full papers:orig source: books.nips.ccD=1500W=12419N=1,900,000 (approx) KOS blog entries:orig source: dailykos.comD=3430W=6906N=467714 NYTimes news articles:orig source: ldc.upenn.eduD=300000W=102660N=100,000,000 (approx) PubMed abstracts:orig source: www.pubmed.govD=8200000W=141043N=730,000,000 (approx)","The format of the docword.*.txt file is 3 header lines, followed byNNZ triples:---DWNNZdocID wordID countdocID wordID countdocID wordID countdocID wordID count...docID wordID countdocID wordID countdocID wordID count--- The format of the vocab.*.txt file is line  contains wordID=n.",N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Eco-hotel,143,Eco-hotel Data Set,../machine-learning-databases/00398/,Text,401,Business,N/A,1,7/23/2017,N/A,N/A,37241,"C.Calheiros, S.Moro, P.Rita (ISCTE-IUL).Acknowledgement: This dataset was provided thanks to GonÃ§alo Alves, the Areias do Seixo Manager (http://www.areiasdoseixo.com/hotel-overview.html).","The CSV holds one cell per review, except the first row, which is the header.All the 401 reviews were collected between January and August of 2015.",Textual review.,"Calheiros, A. C., Moro, S., & Rita, P. (2017). Sentiment Classification of Consumer Generated Online Reviews Using Topic Modeling. Journal of Hospitality Marketing & Management, DOI: 10.1080/19368623.2017.1310075.","If you intend to use this dataset on your research, please cite the following work:Calheiros, A. C., Moro, S., & Rita, P. (2017). Sentiment Classification of Consumer Generated Online Reviews Using Topic Modeling. Journal of Hospitality Marketing & Management, DOI: 10.1080/19368623.2017.1310075.",
http://archive.ics.uci.edu/ml/datasets/detection_of_IoT_botnet_attacks_N_BaIoT,144,detection_of_IoT_botnet_attacks_N_BaIoT Data Set,../machine-learning-databases/00442/,"Multivariate, Sequential",7062606,Computer,Real,115,3/19/2018,"Classification, Clustering",N/A,65524,"-- Creators: Yair Meidan, Michael Bohadana, Yael Mathov, Yisroel Mirsky, Dominik Breitenbacher, Asaf Shabtai and Yuval Elovici* Meidan, Bohadana, Mathov, Mirsky, Shabtai: Department of Software and Information Systems Engineering; Ben-Gurion University of the Negev; Beer-Sheva, 8410501; Israel* Breitenbacher, Elovici: iTrust Centre of Cybersecurity at Singapore University of Technology and Design; 8 Somapah Rd, Singapore 487372 -- Donor: Yair Meidan (yairme '@' bgu.ac.il)-- Date: March, 2018 (databases may change over time without name change!)","(a) Attribute being predicted:-- Originally we aimed at distinguishing between benign and Malicious traffic data by means of anomaly detection techniques.-- However, as the malicious data can be divided into 10 attacks carried by 2 botnets, the dataset can also be used for multi-class classification: 10 classes of attacks, plus 1 class of 'benign'. (b) The study's results:-- For each of the 9 IoT devices we trained and optimized a deep autoencoder on 2/3 of its benign data (i.e., the training set of each device). This was done to capture normal network traffic patterns.-- The test data of each device comprised of the remaining 1/3 of benign data plus all the malicious data. On each test set we applied the respective trained (deep) autoencoder as an anomaly detector. The detection of anomalies (i.e., the cyberattacks launched from each of the above IoT devices) concluded with 100% TPR.","-- The following describes each of the features headers: * Stream aggregation:H: Stats summarizing the recent traffic from this packet's host (IP)HH: Stats summarizing the recent traffic going from this packet's host (IP) to the packet's destination host.HpHp: Stats summarizing the recent traffic going from this packet's host+port (IP) to the packet's destination host+port. Example 192.168.4.2:1242 -> 192.168.4.12:80HH_jit: Stats summarizing the jitter of the traffic going from this packet's host (IP) to the packet's destination host. * Time-frame (The decay factor Lambda used in the damped window): How much recent history of the stream is capture in these statisticsL5, L3, L1, ... * The statistics extracted from the packet stream:weight: The weight of the stream (can be viewed as the number of items observed in recent history)mean: ...std: ...radius: The root squared sum of the two streams' variancesmagnitude: The root squared sum of the two streams' means cov: an approximated covariance between  two streamspcc: an approximated covariance between  two streams","-- Reference to the article where the feature extractor (from *.pcap to *.csv) was described: Y. Mirsky, T. Doitshman, Y. Elovici & A. Shabtai 2018, 'Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection', in Network and Distributed System Security (NDSS) Symposium, San Diego, CA, USA.","-- Reference to the article where the dataset was initially described and used:Y. Meidan, M. Bohadana, Y. Mathov, Y. Mirsky, D. Breitenbacher, A. Shabtai, and Y. Elovici 'N-BaIoT: Network-based Detection of IoT Botnet Attacks Using Deep Autoencoders', IEEE Pervasive Computing, Special Issue - Securing the IoT (July/Sep 2018).",
http://archive.ics.uci.edu/ml/datasets/OpinRank+Review+Dataset,145,OpinRank Review Dataset Data Set,../machine-learning-databases/00205/,Text,N/A,Computer,N/A,N/A,7/26/2011,N/A,N/A,51010,"Kavita Ganesan & ChengXiang ZhaiUniversity of Illinois @ Urbana Champaignhttp://www.kavita-ganesan.com/entity-ranking-data","Car Reviews-------------Full reviews of cars for model-years 2007, 2008, and 2009-There are about 140-250 cars for each model year-Extracted fields include dates, author names, favorites and the full textual review-Total number of reviews: ~42,230 Hotel Reviews---------------Full reviews of hotels in 10 different cities (Dubai, Beijing, London, New York City, New Delhi, San Francisco, Shanghai, Montreal, Las Vegas, Chicago)-There are about 80-700 hotels in each city-Extracted fields include date, review title and the full review-Total number of reviews: ~259,000",N/A,"Ganesan, K. A., and C. X. Zhai, 'Opinion-Based Entity Ranking', Information Retrieval, 2011.","Bibtex as follows:  @article {opinrank,	title = {Opinion-Based Entity Ranking},	journal = {Information Retrieval},	year = {2011},	keywords = {adhoc multifaceted search, entity oriented search, entity ranking, entity retrieval, product search},	doi = {10.1007/s10791-011-9174-8},	attachments = {[Web Link]},	author = {Kavita Ganesan and ChengXiang Zhai}}",
http://archive.ics.uci.edu/ml/datasets/BitcoinHeistRansomwareAddressDataset,146,BitcoinHeistRansomwareAddressDataset Data Set,../machine-learning-databases/00526/,"Multivariate, Time-Series",2916697,Computer,"Integer, Real",10,6/17/2020,"Classification, Clustering",N/A,3669,"Cuneyt Gurcan Akcora (cuneyt.akcora '@' umanitoba.ca) University of Manitoba, CanadaYulia Gel (ygl '@' utdallas.edu) University of Texas at Dallas, USAMurat kantarcioglu (muratk '@' utdallas.edu) University of Texas at Dallas, USA","We have downloaded and parsed the entire Bitcoin transaction graph from 2009 January to 2018 December. Using a time interval of 24 hours, we extracted daily transactions on the network and formed the Bitcoin graph. We filtered out the network edges that transfer less than B0.3, since ransom amounts are rarely below this threshold. Ransomware addresses are taken from three widely adopted studies: Montreal, Princeton and Padua. Please see the BitcoinHeist article for references.","Featuresaddress: String. Bitcoin address.year: Integer. Year.day: Integer. Day of the year. 1 is the first day, 365 is the last day.length: Integer.weight: Float.count: Integer.looped: Integer.neighbors: Integer.income: Integer. Satoshi amount (1 bitcoin = 100 million satoshis).label: Category String. Name of the ransomware family (e.g., Cryptxxx, cryptolocker etc) or white (i.e., not known to be ransomware). Our graph features are designed to quantify specific transaction patterns. Loop is intended to count how many transaction i) split their coins; ii) move these coins in the network by using different paths and finally, and iii) merge them in a single address. Coins at this final address can then be sold and converted to fiat currency. Weight quantifies the merge behavior (i.e., the transaction has more input addresses than output addresses), where coins in multiple addresses are each passed through a succession of merging transactions and accumulated in a final address. Similar to weight, the count feature is designed to quantify the merging pattern. However, the count feature represents information on the number of transactions, whereas the weight feature represents information on the amount (what percent of these transactionsâ€™ output?) of transactions. Length is designed to quantify mixing rounds on Bitcoin, where transactions receive and distribute similar amounts of coins in multiple rounds with newly created addresses to hide the coin origin. White Bitcoin addresses are capped at 1K per day (Bitcoin has 800K addresses daily). Note that although we are certain about ransomware labels, we do not know if all white addresses are in fact not related to ransomware. When compared to non-ransomware addresses, ransomware addresses exhibit more profound right skewness in distributions of feature values.","1 - Goldsmith, D., Grauer, K., & Shmalo, Y. (2020). Analyzing hack subnetworks in the bitcoin transaction graph. Applied Network Science, 5, 1-20.2 - Rivera-Castro, R., Pilyugina, P., & Burnaev, E. (2019, November). Topological Data Analysis for Portfolio Management of Cryptocurrencies. In 2019 International Conference on Data Mining Workshops (ICDMW) (pp. 238-243). IEEE.","@article{akcora2019bitcoinheist,  title={BitcoinHeist: Topological Data Analysis for Ransomware Detection on the Bitcoin Blockchain},  author={Akcora, Cuneyt Gurcan and Li, Yitao and Gel, Yulia R and Kantarcioglu, Murat},  journal={arXiv preprint [Web Link]},  year={2019}}",
http://archive.ics.uci.edu/ml/datasets/Repeat+Consumption+Matrices,147,Repeat Consumption Matrices Data Set,../machine-learning-databases/00441/,Multivariate,130000,Computer,Real,21000,3/22/2018,Clustering,N/A,21013,"Dimitrios Kotzias, dkotzias '@' ics.uci.edu, University of California Irvine","There are 7 datasets from Reddit, Twitter, Gowalla and Lastfm.Each matrix contains how many times a user 'consumed' and item. Items can be locations, artists, or subreddits. Details about each dataset are presented below. (In the parenthesis is the number of Users x Items) tw_oc (13k x 11k): tweets with geolocation from Orange County CA area. Items are locations a user visits in this case.tw_ny (30k x 11k): Same as tw_oc but from the New York area. go_sf (2k x 7k): Check-ins from the app Gowalla, from the San Fransisco area. Full dataset here: [Web Link] go_ny (1k x 7k): Same as go_sf, but from the New York area. lastfm (992 x 15k): How many times, a user listened to each artist. Covers 3 years of listening habbits, full dataset here: [Web Link]âˆ¼ocelma/[Web Link]  reddit_top (113k x 21k): How many times a user posted in a subreddit. These are the 130k most active users from 2015 and 20k most subscribed subreddits. This dataset is very large and can take a lot of time to load/use.reddit_sample (20k x 21k): Same as reddit_top, but a sample of 20k users.","The attributes represent items (categories) that uses tend to select multiple times. These can be music artists, subreddits or locations on the map.","Predicting Consumption Patterns with Repeated and Novel Events by Dimitrios Kotzias, Moshe Lichman and Padhraic Smyth.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Restaurant+%26+consumer+data,148,Restaurant & consumer data Data Set,../machine-learning-databases/00232/,Multivariate,138,Computer,N/A,47,8/4/2012,N/A,Yes,141767,"Creators: Rafael Ponce MedellÃ­n and Juan Gabriel GonzÃ¡lez Sernarafaponce '@' cenidet.edu.mx, gabriel '@' cenidet.edu.mx Department of Computer Science.National Center for Research and Technological Development CENIDET, MÃ©xicoDonors of database:Blanca Vargas-Govea and Juan Gabriel GonzÃ¡lez Sernablanca.vargas '@' cenidet.edu.mx/blanca.vg@gmail.com, gabriel '@' cenidet.edu.mx Department of Computer Science.National Center for Research and Technological Development CENIDET, MÃ©xico","Two approaches were tested: a collaborative filter technique and a contextual approach.   (i) The collaborative filter technique used only one file i.e., rating_final.csv that comprises the user, item and rating attributes.     (ii) The contextual approach generated the recommendations using the remaining eight data files.","Files, instances and attributesNumber of Files: 9 Restaurants1 chefmozaccepts.csv2 chefmozcuisine.csv3 chefmozhours4.csv4 chefmozparking.csv5 geoplaces2.csv Consumers6 usercuisine.csv7 userpayment.csv8 userprofile.csv User-Item-Rating9 rating_final.csv %--- Description formatFile nameNumber of instancesNumber of attributesattribute: Type, Number of missing values (if any), Number of values [list of values]%---  1 chefmozaccepts.csvInstances: 1314Attributes: 2placeID: NominalRpayment: Nominal, 12 [cash,VISA,MasterCard-Eurocard,American_Express,bank_debit_cards,checks,Discover,Carte_Blanche,Diners_Club,Visa,Japan_Credit_Bureau,gift_certificates] 2 chefmozcuisine.csvInstances: 916Attributes: 2placeID: NominalRcuisine: Nominal, 59 [Afghan,African,American,Armenian,Asian,Bagels,Bakery,Bar,Bar_Pub_Brewery,Barbecue,Brazilian,Breakfast-Brunch,Burgers,Cafe-Coffee_Shop,			Cafeteria,California,Caribbean,Chinese,Contemporary,Continental-European,Deli-Sandwiches,Dessert-Ice_Cream,Diner,Dutch-Belgian,Eastern_European,Ethiopian,Family,Fast_Food,Fine_Dining,French,,Game,German,Greek,Hot_Dogs,			International,Italian,Japanese,Juice,Korean,Latin_American,Mediterranean,Mexican,Mongolian,Organic-Healthy,Persian,			Pizzeria,Polish,Regional,Seafood,Soup,Southern,Southwestern,Spanish,Steaks,Sushi,Thai,Turkish,Vegetarian,Vietnamese] 3 chefmozhours4.csvInstances: 2339Attributes: 3placeID: Nominalhours: Nominal, Range:00:00-23:30days:Nominal, 7 [Mon;Tue;Wed;Thu;Fri;Sat;Sun] 4 chefmozparking.csvInstances: 702Attributes: 2placeID: Nominalparking_lot:Nominal, 7[public,none,yes,valet_parking,free,street,validated_parking] 5 geoplaces2.csvInstances: 130Attributes: 21placeID: Nominallatitude: Numericlongitude: Numericthe_geom_meter: Nominal (Geospatial)name: Nominaladdress: Nominal,Missing: 27city: Nominal, Missing: 18state: Nominal, Missing: 18country: Nominal, Missing: 28fax: Numeric, Missing: 130zip: Nominal,Missing: 74alcohol: Nominal, Values: 3 [No_Alcohol_Served,Wine_Beer,Full_Bar]smoking_area: Nominal, 5 [none,only_at_bar,permitted,section,not_permitted]dress_code:	Nominal, 3 [informal,casual,formal]accessibility: Nominal, 3 [no_accessibility,completely,partially]price: Nominal, 3 [medium,low,high]url: Nominal, Missing: 116Rambience: Nominal, 2 [familiar,quiet]franchise: Nominal, 2 [t,f]area: Nominal, 2 [open,closed]other_services:	Nominal, 3 [none,internet,variety] 6 rating_final.csvInstances: 1161Attributes: 5userID: NominalplaceID: Nominalrating: Numeric, 3 [0,1,2]food_rating: Numeric, 3 [0,1,2]service_rating:	Numeric, 3 [0,1,2] 7 usercuisine.csvInstances: 330Attributes: 2userID: NominalRcuisine: Nominal, 103 [Afghan,African,American,Armenian,Asian,Australian,Austrian,Bagels,Bakery,Bar,Bar_Pub_Brewery,Barbecue,Basque,Brazilian,Breakfast-Brunch,British,Burgers,Burmese,Cafe-Coffee_Shop,Cafeteria,Cajun-Creole,California,Cambodian,Canadian,Caribbean,Chilean,Chinese,Contemporary,Continental-European,Cuban,Deli-Sandwiches,Dessert-Ice_Cream,Dim_Sum,Diner,Doughnuts,Dutch-Belgian,Eastern_European,Eclectic,Ethiopian,Family,Fast_Food,Filipino,Fine_Dining,French,Fusion,Game,German,Greek,Hawaiian,Hot_Dogs,Hungarian,Indian-Pakistani,Indigenous,Indonesian,International,Irish,Israeli,Italian,Jamaican,Japanese,Juice,Korean,Kosher,Latin_American,Lebanese,Malaysian,Mediterranean,Mexican,Middle_Eastern,Mongolian,Moroccan,North_African,Organic-Healthy,Pacific_Northwest,Pacific_Rim,Persian,Peruvian,Pizzeria,Polish,Polynesian,Portuguese,Regional,Romanian,Russian-Ukrainian,Scandinavian,Seafood,Soup,Southeast_Asian,Southern,Southwestern,Spanish,Steaks,Sushi,Swiss,Tapas,Tea_House,Tex-Mex,Thai,Tibetan,Tunisian,Turkish,Vegetarian,Vietnamese] 8 userpayment.csvInstances: 177Attributes: 2userID: NominalUpayment: Nominal, 5 [cash,bank_debit_cards,MasterCard-Eurocard,VISA,American_Express] 9 userprofileInstances: 138Attributes: 19userID: Nominallatitude: Numericlongitude: Numericthe_geom_meter: Nominal (Geospatial)smoker: Nominal, Missing: 3, 2 [false,true]drink_level: Nominal, 3 [abstemious,social drinker,casual drinker]dress_preference:Nominal, Missing: 5, 4 [informal,formal,no preference,elegant]ambience: Nominal, Missing: 6, 3 [family,friends,solitary]transport: Nominal, Missing: 7, 3 [on foot,public,car owner]marital_status:	Nominal, Missing: 4, 3 [single,married,widow]hijos: Nominal, Missing: 11, 3 [independent,kids,dependent]birth_year:	Nominalinterest: Nominal, 5 [variety,technology,none,retro,eco-friendly]personality: Nominal, 4 [thrifty-protector,hunter-ostentatious,hard-worker,conformist]religion: Nominal, 5 [none,Catholic,Christian,Mormon,Jewish]activity: Nominal, Missing: 7, 4 [student,professional,unemployed,working-class]color: Nominal, 8 [black,red,blue,green,purple,orange,yellow,white]weight: Numericbudget: Nominal, Missing: 7, 3 [medium,low,high]height: Numeric","Blanca Vargas-Govea, Juan Gabriel GonzÃ¡lez-Serna, Rafael Ponce-MedellÃ­n. Effects of relevant contextual features in the performance of a restaurant recommender system. In RecSysâ€™11: Workshop on Context Aware Recommender Systems (CARS-2011), Chicago, IL, USA, October 23, 2011.","Blanca Vargas-Govea, Juan Gabriel GonzÃ¡lez-Serna, Rafael Ponce-MedellÃ­n. Effects of relevant contextual features in the performance of a restaurant recommender system. In RecSysâ€™11: Workshop on Context Aware Recommender Systems (CARS-2011), Chicago, IL, USA, October 23, 2011.",
http://archive.ics.uci.edu/ml/datasets/HIV-1+protease+cleavage,149,HIV-1 protease cleavage Data Set,../machine-learning-databases/00330/,Multivariate,6590,Life,Categorical,1,4/25/2015,Classification,N/A,60295,"Thorsteinn Rögnvaldsson, denni63 '@' gmail.com, Halmstad University.","Past Usage:   (a) Rögnvaldsson, You and Garwicz (2015) 'State of the art prediction of HIV-1 protease        cleavage sites', Bioinformatics, vol 31 (8), pp. 1204-1210.       - Discusses the characteristics of the four data sets.       - It is shown that a linear SVM with standard orthogonal encoding is the best         predictor when tested across data sets. The AUC (Area Under the ROC Curve)         values are listed below:               Test data  746         1625        Schilling   Impens   Train data   746                   -           0.982       0.870       0.833   1625                  0.981       -           0.855       0.811   Schilling             0.933       0.935       -           0.911   Impens                0.902       0.894       0.929       -   The 746 and 1625 data sets share many patterns.    (b) Kontijevskis, Wikberg and Komorowski (2007) 'Computational Proteomics Analysis of HIV-1 Protease        Interactome'. Proteins: Structure, Function, and Bioinformatics, 68, 305â€“312.        Introduced the 1625 data set and used rough set theory on it.       Note: the 1625 data set used by Kontijevskis et al. is not identical to the 1625 data       set here, there is one octamer that has a different label (same octamer as for the       746 data set).   (c) You, Garwicz and Rögnvaldsson (2005) 'Comprehensive Bioinformatic Analysis of the Specificity        of Human Immunodeficiency Virus Type 1 Protease'. Journal of Virology, 79, 12477â€“12486.        Introduced the 746 data set and explored linear classifiers plus representations       based on amino acid properties.       Note: the 746 data set used by You et al. is not identical to the 746 data       set here, there is one octamer that has a different label (same octamer as for the       1625 data set).Other relevant information   The data sets have appeared in earlier publications (see references in Rögnvaldsson et al. 2015).    However, corrections have been made to them here.    Details on references where data has been collected are provided for the 746 and the 1625 data set.    The origins of the Schilling data and the Impens data are described in the paper Rögnvaldsson et al., 2015.","Each attribute is a letter denoting an amino acid. G (Glycine, Gly); P (Proline, Pro); A (Alanine, Ala); V (Valine, Val); L (Leucine, Leu); I (Isoleucine, Ile); M (Methionine, Met); C (Cysteine, Cys); F (Phenylalanine, Phe); Y (Tyrosine, Tyr); W (Tryptophan, Trp); H (Histidine, His); K (Lysine, Lys); R (Arginine, Arg); Q (Glutamine, Gln); N (Asparagine, Asn); E (Glutamic Acid, Glu); D (Aspartic Acid, Asp); S (Serine, Ser); T (Threonine, Thr). The output denotes cleaved (+1) or not cleaved (-1).","Thorsteinn Rögnvaldsson, Liwen You and Daniel Garwicz, 'State of the art prediction of HIV-1 protease cleavage sites' Bioinformatics (2015) 31 (8): 1204-1210. doi: 10.1093/bioinformatics/btu810, First published online: December 9, 2014","It is appreciated if you can refer to the paper by Rögnvaldsson et al. (2015) if you use the data created for this paper. However, other references (also by other researchers) are provided there if you chose to only use a subpart of the data.",
http://archive.ics.uci.edu/ml/datasets/Avila,150,Avila Data Set,../machine-learning-databases/00459/,Multivariate,20867,Computer,Real,10,6/20/2018,Classification,N/A,31304,"Claudio De Stefano, destefano '@' unicas.it, University of Cassino and Southern Lazio (ITALY)Francesco Fontanella, fontanella '@' unicas.it, University of Cassino and Southern Lazio (ITALY)Marilena Maniaci, m.maniaci '@' unicas.it, University of Cassino and Southern Lazio (ITALY)Alessandra Scotto di Freca, a.scotto '@' unicas.it, University of Cassino and Southern Lazio (ITALY)Provide the names, email addresses, institutions, and other contact information of the donors and creators of the data set.","Data have been normalized by using the Z-normalization method and divided into two data sets: a training set containing 10430 samples, and a test set containing the 10437 samples. CLASS DISTRIBUTION (training set)A: 4286B: 5  C: 103 D: 352 E: 1095 F: 1961 G: 446 H: 519I: 831W: 44X: 522 Y: 266","F1: intercolumnar distance F2: upper margin F3: lower margin F4: exploitation F5: row number F6: modular ratio F7: interlinear spacing F8: weight F9: peak number F10: modular ratio/ interlinear spacingClass: A, B, C, D, E, F, G, H, I, W, X, Y","C. DeÂ Stefano, M. Maniaci, F. Fontanella, A. ScottoÂ diÂ Freca,Reliable writer identification in medieval manuscripts through page layout features: The 'Avila' Bible case, Engineering Applications of Artificial Intelligence, Volume 72, 2018, pp. 99-110. C. De Stefano, F. Fontanella, M. Maniaci and A. Scotto di Freca, 'A Method for Scribe Distinction in Medieval Manuscripts Using Page Layout Features', Lecture Notes in Computer Science, G. Maino and G. Foresti (eds.), Springer-Verlag, vol. 6978, pp. 393-402.","C. DeÂ Stefano, M. Maniaci, F. Fontanella, A. ScottoÂ diÂ Freca, Reliable writer identification in medieval manuscripts through page layout features: The 'Avila' Bible case, Engineering Applications of Artificial Intelligence, Volume 72, 2018, pp. 99-110.",
http://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Pawn%29,151,Chess (King-Rook vs. King-Pawn) Data Set,../machine-learning-databases/chess/king-rook-vs-king-pawn/,Multivariate,3196,Game,Categorical,36,8/1/1989,Classification,No,116780,"Database originally generated and described by Alen Shapiro. Donor/Coder:  Rob Holte (holte '@' uottawa.bitnet).   The database was supplied to Holte by Peter Clark of the Turing Institute in Glasgow (pete '@' turing.ac.uk).",The dataset format is described below.  Note: the format of this database was modified on 2/26/90 to conform with the format of all the other databases in the UCI repository of machine learning databases.,"Classes (2):  -- White-can-win (""won"") and White-cannot-win (""nowin""). I believe that White is deemed to be unable to win if the Black pawn can safely advance. Attributes: see Shapiro's book.","Alen D. Shapiro (1983,1987), ""Structured Induction in Expert Systems"", Addison-Wesley.  This book is based on Shapiro's Ph.D. thesis (1983) at the University of Edinburgh entitled ""The Role of Structured Induction in Expert Systems"".[Web Link]  Stephen Muggleton (1987), ""Structuring Knowledge by Asking Questions"", pp.218-229 in ""Progress in Machine Learning"", edited by I. Bratko and Nada Lavrac, Sigma Press, Wilmslow, England  SK9 5BB.[Web Link]  Robert C. Holte, Liane Acker, and Bruce W. Porter (1989), ""Concept Learning and the Problem of Small Disjuncts"", Proceedings of IJCAI.  Also available as technical report AI89-106, Computer Sciences Department, University of Texas at Austin, Austin, Texas 78712.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Manuel Oliveira. Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted. University of Alberta Library. 2005.  [View Context].Marcus Hutter and Marco Zaffalon. Distribution of Mutual Information from Complete and Incomplete Data. CoRR, csLG/0403025. 2004.  [View Context].Ira Cohen and Fabio Gagliardi Cozman and Nicu Sebe and Marcelo Cesar Cirelo and Thomas S. Huang. Semisupervised Learning of Classifiers: Theory, Algorithms, and Their Application to Human-Computer Interaction. IEEE Trans. Pattern Anal. Mach. Intell, 26. 2004.  [View Context].Douglas Burdick and Manuel Calimlim and Jason Flannick and Johannes Gehrke and Tomi Yiu. MAFIA: A Performance Study of Mining Maximal Frequent Itemsets. FIMI. 2003.  [View Context].Russell Greiner and Wei Zhou. Structural Extension to Logistic Regression: Discriminative Parameter Learning of Belief Net Classifiers. AAAI/IAAI. 2002.  [View Context].Tanzeem Choudhury and James M. Rehg and Vladimir Pavlovic and Alex Pentland. Boosting and Structure Learning in Dynamic Bayesian Networks for Audio-Visual Speaker Detection. ICPR (3). 2002.  [View Context].Marco Zaffalon and Marcus Hutter. Robust Feature Selection by Mutual Information Distributions. CoRR, csAI/0206006. 2002.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].James Bailey and Thomas Manoukian and Kotagiri Ramamohanarao. Fast Algorithms for Mining Emerging Patterns. PKDD. 2002.  [View Context].Jie Cheng and Russell Greiner. Learning Bayesian Belief Network Classifiers: Algorithms and System. Canadian Conference on AI. 2001.  [View Context].Boonserm Kijsirikul and Sukree Sinthupinyo and Kongsak Chongkasemwongse. Approximate Match of Rules Using Backpropagation Neural Networks. Machine Learning, 44. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. DeEPs: A New Instance-based Discovery and Classification System. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao. Instance-Based Classification by Emerging Patterns. PKDD. 2000.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].Adam J. Grove and Dale Schuurmans. Boosting in the Limit: Maximizing the Margin of Learned Ensembles. AAAI/IAAI. 1998.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Brian R. Gaines. Structured and Unstructured Induction with EDAGs. KDD. 1995.  [View Context].Ron Kohavi and Dan Sommerfield. Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology. KDD. 1995.  [View Context].Jerome H. Friedman and Ron Kohavi and Youngkeol Yun. To appear in AAAI-96 Lazy Decision Trees. Statistics Department and Stanford Linear Accelerator Center Stanford University.  [View Context].Grigorios Tsoumakas and Ioannis P. Vlahavas. Fuzzy Meta-Learning: Preliminary Results. Greek Secretariat for Research and Technology.  [View Context].Nikunj C. Oza and Stuart J. Russell. Online Bagging and Boosting. Computer Science Division University of California.  [View Context].Hankil Yoon and Khaled A. Alsabti and Sanjay Ranka. Tree-based Incremental Classification for Large Datasets. CISE Department, University of Florida.  [View Context].Omid Madani and David M. Pennock and Gary William Flake. Co-Validation: Using Model Disagreement to Validate Classification Algorithms. Yahoo! Research Labs.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context].BayesianClassifi552 Pat Langley and Wayne Iba. In Proceedings of the Tenth National ConferenceonArtifi256 Intelligence( 42840. Lambda Kevin Thompson.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/DrivFace,152,DrivFace Data Set,../machine-learning-databases/00378/,Multivariate,606,Computer,Real,6400,5/26/2016,"Classification, Regression, Clustering",N/A,35735,"Katerine Diaz-Chito*Aura HernÃ¡ndez-SabatÃ©Antonio M. LÃ³pez Centre de VisiÃ³ per ComputadorUniversitat AutÃ³noma de Barcelona *Corresponding author:{kdiaz '@' cvc.uab.es}","The DrivFace database contains images sequences of subjects while driving in real scenarios. It is composed of 606 samples of 640Ã—480 pixels each, acquired over different days from 4 drivers (2 women and 2 men) with several facial features like glasses and beard. Additional files:drivFace.mat contains the dataset in Matlab (under prtools library) with the driver faces normalised to 80x80 pixels each and their associated gaze direction labels â€œlooking-rightâ€, â€œfrontalâ€ and  â€œlooking-leftâ€.","The ground truth contains the annotation of the face bounding box and the facial key points (eyes, nose and mouth). A set of labels assigning each image into 3 possible gaze direction classes are given. The first class is the â€œlooking-rightâ€ class and contains the head angles between -45Âº and -30Âº. The second one is the â€œfrontalâ€ class and contains the head angles between -15Âº and 15Âº. The last one is the â€œlooking-leftâ€ class and contains the head angles between 30Âº and 45Âº.  Files and scriptsâ€¢ DrivImages.zip has the driver images. The imag's name has the format:    * YearMonthDay_subject_Driv_imNum_HeadPose.jpg  i.e. 20130529_01_Driv_011_f .jpg is a frame of the fisrts driver corresponding to the 11 sequence's image and the head pose is frontal.subject = [1:4], imNum = [001:...], HeadPose = lr (looking-right), f (frontal) and lf (looking-left).  â€¢ drivPoints.txt contains the ground truth in table's format, where the columns have the follow information:    * fileName is the imagen's name into DrivImages.zip    * subject = [1:4]    * imgNum  = int    * label   = [1/2/3] (head pose class that corresponding to [lr/f/lf], respectively)     * ang     = [-45, -30/ -15 0 15/ 30 15] (head pose angle)    * [xF yF wF hF] = face position     * [xRE yRE]     = rigth eye position     * [xLE yL]      = left eye position     * [xN yN]       = Nose position     * [xRM yRM]     = rigth corner of mouth    * [xLM yLM]     = left corner of mouth     â€¢ read_drivPoints.m is a Matlab function to read the drivPoints file. You can also use:    * Table = readtable('drivPoints.txt'); â€¢ drivFace.mat contains the dataset in Matlab (under prtools library) with the driver faces normalised to 80x80 pixels each and their associated gaze direction labels â€œlooking-rightâ€, â€œfrontalâ€ and  â€œlooking-leftâ€.","Katerine Diaz-Chito, Aura HernÃ¡ndez-SabatÃ©, Antonio M. LÃ³pez, A reduced feature set for driver head pose estimation, Applied Soft Computing, Volume 45, August 2016, Pages 98-107, ISSN 1568-4946, ","Katerine Diaz-Chito, Aura HernÃ¡ndez-SabatÃ©, Antonio M. LÃ³pez, A reduced feature set for driver head pose estimation, Applied Soft Computing, Volume 45, August 2016, Pages 98-107, ISSN 1568-4946, ",
http://archive.ics.uci.edu/ml/datasets/Website+Phishing,153,Website Phishing Data Set,../machine-learning-databases/00379/,Multivariate,1353,Computer,Integer,10,11/2/2016,Classification,N/A,83416," Neda AbdelhamidAuckland Institute of Studiesnedah '@' ais.ac.nz","The phishing problem is considered a vital issue in â€œ.COMâ€ industry especially e-banking and e-commerce taking the number of online transactions involving payments. We have identified different features related to legitimate and phishy websites and collected 1353 different websites from difference sources.Phishing websites were collected from Phishtank data archive (www.phishtank.com), which is a free community site where users can submit, verify, track and share phishing data. The legitimate websites were collected from Yahoo and starting point directories using a web script developed in PHP. The PHP script was plugged with a browser and we collected 548 legitimate websites out of 1353 websites. There is 702 phishing URLs, and 103 suspicious URLs.   When a website is considered SUSPICIOUS that means it can be either phishy or legitimate, meaning the website held some legit and phishy features. ","URL Anchor	Request URL	SFH	URL Length	Having â€™@â€™	Prefix/Suffix	IP	Sub Domain	Web traffic	Domain age	Class    collected features hold the categorical values , â€œLegitimateâ€, â€Suspiciousâ€ and â€œPhishyâ€, these values have been replaced with numerical values 1,0 and -1 respectively.details of each feature are mentioned in the research paper mentioned below","You can view all citations that used the paper that has applied this data,  mentioned below  at [Web Link]","Abdelhamid  et al.,(2014a) Phishing Detection based Associative Classification Data Mining.  Expert Systems With Applications  (ESWA), 41 (2014) 5948â€“5959.",
http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29,154,Breast Cancer Wisconsin (Original) Data Set,../machine-learning-databases/breast-cancer-wisconsin/,Multivariate,699,Life,Integer,10,7/15/1992,Classification,Yes,610312,"Creator: Dr. WIlliam H. Wolberg (physician)University of Wisconsin HospitalsMadison, Wisconsin, USA Donor:  Olvi Mangasarian (mangasarian '@' cs.wisc.edu)Received by David W. Aha (aha '@' cs.jhu.edu)","Samples arrive periodically as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronological grouping of the data. This grouping information appears immediately below, having been removed from the data itself: Group 1: 367 instances (January 1989)Group 2:  70 instances (October 1989)Group 3:  31 instances (February 1990)Group 4:  17 instances (April 1990)Group 5:  48 instances (August 1990)Group 6:  49 instances (Updated January 1991)Group 7:  31 instances (June 1991)Group 8:  86 instances (November 1991)-----------------------------------------Total:   699 points (as of the donated datbase on 15 July 1992) Note that the results summarized above in Past Usage refer to a dataset of size 369, while Group 1 has only 367 instances.  This is because it originally contained 369 instances; 2 were removed.  The following statements summarizes changes to the original Group 1's set of data: #####  Group 1 : 367 points: 200B 167M (January 1989) #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805 #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record#####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial#####                  : Changed 0 to 1 in field 6 of sample 1219406#####                  : Changed 0 to 1 in field 8 of following sample:#####                  : 1182404,2,3,1,1,1,2,0,1,1,1","1. Sample code number:            id number2. Clump Thickness:               1 - 103. Uniformity of Cell Size:       1 - 104. Uniformity of Cell Shape:      1 - 105. Marginal Adhesion:             1 - 106. Single Epithelial Cell Size:   1 - 107. Bare Nuclei:                   1 - 108. Bland Chromatin:               1 - 109. Normal Nucleoli:               1 - 1010. Mitoses:                       1 - 1011. Class:                        (2 for benign, 4 for malignant)","Wolberg, W.H., & Mangasarian, O.L. (1990). Multisurface method of pattern separation for medical diagnosis applied to breast cytology. In Proceedings of the National Academy of Sciences, 87, 9193--9196.[Web Link]  Zhang, J. (1992). Selecting typical instances in instance-based learning.  In Proceedings of the Ninth International Machine Learning Conference (pp. 470--479).  Aberdeen, Scotland: Morgan Kaufmann.[Web Link]","This breast cancer databases was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.  If you publish results when using this database, then please include this information in your acknowledgements.  Also, please cite one or more of:1. O. L. Mangasarian and W. H. Wolberg: ""Cancer diagnosis via linear programming"", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.2. William H. Wolberg and O.L. Mangasarian: ""Multisurface method of pattern separation for medical diagnosis applied to breast cytology"", Proceedings of the National Academy of Sciences, U.S.A., Volume 87, December 1990, pp 9193-9196.3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: ""Pattern recognition via linear programming: Theory and application to medical diagnosis"", in: ""Large-scale numerical optimization"", Thomas F. Coleman and Yuying Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.4. K. P. Bennett & O. L. Mangasarian: ""Robust linear programming discrimination of two linearly inseparable sets"", Optimization Methods and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).","Gavin Brown. Diversity in Neural Network Ensembles. The University of Birmingham. 2004.  [View Context].Kristin P. Bennett and Ayhan Demiriz and Richard Maclin. Exploiting unlabeled data in ensemble methods. KDD. 2002.  [View Context].Hussein A. Abbass. An evolutionary artificial neural networks approach for breast cancer diagnosis. Artificial Intelligence in Medicine, 25. 2002.  [View Context].Baback Moghaddam and Gregory Shakhnarovich. Boosted Dyadic Kernel Discriminants. NIPS. 2002.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. Heterogeneous Forests of Decision Trees. ICANN. 2002.  [View Context].András Antos and Balázs Kégl and Tamás Linder and Gábor Lugosi. Data-dependent margin-based generalization bounds for classification. Journal of Machine Learning Research, 3. 2002.  [View Context].Robert Burbidge and Matthew Trotter and Bernard F. Buxton and Sean B. Holden. STAR - Sparsity through Automated Rejection. IWANN (1). 2001.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Yuh-Jeng Lee. Smooth Support Vector Machines. Preliminary Thesis Proposal Computer Sciences Department University of Wisconsin. 2000.  [View Context].Justin Bradley and Kristin P. Bennett and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Improved Generalization Through Explicit Optimization of Margins. Machine Learning, 38. 2000.  [View Context].P. S and Bradley K. P and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. An Implementation of Logical Analysis of Data. IEEE Trans. Knowl. Data Eng, 12. 2000.  [View Context].Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining. Institute of Information Science. 1999.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Direct Optimization of Margins Improves Generalization in Combined Classifiers. NIPS. 1998.  [View Context].W. Nick Street. A Neural Network Model for Prognostic Prediction. ICML. 1998.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].Huan Liu and Hiroshi Motoda and Manoranjan Dash. A Monotonic Measure for Optimal Feature Selection. ECML. 1998.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. A Parametric Optimization Method for Machine Learning. INFORMS Journal on Computing, 9. 1997.  [View Context].Rudy Setiono and Huan Liu. NeuroLinear: From neural networks to oblique decision rules. Neurocomputing, 17. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Ismail Taha and Joydeep Ghosh. Characterization of the Wisconsin Breast cancer Database Using a Hybrid Symbolic-Connectionist System. Proceedings of ANNIE. 1996.  [View Context].Jennifer A. Blue and Kristin P. Bennett. Hybrid Extreme Point Tabu Search. Department of Mathematical Sciences Rensselaer Polytechnic Institute. 1996.  [View Context].Erin J. Bredensteiner and Kristin P. Bennett. Feature Minimization within Decision Trees. National Science Foundation. 1996.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Huan Liu. A Family of Efficient Rule Generators. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Rudy Setiono. Extracting M-of-N Rules from Trained Neural Networks. School of Computing National University of Singapore.  [View Context].Jarkko Salojarvi and Samuel Kaski and Janne Sinkkonen. Discriminative clustering in Fisher metrics. Neural Networks Research Centre Helsinki University of Technology.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. A hybrid method for extraction of logical rules from data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. An Ant Colony Based System for Data Mining: Applications to Medical Data. CEFET-PR, CPGEI Av. Sete de Setembro, 3165.  [View Context].Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. Statistical methods for construction of neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery. CEFET-PR, Curitiba.  [View Context].Adam H. Cannon and Lenore J. Cowen and Carey E. Priebe. Approximate Distance Classification. Department of Mathematical Sciences The Johns Hopkins University.  [View Context].Andrew I. Schein and Lyle H. Ungar. A-Optimality for Active Learning of Logistic Regression Classifiers. Department of Computer and Information Science Levine Hall.  [View Context].Bart Baesens and Stijn Viaene and Tony Van Gestel and J. A. K Suykens and Guido Dedene and Bart De Moor and Jan Vanthienen and Katholieke Universiteit Leuven. An Empirical Assessment of Kernel Type Performance for Least Squares Support Vector Machine Classifiers. Dept. Applied Economic Sciences.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Rudy Setiono and Huan Liu. Neural-Network Feature Selector. Department of Information Systems and Computer Science National University of Singapore.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Low+Resolution+Spectrometer,155,Low Resolution Spectrometer Data Set,../machine-learning-databases/spectrometer/,Multivariate,531,Physical,"Integer, Real",102,3/1/1988,Classification,N/A,53000,"Originator:  Infra-Red Astronomy Satellite Project Database Donor:  John Stutz <STUTZ '@' pluto.arc.nasa.gov> It's possible that one of John's colleagues actually provided this to UCI, perhaps Mike Marshall (MARSHALL%PLU '@' io.arc.nasa.gov)","The Infra-Red Astronomy Satellite (IRAS) was the first attempt to map the full sky at infra-red wavelengths.  This could not be done from ground observatories because large portions of the infra-red spectrum is absorbed by the atmosphere.  The primary observing program was the full high resolution sky mapping performed by scanning at 4 frequencies. The Low Resolution Observation (IRAS-LRS) program observed high intensity sources over two continuous spectral bands.  This database derives from a subset of the higher quality LRS observations taken between 12h and 24h right ascension.  This database contains 531 high quality spectra derived from the IRAS-LRS database.  The original data contained 100 spectral measurements in each of two overlapping bands.  Of these, 44 blue band and 49 red band channels contain usable flux measurements.  Only these are included here.  The original spectral intensities values are compressed to 4-digits, and each spectrum includes 5 rescaling parameters.  We have used the LRS specified algorithm to rescale these to units of spectral intensity (Janskys).  Total intensity differences have been eliminated by normalizing each spectrum to a mean value of 5000. This database was originally obtained for use in development and testing of our AutoClass system for Bayesian classification.  We have not retained any results from this development, having concentrated our efforts of a 5425 element version of the same data.  Our classifications were based upon simultaneous modeling of all 93 spectral intensities. With the larger database we were able to find classes that correspond well with known spectral types associated with particular stellar types. We also found classes that match with the spectra expected of certain stellar processes under investigation by Ames astronomers.  These classes have considerably enlarged the set of stars being investigated by those researchers.   Original Data: The original fortran data file is given in spectra-2.data.  The file spectra-2.head contains information about the .data file contents and how to rescale the compressed spectral intensities. ","    1. LRS-name: (Suspected format: 5 digits, ""+"" or ""-"", 4 digits)    2. LRS-class: integer - The LRS-class values range from 0 - 99 with the 10's digit giving the basic class and the 1's digit giving the subclass. These classes are based on features (peaks, valleys, and trends) of the spectral curves.      3. ID-type: integer    4. Right-Ascension: float - Astronomical longitude. 1h = 15deg    5. Declination: float - Astronomical lattitude. -90 <= Dec <= 90    6. Scale Factor: float - Proportional to source strength    7. Blue base 1: integer - linear rescaling coefficient    8. Blue base 2: integer - linear rescaling coefficient    9. Red base 1: integer - linear rescaling coefficient   10. Red base 2: integer - linear rescaling coefficient   11-54: fluxes from the following 44 blue-band channel wavelengths: (all given as floating point numerals)     - 11. 7.8636     - 12. 8.0485     - 13. 8.2286     - 14. 8.4043     - 15. 8.5758     - 16. 8.7436     - 17. 8.9078     - 18. 9.0686     - 19. 9.2262     - 20. 9.3809      - 21. 9.5328     - 22. 9.6820     - 23. 9.8286      - 24. 9.9728      - 25. 10.1148      - 26. 10.2545      - 27. 10.3922      - 28. 10.5279      - 29. 10.6616      - 30. 10.7935      - 31. 10.9237      - 32. 11.0521      - 33. 11.1790      - 34. 11.3042      - 35. 11.4280      - 36. 11.5503      - 37. 11.6711      - 38. 11.7907      - 39. 11.9089      - 40. 12.0258      - 41. 12.1415      - 42. 12.2560      - 43. 12.3693      - 44. 12.4816      - 45. 12.5927      - 46. 12.7028      - 47. 12.8118      - 48. 12.9199      - 49. 13.0269      - 50. 13.1330      - 51. 13.2382      - 52. 13.3425      - 53. 13.4459      - 54. 13.5485    55-103: fluxes from the following 49 red-band channel wavelengths: (all given as floating point numerals)     - 55. 10.9929      - 56. 11.3704      - 57. 11.7357      - 58. 12.0899      - 59. 12.4339      - 60. 12.7687      - 61. 13.0948      - 62. 13.4131      - 63. 13.7239      - 64. 14.0278     - 65. 14.3252      - 66. 14.6166      - 67. 14.9022      - 68. 15.1825      - 69. 15.4576      - 70. 15.7280      - 71. 15.9937      - 72. 16.2551      - 73. 16.5123      - 74. 16.7656     - 75. 17.0151      - 76. 17.2610      - 77. 17.5034      - 78. 17.7425      - 79. 17.9784      - 80. 18.2113      - 81. 18.4412      - 82. 18.6682      - 83. 18.8925      - 84. 19.1142     - 85. 19.3334      - 86. 19.5500      - 87. 19.7643      - 88. 19.9763      - 89. 20.1861      - 90. 20.3937      - 91. 20.5992      - 92. 20.8026      - 93. 21.0041      - 94. 21.2037     - 95. 21.4014      - 96. 21.5973      - 97. 21.7914      - 98. 21.9838      - 99. 22.1745      - 100. 22.3636      - 101. 22.5511      - 102. 22.7371      - 103. 22.9216","A NASA-Ames research group concerned with unsupervised learning tasks may have used this database during their empirical studies of their algorithm/system (AUTOCLASS II).  See the 1988 Machine Learning Conference Proceedings, 54-64, for a description of their algorithm.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Reuter_50_50,157,Reuter_50_50 Data Set,../machine-learning-databases/00217/,"Multivariate, Text, Domain-Theory",2500,Computer,Real,10000,9/8/2011,"Classification, Clustering",N/A,65189,"Dataset creator and donator: ZhiLiu, e-mail: liuzhi8673 '@' gmail.com, institution: National Engineering Research Center for E-Learning, Hubei Wuhan, China  ","The dataset is the subset of RCV1. These corpus has already been used in author identification experiments. In the top 50 authors (with respect to total size of articles) were selected. 50 authors of texts labeled with at least one subtopic of the class CCAT(corporate/industrial) were selected.That way, it is attempted to minimize the topic factor in distinguishing among the texts. The training corpus consists of 2,500 texts (50 per author) and the test corpus includes other 2,500 texts (50 per author) non-overlapping with the training texts.",Attributes of the dataset are character n-grams(n=1-5),"J. Houvardas, E. Stamatatos, â€œN-gram Feature Selection for Authorship Identification,â€ in Proc. of the 12th Int. Conf. on Artificial Intelligence: Methodology, Systems, Applications, vol. 4183, pp.77-86, (2006) September 12-15; Varna, Bulgaria.	E. Stamatatos, â€œAuthor Identification Using Imbalanced and Limited Training Texts,â€ In Proc. of the 4th International Workshop on Text-based Information Retrieval, (2007) September 3-7; Regensburg, Germany.","Please refer to the donator Zhi Liu from National Engineering Research Center For E-Learning Technologyï¼ŒChina.",
http://archive.ics.uci.edu/ml/datasets/Kinship,158,Kinship Data Set,../machine-learning-databases/kinship/,Relational,104,Social,Categorical,12,7/1/1990,Relational-Learning,No,76204,"Creator:  Geoff Hinton Donor:  J. Ross Quinlan","This relational database consists of 24 unique names in two families (they have equivalent structures).  Hinton used one unique output unit for each person and was interested in predicting the following relations: wife, husband, mother, father, daughter, son, sister, brother, aunt, uncle, niece, and nephew.  Hinton used 104 input-output vector pairs (from a space of 12x24=288 possible pairs).  The prediction task is as follows: given a name and a relation, have the outputs be on for only those individuals (among the 24) that satisfy the relation.  The outputs for all other individuals should be off. Hinton's results: Using 100 vectors as input and 4 for testing, his results on two passes yielded 7 correct responses out of 8.  His network of 36 input units, 3 layers of hidden units, and 24 output units used 500 sweeps of the training set during training. Quinlan's results: Using FOIL, he repeated the experiment 20 times (rather than Hinton's 2 times).  FOIL was correct 78 out of 80 times on the test cases.  ","   -- The relation names are:      wife      husband      mother      father      daughter      son      sister      brother      aunt      uncle      niece      nephew","Hinton, G.E (1986). Learning distributed representations of concepts, Proceedings of CogSci 1986.[Web Link]  Quinlan, J.R. (1989).  Learning relations: Comparison of a symbolic and a connectionist approach.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Localization+Data+for+Person+Activity,159,Localization Data for Person Activity Data Set,../machine-learning-databases/00196/,"Univariate, Sequential, Time-Series",164860,Life,Real,8,11/3/2010,Classification,N/A,105864,"- Creators: Mitja Lustrek (mitja.lustrek '@' ijs.si), Bostjan Kaluza (bostjan.kaluza '@' ijs.si), Rok Piltaver (rok.piltaver '@' ijs.si), Jana Krivec (jana.krivec '@' ijs.si), Vedrana Vidulin (vedrana.vidulin '@' ijs.si)   - Jozef Stefan Institute, Jamova cesta 39, 1000 Ljubljana, Slovenija- Donor: Bozidara Cvetkovic (boza.cvetkovic '@' ijs.si) - Jozef Stefan Institute, Jamova cesta 39, 1000 Ljubljana, Slovenija- Date received: October, 2010","People used for recording of the data were wearing four tags (ankle left, ankle right, belt and chest). Each instance is a localization data for one of the tags. The tag can be identified by one of the attributes.","Instance example: A01,020-000-033-111,633790226057226795,27.05.2009 14:03:25:723,4.292500972747803,2.0738532543182373,1.36650812625885,walking    1) Sequence Name {A01,A02,A03,A04,A05,B01,B02,B03,B04,B05,C01,C02,C03,C04,C05,D01,D02,D03,D04,D05,E01,E02,E03,E04,E05} (Nominal)      - A, B, C, D, E  = 5 people   2) Tag identificator {010-000-024-033,020-000-033-111,020-000-032-221,010-000-030-096}	(Nominal)      - ANKLE_LEFT = 010-000-024-033      - ANKLE_RIGHT = 010-000-030-096      - CHEST = 020-000-033-111      - BELT = 020-000-032-221   3) timestamp (Numeric) all unique   4) date FORMAT = dd.MM.yyyy HH:mm:ss:SSS (Date)    5) x coordinate of the tag (Numeric)   6) y coordinate of the tag (Numeric)   7) z coordinate of the tag (Numeric)   8) activity  {walking,falling,'lying down',lying,'sitting down',sitting,'standing up from lying','on all fours','sitting on the ground','standing up from sitting','standing up from sitting on the ground'} (Nominal) ","B. Kaluza, V. Mirchevska, E. Dovgan, M. Lustrek, M. Gams, An Agent-based Approach to Care in Independent Living, International Joint Conference on Ambient Intelligence (AmI-10), Malaga, Spain, In press","B. Kaluza, V. Mirchevska, E. Dovgan, M. Lustrek, M. Gams, An Agent-based Approach to Care in Independent Living, International Joint Conference on Ambient Intelligence (AmI-10), Malaga, Spain, In press",
http://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant,160,Combined Cycle Power Plant Data Set,../machine-learning-databases/00294/,Multivariate,9568,Computer,Real,4,3/26/2014,Regression,N/A,167823,"Pınar Tüfekci, Çorlu Faculty of Engineering, Namık Kemal University, TR-59860 Çorlu, Tekirdağ, TurkeyEmail: ptufekci '@' nku.edu.trHeysem Kaya, Department of Computer Engineering, Boğaziçi University, TR-34342, Beşiktaş, İstanbul, TurkeyEmail: heysem '@' boun.edu.tr","The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP)  of the plant.A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, he other three of the ambient variables effect the GT performance.For comparability with our baseline studies, and to allow 5x2 fold statistical tests be carried out, we provide the data shuffled five times. For each shuffling 2-fold CV is carried out and the resulting 10 measurements are used for statistical testing.We provide the data both in .ods and in .xlsx formats.","Features consist of hourly average ambient variables - Temperature (T) in the range 1.81°C and 37.11°C,- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,- Relative Humidity (RH) in the range 25.56% to 100.16%- Exhaust Vacuum (V) in teh range 25.36-81.56 cm Hg- Net hourly electrical energy output (EP) 420.26-495.76 MWThe averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization. ","Pınar Tüfekci, Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods, International Journal of Electrical Power & Energy Systems, Volume 60, September 2014, Pages 126-140, ISSN 0142-0615, [Web Link]. ([Web Link])Heysem Kaya, Pınar Tüfekci , Sadık Fikret Gürgen: Local and Global Learning Methods for Predicting Power of a Combined Gas & Steam Turbine, Proceedings of the International Conference on Emerging Trends in Computer and Electronics Engineering ICETCEE 2012, pp. 13-18 (Mar. 2012, Dubai)","Pınar Tüfekci, Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods, International Journal of Electrical Power & Energy Systems, Volume 60, September 2014, Pages 126-140, ISSN 0142-0615, [Web Link].([Web Link])Heysem Kaya, Pınar Tüfekci , Sadık Fikret Gürgen: Local and Global Learning Methods for Predicting Power of a Combined Gas & Steam Turbine, Proceedings of the International Conference on Emerging Trends in Computer and Electronics Engineering ICETCEE 2012, pp. 13-18 (Mar. 2012, Dubai)",
http://archive.ics.uci.edu/ml/datasets/ISOLET,161,ISOLET Data Set,../machine-learning-databases/isolet/,Multivariate,7797,Computer,Real,617,9/12/1994,Classification,No,122817,"Creators:  Ron Cole and Mark FantyDepartment of Computer Science and Engineering,Oregon Graduate Institute, Beaverton, OR 97006.cole '@' cse.ogi.edu, fanty '@' cse.ogi.edu  Donor:  Tom DietterichDepartment of Computer ScienceOregon State University, Corvallis, OR 97331tgd '@' cs.orst.edu","This data set was generated as follows. 150 subjects spoke the name of each letter of the alphabet twice. Hence, we have 52 training examples from each speaker. The speakers are grouped into sets of 30 speakers each, and are referred to as isolet1, isolet2, isolet3, isolet4, and isolet5. The data appears in isolet1+2+3+4.data in sequential order, first the speakers from isolet1, then isolet2, and so on.  The test set, isolet5, is a separate file. You will note that 3 examples are missing.  I believe they were dropped due to difficulties in recording. I believe this is a good domain for a noisy, perceptual task.  It is also a very good domain for testing the scaling abilities of algorithms. For example, C4.5 on this domain is slower than backpropagation! I have formatted the data for C4.5 and provided a C4.5-style names file as well.","The features are described in the paper by Cole and Fanty cited above.  The features include spectral coefficients; contour features, sonorant features, pre-sonorant features, and post-sonorant features.  Exact order of appearance of the features is not known.","Fanty, M., Cole, R. (1991).  Spoken letter recognition.  In Lippman, R. P., Moody, J., and Touretzky, D. S. (Eds). Advances in Neural Information Processing Systems 3.  San Mateo, CA: Morgan Kaufmann.[Web Link]  Dietterich, T. G., Bakiri, G. (1991)  Error-correcting output codes: A general method for improving multiclass inductive learning programs.  Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), Anaheim, CA: AAAI Press.[Web Link]  Dietterich, T. G., Bakiri, G. (1994) Solving Multiclass Learning Problems via Error-Correcting Output Codes. Available as URL: [Web Link] [Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Jaakko Peltonen and Samuel Kaski. Discriminative Components of Data. IEEE. 2004.  [View Context].Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].David Littau and Daniel Boley. Using Low-Memory Representations to Cluster Very Large Data Sets. SDM. 2003.  [View Context].Inderjit S. Dhillon and Dharmendra S. Modha and W. Scott Spangler. Class visualization of high-dimensional data with applications. Department of Computer Sciences, University of Texas. 2002.  [View Context].Erin L. Allwein and Robert E. Schapire and Yoram Singer. Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers. ICML. 2000.  [View Context].Hiroshi Shimodaira and Jun Okui and Mitsuru Nakai. Modified Minimum Classification Error Learning and Its Application to Neural Networks. SSPR/SPR. 1998.  [View Context].Khaled A. Alsabti and Sanjay Ranka and Vineet Singh. CLOUDS: A Decision Tree Classifier for Large Datasets. KDD. 1998.  [View Context].Thomas G. Dietterich and Ghulum Bakiri. Solving Multiclass Learning Problems via Error-Correcting Output Codes. CoRR, csAI/9501101. 1995.  [View Context].Hiroshi Shimodaira and Jun Okui and Mitsuru Nakai. IMPROVING THE GENERALIZATION PERFORMANCE OF THE MCE/GPD LEARNING. School of Information Science Japan Advanced Institute of Science and Technology Tatsunokuchi, Ishikawa.  [View Context].Shlomo Dubnov and Ran El and Yaniv Technion and Yoram Gdalyahu and Elad Schneidman and Naftali Tishby and Golan Yona. Clustering By Friends : A New Nonparametric Pairwise Distance Based Clustering Algorithm. Ben Gurion University.  [View Context].Jakub Zavrel. An Empirical Re-Examination of Weighted Voting for k-NN. Computational Linguistics.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Audiology+%28Original%29,162,Audiology (Original) Data Set,../machine-learning-databases/audiology/,Multivariate,226,Life,Categorical,N/A,12/3/1987,Classification,Yes,110441,"Original Owner:  Professor Jergen at Baylor College of Medicine Donor:  Bruce Porter (porter '@' fall.cs.utexas.EDU)","This database does NOT use a standard set of attributes per instance. Contact Ray Bareiss (rbareiss '@' uunet.uucp ?) for more information. Domain expert: Professor Craig Wier of the University of Texas, Austin. ","(all attributes are nominally valued)   1. case identifier.   2. classification (24 classes)   3. List of case features      -- format: form f(v) should be read as ""feature f has value v""","Bareiss, E. Ray, & Porter, Bruce (1987).  Protos: An Exemplar-Based Learning Apprentice.  In the Proceedings of the 4th International Workshop on Machine Learning, 12-23, Irvine, CA: Morgan Kaufmann.[Web Link]",WARNING: This database should be credited to the original owner whenever used for any publication whatsoever.,"Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Marcus Hutter and Marco Zaffalon. Distribution of Mutual Information from Complete and Incomplete Data. CoRR, csLG/0403025. 2004.  [View Context].Richard Nock and Marc Sebban and David Bernard. A SIMPLE LOCALLY ADAPTIVE NEAREST NEIGHBOR RULE WITH APPLICATION TO POLLUTION FORECASTING. International Journal of Pattern Recognition and Artificial Intelligence Vol. 2003.  [View Context].Alexander K. Seewald. How to Make Stacking Better and Faster While Also Taking Care of an Unknown Weakness. ICML. 2002.  [View Context].Wai Lam and Kin Keung and Charles X. Ling. PR 1527. Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong. 2001.  [View Context].Alexander K. Seewald and Johann Petrak and Gerhard Widmer. Hybrid Decision Tree Learners with Alternative Leaf Classifiers: An Empirical Study. FLAIRS Conference. 2001.  [View Context].Jihoon Yang and Rajesh Parekh and Vasant Honavar. DistAl: An inter-pattern distance-based constructive learning algorithm. Intell. Data Anal, 3. 1999.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Pedro Domingos. Unifying Instance-Based and Rule-Based Induction. Machine Learning, 24. 1996.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Thomas G. Dietterich and Ghulum Bakiri. Solving Multiclass Learning Problems via Error-Correcting Output Codes. CoRR, csAI/9501101. 1995.  [View Context].Jerome H. Friedman and Ron Kohavi and Youngkeol Yun. To appear in AAAI-96 Lazy Decision Trees. Statistics Department and Stanford Linear Accelerator Center Stanford University.  [View Context].Alexander K. Seewald. Meta-Learning for Stacked Classification. Austrian Research Institute for Artificial Intelligence.  [View Context].Bernhard Pfahringer and Ian H. Witten and Philip Chan. Improving Bagging Performance by Increasing Decision Tree Diversity. Austrian Research Institute for AI.  [View Context].D. Randall Wilson and Roel Martinez. Improved Center Point Selection for Probabilistic Neural Networks. Proceedings of the International Conference on Artificial Neural Networks and Genetic Algorithms.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Geoffrey I Webb. Learning Decision Lists by Prepending Inferred Rules. School of Computing and Mathematics Deakin University.  [View Context].Mohammed Waleed Kadous and Claude Sammut. The University of New South Wales School of Computer Science and Engineering Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series.  [View Context].Mohammed Waleed Kadous. Expanding the Scope of Concept Learning Using Metafeatures. School of Computer Science and Engineering, University of New South Wales.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/NYSK,163,NYSK Data Set,../machine-learning-databases/00260/,"Multivariate, Sequential, Text",10421,Social,N/A,7,10/11/2013,Clustering,N/A,53307,- Aurélien Lauf (alu '@' amisw.com)- Leila Khouas (lkh '@' amisw.com)- Mohamed Dermouche (mde '@' amisw.com),"Documents are first obtained via a Web search using AMIEI: an integrated platform for delivering enterprise intelligence, developed by AMI Software ([Web Link]) with the following query: ``dsk'' OR ``strauss-kahn'' OR ``strauss-khan''. NYSK dataset was used to extract topic-sentiment correlation and evolution over time but may be used for other text mining tasks like topic extraction, sentiment analysis, etc.",Documents are then filtered and presented in XML format. All XML fields are self explanatory.,"(1) Mohamed Dermouche, Julien Velcin, Leila Khouas, and Sabine Loudcher. A Joint Model for Topic-Sentiment Evolution over Time. In Proceedings of The IEEE 14th International Conference on Data Mining (ICDM’2014), pages 773–778, Shenzhen, China, 2014. IEEE Computer Society.(2) Mohamed Dermouche, Leila Khouas, Julien Velcin, and Sabine Loudcher. A Joint Model for Topic-Sentiment Modeling from Text. In Proceedings of The 30th ACM/SIGAPP Symposium On Applied Computing (SAC’2015), pages 819--824, Salamanca, Spain, 2015. ACM.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer,164,Dataset for ADL Recognition with Wrist-worn Accelerometer Data Set,../machine-learning-databases/00283/,"Multivariate, Time-Series",N/A,Computer,N/A,3,2/11/2014,"Classification, Clustering",N/A,78994,"Barbara Bruno, Fulvio Mastrogiovanni, Antonio SgorbissaLaboratorium - Laboratory for Ambient Intelligence and Mobile RoboticsDIBRIS, University of Genova,via Opera Pia 13, 16145, Genova, Italia (IT)","The Dataset for ADL Recognition with Wrist-worn Accelerometer is a public collection of labelled accelerometer data recordings to be used for the creation and validation of acceleration models of simple ADL. The Dataset is composed of the recordings of 14 simple ADL (brush_teeth, climb_stairs, comb_hair, descend_stairs, drink_glass, eat_meat, eat_soup, getup_bed, liedown_bed, pour_water, sitdown_chair, standup_chair, use_telephone, walk) perfomed by a total of 16 volunteers. The data are collected by a single tri-axial accelerometer attached to the right-wrist of the volunteer. Accelerometer specifications are detailed in the file MANUAL.TXT inside the Dataset folder. Detailed documentation about the dataset is provided in the files README.TXT and MANUAL.TXT inside the Dataset folder.","Each file in the dataset follows the following naming convention:        Accelerometer-[START_TIME]-[ADL]-[VOLUNTEER]where: - [START_TIME]: timestamp of the starting moment of the recording in the format [YYYY-MM-DD-HH-MM-SS] - [HMP]:	 name of the ADL performed in the recorded trial - [VOLUNTEER]:	 identification code of the volunteer performing the recorded motion in the format [gN] where:		  - 'g' indicates the gender of the volunteer (m -> male, f -> female)		  - 'N' indicates the progressive number associated to the volunteer Each record of a file reports: - acceleration along the x axis of the accelerometer - acceleration along the y axis of the accelerometer - acceleration along the z axis of the accelerometer","A description of the ADL monitoring system that we have designed to work with the provided dataset can be found at:- Bruno, B., Mastrogiovanni, F., Sgorbissa, A., Vernazza, T., Zaccaria, R.:  Analysis of human behavior recognition algorithms based on acceleration data.  In: IEEE Int Conf on Robotics and Automation (ICRA),  pp. 1602--1607 (2013) - Bruno, B., Mastrogiovanni, F., Sgorbissa, A., Vernazza, T., Zaccaria, R.:  Human motion modelling and recognition: A computational approach.  In: IEEE Int Conf on Automation Science and Engineering (CASE),  pp. 156--161 (2012)","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Daily+Demand+Forecasting+Orders,165,Daily Demand Forecasting Orders Data Set,../machine-learning-databases/00409/,Time-Series,60,Business,Integer,13,11/21/2017,Regression,N/A,78216,"Creators original owner and donors: Ricardo Pinto Ferreira (1), Andrea Martiniano (2), Arthur Ferreira (3), Aleister Ferreira (4) and Renato Jose Sassi (5). E-mail address: kasparov '@' uni9.pro.br (1), andrea.martiniano '@' gmail.com (2), arthur2.ferreira '@' usp.br (3), aleisterferreira '@' hotmail.com (4), sassi '@' uni9.pro.br (5) - PhD student (1, 2), Graduation student (3, 4), Prof. Doctor (5). Universidade Nove de Julho - Post-Graduation Program in Informatics and Knowledge Management. Address: Rua Vergueiro, 235/249 Liberdade, Sao Paulo – SP, Brazil. Zip code: 01504-001. Website: http://www.uninove.br","The database was collected during 60 days, this is a real database of a Brazilian company of large logistics. Twelve predictive attributes and a target that is the total of orders for daily. treatment","The dataset was collected during 60 days, this is a real database of a brazilian logistics company. The dataset has twelve predictive attributes and a target that is the total of orders for daily treatment. The database was used in academic research at the Universidade Nove de Julho..arff header for Weka:@relation Daily_Demand_Forecasting_Orders@attribute Week_of_the_month {1.0, 2.0, 3.0, 4.0, 5.0}@attribute Day_of_the_week_(Monday_to_Friday) {2.0, 3.0, 4.0, 5.0, 6.0}@attribute Non_urgent_order integer@attribute Urgent_order integer@attribute Order_type_A integer@attribute Order_type_B integer@attribute Order_type_C integer@attribute Fiscal_sector_orders integer@attribute Orders_from_the_traffic_controller_sector integer@attribute Banking_orders_(1) integer@attribute Banking_orders_(2) integer@attribute Banking_orders_(3) integer@attribute Target_(Total_orders) integer@data","Ferreira, R. P., Martiniano, A., Ferreira, A., Ferreira, A., & Sassi, R. J. (2016). Study on daily demand forecasting orders using artificial neural network. IEEE Latin America Transactions, 14(3), 1519-1525.","Ferreira, R. P., Martiniano, A., Ferreira, A., Ferreira, A., & Sassi, R. J. (2016). Study on daily demand forecasting orders using artificial neural network. IEEE Latin America Transactions, 14(3), 1519-1525.",
http://archive.ics.uci.edu/ml/datasets/Burst+Header+Packet+%28BHP%29+flooding+attack+on+Optical+Burst+Switching+%28OBS%29+Network,166,Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network Data Set,../machine-learning-databases/00404/,Text,1075,Computer,Integer,22,8/28/2017,Classification,N/A,30223,"Adel RajabDepartment of Computer Science and Engineering,University of South Carolina,Columbia, SC, USA, 29208Phone number:(803)238-6657rajaba '@' email.sc.edu ",For Further information about the variables see the file in the data folder.,"1. Node: This is the number of the sending node (numeric).2. Utilized Bandwidth Rate: This is the normalization of â€˜Used_Bandidthâ€™ (numeric).3. Packet Drop Rate: This is the normalization of â€˜Percentage_Of_Lost_Pcaket_Rateâ€™ (numeric).4. Reserved_Bandwidth: Initial reserved Bandwidth assigned (given) to each node, the user (usr) in the experiments assign these values. (numeric).5. Average_Delay_Time_Per_Sec:  Average Delay Time (per second) for each node. This is (End-to End Delay). (numeric).6. Percentage_Of_Lost_Pcaket_Rate: Percentage of Packets Drop Rate for each node (numeric).7. Percentage_Of_Lost_Byte_Rate: Percentage of Lost Byte Rate for each node (numeric).8. Packet Received Rate: Total received packets (per second) for each node based on â€˜Reserved_Bandwidthâ€™ (numeric).9. Used_Bandwidth: This is what each node could reserve from the â€˜Reserved_Bandwidthâ€™ (numeric).10. Lost_Bandwidth: The amount of lost Bandwidth by each node from â€˜Reserved_Bandwidthâ€™ (numeric).11. Packet Size_Byte: Packets size in Byte assigned specifically for each node to transmit. Note: 60 Byte will be added to the 1440 for the IP Header and the UDP Header ((Data size 1440 Byte) + (IP Header 40 Byte) + (UDP Header 20 Byte)) =1500 Byte (numeric).12. Packet_Transmitted: Total transmitted packets (per second) for each node based on the â€˜Reserved_Bandwidthâ€™ (numeric).13. Packet_Received: Total received packets (per second) for each node based on the â€˜Reserved_Bandwidthâ€™ (numeric).14. Packet_lost: Total lost packets (per second) for each node, which based on the â€˜Lost_Bandwidthâ€™ (numeric).15. Transmitted_Byte: Total transmitted Byte (per second) for each node (numeric).16. Received_Byte: Total received Byte (per second) for each node based on the â€˜Reserved_Bandwidthâ€™ (numeric).17. 10-Run-AVG-Drop-Rate: Average packet drop rate for 10 consecutive (run) iterations (numeric).18. 10-Run-AVG-Bandwidth-Use: Average Bandwidth utilized for 10 consecutive (run) iterations (numeric).19. 10-Run-Delay: Average delay time for 10 consecutive (run) iterations (numeric).20. Node Status' {B, NB, P NB}: initial classification of nodes based on â€˜Packet Drop Rateâ€™, Used_Bandwidth and â€˜Average_Delay_Time_Per_Secâ€™. B = Behaving, NB = Not Behaving and P NB = Potentially Not Behaving. (Categorical)21. Flood Status: Percentage of flood per node based on â€˜Packet Drop Rateâ€™ Medium and high level of BHP flood attack in case B (numeric).22. Class ' {NB-No Block, Block, No Block, NB-Wait}: The final classification of nodes based on â€˜Packet Drop Rateâ€™, â€˜Reserved_Bandwidthâ€™, â€˜Iteration #â€™, â€˜Used_Bandwidthâ€™, â€˜Packet Drop Rateâ€™. This is for case B (Categorical ).","A. Rajab, C. T. Huang, M. Alshargabi, and J. Cobb, â€œCountering Burst Header Packet Flooding Attack in Optical Burst Switching Network,â€ In: International Conference on Information Security Practice and Experience, Springer International Publishing, pp. 315â€“329, Nov 16 2016.",Please refer to the Machine Learning Repository's citation policy,
http://archive.ics.uci.edu/ml/datasets/Parkinson+Speech+Dataset+with++Multiple+Types+of+Sound+Recordings,167,Parkinson Speech Dataset with  Multiple Types of Sound Recordings Data Set,../machine-learning-databases/00301/,Multivariate,1040,Life,"Integer, Real",26,6/12/2014,"Classification, Regression",N/A,99046,"1. Olcay KURSUN, PhD., Istanbul University, Department of Computer Engineering, 34320, Istanbul, Turkey Phone: +90 (212) 473 7070 - 17827 Email: okursun '@' istanbul.edu.tr  2. Betul ERDOGDU SAKAR, PhD., Bahcesehir University, Department of Software Engineering, 34381, Istanbul, Turkey Phone: +90 (212) 381 0589 Email: betul.erdogdu '@' eng.bahcesehir.edu.tr  3. M. Erdem ISENKUL, M.S., Istanbul University, Department of Computer Engineering, 34320, Istanbul, Turkey Email: eisenkul '@' istanbul.edu.tr  4. C. Okan SAKAR, PhD., Bahcesehir University, Department of Computer Engineering, 34381, Istanbul, Turkey Phone: +90 (212) 381 0571 Email: okan.sakar '@' eng.bahcesehir.edu.tr  5. Ahmet SERTBAS, PhD, Istanbul University, Department of Computer Engineering, 34320, Istanbul, Turkey Email: asertbas '@' istanbul.edu.tr  6. Fikret GURGEN, PhD., Bogazici University, Department of Computer Engineering, 34342, Istanbul, Turkey Email: gurgen '@' boun.edu.tr  7. Sakir DELIL, M.D., PhD., Istanbul University,CerrahpaÅŸa Faculty of Medicine, Department of Neurology, 34098, Istanbul, Turkey Email: sakir.delil '@' ctf.edu.tr  8. Hulya APAYDIN, M.D., PhD., Istanbul University, CerrahpaÅŸa Faculty of Medicine, Department of Neurology, 34098, Istanbul, Turkey Email: hulya.apaydin '@' ctf.edu.tr  Donor:C. Okan SAKAR, PhD., Bahcesehir University, Department of Computer Engineering, 34381, Istanbul, Turkey Phone: +90 (212) 381 0571 Email: okan.sakar '@' eng.bahcesehir.edu.tr ","The PD database consists of training and test files. The training data belongs to 20 PWP (6 female, 14 male) and 20 healthy individuals (10 female, 10 male) who appealed at the Department of Neurology in Cerrahpasa Faculty of Medicine, Istanbul University. From all subjects, multiple types of sound recordings (26 voice samples including sustained vowels, numbers, words and short sentences) are taken.  A group of 26 linear and timeâ€“frequency based features are extracted from each voice sample. UPDRS ((Unified Parkinsonâ€™s Disease Rating Scale) score of each patient which is determined by expert physician is also available in this dataset. Therefore, this dataset can also be used for regression. After collecting the training dataset which consists of multiple types of sound recordings and performing our experiments, in line with the obtained findings we continued collecting an independent test set from PWP via the same physicianâ€™s examination process under the same conditions. During the collection of this dataset, 28 PD patients are asked to say only the sustained vowels 'a' and 'o' three times respectively which makes a total of 168 recordings. The same 26 features are extracted from voice samples of this dataset. This dataset can be used as an independent test set to validate the results obtained on training set. Further details are contained in the following reference -- if you use this dataset, please cite: Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun,O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of SoundRecordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013 Training Data File:Each subject has 26 voice samples including sustained vowels, numbers, words and short sentences. The voice samples in the training data file are given in the following order: sample# - corresponding voice samples1: sustained vowel (aaaâ€¦â€¦)2: sustained vowel (oooâ€¦...)3: sustained vowel (uuuâ€¦...)4-13: numbers from 1 to 1014-17: short sentences18-26: words Test Data File:28 PD patients are asked to say only the sustained vowels 'a' and 'o' three times respectively which makes a total of 168 recordings (each subject has 6 voice samples) The voice samples in the test data file are given in the following order: sample# - corresponding voice samples1-3: sustained vowel (aaaâ€¦â€¦)4-6: sustained vowel (oooâ€¦â€¦)","Training Data File:column 1: Subject id colum 2-27: features features 1-5: Jitter (local),Jitter (local, absolute),Jitter (rap),Jitter (ppq5),Jitter (ddp),features 6-11: Shimmer (local),Shimmer (local, dB),Shimmer (apq3),Shimmer (apq5), Shimmer (apq11),Shimmer (dda),features 12-14: AC,NTH,HTN,features 15-19: Median pitch,Mean pitch,Standard deviation,Minimum pitch,Maximum pitch,features 20-23: Number of pulses,Number of periods,Mean period,Standard deviation of period, features 24-26: Fraction of locally unvoiced frames,Number of voice breaks,Degree of voice breaks column 28: UPDRScolumn 29: class information Test Data File:column 1: Subject id colum 2-27: features features 1-5: Jitter (local),Jitter (local, absolute),Jitter (rap),Jitter (ppq5),Jitter (ddp),features 6-11: Shimmer (local),Shimmer (local, dB),Shimmer (apq3),Shimmer (apq5), Shimmer (apq11),Shimmer (dda),features 12-14: AC,NTH,HTN,features 15-19: Median pitch,Mean pitch,Standard deviation,Minimum pitch,Maximum pitch,features 20-23: Number of pulses,Number of periods,Mean period,Standard deviation of period,features 24-26: Fraction of locally unvoiced frames,Number of voice breaks,Degree of voice breaks column 28: class information","Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun, O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of Sound Recordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013. Isenkul, M.E., ErdoÄŸdu, B., Sakar, C.O., GÃ¼mÃ¼s, E., Delil, M.S., GÃ¼rgen, F., Sertbas, A., Kursun, O.,Parkinson HastalÄ±ÄŸÄ±nÄ±n Ses Disfonilerinden TeÅŸhisi iÃ§in bir Ses VeritabanÄ± OlusturulmasÄ± veÃ–rÃ¼ntÃ¼lerinin KullanÄ±mÄ±, 16. Biyomedikal MÃ¼hendisliÄŸi Ulusal ToplantÄ±sÄ± (BÄ°YOMUT 2011),Antalya, Turkey, October, 2011.","Please cite the following paper if you use this dataset:Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun, O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of Sound Recordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013.",
http://archive.ics.uci.edu/ml/datasets/Shuttle+Landing+Control,168,Shuttle Landing Control Data Set,../machine-learning-databases/shuttle-landing-control/,Multivariate,15,Physical,Categorical,6,11/1/1988,Classification,No,103637,"Original source:  unknownNASA: Mr. Roger Burke's autolander design team Donor:  Bojan CestnikJozef Stefan InstituteJamova 3961000 LjubljanaYugoslavia (tel.: (38)(+61) 214-399 ext.287) ",This is a tiny database.  Michie reports that Burke's group used RULEMASTER to generate comprehendable rules for determining the conditions under which an autolanding would be preferable to manual control of the spacecraft.,"    1. Class: noauto, auto       -- that is, advise using manual/automatic control    2. STABILITY: stab, xstab    3. ERROR: XL, LX, MM, SS    4. SIGN: pp, nn    5. WIND: head, tail    6. MAGNITUDE: Low, Medium, Strong, OutOfRange    7. VISIBILITY: yes, no","Michie,D. (1988).  The Fifth Generation's Unbridged Gap. In Rolf Herken (Ed.) The Universal Turing Machine: A Half-Century Survey, 466-489, Oxford University Press.","Please refer to the Machine Learning
Repository's citation policy","Adil M. Bagirov and Julien Ugon. An algorithm for computation of piecewise linear function separating two sets. CIAO, School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Christophe Giraud and Tony Martinez. ADYNAMIC INCREMENTAL NETWORK THAT LEARNS BY DISCRIMINATION. AA.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Statlog+%28Image+Segmentation%29,169,Statlog (Image Segmentation) Data Set,../machine-learning-databases/statlog/segment/,Multivariate,2310,N/A,Real,19,11/1/1990,Classification,No,61416,"Creators:  Vision Group, University of Massachusetts Donor:  Vision Group (Carla Brodley, brodley '@' cs.umass.edu)","The instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.   Each instance is a 3x3 region.","1.  region-centroid-col:  the column of the center pixel of the region.2.  region-centroid-row:  the row of the center pixel of the region.3.  region-pixel-count:  the number of pixels in a region = 9.4.  short-line-density-5:  the results of a line extractoin algorithm that counts how many lines of length 5 (any orientation) with low contrast, less than or equal to 5, go through the region.5.  short-line-density-2:  same as short-line-density-5 but counts lines of high contrast, greater than 5.6.  vedge-mean:  measure the contrast of horizontally adjacent pixels in the region.  There are 6, the mean and standard deviation are given.  This attribute is used as a vertical edge detector.7.  vegde-sd:  (see 6)8.  hedge-mean:  measures the contrast of vertically adjacent pixels. Used for horizontal line detection. 9.  hedge-sd: (see 8).10. intensity-mean:  the average over the region of (R + G + B)/311. rawred-mean: the average over the region of the R value.12. rawblue-mean: the average over the region of the B value.13. rawgreen-mean: the average over the region of the G value.14. exred-mean: measure the excess red:  (2R - (G + B))15. exblue-mean: measure the excess blue:  (2B - (G + R))16. exgreen-mean: measure the excess green:  (2G - (R + B))17. value-mean:  3-d nonlinear transformation of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals of Interactive Computer Graphics)18. saturatoin-mean:  (see 17)19. hue-mean:  (see 17) Classes: 1 = brickface, 2 = sky, 3 = foliage, 4 = cement, 5 = window, 6 = path, 7 = grass.",N/A,"Please refer to the Machine Learning
Repository's citation policy","Anthony K H Tung and Xin Xu and Beng Chin Ooi. CURLER: Finding and Visualizing Nonlinear Correlated Clusters. SIGMOD Conference. 2005.  [View Context].Xiaoli Z. Fern and Carla Brodley. Cluster Ensembles for High Dimensional Clustering: An Empirical Study. Journal of Machine Learning Research n, a. 2004.  [View Context].Aristidis Likas and Nikos A. Vlassis and Jakob J. Verbeek. The global k-means clustering algorithm. Pattern Recognition, 36. 2003.  [View Context].Manoranjan Dash and Huan Liu and Peter Scheuermann and Kian-Lee Tan. Fast hierarchical clustering and its validation. Data Knowl. Eng, 44. 2003.  [View Context].Amund Tveit. Empirical Comparison of Accuracy and Performance for the MIPSVM classifier with Existing Classifiers. Division of Intelligent Systems Department of Computer and Information Science, Norwegian University of Science and Technology.  [View Context].Je Scott and Mahesan Niranjan and Richard W. Prager. Realisable Classifiers: Improving Operating Performance on Variable Cost Problems. Cambridge University Department of Engineering.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].K. A. J Doherty and Rolf Adams and Neil Davey. Unsupervised Learning with Normalised Data and Non-Euclidean Norms. University of Hertfordshire.  [View Context].Adil M. Bagirov and John Yearwood. A new nonsmooth optimization algorithm for clustering. Centre for Informatics and Applied Optimization, School of Information Technology and Mathematical Sciences, University of Ballarat.  [View Context].K. A. J Doherty and Rolf Adams and Neil Davey. Non-Euclidean Norms and Data Normalisation. Department of Computer Science, University of Hertfordshire, College Lane.  [View Context].Michael Lindenbaum and Shaul Markovitch and Dmitry Rusakov. Selective Sampling Using Random Field Modelling.  [View Context].James Tin and Yau Kwok. Moderating the Outputs of Support Vector Machine Classifiers. Department of Computer Science Hong Kong Baptist University Hong Kong.  [View Context].Thomas T. Osugi and M. S. EXPLORATION-BASED ACTIVE MACHINE LEARNING. Faculty of The Graduate College at the University of Nebraska In Partial Fulfillment of Requirements.  [View Context].Nikos A. Vlassis and Aristidis Likas. A greedy EM algorithm for Gaussian mixture. Intelligent Autonomous Systems, IAS.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29,170,Molecular Biology (Splice-junction Gene Sequences) Data Set,../machine-learning-databases/molecular-biology/splice-junction-gene-sequences/,"Sequential, Domain-Theory",3190,Life,Categorical,61,1/1/1992,Classification,No,101540,"Creators:  1. All examples taken from Genbank 64.1 (ftp site: genbank.bio.net)2. Categories ""ei"" and ""ie"" include every ""split-gene"" for primates in Genbank 64.13. non-splice examples taken from sequences known not to include a splicing site  Donor:  G. Towell, M. Noordewier, and J. Shavlik, {towell,shavlik}@cs.wisc.edu, noordewi '@' cs.rutgers.edu","Problem Description:  Splice junctions are points on a DNA sequence at which `superfluous' DNA is removed during the process of protein creation in higher organisms.  The problem posed in this dataset is to recognize, given a sequence of DNA, the boundaries between exons (the parts of the DNA sequence retained after splicing) and introns (the parts of the DNA sequence that are spliced out). This problem consists of two subtasks: recognizing exon/intron boundaries (referred to as EI sites), and recognizing intron/exon boundaries (IE sites). (In the biological community, IE borders are referred to a ``acceptors'' while EI borders are referred to as ``donors''.) This dataset has been developed to help evaluate a ""hybrid"" learning algorithm (KBANN) that uses examples to inductively refine preexisting knowledge.  Using a ""ten-fold cross-validation"" methodology on 1000 examples randomly selected from the complete set of 3190, the following  error rates were produced by various ML algorithms (all experiments run at the Univ of Wisconsin, sometimes with local implementations of published algorithms).  System -- Neither -- EI -- IE---------------------------------------------------KBANN -- 4.62 -- 7.56 --  8.47BACKPROP -- 5.29 --  5.74 -- 10.75PEBLS -- 6.86 -- 8.18 -- 7.55PERCEPTRON -- 3.99 -- 16.32 -- 17.41ID3 -- 8.84 -- 10.58 -- 13.99COBWEB  -- 11.80 -- 15.04 -- 9.46Near. Neighbor -- 31.11 -- 11.65 -- 9.09","1.   One of {n ei ie}, indicating the class.2.   The instance name.3-62.   The remaining 60 fields are the sequence, starting at position -30 and ending at position +30. Each of these fields is almost always filled by one of {a, g, t, c}. Other characters indicate ambiguity among the standard characters according to the following table: character: meaningD:  A or G or TN:  A or G or C or TS:  C or GR:  A or G","M. O. Noordewier and G. G. Towell and J. W. Shavlik, 1991; ""Training Knowledge-Based Neural Networks to Recognize Genes in DNA Sequences"".  Advances in Neural Information Processing Systems, volume 3, Morgan Kaufmann.[Web Link]  G. G. Towell and J. W. Shavlik and M. W. Craven, 1991;  ""Constructive Induction in Knowledge-Based Neural Networks"",  In Proceedings of the Eighth International Machine Learning Workshop, Morgan Kaufmann.[Web Link]  G. G. Towell, 1991; ""Symbolic Knowledge and Neural Networks: Insertion, Refinement, and Extraction"", PhD Thesis, University of Wisconsin - Madison.[Web Link]  G. G. Towell and J. W. Shavlik, 1992; ""Interpretation of Artificial Neural Networks: Mapping Knowledge-based Neural Networks into Rules"", In Advances in Neural Information Processing Systems, volume 4, Morgan Kaufmann.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Jinyan Li and Limsoon Wong. Using Rules to Analyse Bio-medical Data: A Comparison between C4.5 and PCL. WAIM. 2003.  [View Context].S. Sathiya Keerthi and Kaibo Duan and Shirish Krishnaj Shevade and Aun Neow Poo. A Fast Dual Algorithm for Kernel Logistic Regression. ICML. 2002.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].Xiaojin Zhu. Label Propagation for Eukaryotic Splice Junction Identification. 2002.  [View Context].Mukund Deshpande and George Karypis. Evaluation of Techniques for Classifying Biological Sequences. PAKDD. 2002.  [View Context].Susanne Hoche and Stefan Wrobel. Scaling Boosting by Margin-Based Inclusionof Features and Relations. ECML. 2002.  [View Context].Jinyan Li and Kotagiri Ramamohanarao and Guozhu Dong. Combining the Strength of Pattern Frequency and Distance for Classification. PAKDD. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. DeEPs: A New Instance-based Discovery and Classification System. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao. Instance-Based Classification by Emerging Patterns. PKDD. 2000.  [View Context].Thomas G. Dietterich. An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization. Machine Learning, 40. 2000.  [View Context].Marina Meila and Michael I. Jordan. Learning with Mixtures of Trees. Journal of Machine Learning Research, 1. 2000.  [View Context].Yoav Freund and Lorne Mason. The Alternating Decision Tree Learning Algorithm. ICML. 1999.  [View Context].Lorne Mason and Jonathan Baxter and Peter L. Bartlett and Marcus Frean. Boosting Algorithms as Gradient Descent. NIPS. 1999.  [View Context].Kagan Tumer and Nikunj C. Oza. Decimated Input Ensembles for Improved Generalization. NASA Ames Research Center. 1999.  [View Context].Blaz Zupan and Marko Bohanec and Janez Dem#sar and Ivan Bratko. Learning by Discovering Concept Hierarchies. Artif. Intell, 109. 1999.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Andreas L. Prodromidis. On the Management of Distributed Learning Agents Ph.D. Thesis Proposal CUCS-032-97. Department of Computer Science Columbia University. 1998.  [View Context].Manoranjan Dash and Huan Liu. Hybrid Search of Feature Subsets. PRICAI. 1998.  [View Context].Adam J. Grove and Dale Schuurmans. Boosting in the Limit: Maximizing the Margin of Learned Ensembles. AAAI/IAAI. 1998.  [View Context].Foster J. Provost and Tom Fawcett and Ron Kohavi. The Case against Accuracy Estimation for Comparing Induction Algorithms. ICML. 1998.  [View Context].Kai Ming Ting and Boon Toh Low. Model Combination in the Multiple-Data-Batches Scenario. ECML. 1997.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Gustavo E. A and Gustavo E A P A Batista and Ronaldo C. Prati and Maria Carolina Monard. A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data. Instituto de Ci ^ encias Matem aticas e de Computac~ ao.  [View Context].Kai Ming Ting and Boon Toh Low. Theory Combination: an alternative to Data Combination. University of Waikato.  [View Context].Rudy Setiono. Extracting M-of-N Rules from Trained Neural Networks. School of Computing National University of Singapore.  [View Context].Rong-En Fan and P. -H Chen and C. -J Lin. Working Set Selection Using the Second Order Information for Training SVM. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context].Pedro Domingos. Using Partitioning to Speed Up Specific-to-General Rule Induction. Department of Information and Computer Science University of California, Irvine.  [View Context].Kai Ming Ting and Ian H. Witten. Stacked Generalization: when does it work. Department of Computer Science University of Waikato.  [View Context].Cesar Guerra-Salcedo and Stephen Chen and Darrell Whitley and Sarah Smith. Fast and Accurate Feature Selection Using Hybrid Genetic Strategies. Department of Computer Science Colorado State University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Amazon+Commerce+reviews+set,171,Amazon Commerce reviews set Data Set,../machine-learning-databases/00215/,"Multivariate, Text, Domain-Theory",1500,Physical,Real,10000,6/11/2011,Classification,N/A,198876,"Dataset creator and donator: ZhiLiu, e-mail: liuzhi8673 '@' gmail.com, institution: National Engineering Research Center for E-Learning, Hubei Wuhan, China","dataset are  derived  from  the customersâ€™ reviews  in Amazon Commerce Website for authorship identification. Most previous studies conducted  the identification experiments for two to ten authors. But in the online context, reviews to be identified usually have more potential authors, and normally classification algorithms are not adapted to large number of target classes. To examine the robustness of clasification algorithms, we identified 50 of the most active users (represented by a unique ID and username) who frequently posted reviews in these newsgroups. The number of reviews we collected for each author is 30.","attribution includes authors' lingustic style such as usage of digit, punctuation, words and sentences' length and usage frequency of words and so on","Sanya Liu, Zhi Liu, Jianwen Sun, Lin Liu, 'Application of Synergetic Neural Network in Online Writeprint Identification', JDCTA: International Journal of Digital Content Technology and its Applications, Vol. 5, No. 3, pp. 126 ~ 135, 2011 Jianwen Sun, Zongkai Yang, Pei Wang, Sanya Liu, 'Variable Length Character N-Gram Approach for Online Writeprint Identification,' mines, pp.486-490, 2010 International Conference on Multimedia Information Networking and Security, 2010","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/User+Identification+From+Walking+Activity,172,User Identification From Walking Activity Data Set,../machine-learning-databases/00286/,"Univariate, Sequential, Time-Series",N/A,N/A,Real,N/A,3/2/2014,"Classification, Clustering",N/A,73025,"Pierluigi Casale, Computer Vision Center, Barcelona, Spain. Email: plcasale '@' ieee.org","The dataset collects data from an Android smartphone positioned in the chest pocket. Accelerometer Data are collected from 22 participants walking in the wild over a predefined path. The dataset is intended for Activity Recognition research purposes. It provides challenges for identification and authentication of people using motion patterns.   --- Sampling frequency of the accelerometer: DELAY_FASTEST with network connections disabled   --- Number of Participants: 22   --- Data Format: CSV","   --- Data are separated by participant   --- Each file contains the following information       ---- time-step, x acceleration, y acceleration, z acceleration","  --- Casale, P. Pujol, O. and Radeva, P.        'Personalization and user verification in wearable systems using biometric walking patterns'       Personal and Ubiquitous Computing, 16(5), 563-580, 2012","  --- Casale, P. Pujol, O. and Radeva, P.        'Personalization and user verification in wearable systems using biometric walking patterns'       Personal and Ubiquitous Computing, 16(5), 563-580, 2012",
http://archive.ics.uci.edu/ml/datasets/Query+Analytics+Workloads+Dataset,173,Query Analytics Workloads Dataset Data Set,../machine-learning-databases/00493/,Multivariate,260000,Computer,Real,8,6/22/2019,"Regression, Clustering",N/A,13923,"Source: Dr Christos Anagnostopoulos; School of Computing Science, University of Glasgow; email: christos.anagnostopoulos '@' glasgow.ac.uk; G12 8QQ Scotland, UK. (Essence: Pervasive & Distributed Intelligence: http://www.dcs.gla.ac.uk/essence/)","The data-set contains three (3) sets of synthetic range and radius query workloads derived from Gaussian distributions over the real dataset in [URL-1]. Each processed query is associated with aggregate scalar values (count, sum, average) over the dataset in [URL-1]. [URL-1]: [Web Link]  Note: the current dataset is processed data derived after synthetic query analytics workloads over the real-dataset in [URL-1] and does not include any data from [URL-1]","[*] The dataset 'Radius Queries' contains records of the format: {'X-coordinate','Y-coordinate', 'R-Radius'}. These queries define a disc over a 2D space with center (X,Y) and radius R in order to investigate the number of crime incidents, the total arrests and the average beat of the disc region (spatial area) defined by each query.    [*] The dataset 'Radius Queries Count' contains records of the format: {'X-coordinate','Y-coordinate', 'R-Radius', 'Count'}. These queries define a disc over a 2D space with center (X,Y) and radius R and the number of crime incidents Count of the disc region (spatial area) defined by each query. [*] The dataset 'Range Queries Aggregates' contains records of the format: {'X-coordinate','Y-coordinate', 'X-range', 'Y-range', 'Count', 'SUM', 'AVG'}. These queries define a rectangle over a 2D space with coordinates/points: X +/- X-range and Y +/- Y-range. The count, sum, and avg is the number of incidents, total arrests and average beat of the rectangle region (spatial area) defined by each query. [*] All datasets are .csv Example of a Range Query with Count, SUM, and AVG:  [1159191.2534425869,1894755.9479944962,5225.375665408865,2981.728430851036,96046.0,34927.0,1111.618901359765] where: 'X-coordinate' = 1159191.2534425869, 'Y-coordinate' = 1894755.9479944962, 'X-range' = 5225.375665408865, 'Y-range' = 2981.728430851036, 'Count' = 96046.0, 'SUM' = 34927, 'AVG' = 1111.618901359765. Attribute Information: Attributes:'ID' = serial number of query (optional) 'X-coordinate' = spatial x-coordinate (float) 'Y-coordinate' = spatial y-coordinate (float) 'R-Radius' = spatial radius of a disc (X,Y) for radius query (float) 'X-range' = spatial x-range for range query (float) 'Y-range' = spatial y-range for range query (float) 'Count' = number of crime incidents in the 2D disc (radius queries) or rectangle (range queries)'SUM' = summation of Arrests in the 2D disc (radius queries) or rectangle (range queries)'AVG' = average Beat in the 2D disc (radius queries) or rectangle (range queries)","[1] Savva, F. , Anagnostopoulos, C. and Triantafillou, P. (2018) Explaining Aggregates for Exploratory Analytics. In: IEEE Big Data 2018, Seattle, WA, USA, 10-13 Dec 2018 [2] Anagnostopoulos, C. , Savva, F. and Triantafillou, P. (2018) Scalable aggregation predictive analytics: a query-driven machine learning approach. Applied Intelligence, 48(9), pp. 2546-2567.","[1] Savva, F. , Anagnostopoulos, C. and Triantafillou, P. (2018) Explaining Aggregates for Exploratory Analytics. In: IEEE Big Data 2018, Seattle, WA, USA, 10-13 Dec 2018 [2] Anagnostopoulos, C. , Savva, F. and Triantafillou, P. (2018) Scalable aggregation predictive analytics: a query-driven machine learning approach. Applied Intelligence, 48(9), pp. 2546-2567.",
http://archive.ics.uci.edu/ml/datasets/Abscisic+Acid+Signaling+Network,174,Abscisic Acid Signaling Network Data Set,../machine-learning-databases/abscisic-acid/,Multivariate,300,Life,Integer,43,4/3/2008,Causal-Discovery,N/A,56272,"Jerry W. Jenkins, Ph.D.Systems Biology and Bioinformations GroupCFD Research Corporation215 Wynn DriveHuntsville, AL 35805email: jwj '@' cfdrc.com  Abhishek Soni, Ph.D.Systems Biology and Bioinformations GroupCFD Research Corporation215 Wynn DriveHuntsville, AL 35805email: axs '@' cfdrc.com ","The objective is to determine the set of boolean rules that describe the interactions of the nodes within this plant signaling network. The dataset includes 300 separate boolean pseudodynamic simulations of the true rules, using an asynchronous update scheme. Each of the 300 simulations begin with a randomly generated initial condition, in order to ensure sampling of all of the steady states of the system.  There are a total of 43 nodes in this dataset, with 5 ndoes being constants. The results for 300 separate simulations are included in the dataset.  Each simulation consists of a matrix of 0's and 1's, with 21 rows and 43 columns.  The first row is the randomly generated initial condition for the particular simulation, with the next 20 rows being the output from the boolean pseudodynamics simulation.  Each of the 43 columns represent the transient response of a particular node.  The nodal names are identified at the top of the data file.  A line of asterisks is used to separate the simulations from one another.  An example set of data is included below: ***************************101110111010110110110100101000101100001100111000011101111011011011111110110010111010111100011110111110101101100011010001110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010 ","Each node can have a value of 0 or 1.  38 of the 43 nodes are allowed to vary, with 5 nodes held constant throughout the simulation. ","Li S, Assman SM, Albert R (2006) Predicting essential components of signal transduction networks: a dynamic model of guard cell abscisic acid signaling. Plos Biology 4: p. 1732-1748 Soni, A.S., Jenkins, J.W., and Sundaram, S.S.: ”Determination of critical network interactions: An augmented Boolean pseudo-dynamics approach”, IET Systems Biology, vol. 2, p. 55-63 (2008).","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Wilt,175,Wilt Data Set,../machine-learning-databases/00285/,Multivariate,4889,Life,N/A,6,3/13/2014,Classification,N/A,59614,"Brian Johnson;Institute for Global Environmental Strategies;2108-11 Kamiyamaguchi, Hayama, Kanagawa,240-0115 Japan;Email: Johnson '@' iges.or.jp ","This data set contains some training and testing data from a remote sensing study by Johnson et al. (2013) that involved detecting diseased trees in Quickbird imagery. There are few training samples for the 'diseased trees' class (74) and many for 'other land cover' class (4265).  The data set consists of image segments, generated by segmenting the pansharpened image. The segments contain spectral information from the Quickbird multispectral image bands and texture information from the panchromatic (Pan) image band. The testing data set is for the row with â€œSegmentation scale 15â€ segments and â€œoriginal multi-spectral imageâ€ Spectral information in Table 2 of the reference (i.e. row 5). Please see the reference below for more information on the data set, and please cite the reference if you use this data set. Enjoy! Filestraining.csv: training data set (4339 image segments)testing.csv: testing data set (500 image segments)","class: 'w' (diseased trees), 'n' (all other land cover)GLCM_Pan: GLCM mean texture (Pan band)Mean_G: Mean green valueMean_R: Mean red valueMean_NIR: Mean NIR valueSD_Pan: Standard deviation (Pan band)","Johnson, B., Tateishi, R., Hoan, N., 2013. A hybrid pansharpening approach and multiscale object-based image analysis for mapping diseased pine and oak trees. International Journal of Remote Sensing, 34 (20), 6969-6982.","Please cite: Johnson, B., Tateishi, R., Hoan, N., 2013. A hybrid pansharpening approach and multiscale object-based image analysis for mapping diseased pine and oak trees. International Journal of Remote Sensing, 34 (20), 6969-6982.",
http://archive.ics.uci.edu/ml/datasets/MoCap+Hand+Postures,176,MoCap Hand Postures Data Set,../machine-learning-databases/00391/,Multivariate,78095,Computer,"Integer, Real",38,11/22/2016,"Classification, Clustering",Yes,21558,"[1] A. Gardner, R. R. Selmic, J. Kanno    Louisiana Tech University abg010 '@' latech.edu, rselmic '@' latech.edu, jkanno '@' latech.edu [2] C. A. Duncan    Quinnipiac University christian.duncan '@' quinnipiac.edu","A Vicon motion capture camera system was used to record 12 users performing 5 hand postures with markers attached to a left-handed glove.  A rigid pattern of markers on the back of the glove was used to establish a local coordinate system for the hand, and 11 other markers were attached to the thumb and fingers of the glove. 3 markers were attached to the thumb with one above the thumbnail and the other two on the knuckles. 2 markers were attached to each finger with one above the fingernail and the other on the joint between the proximal and middle phalanx. The 11 markers not part of the rigid pattern were unlabeled; their positions were not explicitly tracked. Consequently, there is no a priori correspondence between the markers of two given records. In addition, due to the resolution of the capture volume and self-occlusion due to the orientation and configuration of the hand and fingers, many records have missing markers. Extraneous markers were also possible due to artifacts in the Vicon software's marker reconstruction/recording process and other objects in the capture volume. As a result, the number of visible markers in a record varied considerably. The data presented here is already partially preprocessed. First, all markers were transformed to the local coordinate system of the record containing them. Second, each transformed marker with a norm greater than 200 millimeters was pruned. Finally, any record that contained fewer than 3 markers was removed. The processed data has at most 12 markers per record and at least 3. For more information, see 'Attribute Information'. Due to the manner in which data was captured, it is likely that for a given record and user there exists a near duplicate record originating from the same user. We recommend therefore to evaluate classification algorithms on a leave-one-user-out basis wherein each user is iteratively left out from training and used as a test set. One then tests the generalization of the algorithm to new users. A 'User' attribute is provided to accomodate this strategy.  This dataset may be used for a variety of tasks, the most obvious of which is posture recognition via classification. One may also attempt user identification. Alternatively, one may perform clustering (constrained or unconstrained) to discover marker distributions either as an attempt to predict marker identities or obtain statistical descriptions/visualizations of the postures. In previous work, we randomly sampled without replacement a constant number (e.g. 75) of records per class per user in order to balance classes.","Data is provided as a CSV file. A header provides the name of each attribute. An initial dummy record composed entirely of 0s should be ignored. A question mark '?' is used to indicate a missing value. A record corresponds to a single instant or frame as recorded by the camera system. 'Class' - Integer. The class ID of the given record. Ranges from 1 to 5 with 1=Fist(with thumb out), 2=Stop(hand flat), 3=Point1(point with pointer finger), 4=Point2(point with pointer and middle fingers), 5=Grab(fingers curled as if to grab).'User' - Integer. The ID of the user that contributed the record. No meaning other than as an identifier.'Xi' - Real. The x-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Yi' - Real. The y-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Zi' - Real. The z-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11. Each record is a set. The i-th marker of a given record does not necessarily correspond to the i-th marker of a different record. One may randomly permute the visible (not missing) markers of a given record without changing the set that the record represents. For the sake of convenience, all visible markers of a given record are given a lower index than any missing marker. A class is not guaranteed to have even a single record with all markers visible.","[1] A. Gardner, J. Kanno, C. A. Duncan, and R. Selmic. 'Measuring distance between unordered sets of different sizes,' in 2014 IEEE Conference on Computer Vision and Pattern Recognition(CVPR), June 2014, pp. 137-143.[2] A. Gardner, C. A. Duncan, J. Kanno, and R. Selmic. '3D hand posture recognition from small unlabeled point sets,' in 2014 IEEE International Conference on Systems, Man and Cybernetics (SMC), Oct 2014, pp. 164-169.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29,177,Statlog (Vehicle Silhouettes) Data Set,../machine-learning-databases/statlog/vehicle/,Multivariate,946,N/A,Integer,18,N/A,Classification,N/A,127860,"SOURCE: 	Drs.Pete Mowforth and Barry Shepherd	Turing Institute	George House	36 North Hanover St.	Glasgow	G1 2AD CONTACT: 	Alistair Sutherland	Statistics Dept.	Strathclyde University	Livingstone Tower	26 Richmond St.	GLASGOW G1 1XH	Great Britain 	Tel: 041 552 4400 x3033 	Fax: 041 552 4711  	e-mail: alistair '@' uk.ac.strathclyde.stams ","The purpose is to classify a given silhouette as one of four types of vehicle, using  a set of features extracted from the silhouette. The vehicle may be viewed from one of many different angles.   HISTORY: This data was originally gathered at the TI in 1986-87 by JP Siebert. It was partially financed by Barr and Stroud Ltd. The original purpose was to find a method of distinguishing 3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects. Measures of shape features extracted from example silhouettes of objects to be discriminated were used to generate a classification rule tree by means of computer induction. This object recognition strategy was successfully used to discriminate between silhouettes of model cars, vans and buses viewed from constrained elevation but all angles of rotation. The rule tree classification performance compared favourably to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neighbour) statistical classifiers in terms of both error rate and computational efficiency. An investigation of these rule trees generated by example indicated that the tree structure was heavily influenced by the orientation of the objects, and grouped similar object views into single decisions.  DESCRIPTION: The features were extracted from the silhouettes by the HIPS (Hierarchical Image Processing System) extension BINATTS, which extracts a combination of scale independent features utilising both classical moments based measures such as scaled variance, skewness and kurtosis about the major/minor axes and heuristic measures such as hollows, circularity, rectangularity and compactness. Four ""Corgie"" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400. This particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars. The images were acquired by a camera looking downwards at the model vehicle from a fixed angle of elevation (34.2 degrees to the horizontal). The vehicles were placed on a diffuse backlit surface (lightbox). The vehicles were painted matte black to minimise highlights. The images were captured using a CRS4000 framestore connected to a vax 750. All images were captured with a spatial resolution of 128x128 pixels quantised to 64 greylevels. These images were thresholded to produce binary vehicle silhouettes, negated (to comply with the processing requirements of BINATTS) and thereafter subjected to shrink-expand-expand-shrink HIPS modules to remove ""salt and pepper"" image noise. The vehicles were rotated and their angle of orientation was measured using a radial graticule beneath the vehicle. 0 and 180 degrees corresponded to ""head on"" and ""rear"" views respectively while 90 and 270 corresponded to profiles in opposite directions. Two sets of 60 images, each set covering a full 360 degree rotation, were captured for each vehicle. The vehicle was rotated by a fixed angle between images. These datasets are known as e2 and e3 respectively.  A further two sets of images, e4 and e5, were captured with the camera at elevations of 37.5 degs and 30.8 degs respectively. These sets also contain 60 images per vehicle apart from e4.van which contains only 46 owing to the difficulty of containing the van in the image at some orientations.","ATTRIBUTES 	COMPACTNESS	(average perim)**2/area 	CIRCULARITY	(average radius)**2/area 	DISTANCE CIRCULARITY	area/(av.distance from border)**2 	RADIUS RATIO	(max.rad-min.rad)/av.radius 	PR.AXIS ASPECT RATIO	(minor axis)/(major axis) 	MAX.LENGTH ASPECT RATIO	(length perp. max length)/(max length) 	SCATTER RATIO	(inertia about minor axis)/(inertia about major axis) 	ELONGATEDNESS		area/(shrink width)**2 	PR.AXIS RECTANGULARITY	area/(pr.axis length*pr.axis width) 	MAX.LENGTH RECTANGULARITY area/(max.length*length perp. to this) 	SCALED VARIANCE 	(2nd order moment about minor axis)/area	ALONG MAJOR AXIS 	SCALED VARIANCE 	(2nd order moment about major axis)/area	ALONG MINOR AXIS  	SCALED RADIUS OF GYRATION	(mavar+mivar)/area 	SKEWNESS ABOUT 	(3rd order moment about major axis)/sigma_min**3	MAJOR AXIS 	SKEWNESS ABOUT 	(3rd order moment about minor axis)/sigma_maj**3	MINOR AXIS 	KURTOSIS ABOUT 	(4th order moment about major axis)/sigma_min**4	MINOR AXIS   	KURTOSIS ABOUT 	(4th order moment about minor axis)/sigma_maj**4	MAJOR AXIS 	HOLLOWS RATIO	(area of hollows)/(area of bounding polygon) 	 Where sigma_maj**2 is the variance along the major axis and sigma_min**2 is the variance along the minor axis, and 	area of hollows= area of bounding poly-area of object  	 The area of the bounding polygon is found as a side result of the computation to find the maximum length. Each individual length computation yields a pair of calipers to the object orientated at every 5 degrees. The object is propagated into an image containing the union of these calipers to obtain an image of the bounding polygon.  NUMBER OF CLASSES 	4	OPEL, SAAB, BUS, VAN","Turing Institute Research Memorandum TIRM-87-018 ""Vehicle Recognition Using Rule Based Methods"" by Siebert,JP (March 1987)[Web Link]","This dataset comes from the Turing Institute, Glasgow, Scotland. If you use this dataset in any publication you must acknowledge this source.","Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.  [View Context].Ping Zhong and Masao Fukushima. A Regularized Nonsmooth Newton Method for Multi-class Support Vector Machines. 2005.  [View Context].Remco R. Bouckaert and Eibe Frank. Evaluating the Replicability of Significance Tests for Comparing Learning Algorithms. PAKDD. 2004.  [View Context].Dmitry Pavlov and Alexandrin Popescul and David M. Pennock and Lyle H. Ungar. Mixtures of Conditional Maximum Entropy Models. ICML. 2003.  [View Context].Gisele L. Pappa and Alex Alves Freitas and Celso A A Kaestner. Attribute Selection with a Multi-objective Genetic Algorithm. SBIA. 2002.  [View Context].James Bailey and Thomas Manoukian and Kotagiri Ramamohanarao. Fast Algorithms for Mining Emerging Patterns. PKDD. 2002.  [View Context].Robi Polikar and L. Upda and S. S. Upda and Vasant Honavar. Learn++: an incremental learning algorithm for supervised neural networks. IEEE Transactions on Systems, Man, and Cybernetics, Part C, 31. 2001.  [View Context].Thomas G. Dietterich. An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization. Machine Learning, 40. 2000.  [View Context].Thierry Denoeux. A neural network classifier based on Dempster-Shafer theory. IEEE Transactions on Systems, Man, and Cybernetics, Part A, 30. 2000.  [View Context].Robert E. Schapire and Yoav Freund and Peter Bartlett and Wee Sun Lee. The Annals of Statistics, to appear. Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods. AT&T Labs. 1998.  [View Context].Richard Maclin. Boosting Classifiers Regionally. AAAI/IAAI. 1998.  [View Context].Ron Kohavi and Mehran Sahami. Error-Based and Entropy-Based Discretization of Continuous Features. KDD. 1996.  [View Context].Ron Kohavi. A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection. IJCAI. 1995.  [View Context].Gisele L. Pappa and Alex Alves Freitas and Celso A A Kaestner. AMultiobjective Genetic Algorithm for Attribute Selection. Computing Laboratory Pontificia Universidade Catolica do Parana University of Kent at Canterbury.  [View Context].Chih-Wei Hsu and Cheng-Ru Lin. A Comparison of Methods for Multi-class Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Yin Zhang and W. Nick Street. Bagging with Adaptive Costs. Management Sciences Department University of Iowa Iowa City.  [View Context].H. Altay Guvenir. A Classification Learning Algorithm Robust to Irrelevant Features. Bilkent University, Department of Computer Engineering and Information Science.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Ron Kohavi and George H. John. Automatic Parameter Selection by Minimizing Estimated Error. Computer Science Dept. Stanford University.  [View Context].Rajesh Parekh and Jihoon Yang and Vasant Honavar. Constructive Neural-Network Learning Algorithms for Pattern Classification.  [View Context].Vikas Sindhwani and P. Bhattacharya and Subrata Rakshit. Information Theoretic Feature Crediting in Multiclass Support Vector Machines.  [View Context].Maria Salamo and Elisabet Golobardes. Analysing Rough Sets weighting methods for Case-Based Reasoning Systems. Enginyeria i Arquitectura La Salle.  [View Context].Ronaldo C. Prati and Peter A. Flach. ROCCER: an Algorithm for Rule Learning Based on ROC Analysis. Institute of Mathematics and Computer Science University of S~ ao Paulo.  [View Context].Jeffrey P. Bradford and Clayton Kunz and Ron Kohavi and Clifford Brunk and Carla Brodley. Appears in ECML-98 as a research note Pruning Decision Trees with Misclassification Costs. School of Electrical Engineering.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Madelon,178,Madelon Data Set,../machine-learning-databases/madelon/,Multivariate,4400,N/A,Real,500,2/29/2008,Classification,N/A,135366,"Isabelle GuyonClopinet955 Creston RoadBerkeley, CA 90708isabelle '@' clopinet.com ","MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. MADELON -- Positive ex. -- Negative ex. -- Total		   Training set -- 1000 -- 1000 -- 2000		   Validation set -- 300 -- 300 -- 600		   Test set -- 900 -- 900 -- 1800		   All -- 2200 -- 2200 -- 4400		  Number of variables/features/attributes:Real: 20Probes: 480Total: 500 This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link]. All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge. The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link]. The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (in the order the features are found in the data).dataname_train.data: Training set (a space-delimited regular matrix, patterns in lines, features in columns).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).","We do not provide attribute information, to avoid biasing the feature selection process.","The best challenge entrants wrote papers collected in the book:Isabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer. [Web Link]  See also:Isabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 1438–1444.and the associated technical report:Isabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report. [Web Link].","Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge. In: NIPS. [Web Link].",
http://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice,179,Contraceptive Method Choice Data Set,../machine-learning-databases/cmc/,Multivariate,1473,Life,"Categorical, Integer",9,7/7/1997,Classification,No,194079,"Origin:   This dataset is a subset of the 1987 National Indonesia Contraceptive Prevalence Survey Creator:  Tjen-Sien Lim (limt '@' stat.wisc.edu) Donor:    Tjen-Sien Lim (limt '@' stat.wisc.edu)","This dataset is a subset of the 1987 National Indonesia Contraceptive Prevalence Survey. The samples are married women who were either not pregnant or do not know if they were at the time of interview. The problem is to predict the current contraceptive method choice (no use, long-term methods, or short-term methods) of a woman based on her demographic and socio-economic characteristics.","   1. Wife's age                     (numerical)   2. Wife's education               (categorical)      1=low, 2, 3, 4=high   3. Husband's education            (categorical)      1=low, 2, 3, 4=high   4. Number of children ever born   (numerical)   5. Wife's religion                (binary)           0=Non-Islam, 1=Islam   6. Wife's now working?            (binary)           0=Yes, 1=No   7. Husband's occupation           (categorical)      1, 2, 3, 4   8. Standard-of-living index       (categorical)      1=low, 2, 3, 4=high   9. Media exposure                 (binary)           0=Good, 1=Not good   10. Contraceptive method used     (class attribute)  1=No-use, 2=Long-term, 3=Short-term","Lim, T.-S., Loh, W.-Y. & Shih, Y.-S. (1999). A Comparison of Prediction Accuracy, Complexity, and Training Time of Thirty-three Old and New Classification Algorithms. Machine Learning.    ([Web Link] or [Web Link])[Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Earl Harris Jr. Information Gain Versus Gain Ratio: A Study of Split Method Biases. The MITRE Corporation/Washington C. 2001.  [View Context].Soumya Ray and David Page. Generalized Skewing for Functions with Continuous and Nominal Attributes. Department of Computer Sciences and Department of Biostatistics and Medical Informatics, University of Wis.  [View Context].Jos'e L. Balc'azar. Rules with Bounded Negations and the Coverage Inference Scheme. Dept. LSI, UPC.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Newspaper+and+magazine+images+segmentation+dataset,180,Newspaper and magazine images segmentation dataset Data Set,../machine-learning-databases/00306/,N/A,101,Computer,N/A,N/A,7/15/2014,Classification,N/A,27601,"Creators: Aleksey Vilkin and Ilia Safonov, NRNU MEPhI, Moscow, Russia, Date: 2012","This dataset was collected for training and validation of machine learning algorithm for classification regions of documents on text, picture and background areas. It contains 101 scanned images of various newspapers and magazines in Russian. Most of the images have resolution 300 dpi and size A4, about 2400x3500 pixels. For all images ground truth pixel-based masks were manually created. The ground truth masks named like original images with postfix _m. There are three classes: text area, picture area, background. Pixels on the mask with color 255, 0, 0 (rgb, red color) correspond to picture area, pixels with color 0, 0, 255 (rgb, blue color) correspond to text area, all other pixels correspond to background. Images with background of different colors are in the dataset. "," There are three classes: text area, picture area, background. Pixels on the mask with color 255, 0, 0 (rgb, red color) correspond to picture area, pixels with color 0, 0, 255 (rgb, blue color) correspond to text area, all other pixels correspond to background.","A. M. Vilkin, I. V. Safonov, M. A. Egorova. Algorithm for segmentation of documents based on texture features // Pattern Recognition and Image Analysis March 2013, Volume 23, Issue 1, pp 153-159 ","A. M. Vilkin, I. V. Safonov, M. A. Egorova. Algorithm for segmentation of documents based on texture features // Pattern Recognition and Image Analysis March 2013, Volume 23, Issue 1, pp 153-159 ",
http://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease,181,Chronic_Kidney_Disease Data Set,../machine-learning-databases/00336/,Multivariate,400,N/A,Real,25,7/3/2015,Classification,Yes,170935," Source: 			 Dr.P.Soundarapandian.M.D.,D.M			(Senior Consultant Nephrologist), 			Apollo  Hospitals, 			Managiri,			Madurai Main Road, 			Karaikudi,			Tamilnadu,			India.  Creator: 			L.Jerlin Rubini(Research Scholar)			Alagappa University,			EmailId   :jel.jerlin '@' gmail.com 			ContactNo :+91-9597231281  Guided by: 			Dr.P.Eswaran Assistant Professor,			Department of Computer Science and Engineering,			Alagappa University,			Karaikudi,			Tamilnadu,			India.			Emailid:eswaranperumal '@' gmail.com","We use the following representation to collect the dataset                        age		-	age				bp		-	blood pressure			sg		-	specific gravity			al		-   	albumin			su		-	sugar			rbc		-	red blood cells			pc		-	pus cell			pcc		-	pus cell clumps			ba		-	bacteria			bgr		-	blood glucose random			bu		-	blood urea			sc		-	serum creatinine			sod		-	sodium			pot		-	potassium			hemo		-	hemoglobin			pcv		-	packed cell volume			wc		-	white blood cell count			rc		-	red blood cell count			htn		-	hypertension			dm		-	diabetes mellitus			cad		-	coronary artery disease			appet		-	appetite			pe		-	pedal edema			ane		-	anemia			class		-	class	","We use 24 + class = 25 ( 11  numeric ,14  nominal)1.Age(numerical)  	  	age in years 	2.Blood Pressure(numerical)	       	bp in mm/Hg 	3.Specific Gravity(nominal)	  	sg - (1.005,1.010,1.015,1.020,1.025) 	4.Albumin(nominal)		al - (0,1,2,3,4,5) 	5.Sugar(nominal)		su - (0,1,2,3,4,5) 	6.Red Blood Cells(nominal)		rbc - (normal,abnormal) 	7.Pus Cell (nominal)		pc - (normal,abnormal) 	8.Pus Cell clumps(nominal)		pcc - (present,notpresent) 	9.Bacteria(nominal)		ba  - (present,notpresent) 	10.Blood Glucose Random(numerical)				bgr in mgs/dl 	11.Blood Urea(numerical)			bu in mgs/dl 	12.Serum Creatinine(numerical)			sc in mgs/dl 	13.Sodium(numerical)		sod in mEq/L 	14.Potassium(numerical)			pot in mEq/L 	15.Hemoglobin(numerical)		hemo in gms 	16.Packed  Cell Volume(numerical) 	17.White Blood Cell Count(numerical)		wc in cells/cumm 	18.Red Blood Cell Count(numerical)			rc in millions/cmm 	19.Hypertension(nominal)			htn - (yes,no) 	20.Diabetes Mellitus(nominal)			dm - (yes,no) 	21.Coronary Artery Disease(nominal)		cad - (yes,no) 	22.Appetite(nominal)			appet - (good,poor) 	23.Pedal Edema(nominal)		pe - (yes,no)	 	24.Anemia(nominal)		ane - (yes,no) 	25.Class (nominal)				class - (ckd,notckd)",N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Bach+Choral+Harmony,182,Bach Choral Harmony Data Set,../machine-learning-databases/00298/,Sequential,5665,N/A,N/A,17,5/20/2014,Classification,N/A,49594,"-- Creators: Daniele P. Radicioni and Roberto Esposito-- Donor: Daniele P. Radicioni (radicion '@' di.unito.it) and Roberto Esposito (esposito '@' di.unito.it)-- Date: May, 2014","Pitch classes information has been extracted from MIDI sources downloadedfrom (JSB Chorales)[[Web Link]]. Meter information hasbeen computed through the Meter program which is part of the Melismamusic analyser (Melisma)[[Web Link]].Chord labels have been manually annotated by a human expert.","1. Choral ID: corresponding to the file names from (Bach Central)[[Web Link]].2. Event number: index (starting from 1) of the event inside the chorale.3-14. Pitch classes: YES/NO depending on whether a given pitch is present.   Pitch classes/attribute correspondence is as follows:     C       -> 3     C#/Db   -> 4     D       -> 5     ...     B       -> 1415. Bass: Pitch class of the bass note16. Meter: integers from 1 to 5. Lower numbers denote less accented events,   higher numbers denote more accented events.17. Chord label: Chord resonating during the given event.","1. D. P. Radicioni and R. Esposito. Advances in Music Information Retrieval,   chapter BREVE: an HMPerceptron-Based Chord Recognition System. Studies   in Computational Intelligence, Zbigniew W. Ras and Alicja Wieczorkowska   (Editors), Springer, 2010.2. Esposito, R. and Radicioni, D. P., CarpeDiem: Optimizing the Viterbi    Algorithm and Applications to Supervised Sequential Learning, Journal    of Machine Learning Research, 10(Aug):1851-1880, 2009.","D. P. Radicioni and R. Esposito. Advances in Music Information Retrieval, chapter BREVE: an HMPerceptron-Based Chord Recognition System. Studies in Computational Intelligence, Zbigniew W. Ras and Alicja Wieczorkowska (Editors), Springer, 2010.",
http://archive.ics.uci.edu/ml/datasets/Ultrasonic+flowmeter+diagnostics,183,Ultrasonic flowmeter diagnostics Data Set,../machine-learning-databases/00433/,Multivariate,540,Computer,Real,173,1/13/2018,Classification,N/A,16637,"Kojo Sarfo GyamfiCoventry University, UKgyamfik '@' uni.coventry.ac.uk  Craig MarshallNational Engineering Laboratory, TUV-NEL, UKCraig.Marsall '@' tuv-sud.co.uk","Meter A contains 87 instances of diagnostic parameters for an 8-path liquid ultrasonic flow meter (USM). It has 37 attributes and 2 classes or health states:Class '1' - HealthyClass '2' - Installation effects Meter B contains 92 instances of diagnostic parameters for a 4-path liquid USM. It has 52 attributes and 3 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - Waxing Meter C contains 181 instances of diagnostic parameters for a 4-path liquid USM. It has 44 attributes and 4 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - Installation effectsClass '4' - Waxing Meter D contains 180 instances of diagnostic parameters for a 4-path liquid USM. It has 44 attributes and 4 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - Installation effectsClass '4' - Waxing","All attributes are continuous, with the exception of the class attribute. Meter A(1)        -- Flatness ratio(2)        -- Symmetry(3)        -- Crossflow(4)-(11)   -- Flow velocity in each of the eight paths(12)-(19)  -- Speed of sound in each of the eight paths(20)       -- Average speed of sound in all eight paths(21)-(36)  -- Gain at both ends of each of the eight paths (37)       -- Class attribute or health state of meter: 1,2 Meter B(1)       -- Profile factor(2)       -- Symmetry(3)       -- Crossflow(4)       -- Swirl angle(5)-(8)   -- Flow velocity in each of the four paths(9)       -- Average flow velocity in all four paths(10)-(13)  -- Speed of sound in each of the four paths(14)       -- Average speed of sound in all four paths(15)-(22)  -- Signal strength at both ends of each of the four paths (23)-(26)  -- Turbulence in each of the four paths(27)      -- Meter performance(28)-(35) -- Signal quality at both ends of each of the four paths(36)-(43) -- Gain at both ends of each of the four paths(44)-51   -- Transit time at both ends of each of the four paths(52)      -- Class attribute or health state of meter: 1,2,3 Meters C and D(1)       -- Profile factor(2)       -- Symmetry(3)       -- Crossflow(4)-(7)   -- Flow velocity in each of the four paths(8)-(11)  -- Speed of sound in each of the four paths(12)-(19) -- Signal strength at both ends of each of the four paths (20)-(27) -- Signal quality at both ends of each of the four paths(28)-(35) -- Gain at both ends of each of the four paths(36)-(43) -- Transit time at both ends of each of the four paths(44)      -- Class attribute or health state of meter: 1,2,3,4    ","K. S. Gyamfi, J. Brusey, A. Hunt, E. Gaura , â€œLinear dimensionality reduction for classification via a sequential Bayes error minimisation with an application to flow meter diagnostics,â€ Expert Systems with Applications (IF: 3.928), September 2017","K. S. Gyamfi, J. Brusey, A. Hunt, E. Gaura , â€œLinear dimensionality reduction for classification via a sequential Bayes error minimisation with an application to flow meter diagnostics,â€ Expert Systems with Applications (IF: 3.928), September 2017",
http://archive.ics.uci.edu/ml/datasets/KDC-4007+dataset+Collection,184,KDC-4007 dataset Collection Data Set,../machine-learning-databases/00376/,"Multivariate, Text",4007,Computer,Integer,N/A,4/27/2017,"Classification, Regression",N/A,31104,"Arazo M. Mustafa, (arazo.2007 '@' yahoo.com), School of Computer Science University of Sulaimania, Kurdistan, Iraq","The most important feature of this dataset is its simplicity to use and its being well-documented, which can be widely used in various studies of text analysis regarding Kurdish Sorani news and articles.   The documents consist of eight categories, which are Sport, Religion, Art, Economic, Education, Social, Style, and Health. Each of them consisted of 500 text documents, where the total size of the corpus is 4,007 text files. The dataset and documents have become freely accessible in order to have repeatable outcomes for experimental assessment.","There is four collection: - ST-Ds datasets, just stop words elimination is performed by using Kurdish preprocessing-step approach. - The pre-ds dataset, Kurdish preprocessing-step approach is used. - The Pre+TW-Ds dataset, TFÃ—IDF term weighting on the Pre-Ds dataset is performed. - Orig-Ds datasets, no process is used which is the original dataset.","[1] Arazo M. Mustafa and Tarik A. Rashid,â€œ Kurdish Stemmer Pre-processing Steps for Improving Information Retrievalâ€, Journal of Information Science, First published date: january-01-2017, 10.1177/0165551516683617.[2] Tarik A. Rashid, Arazo M. Mustafa and Ari M. Saeed, 2017.'A Robust Categorization System for Kurdish Sorani Text Documents'. Information Technology Journal, 16: 27-34.[3] Tarik A. Rashid, Arazu M. Mustafa, Ari M. Saeed Automatic Kurdish Text Classification Using KDC 4007 Dataset, accepted in Springer book, Series Title: Lecture Notes on Data Engineering and Communications Technologies: Book title: Advances in Internetworking, Data & Web Technologies, Indexing: The books of this series are submitted to ISI Proceedings, EI, Scopus, MetaPress, Springerlink, 2017.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Synthetic+Control+Chart+Time+Series,185,Synthetic Control Chart Time Series Data Set,../machine-learning-databases/synthetic_control-mld/,Time-Series,600,N/A,Real,N/A,6/8/1999,"Classification, Clustering",No,80071,"Dr Robert Alcock rob '@' skyblue.csd.auth.gr ","This dataset contains 600 examples of control charts synthetically generated by the process in Alcock and Manolopoulos (1999). There are six different classes of control charts:    1. Normal   2. Cyclic   3. Increasing trend   4. Decreasing trend   5. Upward shift   6. Downward shift The following image shows ten examples from each class: data.jpeg, where (A) Downward Trend. (B) Cyclic. (C) Normal. (D) Upward Shift. (E) Upward Trend. (F) Downward Shift.","The data is stored in an ASCII file, 600 rows, 60 columns, with a single chart per line. The classes are organized as follows: 1-100   Normal101-200 Cyclic201-300 Increasing trend301-400 Decreasing trend401-500 Upward shift501-600 Downward shift","Alcock R.J. and Manolopoulos Y. Time-Series Similarity Queries Employing a Feature-Based Approach. 7th Hellenic Conference on Informatics. August 27-29. Ioannina,Greece 1999.[Web Link]  D.T. Pham and A.B. Chan ""Control Chart Pattern Recognition using a New Type of Self Organizing Neural Network"" Proc. Instn, Mech, Engrs. Vol 212, No 1, pp 115-127 1998.",Image courtesy of Eamonn Keogh.,
http://archive.ics.uci.edu/ml/datasets/First-order+theorem+proving,186,First-order theorem proving Data Set,../machine-learning-databases/00249/,Multivariate,6118,Computer,Real,51,4/17/2013,Classification,N/A,42987,"James P Bridge, Sean B Holden and Lawrence C Paulson University of CambridgeComputer LaboratoryWilliam Gates Building15 JJ Thomson AvenueCambridge CB3 0FDUK  +44 (0)1223 763500 forename.surname '@' cl.cam.ac.uk",See the file bridge-holden-paulson-details.txt in the submitted tarball.,The attributes are a mixture of static and dynamic features derived from theorems to be proved. See the paper for full details.,"Machine learning for first-order theorem proving: learning to select a good heuristic James P Bridge, Sean B Holden and Lawrence C Paulson Submitted for publication in the Journal of Automated Reasoning, Springer 2012/13.",Please cite the paper if you use this data set.,
http://archive.ics.uci.edu/ml/datasets/Online+Retail,187,Online Retail Data Set,../machine-learning-databases/00352/,"Multivariate, Sequential, Time-Series",541909,Business,"Integer, Real",8,11/6/2015,"Classification, Clustering",N/A,489566,"Dr Daqing Chen, Director: Public Analytics group. chend '@' lsbu.ac.uk, School of Engineering, London South Bank University, London SE1 0AA, UK. ",This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.,"InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.Description: Product (item) name. Nominal.Quantity: The quantities of each product (item) per transaction. Numeric.	InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.UnitPrice: Unit price. Numeric, Product price per unit in sterling.CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.Country: Country name. Nominal, the name of the country where each customer resides. ","The evolution of direct, data and digital marketing, Richard Webber, Journal of Direct, Data and Digital Marketing Practice (2013) 14, 291â€“309.Clustering Experiments on Big Transaction Data for Market Segmentation, Ashishkumar Singh, Grace Rumantir, Annie South, Blair Bethwaite, Proceedings of the 2014 International Conference on Big Data Science and Computing.A decision-making framework for precision marketing, Zhen You, Yain-Whar Si, Defu Zhang, XiangXiang Zeng, Stephen C.H. Leung c, Tao Li, Expert Systems with Applications, 42 (2015) 3357â€“3367.","Daqing Chen, Sai Liang Sain, and Kun Guo, Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining, Journal of Database Marketing and Customer Strategy Management, Vol. 19, No. 3, pp. 197â€“208, 2012 (Published online before print: 27 August 2012. doi: 10.1057/dbm.2012.17).",
http://archive.ics.uci.edu/ml/datasets/Semeion+Handwritten+Digit,188,Semeion Handwritten Digit Data Set,../machine-learning-databases/semeion/,Multivariate,1593,Computer,Integer,256,11/11/2008,Classification,N/A,127767,"The dataset was created by Tactile Srl, Brescia, Italy (http://www.tattile.it) and donated in 1994 to Semeion Research Center of Sciences of Communication, Rome, Italy (http://www.semeion.it), for machine learning research. For any questions, e-mail Massimo Buscema (m.buscema '@' semeion.it) or Stefano Terzi (s.terzi '@' semeion.it)","1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.Then each pixel of each image was scaled into a bolean (1/0) value using a fixed threshold. Each person wrote on a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy).  The best validation protocol for this dataset seems to be a 5x2CV, 50% Tune (Train +Test) and completly blind 50% Validation","This dataset consists of 1593 records (rows) and 256 attributes (columns). Each record represents a handwritten digit, orginally scanned with a resolution of 256 grays scale (28). Each pixel of the each original scanned image was first stretched,  and after scaled between 0 and 1 (setting to 0 every pixel whose value was under tha value 127 of the grey scale (127 included) and setting to 1 each pixel whose orinal value in the grey scale was over 127). Finally, each binary image was scaled again into a 16x16 square box (the final 256 binary attributes). ","M Buscema, MetaNet: The Theory of Independent Judges, in Substance Use & Misuse 33(2)1998, pp 439-461.","Semeion Research Center of Sciences of Communication, via Sersale 117, 00128 Rome, ItalyTattile Via Gaetano Donizetti, 1-3-5,25030 Mairano (Brescia), Italy.",
http://archive.ics.uci.edu/ml/datasets/HTRU2,189,HTRU2 Data Set,../machine-learning-databases/00372/,Multivariate,17898,Physical,Real,9,2/14/2017,"Classification, Clustering",N/A,61898,"Dr Robert Lyon, University of Manchester, School of Physics and Astronomy, Alan Turing Building, Manchester M13 9PL, United Kingdom, robert.lyon '@' manchester.ac.uk","HTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey (South) [1].  Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter (see [2] for more uses).  As pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsarsrotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes. Each pulsar produces a slightly different emission pattern, which varies slightly with each rotation (see [2] for an introduction to pulsar astrophysics to find out why). Thus a  potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find. Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted,(see [4,5,6,7,8,9]) which treat the candidate data sets  as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class. At present multi-class labels are unavailable, given the costs associated with data annotation. The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators.  The data is presented in two formats: CSV and ARFF (used by the WEKA data mining tool). Candidates are stored in both files in separate rows. Each row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive). Please note that the data contains no positional information or other astronomical details. It is simply feature data extracted from candidate files using the PulsarFeatureLab tool (see [10]).","Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency (see [3] for more details). The remaining four variables are similarly obtained from the DM-SNR curve (again see [3] for more details). These are summarised below: 1. Mean of the integrated profile.2. Standard deviation of the integrated profile.3. Excess kurtosis of the integrated profile.4. Skewness of the integrated profile.5. Mean of the DM-SNR curve.6. Standard deviation of the DM-SNR curve.7. Excess kurtosis of the DM-SNR curve.8. Skewness of the DM-SNR curve.9. Class HTRU 2 Summary17,898 total examples.1,639 positive examples.16,259 negative examples.","[1] M. J. Keith et al., 'The High Time Resolution Universe Pulsar Survey - I. System Configuration and Initial Discoveries',2010, Monthly Notices of the Royal Astronomical Society, vol. 409,  pp. 619-627. DOI: 10.1111/j.1365-2966.2010.17325.x [2] D. R. Lorimer and M. Kramer, 'Handbook of Pulsar Astronomy', Cambridge University Press, 2005. [3] R. J. Lyon, 'Why Are Pulsars Hard To Find?', PhD Thesis, University of Manchester, 2016. [4] R. J. Lyon et al., 'Fifty Years of Pulsar Candidate Selection: From simple filters to a new principled real-time classification approach', Monthly Notices of the Royal Astronomical Society 459 (1), 1104-1123, DOI: 10.1093/mnras/stw656 [5] R. P. Eatough et al., 'Selection of radio pulsar candidates using artificial neural networks', Monthly Notices of the Royal Astronomical Society, vol. 407, no. 4, pp. 2443-2450, 2010. [6] S. D. Bates et al., 'The high time resolution universe pulsar survey vi. an artificial neural network and timing of 75 pulsars', Monthly Notices of the Royal Astronomical Society, vol. 427, no. 2, pp. 1052-1065, 2012. [7] D. Thornton, 'The High Time Resolution Radio Sky', PhD thesis, University of Manchester, Jodrell Bank Centre for Astrophysics School of Physics and Astronomy, 2013. [8] K. J. Lee et al., 'PEACE: pulsar evaluation algorithm for candidate extraction a software package for post-analysis processing of pulsar survey candidates', Monthly Notices of the Royal Astronomical Society, vol. 433, no. 1, pp. 688-694, 2013. [9] V. Morello et al., 'SPINN: a straightforward machine learning solution to the pulsar candidate selection problem', Monthly Notices of the Royal Astronomical Society, vol. 443, no. 2, pp. 1651-1662, 2014. [10] R. J. Lyon, 'PulsarFeatureLab', 2015, [Web Link].","If you use the dataset in your work, please cite us using the following paper:  R. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar Candidate Selection: From simple filters to a new principled real-time classification approach, Monthly Notices of the Royal Astronomical Society 459 (1), 1104-1123, DOI: 10.1093/mnras/stw656 If possible, please also cite the DOI of the data set directly: R. J. Lyon, HTRU2, DOI: 10.6084/m9.figshare.3080389.v1. Acknowledgements This data was obtained with the support of grant EP/I028099/1 for the University of Manchester  Centre for Doctoral Training in Computer Science, from the UK Engineering and Physical Sciences Research Council (EPSRC). The raw observational data was collected by the High Time Resolution Universe Collaboration using the Parkes Observatory, funded by the Commonwealth of Australia and managed by the CSIRO.",
http://archive.ics.uci.edu/ml/datasets/Superconductivty+Data,190,Superconductivty Data Data Set,../machine-learning-databases/00464/,Multivariate,21263,Physical,Real,81,10/12/2018,Regression,N/A,42447,"Kam Ham idieh, khamidieh '@' gmail.com, University of Pennsylvania, Statistics","There are two files: (1) train.csv contains 81 features extracted from 21263 superconductors along with the critical temperature in the 82nd column, (2) unique_m.csv contains the chemical formula broken up for all the 21263 superconductors from the train.csv file.  The last two columns have the critical temperature and chemical formula.  The original data comes from [Web Link] which is public.  The goal here is to predict the critical temperature based on the features extracted.",Please see the relevant paper for the feature explanations.,"Hamidieh, Kam, A data-driven statistical model for predicting the critical temperature of a superconductor, Computational Materials Science, Volume 154, November 2018, Pages 346-354, [Web Link]","Hamidieh, Kam, A data-driven statistical model for predicting the critical temperature of a superconductor, Computational Materials Science, Volume 154, November 2018, Pages 346-354, [Web Link]",
http://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification,191,MiniBooNE particle identification Data Set,../machine-learning-databases/00199/,Multivariate,130065,Physical,Real,50,12/13/2010,Classification,N/A,52085,"Byron Roe (byronroe '@' umich.edu)Department of Physics University of MichiganAnn Arbor, MI  48109","The submitted file is set up as follows. In the first line is the the number of signal events followed by the number of background events. The signal events come first, followed by the background events. Each line, after the first line has the 50 particle ID variables for one event.",50 particle ID variables (real) for each event.,"B. Roe et al., 'Boosted Decision Trees, an Alternative to Artificial Neural Networks' <[Web Link]>,arXiv:physics/0408124, Nucl. Instrum. Meth. A543, 577 (2005).","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/banknote+authentication,192,banknote authentication Data Set,../machine-learning-databases/00267/,Multivariate,1372,Computer,Real,5,4/16/2013,Classification,N/A,252153,"Owner of database: Volker Lohweg (University of Applied Sciences, Ostwestfalen-Lippe, volker.lohweg '@' hs-owl.de)Donor of database: Helene DÃ¶rksen (University of Applied Sciences, Ostwestfalen-Lippe, helene.doerksen '@' hs-owl.de)Date received: August, 2012","Data were extracted from images that were taken from genuine and forged banknote-like specimens.  For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.  ","       1. variance of Wavelet Transformed image (continuous)        2. skewness of Wavelet Transformed image (continuous)       3. curtosis of Wavelet Transformed image (continuous)       4. entropy of image (continuous)       5. class (integer) ",paper submitted (info will be uploaded asap),"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Zoo,193,Zoo Data Set,../machine-learning-databases/zoo/,Multivariate,101,Life,"Categorical, Integer",17,5/15/1990,Classification,No,320027,"Creator: Richard Forsyth Donor:  Richard S. Forsyth 8 Grosvenor AvenueMapperley ParkNottingham NG3 5DX0602-621676","A simple database containing 17 Boolean-valued attributes.  The ""type"" attribute appears to be the class attribute.  Here is a breakdown of which animals are in which type: (I find it unusual that there are 2 instances of ""frog"" and one of ""girl""!) Class# -- Set of animals:====== ====================================================1 -- (41) aardvark, antelope, bear, boar, buffalo, calf, cavy, cheetah, deer, dolphin, elephant, fruitbat, giraffe, girl, goat, gorilla, hamster, hare, leopard, lion, lynx, mink, mole, mongoose, opossum, oryx, platypus, polecat, pony, porpoise, puma, pussycat, raccoon, reindeer, seal, sealion, squirrel, vampire, vole, wallaby,wolf2 -- (20) chicken, crow, dove, duck, flamingo, gull, hawk, kiwi, lark, ostrich, parakeet, penguin, pheasant, rhea, skimmer, skua, sparrow, swan, vulture, wren3 -- (5)  pitviper, seasnake, slowworm, tortoise, tuatara 4 -- (13) bass, carp, catfish, chub, dogfish, haddock, herring, pike, piranha, seahorse, sole, stingray, tuna5 -- (4)  frog, frog, newt, toad 6 -- (8)  flea, gnat, honeybee, housefly, ladybird, moth, termite, wasp7 -- (10) clam, crab, crayfish, lobster, octopus, scorpion, seawasp, slug, starfish, worm","   1. animal name:      Unique for each instance   2. hair:		Boolean   3. feathers:		Boolean   4. eggs:		Boolean   5. milk:		Boolean   6. airborne:		Boolean   7. aquatic:		Boolean   8. predator:		Boolean   9. toothed:		Boolean  10. backbone:		Boolean  11. breathes:		Boolean  12. venomous:		Boolean  13. fins:		Boolean  14. legs:		Numeric (set of values: {0,2,4,5,6,8})  15. tail:		Boolean  16. domestic:		Boolean  17. catsize:		Boolean  18. type:		Numeric (integer values in range [1,7])",Forsyth's PC/BEAGLE User's Guide.,"Please refer to the Machine Learning
Repository's citation policy","Mikko Koivisto and Kismat Sood. Exact Bayesian Structure Discovery in Bayesian Networks. Journal of Machine Learning Research, 5. 2004.  [View Context].Eibe Frank and Stefan Kramer. Ensembles of nested dichotomies for multi-class problems. ICML. 2004.  [View Context].Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].Eibe Frank and Mark Hall and Bernhard Pfahringer. Locally Weighted Naive Bayes. UAI. 2003.  [View Context].Michael Bain. Structured Features from Concept Lattices for Unsupervised Learning and Classification. Australian Joint Conference on Artificial Intelligence. 2002.  [View Context].Mukund Deshpande and George Karypis. Using conjunction of attribute values for classification. CIKM. 2002.  [View Context].Huan Liu and Hiroshi Motoda and Lei Yu. Feature Selection with Selective Sampling. ICML. 2002.  [View Context].Neil Davey and Rod Adams and Mary J. George. The Architecture and Performance of a Stochastic Competitive Evolutionary Neural Tree Network. Appl. Intell, 12. 2000.  [View Context].Manoranjan Dash and Huan Liu. Hybrid Search of Feature Subsets. PRICAI. 1998.  [View Context].Guszti Bartfai. VICTORIA UNIVERSITY OF WELLINGTON Te Whare Wananga o te Upoko o te Ika a Maui. Department of Computer Science PO Box 600. 1996.  [View Context].D. Randall Wilson and Tony R. Martinez. Heterogeneous Radial Basis Function Networks. Proceedings of the International Conference on Neural Networks (ICNN. 1996.  [View Context].Christophe Giraud and Tony Martinez and Christophe G. Giraud-Carrier. University of Bristol Department of Computer Science ILA: Combining Inductive Learning with Prior Knowledge and Reasoning. 1995.  [View Context].Christophe G. Giraud-Carrier and Tony Martinez. AN INCREMENTAL LEARNING MODEL FOR COMMONSENSE REASONING. Department of Computer Science Brigham Young University.  [View Context].Jun Wang. Classification Visualization with Shaded Similarity Matrix. Bei Yu Les Gasser Graduate School of Library and Information Science University of Illinois at Urbana-Champaign.  [View Context].Mehmet Dalkilic and Arijit Sengupta. A Logic-theoretic classifier called Circle. School of Informatics Center for Genomics and BioInformatics Indiana University.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Gas+sensor+arrays+in+open+sampling+settings,194,Gas sensor arrays in open sampling settings Data Set,../machine-learning-databases/00251/,"Multivariate, Time-Series",18000,Computer,Real,1950000,6/5/2013,Classification,N/A,46026,"Creators:Alexander Vergara (vergara '@' ucsd.edu)BioCircutis InstituteUniversity of California San DiegoSan Diego, California, USA Donors of the Dataset:Alexander Vergara (vergara '@' ucsd.edu)Jordi Fonollosa (fonollosa '@' ucsd.edu)Marco Trincavelli (marco.trincavelli '@' oru.se)Nikolai F. Rulkov (nrulkov '@' ucsd.edu)Ramon Huerta (rhuerta '@' ucsd.edu)","Number of instances:18000 times-series measurements recorded from a 72 metal-oxide gas sensor array-based chemical detection platform. Number of attributes (features):Every measurement contains 72 time-series recorded during 260 seconds, each collected at a sample rate of 100 Hz (samples per second).The dataset also contains time, temperature, and relative humidity information.The resulting dataset ultimately includes 75-time series composed of 26000 points.  This archive contains 18000 time-series measurement recordings collected from an array of 72 metal-oxide gas sensors composing our sensing platform utilized in the detection and identification of potentially-dangerous chemical gaseous substances under complex environmental conditions, as reported in the related manuscript below. Our primary purpose is to make our dataset freely accessible on-line to the chemo-sensing research and machine-learning communities, as well as other interested communities, to develop alternative competitive solutions relevant to gas-sensing discrimination tasks in open sampling settings, such as the one pursued here, and/or navigation. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.The dataset was gathered from December 2010 to April 2012 (16 months) in a 2.5 m Ã— 1.2 m Ã— 0.4 m wind tunnel research test-bed facility situated at the BioCircuits Institute, University of California San Diego. Specifically, our customized research facility, endowed with a computer-supervised mass flow controller-based continuous flow gas delivery system, operates in a propulsion open-cycle mode, by continuously drawing external turbulent air into and throughout the tunnel and exhausting it back to the outside, thereby creating a relatively less-turbulent airflow moving downstream towards the end of the test field, which is particularly suitable for applications pursued here that require injecting chemical poisonous agents or explosive mixtures because it prevents saturation. Being operated by a fully computerized environment â€”controlled by a player/stage robot server software programmed on C++ on a PC fitted with the appropriate serial cardsâ€” and with minimum human intervention, the designed wind tunnel test-bed facility provides versatility for releasing the chemical substances of interest at the desired concentrations with high accuracy and in a highly reproducible manner during the entire experiment and simultaneously in preserving the appropriate environmental conditions to generate chemical gas plumes exhibiting turbulent patterns. A graphical illustration of the designed wind tunnel test-bed facility considered in this study along with the characteristics of the geometry of the problem as well as the exact locations of the chemical analyte source and chemo-sensory platform is presented in Figure 2 of the manuscript cited below. Actual pictures of the designed wind tunnel are also presented in the Supplementary Material, Figure S.1 of the accompanying manuscript.The resulting dataset induces a ten-class gas discrimination problem, comprising recordings from ten distinct pure chemical gases, namely Acetone, Acetaldehyde, Ammonia, Butanol, Ethylene, Methane, Methanol, Carbon Monoxide, Benzene, and Toluene. The goal is to identify and discriminate the mentioned chemical hazards at relevant concentrations regardless of the location of the sensory system platform within the annotated wind tunnel research facility as well as the environmental and parametric conditions induced in the setting (Please see manuscript for more details). See Table 1 on Vergara et a. 2013 (manuscript below) for specifics on the identity of chemical analyte hazards as well as their nominal concentration values at the outlet of the gas source in parts-per-million by volume (ppmv). Please refer to the manuscript below for a more details of the wind tunnel test-bed facility as well as for specifics on the collection procedure followed and the operating and environmental parameters utilized during the creation of the aforementioned dataset.","The response of the sensor platform is read-out in the form of the resistance across the active sensitive film of each of the 72 gas sensors integrating the sensor array; hence, each measurement produced a 72-channel time series, each of which represented by a 260-second time series collected at a sample rate of 100 samples per second (Hz), reflecting all the environmental changes in the evaluated scenario. For a more detailed analysis and discussion on the processing of the time series as well as a graphical illustration of them please refer to Sections 2 and 3 and Figure 4, respectively, of the manuscript below.For manipulation purposes, the data is organized into eleven folders, each containing the number of measurements per chemical class identity and nominal concentration indicated above and described in the Table 2 of the manuscript. For example the folder named â€œToluene_200â€ means the name of the gas identity is Toluene, which has been dosed at 200 ppmv. Each folder contains 6 folders, each representing the line location within the test area of the wind tunnel (location 1, L1, to location 6, L6, being L1 the closest point to the gas source) from which the set of time-series were recorded. In each of these folders there are 300 files, each of which corresponding to the number of measurements recorded at each location in the tunnel. The name of each file contains the exact log information of each of the measurements performed during the entire experiment, which is organized as follows. The first 12 digits of the file name (e.g., 201106060617) indicate the date and time at which each specific measurement was collected, starting from the year, month, day, and time. The last 4 digits in the following 19 characters of the name file, (e.g., board_setPoint_500V), indicate the fixed operating temperature value, represented by a voltage value applied to the embedded heating element in the chemical sensor, applied to the entire sensing platform, which can adopt nominal values from 4 to 6 V with an resolution value of 0.5 V. Note that the value 500V in the example is a graphical representation of the 5V value applied to the sensorâ€™s heater. For more details on the operating principles of the chemical sensors utilized in our platform please refer to Section 2 of the manuscript. The last 3 digits in the following 16 characters of the file name (e.g., fan_setPoint_060) indicates the set-point value of the nominal rotational speeds of the multiple-step motor-driven exhaust fan utilized to induce the distinct artificial airflows speed in the wind tunnel. Only three values were adopted in this condition: the value â€œ000â€ in the file name, which indicates the slowest rotational speed (1500 rpm), the value â€œ060â€, indicating the mid-point rotational speed value of the fan (3900rpm), and the value â€œ100â€, which refers to the fastest induced speed of the fan, 5500 rpm. The last 14 characters of the following string of 27 characters (e.g., mfc_setPoint_Toluene_200ppm) describe the analyte identity and concentration value for each particular measurement. Thus, the just mentioned example represents the class corresponding to the chemical analyte identity â€œTolueneâ€ dosed at the nominal concentration value of 200 ppm. Finally, the last 2 or 3 digits in the name (e.g., â€œp7â€) describe the line point location at which the chemo-sensory platform was located in the wind tunnel. Note that there is a shift of two numbers in the value of this position, i.e., the value p7 in actuality represents the line location 4 illustrated in Figure 2 of the cited manuscript. For example, in201106060617_board_setPoint_500V_fan_setPoint_060_mfc_setPoint_Toluene_200ppm_p7the entire text line stands for a stand-alone measurement of the chemo-sensory platform located at the line location L4 and in response to 200 ppm of Toluene collected on June 06 of 2011, at 06:17 am (PST), with an operating voltage applied to the heater of 5V and a nominal rotational speed of the exhaust fan of 3900 rpm. Having described the naming configuration adopted in the generated dataset, we describe the organization of the information in each of the attached files of the dataset. The data format encloses information relevant to each measurement file, containing all the time series indicated above (9 portable modules Ã— 8 sensors, temperature and humidity values (oC and %, respectively), exhaust fan set-point and reading values, mass flow controller set-point and actual reading values (%), and reading time (ms)), which is organized as follows:Reading time (ms) fan_set_point fan_reading* mcf1_setpoint mcf2_setpoint mcf3_setpoint mcf1_read mcf2_read mcf3_read T RH 1 board1(Ã— 8 chemical sensors) 1 board2(Ã— 8 chemical sensors) 1 .... 1 board9(Ã— 8 chemical sensors) where: â€œReading time (ms)â€ is the time step for each recording (in ms, at a sample rate of 100 Hz), â€œfan_set_pointâ€ and â€œfan_readingâ€, is the set-point and actual reading of the exhaust fan, respectively, â€œmcf1_setpointâ€ to â€œmcf3_setpointâ€ are the opening degree set-point values given to the mass flow controllers 1 to 3 during the experiment, respectively, â€œmcf1_readâ€ to â€œmcf1_readâ€ are the measured opening degree of mass flow controllers 1 to 3, respectively, â€œTâ€ and â€œRâ€ are the temperature and relative humidity values (in oC and %, respectively) during the entire experiment, and â€œboard1(Ã— 8 chemical sensors)â€ to â€œboard9(Ã— 8 chemical sensors)â€ are the 72 time series collected as a function of time from the 8 gas sensors (in KÎ©) integrating modules 1 to 9 in each location, respectively, each separated by the number â€œ1â€ that stands as indicator label, forming thus the 72 time-series chemical sensor responses that is fetched to the classifier for training as described in the study. Note that there is a blank space between and among each column in the dataset. Thus, for example, in line1:22250    0    0    100    100    100    103    103    105    22.22    63.43    1    476    555    803    497    775    885    873    843    1    346    545    635    616    571    552    773    745    1    397    509    660    638    755    744    745    657    1    420    510    525    531    504    650    719    715    1    2201    449    652    1228    847    654    850    737    1    370    459    650    445    756    773    847    803    1    345    457    587    554    757    704    769    818    1    354    407    499    696    786    686    757    733    1    339    418    547    567    653    573    773    84 The number â€œ22250â€ stands for the recording made at time 22.25s, the following two numbers stand for the set-point and measured value of the fan speed, the following 6 numbers indicate the set-point (in this case, 100) and actual measured values of the MFC (103, 103, 105), the numbers â€œ22.22â€ and â€œ63.43â€ stand for the temperature and humidity values at that specific time recording, whereas the remaining 80 columns list the actual time series values for each measurement recording organized as described above, and in which the number â€œ1â€ indicates the boundary between each sensor module board. The first and ninth boards correspond to the positions closer to the walls, whereas the board 5 is located in the main line orthogonal to the gas plume. For the exact location of each board, please refer to Figure 2 of the mentioned Journal article.*: we found out that the exhaust fan actual reading value registered on each file is not completely accurate, showing a â€œ0â€ or other random values for some of the measurement recordings. Please discard this information value and utilize only the set point information for processing purposes; The value is accurate.Finally, to make the results presented in the associated article reproducible for the user of this read-me file, please use the hyper-parameter values described in the manuscript for the training task.",Provide references to papers that have cited this data set in the past (if any).,"Please cite:Alexander Vergara, Jordi Fonollosa, Jonas Mahiques, Marco Trincavelli, Nikolai Rulkov, RamÃ³n Huerta, On the performance of gas sensor arrays in open sampling systems using Inhibitory Support Vector Machines, Sensors and Actuators B: Chemical, Available online 18 May 2013, ISSN 0925-4005, 10.1016/j.snb.2013.05.027. ([Web Link])",
http://archive.ics.uci.edu/ml/datasets/Gesture+Phase+Segmentation,195,Gesture Phase Segmentation Data Set,../machine-learning-databases/00302/,"Multivariate, Sequential, Time-Series",9900,N/A,Real,50,6/18/2014,"Classification, Clustering",N/A,52373,"Creators:      Renata Cristina Barros Madeo (Madeo, R. C. B.)     Priscilla Koch Wagner (Wagner, P. K.)		     Sarajane Marques Peres (Peres, S. M.)     {renata.si, priscilla.wagner, sarajane} at usp.br http://each.uspnet.usp.br/sarajane/  Donor:      University of Sao Paulo - Brazil","The dataset is composed by features extracted from 7 videos with people gesticulating, aiming at studying Gesture Phase Segmentation.Each video is represented by two files: a raw file, which contains the position of hands, wrists, head and spine of the user in each frame; and a processed file, which contains velocity and acceleration of hands and wrists. See the data set description for more information on the dataset.","Raw files: 18 numeric attributes (double), a timestamp and a class attribute (nominal).Processed files: 32 numeric attributes (double) and a class attribute (nominal).A feature vector with up to 50 numeric attributes can be generated with the two files mentioned above.","   1.  Madeo, R. C. B. ; Lima, C. A. M. ; PERES, S. M. . Gesture Unit Segmentation using Support Vector Machines: Segmenting        Gestures from Rest Positions. In: Symposium on Applied Computing (SAC), 2013, Coimbra. Proceedings of the 28th Annual        ACM Symposium on Applied Computing (SAC), 2013. p. 46-52.       * In this paper, the videos A1 and A2 were studied.    2.  Wagner, P. K. ; PERES, S. M. ; Madeo, R. C. B. ; Lima, C. A. M. ; Freitas, F. A. . Gesture Unit Segmentation Using        Spatial-Temporal Information and Machine Learning. In: 27th Florida Artificial Intelligence Research Society Conference        (FLAIRS), 2014, Pensacola Beach. Proceedings of the 27th Florida Artificial Intelligence Research Society Conference        (FLAIRS). Palo Alto : The AAAI Press, 2014. p. 101-106.       * In this paper, the videos A1, A2, A3, B1, B3, C1 and C3 were studied.    3.  Madeo, R. C. B.. Support Vector Machines and Gesture Analysis: incorporating temporal aspects  (in Portuguese). Master        Thesis - Universidade de Sao Paulo, Sao Paulo Researcher Foundation. 2013.       * In this document, the videos named B1 and B3 in the document correspond to videos C1 and C3 in this dataset. Only        five videos were explored in this document: A1, A2, A3, C1 and C3.    4.  Wagner, P. K. ; Madeo, R. C. B. ; PERES, S. M. ; Lima, C. A. M. . SegmentaÃ§ao de Unidades Gestuais com Multilayer        Perceptrons (in Portuguese). In: Encontro Nacional de Inteligencia Artificial e Computacional (ENIAC), 2013, Fortaleza.        Anais do X Encontro Nacional de Inteligencia Artificial e Computacional (ENIAC), 2013.       * In this paper, the videos A1, A2 and A3 were studied.","Please refer to the Machine Learning Repository's citation policy.Additionally, the authors require a citation to one or more publications from those cited as relevant papers.",
http://archive.ics.uci.edu/ml/datasets/USPTO+Algorithm+Challenge%2C+run+by+NASA-Harvard+Tournament+Lab+and+TopCoder++++Problem%3A+Pat,196,"USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder    Problem: Pat Data Set",../machine-learning-databases/00268/,Domain-Theory,306,N/A,Integer,5,10/13/2013,Classification,N/A,33422,"-- Creator: TopCoder, Inc.-- Released under Apache License, Version 2.0http://www.apache.org/licenses/LICENSE-2.0.html","USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder   Problem: Patent Labeling","Dataset Information:    -- This folder contains 4 groups of USPTO patent images including ground truth information. 	-- The 4 groups are 'train1', 'train2', 'test', 'evaluation'. 	-- 'train1', 'test', 'evaluation' contains data in the original 'USPTO Algorithm Challenge' for training, testing and final evaluation, respectively.	-- 'train2' contains additional data which was used in the 'USPTO Algorithm Followup Challenge.'  	   Notice that 'train2' includes some cover page images of patent document which is not included in other groups.     -- In each group, there are two folders contain original images and corresponding ground truth informations. 	-- The original images are in 'jpeg' format.	-- There are two types of ground truth: figure label ground truth and part label ground truth.	-- The ground truth files are text files with '.ans' extension.      -- The structure of the ground truth files are described as below:	-- The first line is one number indicating how many instances exist in corresponding image	-- The following lines are polygon coordinates and corresponding label contents, each line corresponds to a figure label or part label, in the form 'N x1 y1 x2 y2 â€¦ xN yN x1 y1 content'. 	-- In each of those lines, the first number N indicates how many polygon vertices are recorded in current instance. 	-- The following numbers are x, y coordinates of those vertices.	-- The final word in each line is the content of figure label or part label.  	-- Each number or word is separated by a white space.	-- For group 'train2', there are only part label ground truth available.	-- We also release the source code of the top 5 winning solution. See additional archive file.","Christoph Riedl, Richard Zanibbi, Marti A. Hearst, Siyu Zhu, Michael Minetti, Jason Crusan, Ivan Metelsky, and Karim R. Lakhani, 'Detecting Figures and Part Labels in Patents: ACompetition-Based Development of Image Processing Algorithms', working paper, [Web Link].","Christoph Riedl, Richard Zanibbi, Marti A. Hearst, Siyu Zhu, Michael Minetti, Jason Crusan, Ivan Metelsky, and Karim R. Lakhani, 'Detecting Figures and Part Labels in Patents: A Competition-Based Development of Image Processing Algorithms,' International Journal on Document Analysis and Recognition, 1-18, DOI 10.1007/s10032-016-0260-8",
http://archive.ics.uci.edu/ml/datasets/Record+Linkage+Comparison+Patterns,197,Record Linkage Comparison Patterns Data Set,../machine-learning-databases/00210/,Multivariate,5749132,N/A,Real,12,3/10/2011,Classification,Yes,80492,"The underlying records stem from the epidemiological cancer registry of theGerman state of North Rhine-Westphalia (Epidemiologisches Krebsregister NRW,http://www.krebsregister.nrw.de). Creation of comparison patterns andassignment of matching status were undertaken by staff members ofthe Institute for Medical Biostatistics, Epidemiology and Informatics (IMBEI)at the University Medical Center of the Johannes Gutenberg University in Mainz, Germany (http://www.imbei.uni-mainz.de).","The records represent individual data including first and family name, sex, date of birth and postal code, which were collected through iterative insertions in the course of several years. The comparison patterns in this data set are based on a sample of 100.000 records dating from 2005 to 2008. Data pairs were classified as 'match' or 'non-match' during an extensive manual review where several documentarists were involved. The resulting classification formed the basis for assessing the quality of the registryâ€™s own record linkage procedure. In order to limit the amount of patterns, a blocking procedure was applied,which selects only record pairs that meet specific agreement conditions. Theresults of the following six blocking iterations were merged together:   1. Phonetic equality of first name and family name, equality of date of birth.  2. Phonetic equality of first name, equality of day of birth.  3. Phonetic equality of first name, equality of month of birth.  4. Phonetic equality of first name, equality of year of birth.  5. Equality of complete date of birth.  6. Phonetic equality of family name, equality of sex. This procedure resulted in 5.749.132 record pairs, of which 20.931 are matches. The data set is split into 10 blocks of (approximately) equal size and ratioof matches to non-matches. The separate file frequencies.csv contains for every predictive attribute the average number of values in the underlying records. These values can, for example,be used as u-probabilities in weight-based record linkage following theframework of Fellegi and Sunter.","1. id_1: internal identifier of first record.2. id_2: internal identifier of second record.3. cmp_fname_c1: agreement of first name, first component4. cmp_fname_c2: agreement of first name, second component5. cmp_lname_c1: agreement of family name, first component6. cmp_lname_c2: agreement of family name, second component7. cmp_sex: agreement sex8. cmp_bd: agreement of date of birth, day component9. cmp_bm: agreement of date of birth, month component10. cmp_by: agreement of date of birth, year component11. cmp_plz: agreement of postal code12. is_match: matching status (TRUE for matches, FALSE for non-matches) The agreement of name components is measured as a real number in the interval [0,1], where 0 denotes maximal disagreement and 1 equality of the underlying values. For the other comparisons, only the values 0 (not equal) and 1 (equal) are used. is_match is the outcome variable. id_1 and id_2 are not used for prediction but could be used to construct connected components from the found matches.","    1. Irene Schmidtmann, Gael Hammer, Murat Sariyar, Aslihan Gerhold-Ay:       Evaluation des Krebsregisters NRW Schwerpunkt Record Linkage. Technical       Report, IMBEI 2009.  [Web Link]        -- Describes the external evaluation of the registry's record linkage          procedures.       -- The comparison patterns in this data set were created in course of          this evaluation.     2. Murat Sariyar, Andreas Borg, Klaus Pommerening:        Controlling false match rates in record linkage using extreme value theory.       Journal of Biomedical Informatics, 2011 (in press).        -- Predicted attribute: matching status (boolean).       -- Results:          -- A new approach for estimating the false match rate in record              linkage by methods of Extreme Value Theory (EVT).          -- The model eliminates the need for labelled training data while             achieving only slighter lower accuracy compared to a procedure             that has knowledge about the matching status.",Please refer to the Epidemiological Cancer Registry of North Rhine-Westphalia ('Epidemiologisches Krebsregister') and to one of the mentioned papers when using this data set in a publication.,
http://archive.ics.uci.edu/ml/datasets/Facebook+Comment+Volume+Dataset,198,Facebook Comment Volume Dataset Data Set,../machine-learning-databases/00363/,Multivariate,40949,N/A,"Integer, Real",54,3/11/2016,Regression,N/A,93028,"Kamaljot Singh, Assistant Professor, Lovely Professional University, Jalandhar.Kamaljotsingh2009 '@' gmail.com","The Dataset is uploaded in ZIP format. The dataset contains 5 variants of the dataset, for the details about the variants and detailed analysis read and cite the research paper  @INPROCEEDINGS{Sing1503:Comment,AUTHOR='Kamaljot Singh and Ranjeet Kaur Sandhu and Dinesh Kumar',TITLE='Comment Volume Prediction Using Neural Networks and Decision Trees',BOOKTITLE='IEEE UKSim-AMSS 17th International Conference on Computer Modelling andSimulation, UKSim2015 (UKSim2015)',ADDRESS='Cambridge, United Kingdom',DAYS=25,MONTH=mar,YEAR=2015,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The leading treads towards social networking services had drawn massivepublic attention from last one and half decade. The amount of data that isuploaded to these social networking services is increasing day by day. So,there is massive requirement to study the highly dynamic behavior of userstowards these services. This is a preliminary work to model the userpatterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. In order to automate the process, we developed a software prototypeconsisting of the crawler, Information extractor, information processor andknowledge discovery module. We used Neural Networks and Decision Trees,predictive modeling techniques on different dataset variants and evaluatedthem under Hits(at)10 (custom measure), Area Under Curve, Evaluation Timeand Mean Absolute error evaluation metrics. We concluded that the Decisiontrees performed better than the Neural Networks under light of allevaluation metrics.'}   The research paper is also available at conference website: uksim.info/uksim2015/[Web Link]     another extended paper is that is to be published soon is : @ARTICLE{Sing1601:Facebook,AUTHOR='Kamaljot Singh',TITLE='Facebook Comment Volume Prediction',JOURNAL='International Journal of Simulation- Systems, Science and Technology-IJSSST V16',ADDRESS='Cambridge, United Kingdom',DAYS=30,MONTH=jan,YEAR=2016,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The amount of data that is uploaded to social networking services isincreasing day by day. So, their is massive requirement to study the highlydynamic behavior of users towards these services. This work is to model theuser patterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. To automate the process, we developed a software prototype consistingof the crawler, Information extractor, information processor and knowledgediscovery module. We used Neural Networks and Decision Trees, predictivemodeling techniques on different data-set variants and evaluated them underHits(at)10, Area Under Curve, Evaluation Time and M.A.E metrics. Weconcluded that the Decision trees performed better than the Neural Networksunder light of all metrics.'}  this above paper will be freely available after publication at www.ijssst.info"," 1Page Popularity/likesDecimal EncodingPage featureDefines the popularity or support for the source of the document.  2Page Checkinsâ€™sDecimal EncodingPage  featureDescribes how many individuals so far visited this place. This feature is only associated with the places eg:some institution, place, theater etc.  3Page talking aboutDecimal EncodingPage featureDefines the daily interest of individuals towards source of the document/ Post. The people who actually come back to the page, after liking the page. This include activities such as comments, likes to a post, shares, etc by visitors to the page.  4Page CategoryValue  EncodingPage featureDefines the category of the source of the document eg: place, institution, brand etc.  5 - 29DerivedDecimal  EncodingDerived featureThese features are aggregated by page, by calculating min, max, average, median and standard deviation of essential features.  30CC1Decimal EncodingEssential featureThe total number of comments before selected base date/time.  31CC2Decimal EncodingEssential featureThe number of comments in last 24 hours, relative to base date/time.  32CC3Decimal EncodingEssential featureThe number of comments in last 48 to last 24 hours relative to base date/time.  33CC4Decimal EncodingEssential featureThe number of comments in the first 24 hours after the publication of post but before base date/time.  34CC5Decimal EncodingEssential featureThe difference between CC2 and CC3.  35Base timeDecimal(0-71) EncodingOther featureSelected time in order to simulate the scenario.  36Post lengthDecimal EncodingOther featureCharacter count in the post.  37Post Share Countï¿¼ï¿¼Decimal EncodingOther featureThis features counts the no of shares of the post, that how many peoples had shared this post on to their timeline.  38Post Promotion Statusï¿¼ï¿¼Binary EncodingOther featureTo reach more people with posts in News Feed, individual promote their post and this features tells that whether the post is promoted(1) or not(0).  39H Localï¿¼Decimal(0-23) EncodingOther featureThis describes the H hrs, for which we have the target variable/ comments received.  40-46Post published weekdayBinary EncodingWeekdays featureThis represents the day(Sunday...Saturday) on which the post was published.  47-53Base DateTime weekdayBinary EncodingWeekdays featureThis represents the day(Sunday...Saturday) on selected base Date/Time. 54Target VariableDecimalTargetThe no of comments in next H hrs(H is given in Feature no 39).","Provide references to papers that have cited this data set in the past (if any).The Dataset is uploaded in ZIP format. The dataset contains 5 variants of the dataset, for the details about the variants and detailed analysis read and cite the research paper  @INPROCEEDINGS{Sing1503:Comment,AUTHOR='Kamaljot Singh and Ranjeet Kaur Sandhu and Dinesh Kumar',TITLE='Comment Volume Prediction Using Neural Networks and Decision Trees',BOOKTITLE='IEEE UKSim-AMSS 17th International Conference on Computer Modelling andSimulation, UKSim2015 (UKSim2015)',ADDRESS='Cambridge, United Kingdom',DAYS=25,MONTH=mar,YEAR=2015,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The leading treads towards social networking services had drawn massivepublic attention from last one and half decade. The amount of data that isuploaded to these social networking services is increasing day by day. So,there is massive requirement to study the highly dynamic behavior of userstowards these services. This is a preliminary work to model the userpatterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. In order to automate the process, we developed a software prototypeconsisting of the crawler, Information extractor, information processor andknowledge discovery module. We used Neural Networks and Decision Trees,predictive modeling techniques on different dataset variants and evaluatedthem under Hits(at)10 (custom measure), Area Under Curve, Evaluation Timeand Mean Absolute error evaluation metrics. We concluded that the Decisiontrees performed better than the Neural Networks under light of allevaluation metrics.'}   The research paper is also available at conference website: uksim.info/uksim2015/[Web Link]     another extended paper is that is to be published soon is : @ARTICLE{Sing1601:Facebook,AUTHOR='Kamaljot Singh',TITLE='Facebook Comment Volume Prediction',JOURNAL='International Journal of Simulation- Systems, Science and Technology-IJSSST V16',ADDRESS='Cambridge, United Kingdom',DAYS=30,MONTH=jan,YEAR=2016,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The amount of data that is uploaded to social networking services isincreasing day by day. So, their is massive requirement to study the highlydynamic behavior of users towards these services. This work is to model theuser patterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. To automate the process, we developed a software prototype consistingof the crawler, Information extractor, information processor and knowledgediscovery module. We used Neural Networks and Decision Trees, predictivemodeling techniques on different data-set variants and evaluated them underHits(at)10, Area Under Curve, Evaluation Time and M.A.E metrics. Weconcluded that the Decision trees performed better than the Neural Networksunder light of all metrics.'}  this above paper will be freely available after publication at www.ijssst.info"," @INPROCEEDINGS{Sing1503:Comment,AUTHOR='Kamaljot Singh and Ranjeet Kaur Sandhu and Dinesh Kumar',TITLE='Comment Volume Prediction Using Neural Networks and Decision Trees',BOOKTITLE='IEEE UKSim-AMSS 17th International Conference on Computer Modelling andSimulation, UKSim2015 (UKSim2015)',ADDRESS='Cambridge, United Kingdom',DAYS=25,MONTH=mar,YEAR=2015,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The leading treads towards social networking services had drawn massivepublic attention from last one and half decade. The amount of data that isuploaded to these social networking services is increasing day by day. So,there is massive requirement to study the highly dynamic behavior of userstowards these services. This is a preliminary work to model the userpatterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. In order to automate the process, we developed a software prototypeconsisting of the crawler, Information extractor, information processor andknowledge discovery module. We used Neural Networks and Decision Trees,predictive modeling techniques on different dataset variants and evaluatedthem under Hits(at)10 (custom measure), Area Under Curve, Evaluation Timeand Mean Absolute error evaluation metrics. We concluded that the Decisiontrees performed better than the Neural Networks under light of allevaluation metrics.'}   The research paper is also available at conference website: uksim.info/uksim2015/[Web Link]     another extended paper is that is to be published soon is : @ARTICLE{Sing1601:Facebook,AUTHOR='Kamaljot Singh',TITLE='Facebook Comment Volume Prediction',JOURNAL='International Journal of Simulation- Systems, Science and Technology-IJSSST V16',ADDRESS='Cambridge, United Kingdom',DAYS=30,MONTH=jan,YEAR=2016,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The amount of data that is uploaded to social networking services isincreasing day by day. So, their is massive requirement to study the highlydynamic behavior of users towards these services. This work is to model theuser patterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. To automate the process, we developed a software prototype consistingof the crawler, Information extractor, information processor and knowledgediscovery module. We used Neural Networks and Decision Trees, predictivemodeling techniques on different data-set variants and evaluated them underHits(at)10, Area Under Curve, Evaluation Time and M.A.E metrics. Weconcluded that the Decision trees performed better than the Neural Networksunder light of all metrics.'}  this above paper will be freely available after publication at www.ijssst.info",
http://archive.ics.uci.edu/ml/datasets/QSAR+fish+toxicity,199,QSAR fish toxicity Data Set,../machine-learning-databases/00504/,Multivariate,908,Physical,Real,7,9/23/2019,Regression,N/A,25505,"Davide Ballabio (davide.ballabio @ unimib.it), Matteo Cassotti, Viviana Consonni, Roberto Todeschini, Milano Chemometrics and QSAR Research Group (http://www.michem.unimib.it/), UniversitÃ  degli Studi Milano - Bicocca, Milano (Italy)","This dataset was used to develop quantitative regression QSAR models to predict acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow) on a set of 908 chemicals. LC50 data, which is the concentration that causes death in 50% of test fish over a test duration of 96 hours, was used as model response. The model comprised 6 molecular descriptors: MLOGP (molecular properties), CIC0 (information indices), GATS1i (2D autocorrelations), NdssC (atom-type counts), NdsCH ((atom-type counts), SM1_Dz(Z) (2D matrix-based descriptors). Details can be found in the quoted reference: M. Cassotti, D. Ballabio, R. Todeschini, V. Consonni. A similarity-based QSAR model for predicting acute toxicity towards the fathead minnow (Pimephales promelas), SAR and QSAR in Environmental Research (2015), 26, 217-243; doi: 10.1080/1062936X.2015.1018938","6 molecular descriptors and 1 quantitative experimental response:1) CIC02) SM1_Dz(Z)3) GATS1i4) NdsCH5) NdssC6) MLOGP7) quantitative response, LC50 [-LOG(mol/L)]","M. Cassotti, D. Ballabio, R. Todeschini, V. Consonni. A similarity-based QSAR model for predicting acute toxicity towards the fathead minnow (Pimephales promelas), SAR and QSAR in Environmental Research (2015), 26, 217-243; doi: 10.1080/1062936X.2015.1018938","Please, cite the following paper if you publish results based on the QSAR fish toxicity dataset: M. Cassotti, D. Ballabio, R. Todeschini, V. Consonni. A similarity-based QSAR model for predicting acute toxicity towards the fathead minnow (Pimephales promelas), SAR and QSAR in Environmental Research (2015), 26, 217-243; doi: 10.1080/1062936X.2015.1018938",
http://archive.ics.uci.edu/ml/datasets/microblogPCU,200,microblogPCU Data Set,../machine-learning-databases/00323/,"Multivariate, Univariate, Sequential, Text",221579,Computer,"Integer, Real",20,3/17/2015,"Classification, Causal-Discovery",Yes,49525,"Jun Liu(liukeen '@' mail.xjtu.cn), Hao Chen(lechenhao '@' gmail.com) , Mengting Zhan, Jianhong Mi,Yanzhang Lv MOEKLINNS Lab, Department of Computer Science ,Xi'an Jiaotong University, China",Our dataset is used by us to explore spammers in microblog and you can access our demo system at [Web Link]Please add :8080 after the domain name as port. The repository webpage fails to parse the weblink when it's added in the source. (under inspection),"weibo_user.csv has the following attributes:-user_id: account ID in sina weibo;-user_name: account nicknameï¼›-gender:account registration gender including maleï¼Œ female and otherï¼›-class:account level given by sina weibo;-message:account registration location or other personal information;-post_num: the number of posts of this account up to now;-follower_num: the number of followers of this account;-followee_num: the number of followee of this account;-follow ratio: followee_num/follower_num;-is_spammer: manually annotated label, 1 means spammer and -1 means non-spammer;user_post.csv has the following attributes:-post_id:user post ID given by sina weibo;-post_time:the time when a post is posted;-poster_id: the user ID who posted this post;-repost_num:the number of retweet by others;-commnet_num: the number of comment by others;followe-followee.csv has the following attributes:-follower: the nickname of follower;-follower_id: the user ID of follower;-followee: the nickname of followee;-followee_id: the user ID of followee;post.csv is almost the as user_post.csv and the post in it are retrievalled by a certain key word related to a topic;-content: the post text(mostly in Chinese, please set your Microsoft Office to make it readable)",N/A,Thanks to MOEKLINNS Lab[[Web Link]] especially Spammer Detection Group for opening its data ,
http://archive.ics.uci.edu/ml/datasets/ISTANBUL+STOCK+EXCHANGE,201,ISTANBUL STOCK EXCHANGE Data Set,../machine-learning-databases/00247/,"Multivariate, Univariate, Time-Series",536,Business,Real,8,6/1/2013,"Classification, Regression",N/A,136096,"Dr.Oguz Akbilgic,oguzakbilgic '@' gmail.com University of Tennessee, Knoxville",Data is collected from imkb.gov.tr and finance.yahoo.com. Data is organized with regard to working days in Istanbul Stock Exchange. ,"Stock exchange returns. Istanbul stock exchange national 100 index, Standard & poorâ€™s 500 return index, Stock market return index of Germany, Stock market return index of UK, Stock market return index of Japan, Stock market return index of Brazil, MSCI European index, MSCI emerging markets index","Paper: Akbilgic, O., Bozdogan, H., Balaban, M.E., (2013) A novel Hybrid RBF Neural Networks model as a forecaster, Statistics and Computing. DOI 10.1007/s11222-013-9375-7PhD Thesis: Oguz Akbilgic, (2011) Hibrit Radyal TabanlÄ± Fonksiyon AÄŸlarÄ± ile DeÄŸiÅŸken SeÃ§imi ve Tahminleme: Menkul KÄ±ymet YatÄ±rÄ±m KararlarÄ±na Ä°liÅŸkin Bir Uygulama, Istanbul University","Paper: Akbilgic, O., Bozdogan, H., Balaban, M.E., (2013) A novel Hybrid RBF Neural Networks model as a forecaster, Statistics and Computing. DOI 10.1007/s11222-013-9375-7PhD Thesis: Oguz Akbilgic, (2011) Hibrit Radyal TabanlÄ± Fonksiyon AÄŸlarÄ± ile DeÄŸiÅŸken SeÃ§imi ve Tahminleme: Menkul KÄ±ymet YatÄ±rÄ±m KararlarÄ±na Ä°liÅŸkin Bir Uygulama, Istanbul University",
http://archive.ics.uci.edu/ml/datasets/Arcene,202,Arcene Data Set,../machine-learning-databases/arcene/,Multivariate,900,Life,Real,10000,2/29/2008,Classification,N/A,133134,"a. Original ownersThe data were obtained from two sources: The National Cancer Institute (NCI) and the Eastern Virginia Medical School (EVMS). All the data consist of mass-spectra obtained with the SELDI technique. The samples include patients with cancer (ovarian or prostate cancer), and healthy or control patients. b. Donor of databaseThis version of the database was prepared for the NIPS 2003 variable and feature selection benchmark by Isabelle Guyon, 955 Creston Road, Berkeley, CA 94708, USA (isabelle '@' clopinet.com).","ARCENE was obtained by merging three mass-spectrometry datasets to obtain enough training and test data for a benchmark. The original features indicate the abundance of proteins in human sera having a given mass value. Based on those features one must separate cancer patients from healthy patients. We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. ARCENE -- Positive ex. -- Negative ex. -- TotalTraining set -- 44 -- 56 -- 100Validation set -- 44 -- 56 -- 100Test set -- 310 -- 390 -- 700All -- 398 -- 502 -- 900 Number of variables/features/attributes:Real: 7000Probes: 3000Total: 10000 This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link]. All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge. The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link]. The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a coma delimited regular matrix, patterns in lines, features in columns).dataname_valid.data: Validation set.dataname_test.data: Test set.dataname_train.labels: Labels (truth values of the classes) for training examples.dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels (withheld, so the data can still be use as a benchmark). ",We do not provide attribute information to avoid biasing the feature selection process. ,"The best challenge entrants wrote papers collected in the book:Isabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer. [Web Link]  See also:Isabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 14381444.and the associated technical report:Isabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report. [Web Link].","Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge. In: NIPS. [Web Link]. ",
http://archive.ics.uci.edu/ml/datasets/SkillCraft1+Master+Table+Dataset,203,SkillCraft1 Master Table Dataset Data Set,../machine-learning-databases/00272/,Multivariate,3395,Game,"Integer, Real",20,10/22/2013,Regression,Yes,63836,"   -- Creators: Mark Blair, Joe Thompson, Andrew Henrey, Bill Chen     -- Mark Blair: Department of Psychology; Simon Fraser University; Burnaby;          8888 University Drive; mblair '@' sfu.ca)      -- Date: September, 20, 2013","   -- We aggregated screen movements into screen-fixations using a Salvucci & Goldberg (2000) dispersion-threshold algorithm, and defined Perception Action Cycles (PACs) as fixations with at least one action.   -- Time is recorded in terms of timestamps in the StarCraft 2 replay file. When the game is played on 'faster', 1 real-time second is equivalent to roughly 88.5 timestamps.   -- List of possible game actions is discussed in Thompson, Blair, Chen, & Henrey (2013)","   1. GameID: Unique ID number for each game (integer)   2. LeagueIndex: Bronze, Silver, Gold, Platinum, Diamond, Master, GrandMaster, and Professional leagues coded 1-8 (Ordinal)   3. Age: Age of each player (integer)   4. HoursPerWeek: Reported hours spent playing per week (integer)   5. TotalHours: Reported total hours spent playing (integer)   6. APM: Action per minute (continuous)   7. SelectByHotkeys: Number of unit or building selections made using hotkeys per timestamp (continuous)   8. AssignToHotkeys: Number of units or buildings assigned to hotkeys per timestamp (continuous)   9. UniqueHotkeys: Number of unique hotkeys used per timestamp (continuous)  10. MinimapAttacks: Number of attack actions on minimap per timestamp (continuous)  11. MinimapRightClicks: number of right-clicks on minimap per timestamp (continuous)  12. NumberOfPACs: Number of PACs per timestamp (continuous)  13. GapBetweenPACs: Mean duration in milliseconds between PACs (continuous)  14. ActionLatency: Mean latency from the onset of a PACs to their first action in milliseconds (continuous)  15. ActionsInPAC: Mean number of actions within each PAC (continuous)  16. TotalMapExplored: The number of 24x24 game coordinate grids viewed by the player per timestamp (continuous)  17. WorkersMade: Number of SCVs, drones, and probes trained per timestamp (continuous)  18. UniqueUnitsMade: Unique unites made per timestamp (continuous)  19. ComplexUnitsMade: Number of ghosts, infestors, and high templars trained per timestamp (continuous)  20. ComplexAbilitiesUsed: Abilities requiring specific targeting instructions used per timestamp (continuous)","    1. Thompson JJ, Blair MR, Chen L, Henrey AJ (2013) Video Game Telemetry as a Critical Tool in the Study of Complex Skill Learning. PLoS ONE 8(9): e75129. [Web Link]         -- Results:              -- Skip league conditional inference forest classification (Bronze-Gold;Silver-Platinum;Gold-Diamond;Platinum-Masters;Diamond-Professional) showed changing patterns of variable importance with skill.        -- Predicted attribute: League (Ordinal)","You are free to copy, distribute and transmit this work under the following conditions: You must give attribution to the work (but not in any way that suggests that the author endorses you or your use of the work); You may not use this work for commercial purposes; You may not alter, transform, or build upon this work. Any further uses require the permission of the rights holder (or author if no rights holder is listed). These rights are based on the Creative Commons Attribution-NonCommercial-NoDerivatives License.",
http://archive.ics.uci.edu/ml/datasets/Acute+Inflammations,204,Acute Inflammations Data Set,../machine-learning-databases/acute/,Multivariate,120,Life,"Categorical, Integer",6,2/11/2009,Classification,No,175129,"Jacek Czerniak, Ph.D., Assistant ProfessorSystems Research InstitutePolish Academy of SciencesLaboratory of Intelligent Systems  ul. Newelska 6, Room 21801-447 Warszawa, Polande-mail: jacek.czerniak '@' ibspan.waw.pl or jczerniak '@' ukw.edu.pl ","The main idea of this data set is to prepare the algorithm of the expert system, which will perform the presumptive diagnosis of two diseases of urinary system. It will be the example of diagnosing of the acute inflammations of urinary bladder and acute nephritises. For better understanding of the problem let us consider definitions of both diseases given by medics. Acute inflammation of urinary bladder is characterised by sudden occurrence of pains in the abdomen region and the urination in form of constant urine pushing, micturition pains and sometimes lack of urine keeping. Temperature of the body is rising, however most often not above 38C. The excreted urine is turbid and sometimes bloody. At proper treatment, symptoms decay usually within several days. However, there is inclination to returns. At persons with acute inflammation of urinary bladder, we should expect that the illness will turn into protracted form. Acute nephritis of renal pelvis origin occurs considerably more often at women than at men. It begins with sudden fever, which reaches, and sometimes exceeds 40C. The fever is accompanied by shivers and one- or both-side lumbar pains, which are sometimes very strong. Symptoms of acute inflammation of urinary bladder appear very often. Quite not infrequently there are nausea and vomiting and spread pains of whole abdomen. The data was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two diseases of urinary system.  The basis for rules detection was Rough Sets Theory.  Each instance represents an potential patient. The data is in an ASCII file. Attributes are separated by TAB.Each line of the data file starts with a digit which tells the temperature of patient.   -- Attribute lines:       For example, '35,9	no	no	yes	yes	yes	yes	no'       Where:	 '35,9'	Temperature of patient 		 'no'	Occurrence of nausea 		 'no'	Lumbar pain  		 'yes'	Urine pushing (continuous need for urination)  		 'yes'	Micturition pains  	 'yes'	Burning of urethra, itch, swelling of urethra outlet 		 'yes'	decision: Inflammation of urinary bladder  	 'no'	decision: Nephritis of renal pelvis origin "," a1	Temperature of patient  { 35C-42C }	 a2	Occurrence of nausea  { yes, no }	 a3	Lumbar pain  { yes, no }	 a4	Urine pushing (continuous need for urination)  { yes, no }	 a5	Micturition pains  { yes, no }	 a6	Burning of urethra, itch, swelling of urethra outlet  { yes, no }	 d1	decision: Inflammation of urinary bladder  { yes, no }	 d2	decision: Nephritis of renal pelvis origin { yes, no }	","J.Czerniak, H.Zarzycki, Application of rough sets in the presumptive diagnosis of urinary system diseases, Artifical Inteligence and Security in Computing Systems, ACS'2002 9th International Conference Proceedings, Kluwer Academic Publishers,2003, pp. 41-51","Please cite: J.Czerniak, H.Zarzycki, Application of rough sets in the presumptive diagnosis of urinary system diseases, Artifical Inteligence and Security in Computing Systems, ACS'2002 9th International Conference Proceedings, Kluwer Academic Publishers,2003, pp. 41-51",
http://archive.ics.uci.edu/ml/datasets/Movie,205,Movie Data Set,../machine-learning-databases/movies-mld/,"Multivariate, Relational",10000,N/A,N/A,N/A,7/7/1999,N/A,Yes,209087," Original Owner and Donor Gio Wiederhold Stanford University 650-725-8363 gio '@' cs.stanford.edu ","The data is stored in relational form across several files. The central file (MAIN) is a list of movies, each with a unique identifier. These identifiers may change in successive versions. The actors (CAST) for those movies are listed with their roles in a distinct file. More information about individual actors (ACTORS) is in a third file. All directors in MAIN are listed in a fourth file (PEOPLE), with a number of important producers, writers, and cinematographers. A fifth file (REMAKES) links movies that were copied to a substantial extent from each other. The sixth file (STUDIOS) provides some information about studios shown in MAIN. The original motivation was for database class exercises, to replace the boring `manager of the toy-department' queries. Note that the CASTS, refering MAIN and ACTORS is logically identical to the inventory file refering to suppliers and assemblies in the the standard bill-of-materials problems. Personal interests caused the database to be made complete for all Hitchcock movies and TV episodes. Related films by type and actor were added gradually. Subsequent research on temporal databases caused date fields (years only) to be added. It allows testing, say, if the dates-of-work of an ACTOR match the dates of the MAIN films that the CAST relation shows. Object-oriented database features could be tested with fields having multiple and two-level values, as documented in DOC. The entries were gradually collected during course work starting about 1975 and are still being updated. Most of the entries were manual. The DOC file lists some of the reference works used. Corrections and additions continue to be appreciated. Detailed descriptions of the fields and their formats is provided in doc.html.  Missing Values: Outside of key fields, missing values are common. Their encoding is described in DOC. Sometimes the data seems to be unavailable, sometimes it hasn't been entered. Some information, as `lived-with' is inherently incomplete. Censored Data: Minor actors are ignored. Dependencies: Every MAIN film must have a director in PEOPLE. About 50 pseudo director names ahve been listed in PEOPLE to allow interesting films to with (yet) unknown directors to be entered. Every CASTS entry must relate to a MAIN film entry. Every ACTOR should appear in some CASTS entry, but not vice versa. See DOC for more type information. Other Relevant Information: Films are listed, if known, with their original language title. An Alt(T: ) field provides English translations, where known. Data Format: The current files are in HTML, to allow easy parsing to other formats. An XML version is being considered. The approximate file sizes are:DOC .......    50K MAIN ...... 1 145K   11 400 entriesPEOPLE ....   355K    3 290 entriesCASTS ..... 4 340K   46 000 entriesACTORS ....   811K    6 800 entriesREMAKES ...   135K    1 278 entriesSTUDIOS ...    26K      200 entries",N/A,N/A,"Copyright held by Gio Wiederhold, 1990-1999. This data may not be used for commercial resale. Please acknowledge the source when used: Gio Wiederhold, Stanford University. ",Harsha Nagesh and Sanjay Goil and Alok N. Choudhary. Adaptive Grids for Clustering Massive Data Sets. Department of Energy ASCI.  [View Context].
http://archive.ics.uci.edu/ml/datasets/QSAR+oral+toxicity,206,QSAR oral toxicity Data Set,../machine-learning-databases/00508/,Multivariate,8992,Physical,N/A,1024,10/1/2019,Classification,N/A,6042,"Davide Ballabio (davide.ballabio '@' unimib.it), Francesca Grisoni, Roberto Todeschini, Viviana Consonni, Milano Chemometrics and QSAR Research Group (http://www.michem.unimib.it/), UniversitÃ  degli Studi Milano - Bicocca, Milano (Italy)","This dataset was used to develop classification QSAR models for the discrimination of very toxic/positive (741) and not very toxic/negative (8251) molecules by means of different machine learning methods. Details can be found in the quoted reference: D. Ballabio, F. Grisoni, V. Consonni, R. Todeschini (2019), Integrated QSAR models to predict acute oral systemic toxicity, Molecular Informatics, 38, 180012; doi: 10.1002/minf.201800124. Attributes (molecular fingerprints) were calculated at the Milano Chemometrics and QSAR Research Group (UniversitÃ   degli Studi Milano - Bicocca, Milano, Italy) on a set of chemicals provided by the ICCVAM Acute Toxicity Workgroup (U.S. Department of Health and Human Services), in collaboration with the U.S. Environmental Protection Agency (U.S. EPA, National Center for Computational Toxicology), which coordinated the â€œPredictive Models for Acute Oral Systemic Toxicityâ€ collaborative project to develop in silico models to predict acute oral systemic toxicity for filling regulatory needs.","1024 binary molecular fingerprints and 1 experimental class:1-1024) binary molecular fingerprint1025) experimental class: positive (very toxic) and negative (not very toxic)","D. Ballabio, F. Grisoni, V. Consonni, R. Todeschini (2019), Integrated QSAR models to predict acute oral systemic toxicity, Molecular Informatics, 38, 180012; doi: 10.1002/minf.201800124","Please, cite the following paper if you publish results based on the QSAR oral toxicity dataset: D. Ballabio, F. Grisoni, V. Consonni, R. Todeschini (2019), Integrated QSAR models to predict acute oral systemic toxicity, Molecular Informatics, 38, 180012; doi: 10.1002/minf.201800124",
http://archive.ics.uci.edu/ml/datasets/Epileptic+Seizure+Recognition,207,Epileptic Seizure Recognition Data Set,../machine-learning-databases/00388/,"Multivariate, Time-Series",11500,Life,"Integer, Real",179,5/24/2017,"Classification, Clustering",N/A,110617,"Qiuyi WuSchool of Mathematical SciencesRochester Institute of Technologyemail: qw9477'@'rit.edu Ernest FokoueSchool of Mathematical SciencesRochester Institute of Technologyemail: epfeqa'@'rit.eduPhone: 585 739 6893","Please find the original data at '[Web Link]'","The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for 23.6 seconds. The corresponding time-series is sampled into 4097 data points. Each data point is the value of the EEG recording at a different point in time. So we have total 500 individuals with each has 4097 data points for 23.5 seconds.We divided and shuffled every 4097 data points into 23 chunks, each chunk contains 178 data points for 1 second, and each data point is the value of the EEG recording at a different point in time. So now we have 23 x 500 = 11500 pieces of information(row), each information contains 178 data points for 1 second(column), the last column represents the label y {1,2,3,4,5}. The response variable is y in column 179, the Explanatory variables X1, X2, ..., X178 y contains the category of the 178-dimensional input vector. Specifically y in {1, 2, 3, 4, 5}: 5 - eyes open, means when they were recording the EEG signal of the brain the patient had their eyes open 4 - eyes closed, means when they were recording the EEG signal the patient had their eyes closed 3 - Yes they identify where the region of the tumor was in the brain and recording the EEG activity from the healthy brain area 2 - They recorder the EEG from the area where the tumor was located 1 - Recording of seizure activity All subjects falling in classes 2, 3, 4, and 5 are subjects who did not have epileptic seizure. Only subjects in class 1 have epileptic seizure. Our motivation for creating this version of the data was to simplify access to the data via the creation of a .csv version of it. Although there are 5 classes most authors have done binary classification, namely class 1 (Epileptic seizure) against the rest.","Andrzejak RG, Lehnertz K, Rieke C, Mormann F, David P, Elger CE (2001) Indications of nonlinear deterministic and finite dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state, Phys. Rev. E, 64, 061907","Andrzejak RG, Lehnertz K, Rieke C, Mormann F, David P, Elger CE (2001) Indications of nonlinear deterministic and finite dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state, Phys. Rev. E, 64, 061907",
http://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index,208,Dow Jones Index Data Set,../machine-learning-databases/00312/,Time-Series,750,Business,"Integer, Real",16,10/23/2014,"Classification, Clustering",N/A,211539,"Dr. Michael Brown, michael.brown '@' umuc.edu, University of Maryland University College","In predicting stock prices you collect data over some period of time - day, week, month, etc. But you cannot take advantage of data from a time period until the next increment of the time period. For example, assume you collect data daily.  When Monday is over you have all of the data for that day.  However you can invest on Monday, because you don't get the data until the end of the day.  You can use the data from Monday to invest on Tuesday.   In our research each record (row) is data for a week.  Each record also has the percentage of return that stock has in the following week (percent_change_next_weeks_price). Ideally, you want to determine which stock will produce the greatest rate of return in the following week.  This can help you train and test your algorithm. Some of these attributes might not be use used in your research.  They were originally added to our database to perform calculations.  (Brown, Pelosi & Dirska, 2013) used percent_change_price, percent_change_volume_over_last_wk, days_to_next_dividend, and percent_return_next_dividend.  We left the other attributes in the dataset	in case you wanted to use any of them. Of course what you want to maximize is percent_change_next_weeks_price. Training data vs Test data:In (Brown, Pelosi & Dirska, 2013) we used quarter 1 (Jan-Mar) data for training and quarter 2 (Apr-Jun) data for testing.  Interesting data points:If you use quarter 2 data for testing, you will notice something interesting in the week ending 5/27/2011 every Dow Jones Index stock lost money.","	quarter:  the yearly quarter (1 = Jan-Mar; 2 = Apr=Jun).	stock: the stock symbol (see above)	date: the last business day of the work (this is typically a Friday)	open: the price of the stock at the beginning of the week	high: the highest price of the stock during the week	low: the lowest price of the stock during the week	close: the price of the stock at the end of the week	volume: the number of shares of stock that traded hands in the week	percent_change_price: the percentage change in price throughout the week	percent_chagne_volume_over_last_wek: the percentage change in the number of shares of 		stock that traded hands for this week compared to the previous week	previous_weeks_volume: the number of shares of stock that traded hands in the previous week	next_weeks_open: the opening price of the stock in the following week	next_weeks_close: the closing price of the stock in the following week	percent_change_next_weeks_price: the percentage change in price of the stock in the 		following week days_to_next_dividend: the number of days until the next dividend	percent_return_next_dividend: the percentage of return on the next dividend","Brown, M. S., Pelosi, M. & Dirska, H. (2013). Dynamic-radius Species-conserving Genetic Algorithm for the Financial Forecasting of Dow Jones Index Stocks. Machine Learning and Data Mining in Pattern Recognition, 7988, 27-41.","We request that you provide a citation to this paper when using the dataset.  We welcome you to compare your results against ours in (Brown, Pelosi & Dirska, 2013).",
http://archive.ics.uci.edu/ml/datasets/Vertebral+Column,209,Vertebral Column Data Set,../machine-learning-databases/00212/,Multivariate,310,N/A,Real,6,8/9/2011,Classification,N/A,170386,"Guilherme de Alencar Barreto (guilherme '@' deti.ufc.br) & Ajalmar RÃªgo da Rocha Neto (ajalmar '@' ifce.edu.br), Department of Teleinformatics Engineering, Federal University of CearÃ¡, Fortaleza, CearÃ¡, Brazil. Henrique Antonio Fonseca da Mota Filho (hdamota '@' gmail.com), Hospital Monte Klinikum, Fortaleza, CearÃ¡, Brazil.","Biomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre MÃ©dico-Chirurgical de RÃ©adaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis  (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.","Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB).","(1) Berthonnaud, E., Dimnet, J., Roussouly, P. & Labelle, H. (2005). 'Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters', Journal of Spinal Disorders & Techniques, 18(1):40â€“47. (2) Rocha Neto, A. R. &  Barreto, G. A. (2009). 'On the Application of Ensembles of Classifiers to the Diagnosis of Pathologies of the Vertebral Column: A Comparative Analysis', IEEE Latin America Transactions, 7(4):487-496. (3) Rocha Neto, A. R., Sousa, R., Barreto, G. A. & Cardoso, J. S. (2011). 'Diagnostic of Pathology on the Vertebral Column with Embedded Reject Optionâ€, Proceedings of the 5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011), Gran Canaria, Spain, Lecture Notes on Computer Science, vol. 6669, p. 588-595.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Bach+Chorales,210,Bach Chorales Data Set,../machine-learning-databases/chorales,"Univariate, Time-Series",100,N/A,"Categorical, Integer",6,N/A,N/A,No,131615,"Chorales: Mainous and Ottman edition.Mainous, Frank D. and Robert W. Ottman, eds. 1966.The 371 Bach Chorales.  Holt, Rinehart and Winston, New York. Original Owners of Database: Darrell ConklinZymoGenetics Inc.1201 Eastlake Avenue EastSeattle WA, 98102conklin '@' zgi.com  Donor of database: Same as owner.  Ann Blombach of Ohio State University originally supplied me with 4-voice encodings of 100 chorales.  The present database is the soprano line, converted into Lisp-readable form, and extensively corrected.","Sequential (time-series) domain.  Single-line melodies of 100 Bach chorales (originally 4 voices).  The melody line can be studied independently of other voices.  The grand challenge is to learn a generative grammar for stylistically valid chorales (see references and discussion in ""Multiple Viewpoint Systems for Music Prediction"").","Number of Attributes: 6 (nominal) per event (a) start-time, measured in 16th notes from chorale beginning (time 0)(b) pitch, MIDI number (60 = C4, 61 = C#4, 72 = C5, etc.)(c) duration, measured in 16th notes(d) key signature, number of sharps or flats, positive if key signature has sharps, negative if key signature has flats(e) time signature, in 16th notes per bar(f) fermata, true or false depending on whether event is under a fermata Attribute domains (all integers):  (a) {0,1,2,...}(b) {60,...,75}(c) {1,...,16}(d) {-4,...,+4}(e) {12,16}(f) {0,1}","Conklin, Darrell and Witten, Ian.  1995.  Multiple Viewpoint Systems for Music Prediction.  Journal of New Music Research.  24(1):51-73.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Matthew Brand. An Entropic Estimator for Structure Discovery. NIPS. 1998.  [View Context].Matthew Brand. Pattern discovery via entropy minimization. MERL -- A MITSUBISHI ELECTRIC RESEARCH LABORATORY. 1998.  [View Context].Zoubin Ghahramani and Michael I. Jordan. Factorial Hidden Markov Models. Machine Learning, 29. 1997.  [View Context].Mohammed Waleed Kadous and Claude Sammut. The University of New South Wales School of Computer Science and Engineering Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series.  [View Context].Mohammed Waleed Kadous. Expanding the Scope of Concept Learning Using Metafeatures. School of Computer Science and Engineering, University of New South Wales.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/GNFUV+Unmanned+Surface+Vehicles+Sensor+Data+Set+2,211,GNFUV Unmanned Surface Vehicles Sensor Data Set 2 Data Set,../machine-learning-databases/00466/,"Multivariate, Sequential, Time-Series",10190,Computer,Real,6,9/13/2018,Regression,Yes,9780,"Dr Christos Anagnostopoulos; School of Computing Science, University of Glasgow; email: christos.anagnostopoulos '@' glasgow.ac.uk; G12 8QQ Scotland, UK. (NETLAB Group: https://netlab.dcs.gla.ac.uk/) ","The data-set comprises 2 x (4) sets of mobile sensor readings data (humidity, temperature) from four (4) Raspberry Pi's corresponding to a swarm of four (4) Unmanned Surface Vehicles (USVs). Each USV set contains records of the format: {'Device'; 'humidity-value'; 'temperature-value'; 'experiment-id';'sensing-time','Pi'}. The swarm of the USVs is moving according to a GPS pre-defined trajectory. The USVs are floating over the sea surface in a coastal area of Athens (Greece). More information: [Web Link]","Attributes: 'device' = USV ID (String) 'humidity' = sensed humidity value from the USV sensor (real value) 'temperature' = sensed temperature value from the USV sensor (real value) 'experiment' = 1 (constant real value) 'time' = the sensing and reporting time (real value)'pi' = Raspberry Pi ID","Please cite one of the following papers: [1] Harth, N. and Anagnostopoulos, C. (2018) Edge-centric Efficient Regression Analytics. In: 2018 IEEE International Conference on Edge Computing (EDGE), San Francisco, CA, USA, 02-07 Jul 2018 [2] Harth, N., Anagnostopoulos, C., (2017) Quality-aware Aggregation & Predictive Analytics at the Edge. IEEE International Conference on Big Data (IEEE Big Data 2017), December 11-14, 2017, Boston, MA, USA","Please cite one of the following papers: [1] Harth, N. Anagnostopoulos, C. (2018) Edge-centric Efficient Regression Analytics. In: 2018 IEEE International Conference on Edge Computing (EDGE), San Francisco, CA, USA, 02-07 Jul 2018 [2] Harth, N., Anagnostopoulos, C., (2017) Quality-aware Aggregation & Predictive Analytics at the Edge. IEEE International Conference on Big Data (IEEE Big Data 2017), December 11-14, 2017, Boston, MA, USA.",
http://archive.ics.uci.edu/ml/datasets/Ionosphere,212,Ionosphere Data Set,../machine-learning-databases/ionosphere/,Multivariate,351,Physical,"Integer, Real",34,1/1/1989,Classification,No,231746,"Donor:  Vince Sigillito (vgs '@' aplcen.apl.jhu.edu) Source:  Space Physics GroupApplied Physics LaboratoryJohns Hopkins UniversityJohns Hopkins RoadLaurel, MD 20723 ","This radar data was collected by a system in Goose Bay, Labrador.  This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts.  See the paper for more details.  The targets were free electrons in the ionosphere. ""Good"" radar returns are those showing evidence of some type of structure in the ionosphere.  ""Bad"" returns are those that do not; their signals pass through the ionosphere.   Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number.  There were 17 pulse numbers for the Goose Bay system.  Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.","-- All 34 are continuous-- The 35th attribute is either ""good"" or ""bad"" according to the definition summarized above.  This is a binary classification task.","Sigillito, V. G., Wing, S. P., Hutton, L. V., \& Baker, K. B. (1989). Classification of radar returns from the ionosphere using neural networks. Johns Hopkins APL Technical Digest, 10, 262-266.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Hyunsoo Kim and Se Hyun Park. Data Reduction in Support Vector Machines by a Kernelized Ionic Interaction Model. SDM. 2004.  [View Context].Glenn Fung and M. Murat Dundar and Jinbo Bi and Bharat Rao. A fast iterative algorithm for fisher discriminant using heterogeneous kernels. ICML. 2004.  [View Context].Predrag Radivojac and Zoran Obradovic and A. Keith Dunker and Slobodan Vucetic. Feature Selection Filters Based on the Permutation Test. ECML. 2004.  [View Context].Jeroen Eggermont and Joost N. Kok and Walter A. Kosters. Genetic Programming for data classification: partitioning the search space. SAC. 2004.  [View Context].Jennifer G. Dy and Carla Brodley. Feature Selection for Unsupervised Learning. Journal of Machine Learning Research, 5. 2004.  [View Context].Mikhail Bilenko and Sugato Basu and Raymond J. Mooney. Integrating constraints and metric learning in semi-supervised clustering. ICML. 2004.  [View Context].Zhi-Hua Zhou and Yuan Jiang. NeC4.5: Neural Ensemble Based C4.5. IEEE Trans. Knowl. Data Eng, 16. 2004.  [View Context].Dmitriy Fradkin and David Madigan. Experiments with random projections for machine learning. KDD. 2003.  [View Context].Michael L. Raymer and Travis E. Doom and Leslie A. Kuhn and William F. Punch. Knowledge discovery in medical and biological datasets using a hybrid Bayes classifier/evolutionary algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B, 33. 2003.  [View Context].Marina Skurichina and Ludmila Kuncheva and Robert P W Duin. Bagging and Boosting for the Nearest Mean Classifier: Effects of Sample Size on Diversity and Accuracy. Multiple Classifier Systems. 2002.  [View Context].Robert Burbidge and Matthew Trotter and Bernard F. Buxton and Sean B. Holden. STAR - Sparsity through Automated Rejection. IWANN (1). 2001.  [View Context].P. S and Bradley K. P and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso and Henrik Bostrom. Boosting Interval Based Literals. 2000.  [View Context].Colin Campbell and Nello Cristianini and Alex J. Smola. Query Learning with Large Margin Classifiers. ICML. 2000.  [View Context].Marina Skurichina and Robert P W Duin. Boosting in Linear Discriminant Analysis. Multiple Classifier Systems. 2000.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Improved Generalization Through Explicit Optimization of Margins. Machine Learning, 38. 2000.  [View Context].Justin Bradley and Kristin P. Bennett and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Jennifer G. Dy and Carla Brodley. Feature Subset Selection and Order Identification for Unsupervised Learning. ICML. 2000.  [View Context].Art B. Owen. Tubular neighbors for regression and classification. Stanford University. 1999.  [View Context].Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining. Institute of Information Science. 1999.  [View Context].Lorne Mason and Jonathan Baxter and Peter L. Bartlett and Marcus Frean. Boosting Algorithms as Gradient Descent. NIPS. 1999.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Stephen D. Bay. Nearest neighbor classification from multiple feature subsets. Intell. Data Anal, 3. 1999.  [View Context].Stavros J. Perantonis and Vassilis Virvilis. Input Feature Extraction for Multilayered Perceptrons Using Supervised Principal Component Analysis. Neural Processing Letters, 10. 1999.  [View Context].David M J Tax and Robert P W Duin. Support vector domain description. Pattern Recognition Letters, 20. 1999.  [View Context].Robert E. Schapire and Yoav Freund and Peter Bartlett and Wee Sun Lee. The Annals of Statistics, to appear. Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods. AT&T Labs. 1998.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Direct Optimization of Margins Improves Generalization in Combined Classifiers. NIPS. 1998.  [View Context].Richard Maclin. Boosting Classifiers Regionally. AAAI/IAAI. 1998.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. A Parametric Optimization Method for Machine Learning. INFORMS Journal on Computing, 9. 1997.  [View Context].Aynur Akkus and H. Altay Güvenir. K Nearest Neighbor Classification on Feature Projections. ICML. 1996.  [View Context].Alain Rakotomamonjy. Leave-One-Out errors in Bipartite Ranking SVM. PSI CNRS FRE2645 INSA de Rouen Avenue de l'universite.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski. Meta-learning: searching in the model space. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Federico Divina and Elena Marchiori. Knowledge-Based Evolutionary Search for Inductive Concept Learning. Vrije Universiteit of Amsterdam.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context].K. A. J Doherty and Rolf Adams and Neil Davey. Unsupervised Learning with Normalised Data and Non-Euclidean Norms. University of Hertfordshire.  [View Context].Michael Lindenbaum and Shaul Markovitch and Dmitry Rusakov. Selective Sampling Using Random Field Modelling.  [View Context].Christos Emmanouilidis and Anthony Hunter. A Comparison of Crossover Operators in Neural Network Feature Selection with Multiobjective Evolutionary Algorithms. Centre for Adaptive Systems, School of Computing, Engineering and Technology University of Sunderland.  [View Context].Chiranjib Bhattacharyya and Pannagadatta K. S and Alexander J. Smola. A Second order Cone Programming Formulation for Classifying Missing Data. Department of Computer Science and Automation Indian Institute of Science.  [View Context].Perry Moerland. Mixtures of latent variable models for density estimation and classification. E S E A R C H R E P R O R T I D I A P D a l l e M o l l e I n s t i t u t e f o r Pe r cep t ua l A r t i f i c i a l Intelligence .  [View Context].Markus Breitenbach and Rodney Nielsen and Gregory Z. Grudic. Probabilistic Random Forests: Predicting Data Point Specific Misclassification Probabilities. Department of Computer Science University of Colorado.  [View Context].Federico Divina and Elena Marchiori. Handling Continuous Attributes in an Evolutionary Inductive Learner. Department of Computer Science Vrije Universiteit.  [View Context].Glenn Fung and Sathyakama Sandilya and R. Bharat Rao. Rule extraction from Linear Support Vector Machines. Computer-Aided Diagnosis & Therapy, Siemens Medical Solutions, Inc.  [View Context].Karthik Ramakrishnan. UNIVERSITY OF MINNESOTA.  [View Context].Michalis K. Titsias and Aristidis Likas. Shared Kernel Models for Class Conditional Density Estimation.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski and Geerd H. F Diercksen. Minimal distance neural methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Andrew Watkins and Jon Timmis and Lois C. Boggess. Artificial Immune Recognition System (AIRS): An ImmuneInspired Supervised Learning Algorithm. (abw5,jt6@kent.ac.uk) Computing Laboratory, University of Kent.  [View Context].Aynur Akku and H. Altay Guvenir. Weighting Features in k Nearest Neighbor Classification on Feature Projections. Department of Computer Engineering and Information Science Bilkent University.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. THE SEPARABILITY OF SPLIT VALUE CRITERION. Department of Computer Methods, Nicolaus Copernicus University.  [View Context].Christos Emmanouilidis and A. Hunter and Dr J. MacIntyre. A Multiobjective Evolutionary Setting for Feature Selection and a Commonality-Based Crossover Operator. Centre for Adaptive Systems, School of Computing, Engineering and Technology University of Sunderland.  [View Context].Chiranjib Bhattacharyya. Robust Classification of noisy data using Second Order Cone Programming approach. Dept. Computer Science and Automation, Indian Institute of Science.  [View Context].Ayhan Demiriz and Kristin P. Bennett. Chapter 1 OPTIMIZATIONAPPROACHESTOSEMI-SUPERVISED LEARNING. Department of Decision Sciences and Engineering Systems & Department of Mathematical Sciences, Rensselaer Polytechnic Institute.  [View Context].Isabelle Alvarez and Stephan Bernard. Ranking Cases with Decision Trees: a Geometric Method that Preserves Intelligibility.  [View Context].Christos Dimitrakakis and Samy Bengioy. Online Policy Adaptation for Ensemble Classifiers. IDIAP.  [View Context].Rajesh Parekh and Jihoon Yang and Vasant Honavar. Constructive Neural-Network Learning Algorithms for Pattern Classification.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc,213,UJIIndoorLoc Data Set,../machine-learning-databases/00310/,Multivariate,21048,Computer,"Integer, Real",529,9/18/2014,"Classification, Regression",N/A,97057,"Donors/Contact Joaquín Torres-Sospedra jtorres +@+ uji.es Raul Montoliu montoliu +@+ uji.es Adolfo Martínez-Usó admarus +@+ upv.es Joaquín Huerta huerta +@+ uji.es UJI - Institute of New Imaging Technologies, Universitat Jaume I, Avda. Vicente Sos Baynat S/N, 12071, Castellón, Spain. UPV - Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, Valencia, Spain. Creators Joaquín Torres-Sospedra, Raul Montoliu, Adolfo Martínez-Usó, Tomar J. Arnau, Joan P. Avariento, Mauri Benedito-Bordonau, Joaquín Huerta, Yasmina Andreu, óscar Belmonte, Vicent Castelló, Irene Garcia-Martí, Diego Gargallo, Carlos Gonzalez, Nadal Francisco, Josep López, Ruben Martínez, Roberto Mediero, Javier Ortells, Nacho Piqueras, Ianisse Quizán, David Rambla, Luis E. Rodríguez, Eva Salvador Balaguer, Ana Sanchís, Carlos Serra, and Sergi Trilles.","Many real world applications need to know the localization of a user in the world to provide their services. Therefore, automatic user localization has been a hot research topic in the last years. Automatic user localization consists of estimating the position of the user (latitude, longitude and altitude) by using an electronic device, usually a mobile phone. Outdoor localization problem can be solved very accurately thanks to the inclusion of GPS sensors into the mobile devices. However, indoor localization is still an open problem mainly due to the loss of GPS signal in indoor environments. Although, there are some indoor positioning technologies and methodologies, this database is focused on WLAN fingerprint-based ones (also know as WiFi Fingerprinting). Although there are many papers in the literature trying to solve the indoor localization problem using a WLAN fingerprint-based method, there still exists one important drawback in this field which is the lack of a common database for comparison purposes. So, UJIIndoorLoc database is presented to overcome this gap. We expect that the proposed database will become the reference database to compare different indoor localization methodologies based on WiFi fingerprinting. The UJIIndoorLoc database covers three buildings of Universitat Jaume I with 4 or more floors and almost 110.000m2. It can be used for classification, e.g. actual building and floor identification, or regression, e.g. actual longitude and latitude estimation. It was created in 2013 by means of more than 20 different users and 25 Android devices. The database consists of 19937 training/reference records (trainingData.csv file) and 1111 validation/test records (validationData.csv file). The 529 attributes contain the WiFi fingerprint, the coordinates where it was taken, and other useful information. Each WiFi fingerprint can be characterized by the detected Wireless Access Points (WAPs) and the corresponding Received Signal Strength Intensity (RSSI). The intensity values are represented as negative integer values ranging -104dBm (extremely poor signal) to 0dbM. The positive value 100 is used to denote when a WAP was not detected. During the database creation, 520 different WAPs were detected. Thus, the WiFi fingerprint is composed by 520 intensity values. Then the coordinates (latitude, longitude, floor) and Building ID are provided as the attributes to be predicted.  Additional information has been provided. The particular space (offices, labs, etc.) and the relative position (inside/outside the space) where the capture was taken have been recorded. Outside means that the capture was taken in front of the door of the space. Information about who (user), how (android device & version) and when (timestamp) WiFi capture was taken is also recorded.   ","Attribute 001 (WAP001): Intensity value for WAP001. Negative integer values from -104 to 0 and +100. Positive value 100 used if WAP001 was not detected.....Attribute 520 (WAP520): Intensity value for WAP520. Negative integer values from -104 to 0 and +100. Positive Vvalue 100 used if WAP520 was not detected.Attribute 521 (Longitude): Longitude. Negative real values from -7695.9387549299299000 to -7299.786516730871000Attribute 522 (Latitude): Latitude. Positive real values from 4864745.7450159714 to 4865017.3646842018.Attribute 523 (Floor): Altitude in floors inside the building. Integer values from 0 to 4.Attribute 524 (BuildingID): ID to identify the building. Measures were taken in three different buildings. Categorical integer values from 0 to 2.Attribute 525 (SpaceID): Internal ID number to identify the Space (office, corridor, classroom) where the capture was taken. Categorical integer values.Attribute 526 (RelativePosition): Relative position with respect to the Space (1 - Inside, 2 - Outside in Front of the door). Categorical integer values. Attribute 527 (UserID): User identifier (see below). Categorical integer values. Attribute 528 (PhoneID): Android device identifier (see below). Categorical integer values.  Attribute 529 (Timestamp): UNIX Time when the capture was taken. Integer value.   ---------------------------------------------UserID Anonymized user           Height (cm)---------------------------------------------0     USER0000 (Validation User) N/A1     USER0001                   1702     USER0002                   1763     USER0003                   1724     USER0004                   1745     USER0005                   1846     USER0006                   1807     USER0007                   1608     USER0008                   1769     USER0009                   17710    USER0010                   18611    USER0011                   17612    USER0012                   15813    USER0013                   17414    USER0014                   17315    USER0015                   17416    USER0016                   17117    USER0017                   16618    USER0018                   162---------------------------------------------- ----------------------------------------------PhoneID  Android Device      Android Ver. UserID----------------------------------------------0        Celkon A27          4.0.4(6577)  01        GT-I8160            2.3.6        82        GT-I8160            4.1.2        03        GT-I9100            4.0.4        54        GT-I9300            4.1.2        05        GT-I9505            4.2.2        06        GT-S5360            2.3.6        77        GT-S6500            2.3.6        148        Galaxy Nexus        4.2.2        109        Galaxy Nexus        4.3          010       HTC Desire HD       2.3.5        1811       HTC One             4.1.2        1512       HTC One             4.2.2        013       HTC Wildfire S      2.3.5        0,1114       LT22i               4.0.4        0,1,9,1615       LT22i               4.1.2        016       LT26i               4.0.4        317       M1005D              4.0.4        1318       MT11i               2.3.4        419       Nexus 4             4.2.2        620       Nexus 4             4.3          021       Nexus S             4.1.2        022       Orange Monte Carlo  2.3.5        1723       Transformer TF101   4.0.3        224       bq Curie            4.1.1        12----------------------------------------------","Joaquín Torres-Sospedra, Raúl Montoliu, Adolfo Martínez-Usó, Tomar J. Arnau, Joan P. Avariento, Mauri Benedito-Bordonau, Joaquín Huerta UJIIndoorLoc: A New Multi-building and Multi-floor Database for WLAN Fingerprint-based Indoor Localization Problems In Proceedings of the Fifth International Conference on Indoor Positioning and Indoor Navigation, 2014.Available at: [Web Link]","Joaquín Torres-Sospedra, Raúl Montoliu, Adolfo Martínez-Usó, Tomar J. Arnau, Joan P. Avariento, Mauri Benedito-Bordonau, Joaquín Huerta UJIIndoorLoc: A New Multi-building and Multi-floor Database for WLAN Fingerprint-based Indoor Localization Problems In Proceedings of the Fifth International Conference on Indoor Positioning and Indoor Navigation, 2014.Available at: [Web Link]",
http://archive.ics.uci.edu/ml/datasets/Dresses_Attribute_Sales,214,Dresses_Attribute_Sales Data Set,../machine-learning-databases/00289/,Text,501,Computer,N/A,13,2/19/2014,"Classification, Clustering",Yes,109679,"Muhammad Usman & Adeel Ahmed, usman.madspot '@' gmail.com adeel.ahmed92 '@' gmail.com, Air University, Students at Air University.","Style,	Price,	Rating,	Size,	Season,	NeckLine,	SleeveLength,	waiseline,	Material,	FabricType,	Decoration,	Pattern, Type,	Recommendation are Attributes in dataset.","Style: Bohemia,brief,casual,cute,fashion,flare,novelty,OL,party,sexy,vintage,work.Price:Low,Average,Medium,High,Very-HighRating:1-5Size:S,M,L,XL,Free	Season:Autumn,winter,Spring,SummerNeckLine:O-neck,backless,board-neck,Bowneck,halter,mandarin-collor,open,peterpan-collor,ruffled,scoop,slash-neck,square-collar,sweetheart,turndowncollar,V-neck.SleeveLength:full,half,halfsleeves,butterfly,sleveless,short,threequarter,turndown,nullwaiseline:dropped,empire,natural,princess,null.	Material:wool,cotton,mix etc	FabricType:shafoon,dobby,popline,satin,knitted,jersey,flannel,corduroy etcDecoration:applique,beading,bow,button,cascading,crystal,draped,embroridary,feathers,flowers etcPattern type: solid,animal,dot,leapard etcRecommendation:0,1",Null,"If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Taxi+Service+Trajectory+-+Prediction+Challenge%2C+ECML+PKDD+2015,215,"Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015 Data Set",../machine-learning-databases/00339/,"Multivariate, Sequential, Time-Series, Domain-Theory",1710671,Computer,Real,9,7/11/2015,"Clustering, Causal-Discovery",Yes,81736,Challenge Chair: Luis Moreira-MatiasSteering Committee: - Michel Ferreira - Joao Mendes-Moreiratst.challenge '@' ecmlpkdd2015.orghttp://www.geolink.pt/ecmlpkdd2015-challenge/whoweare.html,"For complete information see the official challenge page:[Web Link]","Each data sample corresponds to one completed trip. It contains a total of 9 (nine) features, described as follows:TRIP_ID: (String) It contains a unique identifier for each trip;CALL_TYPE: (char) It identifies the way used to demand this service. It may contain one of three possible values:  - 'A' if this trip was dispatched from the central;  - 'B' if this trip was demanded directly to a taxi driver at a specific stand;  - 'C' otherwise (i.e. a trip demanded on a random street).ORIGIN_CALL: (integer) It contains a unique identifier for each phone number which was used to demand, at least, one service. It identifies the trip's customer if CALL_TYPE='A'. Otherwise, it assumes a NULL value;ORIGIN_STAND: (integer): It contains a unique identifier for the taxi stand. It identifies the starting point of the trip if CALL_TYPE='B'. Otherwise, it assumes a NULL value;TAXI_ID: (integer): It contains a unique identifier for the taxi driver that performed each trip;TIMESTAMP: (integer) Unix Timestamp (in seconds). It identifies the trip's start;DAYTYPE: (char) It identifies the daytype of the trip's start. It assumes one of three possible values:  - 'B' if this trip started on a holiday or any other special day (i.e. extending holidays, floating holidays, etc.);  - 'C' if the trip started on a day before a type-B day;  - 'A' otherwise (i.e. a normal day, workday or weekend).IMPORTANT NOTICE: This field has not been correctly calculated. Please see the following links as reliable sources for official holidays in Portugal.[Web Link][Web Link]MISSING_DATA: (Boolean) It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing;POLYLINE: (String): It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The last list item corresponds to the trip's destination while the first one represents its start.","Moreira-Matias L., Gama J., Ferreira M., Mendes-Moreira J. and Damas L.,: ""Time-Evolving OD Matrix Estimation using high-speed GPS data streams"". In: Expert Systems with Applications, vol. 44, pp. 275-288, February (2016) Moreira-Matias, L., Gama, J., Ferreira, M., Mendes-Moreira, J., Damas, L., ”Predicting Taxi–Passenger Demand Using Streaming Data”. In: IEEE Transactions on Intelligent Transportation Systems, vol.14, no.3, pp.1393-1402, September (2013)","Moreira-Matias, L., Gama, J., Ferreira, M., Mendes-Moreira, J., Damas, L., ”Predicting Taxi–Passenger Demand Using Streaming Data”. In: IEEE Transactions on Intelligent Transportation Systems, vol.14, no.3, pp.1393-1402, September (2013)",
http://archive.ics.uci.edu/ml/datasets/IDA2016Challenge,216,IDA2016Challenge Data Set,../machine-learning-databases/00414/,Multivariate,76000,Computer,Integer,171,1/17/2017,Classification,Yes,16487,"-- Creator: Scania CV AB               VagnmakarvÃ¤gen 1                151 32 SÃ¶dertÃ¤lje                Stockholm               Sweden    -- Donor:   Tony Lindgren (tony '@' dsv.su.se) and Jonas Biteus (jonas.biteus '@' scania.com)   -- Date:    September, 2016","This file is part of APS Failure and Operational Data for Scania Trucks. Copyright (c) <2016>   This program (APS Failure and Operational Data for Scania Trucks) is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version. This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details. You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <[Web Link]>. ------------------------------------------------------------------------ 1. Title: APS Failure at Scania Trucks 2. Source Information   -- Creator: Scania CV AB               VagnmakarvÃ¤gen 1                151 32 SÃ¶dertÃ¤lje                Stockholm               Sweden    -- Donor:   Tony Lindgren (tony '@' dsv.su.se) and Jonas Biteus (jonas.biteus '@' scania.com)   -- Date:    September, 2016 3. Past Usage:   Industrial Challenge 2016 at The 15th International Symposium on Intelligent Data Analysis (IDA)    -- Results:              The top three contestants                                                | Score | Number of Type 1 faults | Number of Type 2 faults     ------------------------------------------------------------------------------------------------------------------------------------     Camila F. Costa and Mario A. Nascimento                                  | 9920  | 542                     | 9     Christopher Gondek, Daniel Hafner and Oliver R. Sampson                  | 10900 | 490                     | 12     Sumeet Garnaik, Sushovan Das, Rama Syamala Sreepada and Bidyut Kr. Patra | 11480 | 398                     | 15 4. Relevant Information:   -- Introduction     The dataset consists of data collected from heavy Scania      trucks in everyday usage. The system in focus is the      Air Pressure system (APS) which generates pressurised      air that are utilized in various functions in a truck,      such as braking and gear changes. The datasets'      positive class consists of component failures      for a specific component of the APS system.      The negative class consists of trucks with failures      for components not related to the APS. The data consists      of a subset of all available data, selected by experts.     -- Challenge metric        Cost-metric of miss-classification:      Predicted class |      True class       |                     |    pos    |    neg    |     -----------------------------------------      pos            |     -     |  Cost_1   |     -----------------------------------------      neg            |  Cost_2   |     -     |     -----------------------------------------     Cost_1 = 10 and cost_2 = 500      The total cost of a prediction model the sum of 'Cost_1'      multiplied by the number of Instances with type 1 failure      and 'Cost_2' with the number of instances with type 2 failure,      resulting in a 'Total_cost'.      In this case Cost_1 refers to the cost that an unnessecary      check needs to be done by an mechanic at an workshop, while      Cost_2 refer to the cost of missing a faulty truck,      which may cause a breakdown.      Total_cost = Cost_1*No_Instances + Cost_2*No_Instances. 5. Number of Instances:      The training set contains 60000 examples in total in which      59000 belong to the negative class and 1000 positive class.      The test set contains 16000 examples.  6. Number of Attributes: 171  7. Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:     bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20     |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20   The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'."," The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:     bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20     |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20 The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like 'Identifier_Bin'.In total there are 171 attributes, of which 7 are histogram variabels. Missing values are denoted by 'na'."," Industrial Challenge 2016 at The 15th International Symposium on Intelligent Data Analysis (IDA)    -- Results:              The top three contestants                                                | Score | Number of Type 1 faults | Number of Type 2 faults     ------------------------------------------------------------------------------------------------------------------------------------     Camila F. Costa and Mario A. Nascimento                                  | 9920  | 542                     | 9     Christopher Gondek, Daniel Hafner and Oliver R. Sampson                  | 10900 | 490                     | 12     Sumeet Garnaik, Sushovan Das, Rama Syamala Sreepada and Bidyut Kr. Patra | 11480 | 398                     | 15","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Travel+Reviews,217,Travel Reviews Data Set,../machine-learning-databases/00484/,"Multivariate, Text",980,N/A,Real,11,12/19/2018,"Classification, Clustering",N/A,70477,"Shini Renjith, shinirenjith '@' gmail.com","This data set is populated by crawling TripAdvisor.com. Reviews on destinations in 10 categories mentioned across East Asia are considered. Each traveler rating is mapped as Excellent (4), Very Good (3), Average (2), Poor (1), and Terrible (0) and average rating is used against each category per user.","Attribute 1 : Unique user idAttribute 2 : Average user feedback on art galleriesAttribute 3 : Average user feedback on dance clubsAttribute 4 : Average user feedback on juice barsAttribute 5 : Average user feedback on restaurantsAttribute 6 : Average user feedback on museumsAttribute 7 : Average user feedback on resortsAttribute 8 : Average user feedback on parks/picnic spotsAttribute 9 : Average user feedback on beachesAttribute 10 : Average user feedback on theatersAttribute 11 : Average user feedback on religious institutions","Renjith, Shini, A. Sreekumar, and M. Jathavedan. 2018. â€œEvaluation of Partitioning Clustering Algorithms for Processing Social Media Data in Tourism Domainâ€. In 2018 IEEE Recent Advances in Intelligent Computational Systems (RAICS), 127â€“31. IEEE.","Renjith, Shini, A. Sreekumar, and M. Jathavedan. 2018. â€œEvaluation of Partitioning Clustering Algorithms for Processing Social Media Data in Tourism Domainâ€. In 2018 IEEE Recent Advances in Intelligent Computational Systems (RAICS), 127â€“31. IEEE.",
http://archive.ics.uci.edu/ml/datasets/QSAR+Bioconcentration+classes+dataset,218,QSAR Bioconcentration classes dataset Data Set,../machine-learning-databases/00510/,Multivariate,779,Life,N/A,14,10/11/2019,"Classification, Regression",N/A,5677,"Francesca Grisoni (francesca.grisoni '@' unimib.it), Viviana Consonni (viviana.consonni '@' unimib.it), Marco Vighi, Sara Villa, Roberto Todeschini ","A dataset of manually-curated BCF for 779 chemicals was used to determine the mechanisms of bioconcentration, i.e. to predict whether a chemical: (1) is mainly stored within lipid tissues, (2) has additional storage sites (e.g. proteins), or (3) is metabolized/eliminated. Data were randomly split into a training set of 584 compounds (75%) and a test set of 195 compounds (25%), preserving the proportion between the classes. Two QSAR classification trees were developed using CART (Classification and Regression Trees) machine learning technique coupled with Genetic Algorithms. The file contains the selected Dragon descriptors (9) along with CAS, SMILES, experimental BCF, experimental/predicted KOW and mechanistic class (1, 2, 3). Further details on model development and performance along with descriptor definitions and interpretation are provided in the original manuscript (Grisoni et al., 2016).","3 Compound identifiers:- CAS number- Molecular SMILES- Train/test splitting 9 molecular descriptors (independent variables)- nHM- piPC09- PCD	- X2Av- MLOGP- ON1V- N-072	- B02[C-N]- F04[C-O] 2 experimental responses:- Bioconcentration Factor (BCF) in log units (regression)- Bioaccumulation class (three classes)","F. Grisoni, V.Consonni, M.Vighi, S.Villa, R.Todeschini (2016). Investigating the mechanisms of bioconcentration through QSAR classification trees, Environment International, 88, 198-205","The dataset is freeware and may be used if proper reference is given to the authors. Please, refer to the following papers:F. Grisoni, V.Consonni, M.Vighi, S.Villa, R.Todeschini (2016). Investigating the mechanisms of bioconcentration through QSAR classification trees, Environment International, 88, 198-205.F. Grisoni, V. Consonni, S. Villa, M. Vighi, R. Todeschini (2015). QSAR models for bioconcentration: Is the increase in the complexity justified by more accurate predictions?. Chemosphere, 127,  171-179.",
http://archive.ics.uci.edu/ml/datasets/Letter+Recognition,219,Letter Recognition Data Set,../machine-learning-databases/letter-recognition/,Multivariate,20000,Computer,Integer,16,1/1/1991,Classification,No,391541,"Creator:  David J. SlateOdesta Corporation; 1890 Maple Ave; Suite 115; Evanston, IL 60201 Donor:  David J. Slate (dave '@' math.nwu.edu) (708) 491-3867   ","The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet.  The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli.  Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15.  We typically train on the first 16000 items and then use the resulting model to predict the letter category for the remaining 4000.  See the article cited above for more details.","	 1.	lettr	capital letter	(26 values from A to Z)	 2.	x-box	horizontal position of box	(integer)	 3.	y-box	vertical position of box	(integer)	 4.	width	width of box			(integer)	 5.	high 	height of box			(integer)	 6.	onpix	total # on pixels		(integer)	 7.	x-bar	mean x of on pixels in box	(integer)	 8.	y-bar	mean y of on pixels in box	(integer)	 9.	x2bar	mean x variance			(integer)	10.	y2bar	mean y variance			(integer)	11.	xybar	mean x y correlation		(integer)	12.	x2ybr	mean of x * x * y		(integer)	13.	xy2br	mean of x * y * y		(integer)	14.	x-ege	mean edge count left to right	(integer)	15.	xegvy	correlation of x-ege with y	(integer)	16.	y-ege	mean edge count bottom to top	(integer)	17.	yegvx	correlation of y-ege with x	(integer)","P. W. Frey and D. J. Slate. ""Letter Recognition Using Holland-style Adaptive Classifiers"". (Machine Learning Vol 6 #2 March 91)[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Jaakko Peltonen and Arto Klami and Samuel Kaski. Improved Learning of Riemannian Metrics for Exploratory Analysis. Improved Learning of Riemannian Metrics for Exploratory Analysis. Neural Networks. 2004.  [View Context].Xiaoli Z. Fern and Carla Brodley. Cluster Ensembles for High Dimensional Clustering: An Empirical Study. Journal of Machine Learning Research n, a. 2004.  [View Context].Giorgio Valentini. Ensemble methods based on bias--variance analysis Theses Series DISI-TH-2003. Dipartimento di Informatica e Scienze dell'Informazione . 2003.  [View Context].Dmitry Pavlov and Alexandrin Popescul and David M. Pennock and Lyle H. Ungar. Mixtures of Conditional Maximum Entropy Models. ICML. 2003.  [View Context].Kristin P. Bennett and Ayhan Demiriz and Richard Maclin. Exploiting unlabeled data in ensemble methods. KDD. 2002.  [View Context].Stephen D. Bay. Nearest neighbor classification from multiple feature subsets. Intell. Data Anal, 3. 1999.  [View Context].Thomas G. Dietterich. Approximate Statistical Test For Comparing Supervised Classification Learning Algorithms. Neural Computation, 10. 1998.  [View Context].Georgios Paliouras and David S. Brée. The Effect of Numeric Features on the Scalability of Inductive Learning Programs. ECML. 1995.  [View Context].Thomas G. Dietterich and Ghulum Bakiri. Solving Multiclass Learning Problems via Error-Correcting Output Codes. CoRR, csAI/9501101. 1995.  [View Context].Shailesh Kumar and Melba Crawford and Joydeep Ghosh. A versatile framework for labelling imagery with a large number of classes. Department of Electrical and Computer Engineering.  [View Context].Amund Tveit. Empirical Comparison of Accuracy and Performance for the MIPSVM classifier with Existing Classifiers. Division of Intelligent Systems Department of Computer and Information Science, Norwegian University of Science and Technology.  [View Context].Hirotaka Inoue and Hiroyuki Narihisa. Incremental Learning with Self-Organizing Neural Grove. Department of Electrical Engineering and Information Science, Kure National College of Technology.  [View Context].Jaakko Peltonen and Arto Klami and Samuel Kaski. Learning Metrics for Information Visualization. Neural Networks Research Centre Helsinki University of Technology.  [View Context].Adil M. Bagirov and Julien Ugon. An algorithm for computation of piecewise linear function separating two sets. CIAO, School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Miguel Moreira and Alain Hertz and Eddy Mayoraz. Data binarization by discriminant elimination. Proceedings of the ICML-99 Workshop: From Machine Learning to.  [View Context].Arto Klami and Samuel Kaski and Ty n ohjaaja and Janne Sinkkonen. HELSINKI UNIVERSITY OF TECHNOLOGY Department of Engineering Physics and Mathematics Arto Klami Regularized Discriminative Clustering. Regularized Discriminative Clustering.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data,220,Polish companies bankruptcy data Data Set,../machine-learning-databases/00365/,Multivariate,10503,Business,Real,64,4/11/2016,Classification,Yes,104739,"Creator: Sebastian Tomczak -- Department of Operations Research, WrocÅ‚aw University of Science and Technology, wybrzeÅ¼e WyspiaÅ„skiego 27, 50-370, WrocÅ‚aw, Poland Donor: Sebastian Tomczak (sebastian.tomczak '@' pwr.edu.pl), Maciej Zieba (maciej.zieba '@' pwr.edu.pl), Jakub M. Tomczak (jakub.tomczak '@' pwr.edu.pl), Tel. (+48) 71 320 44 53 ","The dataset is about bankruptcy prediction of Polish companies. The data was collected from Emerging Markets Information Service (EMIS, [Web Link]), which is a database containing information on emerging markets around the world. The bankrupt companies were analyzed in the period 2000-2012, while the still operating companies were evaluated from 2007 to 2013.Basing on the collected data five classification cases were distinguished, that depends on the forecasting period:- 1stYear â€“ the data contains financial rates from 1st year of the forecasting period and corresponding class label that indicates bankruptcy status after 5 years. The data contains 7027 instances (financial statements), 271 represents bankrupted companies, 6756 firms that did not bankrupt in the forecasting period.- 2ndYear â€“ the data contains financial rates from 2nd year of the forecasting period and corresponding class label that indicates bankruptcy status after 4 years. The data contains 10173 instances (financial statements), 400 represents bankrupted companies, 9773 firms that did not bankrupt in the forecasting period.- 3rdYear â€“ the data contains financial rates from 3rd year of the forecasting period and corresponding class label that indicates bankruptcy status after 3 years. The data contains 10503 instances (financial statements), 495 represents bankrupted companies, 10008 firms that did not bankrupt in the forecasting period.- 4thYear â€“ the data contains financial rates from 4th year of the forecasting period and corresponding class label that indicates bankruptcy status after 2 years. The data contains 9792 instances (financial statements), 515 represents bankrupted companies, 9277 firms that did not bankrupt in the forecasting period.- 5thYear â€“ the data contains financial rates from 5th year of the forecasting period and corresponding class label that indicates bankruptcy status after 1 year. The data contains 5910 instances (financial statements), 410 represents bankrupted companies, 5500 firms that did not bankrupt in the forecasting period.","X1	net profit / total assetsX2	total liabilities / total assetsX3	working capital / total assetsX4	current assets / short-term liabilitiesX5	[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365X6	retained earnings / total assetsX7	EBIT / total assetsX8	book value of equity / total liabilitiesX9	sales / total assetsX10	equity / total assetsX11	(gross profit + extraordinary items + financial expenses) / total assetsX12	gross profit / short-term liabilitiesX13	(gross profit + depreciation) / salesX14	(gross profit + interest) / total assetsX15	(total liabilities * 365) / (gross profit + depreciation)X16	(gross profit + depreciation) / total liabilitiesX17	total assets / total liabilitiesX18	gross profit / total assetsX19	gross profit / salesX20	(inventory * 365) / salesX21	sales (n) / sales (n-1)X22	profit on operating activities / total assetsX23	net profit / salesX24	gross profit (in 3 years) / total assetsX25	(equity - share capital) / total assetsX26	(net profit + depreciation) / total liabilitiesX27	profit on operating activities / financial expensesX28	working capital / fixed assetsX29	logarithm of total assetsX30	(total liabilities - cash) / salesX31	(gross profit + interest) / salesX32	(current liabilities * 365) / cost of products soldX33	operating expenses / short-term liabilitiesX34	operating expenses / total liabilitiesX35	profit on sales / total assetsX36	total sales / total assetsX37	(current assets - inventories) / long-term liabilitiesX38	constant capital / total assetsX39	profit on sales / salesX40	(current assets - inventory - receivables) / short-term liabilitiesX41	total liabilities / ((profit on operating activities + depreciation) * (12/365))X42	profit on operating activities / salesX43	rotation receivables + inventory turnover in daysX44	(receivables * 365) / salesX45	net profit / inventoryX46	(current assets - inventory) / short-term liabilitiesX47	(inventory * 365) / cost of products soldX48	EBITDA (profit on operating activities - depreciation) / total assetsX49	EBITDA (profit on operating activities - depreciation) / salesX50	current assets / total liabilitiesX51	short-term liabilities / total assetsX52	(short-term liabilities * 365) / cost of products sold)X53	equity / fixed assetsX54	constant capital / fixed assetsX55	working capitalX56	(sales - cost of products sold) / salesX57	(current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)X58	total costs /total salesX59	long-term liabilities / equityX60	sales / inventoryX61	sales / receivablesX62	(short-term liabilities *365) / salesX63	sales / short-term liabilitiesX64	sales / fixed assets","Zieba, M., Tomczak, S. K., & Tomczak, J. M. (2016). Ensemble Boosted Trees with Synthetic Features Generation in Application to Bankruptcy Prediction. Expert Systems with Applications. [Web Link]","Zieba, M., Tomczak, S. K., & Tomczak, J. M. (2016). Ensemble Boosted Trees with Synthetic Features Generation in Application to Bankruptcy Prediction. Expert Systems with Applications. [Web Link]  BibTeX: @article{zikeba2016ensemble,  title={Ensemble Boosted Trees with Synthetic Features Generation in Application to Bankruptcy Prediction},  author={Zi{k{e}}ba, Maciej and Tomczak, Sebastian K and Tomczak, Jakub M},  journal={Expert Systems with Applications},  year={2016},  publisher={Elsevier}}",
http://archive.ics.uci.edu/ml/datasets/Simulated+Falls+and+Daily+Living+Activities+Data+Set,221,Simulated Falls and Daily Living Activities Data Set Data Set,../machine-learning-databases/00455/,Time-Series,3060,Life,Integer,138,6/6/2018,Classification,Yes,79305,"Ahmet Turan Ã–zdemirPhone: +90 352 207 6666 (int 32233)Addr: Erciyes University, Electrical and Electronic Department, TR 38039, Melikgazi/Kayseri/Turkeyaturan '@' erciyes.edu.tr www.aturan.com  Billur BarshanPhone: +90 312 290 2161Addr: Bilkent University, Electrical and Electronic Department, TR 06800, Bilkent/Ankara/Turkeyhttp://kilyos.ee.bilkent.edu.tr/~billur/ billur '@' ee.bilkent.edu.tr ",Provide all relevant information about your data set.,Provide information about each attribute in your data set.,"[1] Ozdemir, A.T.; Barshan, B. “Detecting Falls with Wearable Sensors Using Machine Learning Techniques.”, Sensors 2014, 14, 10691-10708.[2] Ozdemir A.T., Orman A., ' Developing an iPhone smartphone based fall detection algorithm.', IEEE, 23rd Signal Processing and Communications Applications Conference (SIU), Malatya, Turkey, 16-19 May 2015, pp.1-4.[3] Ozdemir A.T., 'An Analysis on Sensor Locations of the Human Body for Wearable Fall Detection Devices: Principles and Practice.', Sensors 2016, 16, 11691.[4] Ntanasis P., Pippa E., Ozdemir A.T., Barshan B., Megalooikonomou V., 'Investigation of sensor placement for accurate fall detection', 6th EAI International Conference on Wireless Mobile Communication and Healthcare (MobiHealth), Milan, Italy, 14-16 Nov. 2016, pp.1-6","Ã–zdemir, A.T.; Barshan, B. â€œDetecting Falls with Wearable Sensors Using Machine Learning Techniques.â€, Sensors 2014, 14, 10691-10708.",
http://archive.ics.uci.edu/ml/datasets/Behavior+of+the+urban+traffic+of+the+city+of+Sao+Paulo+in+Brazil,222,Behavior of the urban traffic of the city of Sao Paulo in Brazil Data Set,../machine-learning-databases/00483/,"Multivariate, Time-Series",135,Computer,"Integer, Real",18,12/12/2018,"Classification, Regression",N/A,46554,"Creators original owner and donors: Ricardo Pinto Ferreira (1), Andrea Martiniano (2) and Renato Jose Sassi (3). E-mail address: log.kasparov'@'gmail.com (1) - PhD student;andrea.martiniano'@'gmail.com (2) - PhD student;sassi'@'uni9.pro.br (3) - Prof. Doctor. Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management. Address: Rua Vergueiro, 235/249 Liberdade, Sao Paulo, SP, Brazil. Zip code: 01504-001. Website: http://www.uninove.br/curso/informatica-e-gestao-do-conhecimento/","The database was created with records of behavior of the urban traffic of the city of Sao Paulo in Brazil from December 14, 2009 to December 18, 2009 (From Monday to Friday). Registered from 7:00 to 20:00 every 30 minutes. The data set Behavior of the urban traffic of the city of Sao Paulo in Brazil was used in academic research at the Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management.","1.	Hour2.	Immobilized bus3.	Broken Truck4.	Vehicle excess5.	Accident victim6.	Running over7.	Fire Vehicles8.	Occurrence involving freight9.	Incident involving dangerous freight10.	Lack of electricity11.	Fire12.	Point of flooding13.	Manifestations14.	Defect in the network of trolleybuses15.	Tree on the road16.	Semaphore off17.	Intermittent Semaphore18.	Slowness in traffic (%) (Target) .arff header for Weka: @relation Behavior@attribute Hour {7:00, 7:30, 8:00, 8:30, 9:00, 9:30, 10:00, 10:30, 11:00, 11:30, 12:00, 12:30, 13:00, 13:30, 14:00, 14:30, 15:00, 15:30, 16:00, 16:30, 17:00, 17:30, 18:00, 18:30, 19:00, 19:30, 20:00}@attribute Immobilized_bus INTEGER@attribute Broken_Truck INTEGER@attribute Vehicle_excess INTEGER@attribute Accident_victim INTEGER@attribute Running_over INTEGER@attribute Fire_vehicles INTEGER@attribute Occurrence_involving_freight INTEGER@attribute Incident_involving_dangerous_freight INTEGER@attribute Lack_of_electricity INTEGER@attribute Fire INTEGER@attribute Point_of_flooding INTEGER@attribute Manifestations INTEGER@attribute Defect_in_the_network_of_trolleybuses INTEGER@attribute Tree_on_the_road INTEGER@attribute Semaphore_off INTEGER@attribute Intermittent_Semaphore INTEGER@attribute Slowness_in_traffic_percent REAL","Sassi, R. J., Affonso, C., & Ferreira, R. P. (2011, August). Rough Neuro-Fuzzy Network Applied to Traffic Flow Breakdown in the City of Sao Paulo. In Management and Service Science (MASS), International Conference on (pp. 1-5). IEEE, 2011. Affonso, C., Sassi, R. J., & Ferreira, R. P. (2011, July). Traffic flow breakdown prediction using feature reduction through rough-neuro fuzzy networks. In Neural Networks (IJCNN), The International Joint Conference Neural Networks (pp. 1943-1947). IEEE, 2011. Ferreira, R. P., Affonso, C., & Sassi, R. J. (2011, November). Combination of Artificial Intelligence Techniques for Prediction the Behavior of Urban Vehicular Traffic in the City of SÃ£o Paulo. In 10th Brazilian Congress on Computational Intelligence (CBICâ€™2011) - Fortaleza, CearÃ¡ â€“ Brazil. (pp.1-7), 2011. Ferreira, R. P., Affonso, C., & Sassi, R. J. (2010, June). Application of a neuro fuzzy network to forecast the behavior of the urban traffic of the city of SÃ£o Paulo. In Information Systems and Technologies (CISTI), 2010 5th Iberian Conference on (pp. 1-4). IEEE, 2010.","Ferreira, R. P., Affonso, C., & Sassi, R. J. (2011, November). Combination of Artificial Intelligence Techniques for Prediction the Behavior of Urban Vehicular Traffic in the City of SÃ£o Paulo. In 10th Brazilian Congress on Computational Intelligence (CBIC) - Fortaleza, CearÃ¡ â€“ Brazil. (pp.1-7), 2011.",
http://archive.ics.uci.edu/ml/datasets/Detect+Malacious+Executable%28AntiVirus%29,223,Detect Malacious Executable(AntiVirus) Data Set,../machine-learning-databases/00355/,Multivariate,373,Computer,Real,513,3/3/2016,Classification,Yes,256103,"Piyush Anasta Rumao,UnderGrad Computer Engineer from Fr.Conceicao Rodrigues College of Enginerring,Bandra,Mumbai,University of Mumbai, email:- piyushrumao '@' gmail.com phone- +91-7387712196 / +91-8554041806you can call / mail me anytime regarding any query or to know more about working model of antivrius that I can created.","TRAINING File : I have created training file with 100+ non malacious examples and 250+ malacious samples. NON-MALACIOUS dataset is represented by +1 while MALACIOUS datset     is represented by -1 as label. Based on comparison and analysis I have selected 500 most commonly occuring features in MALACIOUS and NON-MALACIOUS file and compared extracted features of each file with this best features. The file is saved with .train extension. TESTING file: We select a unknown malacious executable and carry out same procedure on it ( however we can put it in any class +1/ -1) cuz svmpredict will any way corretly find it for us. We save this testing file with .test extension. ","For best results I have used Hybrid Features ( hexdump and DLL) from an executable. After extracting this features I find out the top 500 hex features and top 13 DLL features which are most commonly occuring and prepare file with best features.Now feature amoung this which are found in individual file is been stated in dataset along with 1 while rest are ignored and feature set ends with -1  ie say ( +1 2:1 5:1 45:1 .............. -1)  so here +1 states a NON-malacious file while 2:1 states 2nd feature exists similarly for 5,45 while features which do not occur are simply ignored.For MALACIOUS executable we write it as ( -1 6:1 56:1 ............ -1)so Attribute which exists is given a  colon 1 ahead of it (:1)  ","my project is been done based on paper published byA hybrid Model to detect malacious executable( using data mining and machine learning concept) by -- MM Masud , Latifur Khan, Bhavani Thuraisingham ","I found no dataSet on AntiVirus techniques which is need of hour.So I hope you encourage this work.Looking forward for positive response.",
http://archive.ics.uci.edu/ml/datasets/Physicochemical+Properties+of+Protein+Tertiary+Structure,224,Physicochemical Properties of Protein Tertiary Structure Data Set,../machine-learning-databases/00265/,Multivariate,45730,Life,Real,9,3/31/2013,Regression,N/A,54975,"Prashant Singh Rana, psrana '@' gmail.com, ABV - Indian Institute of Information Technology & Management, Gwalior, MP, India.",Provide all relevant information about your data set.,"RMSD-Size of the residue.F1 - Total surface area.F2 - Non polar exposed area.F3 - Fractional area of exposed non polar residue.F4 - Fractional area of exposed non polar part of residue.F5 - Molecular mass weighted exposed area.F6 - Average deviation from standard exposed area of residue.F7 - Euclidian distance.F8 - Secondary structure penalty.F9 - Spacial Distribution constraints (N,K Value).",N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29,225,Census-Income (KDD) Data Set,../machine-learning-databases/census-income-mld/,Multivariate,299285,Social,"Categorical, Integer",40,3/7/2000,Classification,Yes,174212,"Original Owner: U.S. Census Bureauhttp://www.census.gov/ United States Department of Commerce Donor: Terran Lane and Ronny KohaviData Mining and VisualizationSilicon Graphics.terran '@' ecn.purdue.edu, ronnyk '@' sgi.com  ","This data set contains weighted census data extracted from the 1994 and 1995 Current Population Surveys conducted by the U.S. Census Bureau. The data contains 41 demographic and employment related variables.  The instance weight indicates the number of people in the population that each record represents due to stratified sampling. To do real analysis and derive conclusions, this field must be used. This attribute should *not* be used in the classifiers.  One instance per line with comma delimited fields. There are 199523 instances in the data file and 99762 in the test file.  The data was split into train/test in approximately 2/3, 1/3 proportions using MineSet's MIndUtil mineset-to-mlc. ","More information detailing the meaning of the attributes can be found in the Census Bureau's documentation To make use of the data descriptions at this site, the following mappings to the Census Bureau's internal database column names will be needed:  age						AAGEclass of worker					ACLSWKRindustry code					ADTINDoccupation code					ADTOCCadjusted gross income				AGIeducation					AHGAwage per hour					AHRSPAYenrolled in edu inst last wk			AHSCOLmarital status					AMARITLmajor industry code				AMJINDmajor occupation code				AMJOCCmace						ARACEhispanic Origin					AREORGNsex						ASEXmember of a labor union				AUNMEMreason for unemployment				AUNTYPEfull or part time employment stat		AWKSTATcapital gains					CAPGAINcapital losses					CAPLOSSdivdends from stocks				DIVVALfederal income tax liability			FEDTAXtax filer status				FILESTATregion of previous residence			GRINREGstate of previous residence			GRINSTdetailed household and family stat		HHDFMXdetailed household summary in household		HHDRELinstance weight					MARSUPWTmigration code-change in msa			MIGMTR1migration code-change in reg			MIGMTR3migration code-move within reg			MIGMTR4live in this house 1 year ago			MIGSAMEmigration prev res in sunbelt			MIGSUNnum persons worked for employer			NOEMPfamily members under 18				PARENTtotal person earnings				PEARNVALcountry of birth father				PEFNTVTYcountry of birth mother				PEMNTVTYcountry of birth self				PENATVTYcitizenship					PRCITSHPtotal person income				PTOTVALown business or self employed			SEOTRtaxable income amount				TAXINCfill inc questionnaire for veteran's admin	VETQVAveterans benefits				VETYNweeks worked in year				WKSWORK Note that Incomes have been binned at the $50K level to present a binary classification problem, much like the original UCI/ADULT database. The goal field of this data, however, was drawn from the ""total person income"" field rather than the ""adjusted gross income"" and may, therefore, behave differently than the orginal ADULT goal field. ",N/A,"Please refer to the Machine Learning
Repository's citation policy","Eibe Frank and Geoffrey Holmes and Richard Kirkby and Mark A. Hall. Racing Committees for Large Datasets. Discovery Science. 2002.  [View Context].Stephen D. Bay. Multivariate Discretization for Set Mining. Knowl. Inf. Syst, 3. 2001.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Masahiro Terabe and Takashi Washio and Hiroshi Motoda. The Effect of Subsampling Rate on S 3 Bagging Performance. Mitsubishi Research Institute.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/PM2.5+Data+of+Five+Chinese+Cities,226,PM2.5 Data of Five Chinese Cities Data Set,../machine-learning-databases/00394/,"Multivariate, Time-Series",52854,Physical,"Integer, Real",86,7/18/2017,Regression,Yes,83868,"Song Xi Chen, csx '@' gsm.pku.edu.cn, Guanghua School of Management, Center for Statistical Science, Peking University.","The time period is between Jan 1st, 2010 to Dec 31st, 2015. Missing data are denoted as NA. ","No: row number year: year of data in this row month: month of data in this row day: day of data in this row hour: hour of data in this row season: season of data in this rowPM: PM2.5 concentration (ug/m^3) DEWP: Dew Point (Celsius Degree)TEMP: Temperature (Celsius Degree)HUMI: Humidity (%)PRES: Pressure (hPa) cbwd: Combined wind direction Iws: Cumulated wind speed (m/s) precipitation: hourly precipitation (mm)Iprec: Cumulated precipitation (mm)","Liang, X., S. Li, S. Zhang, H. Huang, and S. X. Chen (2016), PM2.5 data reliability, consistency, and air quality assessment in five Chinese cities, J. Geophys. Res. Atmos., 121, 10220â€“10236, [Web Link].","Liang, X., S. Li, S. Zhang, H. Huang, and S. X. Chen (2016), PM2.5 data reliability, consistency, and air quality assessment in five Chinese cities, J. Geophys. Res. Atmos., 121, 10220â€“10236, [Web Link].",
http://archive.ics.uci.edu/ml/datasets/seeds,227,seeds Data Set,../machine-learning-databases/00236/,Multivariate,210,Life,Real,7,9/29/2012,"Classification, Clustering",N/A,307657,"MaÅ‚gorzata Charytanowicz, Jerzy NiewczasInstitute of Mathematics and Computer Science,The John Paul II Catholic University of Lublin, KonstantynÃ³w 1 H,PL 20-708 Lublin, Polande-mail: {mchmat,jniewczas}@kul.lublin.pl Piotr Kulczycki, Piotr A. Kowalski, Szymon Lukasik, Slawomir ZakDepartment of Automatic Control and Information Technology,Cracow University of Technology, Warszawska 24, PL 31-155 Cracow, PolandandSystems Research Institute, Polish Academy of Sciences, Newelska 6,PL 01-447 Warsaw, Polande-mail: {kulczycki,pakowal,slukasik,slzak}@ibspan.waw.pl","The examined group comprised kernels belonging to three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected forthe experiment. High quality visualization of the internal kernel structure was detected using a soft X-ray technique. It is non-destructive and considerably cheaper than other more sophisticated imaging techniques like scanning microscopy or laser technology. The images were recorded on 13x18 cm X-ray KODAK plates. Studies were conducted using combine harvested wheat grain originating from experimental fields, explored at the Institute of Agrophysics of the Polish Academy of Sciences in Lublin. The data set can be used for the tasks of classification and cluster analysis.","To construct the data, seven geometric parameters of wheat kernels were measured: 1. area A, 2. perimeter P, 3. compactness C = 4*pi*A/P^2, 4. length of kernel,5. width of kernel,6. asymmetry coefficient7. length of kernel groove.All of these parameters were real-valued continuous.","M. Charytanowicz, J. Niewczas, P. Kulczycki, P.A. Kowalski, S. Lukasik, S. Zak, 'A Complete Gradient Clustering Algorithm for Features Analysis of X-ray Images', in: Information Technologies in Biomedicine, Ewa Pietka, Jacek Kawa (eds.), Springer-Verlag, Berlin-Heidelberg, 2010, pp. 15-24. ",Contributors gratefully acknowledge support of their work by the Institute of Agrophysics of the Polish Academy of Sciences in Lublin.,
http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+from+Continuous+Ambient+Sensor+Data,228,Human Activity Recognition from Continuous Ambient Sensor Data Data Set,../machine-learning-databases/00506/,"Multivariate, Sequential, Time-Series",13956534,N/A,"Integer, Real",37,9/20/2019,Classification,Yes,22345,"-- Creators: Diane J. Cook, Aaron S. Crandall, and Brian L. Thomas    -- School of Electrical Engineering and Computer Science,       Voiland College of Engineering and Architecture,       Washington State University-- Donor: Diane J. Cook (djcook '@' wsu.edu) (509-335-4985)          School of Electrical Engineering and Computer Science          EME 121 Spokane Street          Box 642752          Washington State University          Pullman, WA 99164-2752","4. Relevant Information    -- Data Set Characteristics: Multivariate, Sequential, Time-Series    -- This dataset represents ambient data collected in homes with volunteer residents.       Data are collected continuously while residents perform their normal routines.       Ambient PIR motion sensors, door/temperature sensors, and light switch sensors       are placed throughout the home of the volunteer.  The sensors are placed in locations       throughout the home that are related to specific activites of daily living that we       wish to capture.    -- The classification task is to predict the activity that is occurring in the smart       home and being observed by the ambient sensors.  The sensors communicate using the       ZigBee Pro protocol, forming a mesh network with all battery powered sensors as leaf       nodes and always-on devices (light switches and ZigBee relays) forming the branches       that connect back to the USB gateway on our local SHiB [2] server.    -- The original format captured from the sensors is provided, as well as the feature       vector we generate using a sliding window of 30 sensor events.  Each annotated data       file (ex: csh101/csh101.ann.txt) has a corresponding feature vector CSV file       (ex: csh101/csh101.ann.features.csv).  Most of the sensor data files contain labels       for two months of the collection period, though some contain labels for extended       time periods.    -- We have also included the entire dataset collected at each smart home in the original       format (ex: csh101/csh101.rawdata.txt) and the generated feature vector CSV file       (ex: csh101/csh101.rawdata.features.csv).    -- An analysis of the attributes for each features CSV file is found in the corresponding       readme (ex: csh101/csh101.ann.features.csv is described by       csh101/csh101.ann.features.README.txt).    -- The smart home layout, and sensor placement from the original formats is found       in the included sensor map for each smart home (ex: csh101/csh101.sensor_map.png).    -- The original format is:                 --  is YYYY-MM-DD, in local time.        --  is HH:[Web Link], 24-hour and in local time.        --  is the name of the sensor, this can be found on the sensor map.        --  is the room-level sensor location.        --  is more detailed, usually identifying what in the room the sensor           is aimed at or sensing.        --  is the message generated by the sensor (we define these in more detail           below).        --  is the type of sensor generating the event, so you know what to           expect for a message.  In these earlier smart homes many of the sensors could           be identified by their name, but in later configurations you had to use this           field to identify what sensor was sending the message.        -- Motion Sensor Package           Each motion sensor package contains a PIR motion detector and a resistive photocell           light sensor. The package also reports it's battery level and regularly checks           in with the sensor network (ZigBee Check-Ins).            -- Control4-Motion and Control4-MotionArea               Most motion sensors have a sticker in the lens that limits what it can see               to approximately a 3-foot diameter circle when mounted on the ceiling facing               down. Some motion sensors that do not have any sticker limiting their view               are called Control4-MotionArea and can detect motion within view, though               sensitivity to smaller body movements may be reduced beyond 20 feet.                -- Message Values                   Motion and MotionArea sensors always report ON or OFF.                -- Frequency                   The sensor will instantly send an ON message when detecting motion.                   1.25 seconds after it no longer observes motion the sensor will send OFF.            -- Control4-LightSensor                -- Message Values                   The light sensor will send integer values ranging from 0 to 100 (pitch                   black to very bright). The Motion sensors with stickers in the lens have                   a much more limited amount of light that hits the sensor, and may only                   observe a range from 0 to 10, with a rare spike to a much higher value                   when the lid is removed to replace a battery.                -- Frequency                   The current light level is bit-packed and sent with every message the                   package sends on ZigBee, but the light sensor itself can initiate a ZigBee                   message if the value changes by 15% from the last value it reported.            -- Control4-BatteryPercent                -- Message Values                   The battery percent is always an integer ranging from 0 to 100.                -- Frequency                   The battery levels are only allowed to report once every 6 hours, but                   only report when there is a change.  This means that some battery values                   may not be updated for days as the level has not changed.            -- Control4-Radio               These sensor messages were enabled when we upgraded our data collection systems               around 2014.                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 30 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.        -- Door Sensor Package            -- Control4-Door                -- Message Values                   The door sensor always report OPEN or CLOSE.                -- Frequency                   The sensor sends the message as soon as the magnetic reed switch changes.            -- Control4-Temperature               All door sensor packages have an internal temporature sensor, and the ability               to attach a second temperature probe.  This was used in some of the bathrooms               for measuring the temperature at the door and right next to the shower.                -- Message Values                   Messages are a decimal in Celsius with 0.5 degrees Celsius accuracy.                -- Frequency                   Messages are sent when the sensor detects a change in the measured                   temperature by 0.5 Celsius.            -- Control4-BatteryPercent                -- Message Values                   The battery percent is always an integer ranging from 0 to 100.                -- Frequency                   The battery levels are only allowed to report once every 6 hours, but                   only report when there is a change.  This means that some battery values                   may not be updated for days as the level has not changed.            -- Control4-Radio                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 30 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.        -- Light Switch Package            -- Control4-Light                -- Message Values                   Light switch messages are integer values ranging from 0 to 100.  Some of                   the lights are dimmers, they report the change in value from 0 to 100 as                   they ramp up their brightness.  The switches simply report 0 or 100 when                   they turn off or on.                -- Frequency                   The light switches only report light messages when the value changes.            -- Control4-Button               With the data collection upgrade in 2014 we were able to start collecting               sensor events from residents interacting with the light switches.                -- Message Values                   The buttons have a variety of messages they send.  TAP is sent every time                   the button is pressed.  When the button is doing being tapped, the button                   will send TAP_COUNT_01 if the button was tapped once (we have observed                   tap counts as high as 12, but do not know the limit of the device).                   On the dimmer light switches there are also the DEPRESS and RELEASE messages                   that are sent then the button is held down to slowly dim the light up                   or down.                -- Frequency                   Messages are only sent with a participant interacts with the button.            -- Control4-Radio                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 15 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.","This has a full breakdown for each file in the zip.7. For Each Attribute:--------------------------------------------------------------------------------    lastSensorEventHours    (integer)  Hour of the day, in local time.--------------------------------------------------------------------------------    lastSensorEventSeconds    (decimal)  Seconds since midnight, in local time.--------------------------------------------------------------------------------    lastSensorDayOfWeek    (symbolic-valued integer)  Integer day of the week, in local time.--------------------------------------------------------------------------------    windowDuration    (decimal)  Time duration of the 30 event sliding window in seconds.--------------------------------------------------------------------------------    timeSinceLastSensorEvent    (decimal)  Seconds since the last sensor event.--------------------------------------------------------------------------------    prevDominantSensor1    (symbolic-valued integer)  Dominant sensor ID from the previous window.--------------------------------------------------------------------------------    prevDominantSensor2    (symbolic-valued integer)  Dominant sensor ID from the second previous window.--------------------------------------------------------------------------------    lastSensorID    (symbolic-valued integer)  Last sensor ID in the window.--------------------------------------------------------------------------------    lastSensorLocation    (symbolic-valued integer)  Last sensor location ID in the window.--------------------------------------------------------------------------------    lastMotionLocation    (symbolic-valued integer)  Last motion sensor location ID in the window, can be -1 if none within the sliding window.--------------------------------------------------------------------------------    complexity    (decimal)  Complexity or measure of entropy in sensor counts.--------------------------------------------------------------------------------    activityChange    (decimal)  Change in activity levels between 2 halves of the sliding window, bisected temporally.--------------------------------------------------------------------------------    areaTransitions    (integer)  Number of transitions between major sensor locations in the window.--------------------------------------------------------------------------------    numDistinctSensors    (integer)  Number of distinct sensors in the window, this is currently set to always 0.--------------------------------------------------------------------------------    sensorCount-Bathroom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Bedroom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Chair    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-DiningRoom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Hall    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Ignore    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Kitchen    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-LivingRoom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Office    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-OutsideDoor    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-WorkArea    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorElTime-Bathroom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Bedroom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Chair    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-DiningRoom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Hall    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Ignore    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Kitchen    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-LivingRoom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Office    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-OutsideDoor    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-WorkArea    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    activity    (class label)  The annotated activity that is currently being observed.","3. Past Usage:  [Web Link]     -- Relevant Papers:        -- [1] D. Cook, N. Krishnan, and P. Rashidi. Activity discovery and activity               recognition: A new partnership. IEEE Transactions on Systems, Man, and                Cybernetics, Part B, 43(3):820-828, 2013.        -- [2] D. Cook, A. Crandall, B. Thomas, and N. Krishnan. CASAS: A smart home in               a box. IEEE Computer, 46(6):26-33, 2013.        -- [3] D. Cook.  Learning setting-generalized activity models for smart spaces.               IEEE Intelligent Systems, 27(1):32-38, 2012.    -- Citation Request:        -- D. Cook.  Learning setting-generalized activity models for smart spaces.           IEEE Intelligent Systems, 27(1):32-38, 2012.","-- Citation Request:    -- D. Cook.  Learning setting-generalized activity models for smart spaces.       IEEE Intelligent Systems, 27(1):32-38, 2012.",
http://archive.ics.uci.edu/ml/datasets/chipseq,229,chipseq Data Set,../machine-learning-databases/00439/,Sequential,4960,Life,Integer,N/A,2/21/2018,Classification,N/A,20770,"Toby Dylan Hockingtoby.hocking '@' mail.mcgill.ca McGill University","These data are significant because they are among the first to providelabels that formalize the genome-wide peak detection problem, which isa very important problem for biomedical / epigenomics researchers. These labels can be used to train and test supervisedpeak detection algorithms, as explained below. The data are in problem directories such as data/&ltSET&gt/samples/&ltGROUP&gt/&ltSAMPLE&gt/problems/&ltPROBLEM&gt Each problem directory contains two files, labels.bed (weak labels)and coverage.bedGraph.gz (inputs).  Each coverage.bedGraph.gz file represents a vector of non-negativeinteger count data, one entry for each genomic position in a subset ofthe human genome hg19. For example data/H3K9me3_TDH_BP/samples/tcell/ERS358697/problems/chr8:48135599-86500000/coverage.bedGraph.gz represents a vector defined on all genomic positions from 48135600 to86500000 on chr8 (for a particular tcell sample named ERS358697, inthe H3K9me3_TDH_BP data set). To save disk space the vectors are savedusing a run-length encoding; for example the first three lines of thisfile are chr8	48135599	48135625	0chr8	48135625	48135629	1chr8	48135629	48135632	2 which mean that the first 26 entries of the vector are 0, the nextfour entries are 1, and the following three entries are 2. Note thatstart positions are 0-based but end positions are 1-based, so thefirst line means a 0 from all positions from 48135600 to 48135625(excluding the start position 48135599 for which we have noinformation). The goal is to learn a function that takes the coverage.bedGraph.gzfile as input, and outputs a binary classification for every genomicposition. The positive class represents peaks (typically large counts)and the negative class represents background noise (typically smallcounts). Weak labels are given in labels.bed files, each of which indicatesseveral regions of the genome with or without peaks. For example thefile data/H3K4me3_XJ_immune/samples/bcell/McGill0091/problems/chr1:30028082-103863906/labels.bed contains the 6 labels below: chr1	33111786	33114894	noPeakschr1	33114941	33116174	peakStartchr1	33116183	33116620	peakEndchr1	33116633	33116755	noPeakschr1	33116834	33118135	peakschr1	33118161	33120163	noPeaks The four labels are interpreted as follows: noPeaks: all of the predictions in this region should be negative /background noise. For example the first line in the file above meansthat for a vector x_i of count data from i=30028083 to i=103863906,the desired function should predict negative / background noisef(x_i)=0 from i=33111787 to i=33114894. If positive / peaks arepredicted f(x_i)=1 for any i in this region, that is counted as afalse positive label. peakStart: there should be exactly one peak start predicted in thisregion. A peak start is defined as a position i such that a peak ispredicted there f(x_i)=1 but not at the previous positionf(x_{i-1})=0. The exact position is unspecified; any position is fine,as long as there is only one start in the region. Predicting exactlyone peak start in this region results in a true positive. More startsis a false positive, and fewer starts is a false negative. Forexample,  [peakStart] 0 0 0 1 1 1 1 -> correct.  0 0 1 1 1 1 1 -> also correct.  0 0 0 0 0 0 0 -> false negative (no peak starts).0 0 1 0 1 1 1 -> flase positive (two peak starts). peakEnd: there should be exactly one peak end predicted in thisregion. A peak end is defined as a position i such that a peak ispredicted there f(x_i)=1 but not at the next position f(x_{i+1})=0.The exact position is unspecified; any position is fine, as long asthere is only one end in the region. Predicting exactly one peak endin this region results in a true positive. More ends is a falsepositive, and fewer ends is a false negative. For example,  [ peakEnd ] 1 1 1 1 0 0 0 -> correct.  1 1 1 1 1 0 0 -> also correct.  0 0 0 0 0 0 0 -> false negative (no peak ends).1 1 1 0 1 0 0 -> flase positive (two peak ends). peaks: there should be at least one peak predicted somewhere in thisregion (anywhere is fine). Zero predicted peaks in this region is afalse negative. If there is a predicted peak somewhere in this regionthat is a true positive. For a particular set of predicted peaks f(x), the total number ofincorrect labels (false positives + false negatives) can be computedas an evaluation metric (smaller is better). Typically the peakpredictions are also stored using a run-length encoding; the errorrates can be computed using the reference implementation in R packagePeakError, [Web Link]  Receiver Operating Characteristic curves can be computed for a familyof predicted peaks f_lambda(x), where lambda is some significancethreshold, intercept parameter, etc. Compute the TPR and FPR as follows: TPR = (total number of true positives)/(total number of labels that could have a true positive) = (number of correct peaks, peakStart, peakEnd labels)/(number of peaks, peakStart, peakEnd labels) FPR = (total number of false positives)/(total number of labels that could have a false positive) = (number of peakStart/End labels with two or more predicted starts/end + number of noPeaks labels with predicted peaks)/(number of peakStart, peakEnd, and noPeaks labels) Suggested fold ID numbers for four-fold cross-validation experimentscan be found in data/*/folds.csv files. For exampledata/H3K36me3_TDH_[Web Link] contains problem,foldchr16:8686921-32000000,1chr16:60000-8636921,1chr21:43005559-44632664,2chr14:19050000-107289540,3chr15:29209443-77800000,4 which means that problems chr16:8686921-32000000 andchr16:60000-8636921 should be considered fold ID 1,chr21:43005559-44632664 should be considered fold ID 2, etc. Thismeans that for data set H3K36me3_TDH_other, the fold ID 2 consists ofall data indata/H3K36me3_TDH_other/samples/*/*/problems/chr21:43005559-44632664directories. There are several types of learning settings that could be used withthese data. Here are four examples. Unsupervised learning. Train models only using thecoverage.bedGraph.gz files. Only use the labels for evaluation (notfor training model parameters). Supervised learning. Train models only using the coverage.bedGraph.gzand labels.bed files in the train set. Use the labels in the test setto evaluate prediction accuracy. Semi-supervised learning. Train models using the coverage.bedGraph.gzand labels.bed files in the train set. You can additionally use thecoverage.bedGraph.gz files in the test set at training time. Use thelabels in the test set to evaluate prediction accuracy. Multi-task learning. Many data sets come from different experimenttypes, so have different peak patterns. For example H3K4me3_TDH_immuneis a H3K4me3 histone modification (sharp peak pattern) andH3K36me3_TDH_immune is a H3K36me3 histone modification (broad peakpattern). Therefore it is not expected that models should generalizebetween data sets. However there is something common across data setsin that in each data set, the peak / positive class is large values,wheras the noise / negative class is small values. Thereforemulti-task learning may be interesting. To compare a multi-tasklearning model to a single-task learning model, use the suggestedcross-validation fold IDs. For test fold ID 1, train both themulti-task and single-task learning models using all other folds, thenmake predictions on all data with fold ID 1. ","Each attribute is a non-negative integer representing the number DNA sequence reads that has aligned at that particular region of the genome. Larger values are more likely to be peaks / positive, smaller values are more likely to be noise / negative.","The labeling method and details on how to compute the number of incorrect labels is described in Optimizing ChIP-seq peak detectors using visual labels and supervised machine learning.Toby Dylan Hocking, Patricia Goerner-Potvin, Andreanne Morin, Xiaojian Shao, Tomi Pastinen, Guillaume Bourque.Bioinformatics, Volume 33, Issue 4, 15 February 2017, Pages 491â€“499, [Web Link] ",Please cite the Bioinformatics paper above.,
http://archive.ics.uci.edu/ml/datasets/Sentence+Classification,230,Sentence Classification Data Set,../machine-learning-databases/00311/,Text,N/A,N/A,Integer,N/A,11/5/2014,Classification,N/A,75977,"America Chambers, ahollowa '@' ics.uci.edu, University of California, Irvine",Please see the README file that accompanies the data.,Please see the README file that accompanies the data. ,"A. Chambers. Statistical models for text classification: Applications and analysis, Ph.D., University of California, Irvine (2013). ProQuest Dissertations and Theses.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Deepfakes%3A+Medical+Image+Tamper+Detection,231,Deepfakes: Medical Image Tamper Detection Data Set,../machine-learning-databases/00520/,Multivariate,20000,Computer,Real,200000,3/11/2020,Classification,N/A,2160,"Yisroel Mirsky@post.bgu.ac.ilBen-Gurion University of the Negev","Attackers have the ability to intercept and add/remove medical evidence in medical imagery with high realism using deep learning. In this dataset we present medical deepfakes: 3D CT scans of human lungs, where some have been tampered with real cancer removed and with fake cancer injected. The objective of this dataset is to distinguish between real and fake cancers, and identify where medical scans have been tampered. Three expert radiologists have evaluated this dataset and could not reliably tell the difference between real and fake cancers, meaning that the fake cancers are realistic and this detection task is very challenging. For more information, please see our paper 'CT-GAN'.  The dataset consists of two sets (80 scans and 20 scans). The first 80 were used in a blind trial with the radiologists (they weren't told they were tampered), and the 20 scans were used in an open trial with the radiologists (they were told the truth and asked to identify them).  Provided with the scans is a table with the ground truth. For each scan, where a cancer is located (x, y, and z [slice#]) and its classification. A location can be classified as being:True-Benign, (TB): A location that actually has no cancer True-Malicious (TM): A location that has real cancerFalse-Benign (FB): A location that has real cancer, but it was removed.False-Malicious (FM): A location that does not have cancer, but fake cancer was injected there. Access to the dataset is via this link: [Web Link]","Each scan is in the medical dicom format, but it can be loaded as a 3D matrix with Python by using the tools provided in our code repository: [Web Link]  A scan is basically a series of 512x512 images. The series is usually about 100-300 slices long (the z axis). Cancers can occupy multiple slices along the z-axis.The value at each pixel is the Hounsfield unit (radiodensity) at that location.","[Web Link] Mirsky, Yisroel, et al. 'CT-GAN: Malicious tampering of 3D medical imagery using deep learning.' 28th {USENIX} Security Symposium ({USENIX} Security 19). 2019.[Web Link],11&hl=en","If you use this data, please cite:Mirsky, Yisroel, et al. 'CT-GAN: Malicious tampering of 3D medical imagery using deep learning.' 28th {USENIX} Security Symposium ({USENIX} Security 19). 2019. The original medical imagery is from:Armato III, Samuel G., McLennan, Geoffrey, Bidaut, Luc, McNitt-Gray, Michael F., Meyer, Charles R., Reeves, Anthony P., â€¦ Clarke, Laurence P. (2015). Data From LIDC-IDRI. The Cancer Imaging Archive. [Web Link] Published under the Creative Commons Attribution 3.0 Unported License ([Web Link])",
http://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set,232,One-hundred plant species leaves data set Data Set,../machine-learning-databases/00241/,N/A,1600,Life,Real,64,12/3/2012,Classification,N/A,71803,"James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.The colour images are not included in this submission.The Leaves were collected in the Royal Botanic Gardens, Kew, UK.email: james.cope '@' kingston.ac.uk  This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell. Kingston University London.Donor of database Charles Mallah: charles.mallah '@' kingston.ac.uk; James Cope: james.cope '@' kingston.ac.uk","For Each feature, a 64 element vector is given per sample of leaf. These vectors are taken as a contigous descriptors (for shape) or histograms (for texture and margin).","For Each feature, a 64 element vector is given per sample of leaf. One file for each 64-element feature vectors. Each row begins with the class label. The remaining 64 elements is the feature vector.","This is a new data set, provisional paper: 'Plant Leaf Classification Using  Probabilistic Integration of Shape, Texture and Margin Features' at SPPRA 2013. Authors: Charles Mallah, James Cope, and James Orwell or Kingston University London. Previous parts of the data set relate to feature extraction of leaves from: J. Cope, P. Remagnino, S. Barman, and P. Wilkin.Plant texture classification using gabor cooccurrences.Advances in Visual Computing,pages 669â€“677, 2010. T. Beghin, J. Cope, P. Remagnino, and S. Barman.Shape and texture based plant leaf classification. InAdvanced Concepts for Intelligent Vision Systems,pages 345â€“353. Springer, 2010.","Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.",
http://archive.ics.uci.edu/ml/datasets/Predict+keywords+activities+in+a+online+social+media,233,Predict keywords activities in a online social media Data Set,../machine-learning-databases/00276/,"Multivariate, Sequential, Time-Series",51,Computer,"Integer, Real",35,12/12/2013,N/A,N/A,45147,"François Kawala (1,2) Ahlame Douzal (1) Eric Gaussier (1) Eustache Diemert (2) Institutions :(1) Université Joseph Fourier (Grenoble I) - Laboratoire d'informatique de Grenoble (LIG) - Equipe AMA(2) TechMediaNetwork - www.techmedianetwork.comCorresponding author:François Kawala : francois.kawala '@' imag.fr / fkawala '@' techmedianetwork.com",See files and/or [Web Link],See files and/or [Web Link],"Apprentissage d’ordonnancement et influence de l’ambiguïté pour la prédiction d’activité sur les réseaux sociaux (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conférence en Recherche d'Infomations et Applications (CORIA), pp. 22, 2014.","Apprentissage d’ordonnancement et influence de l’ambiguïté pour la prédiction d’activité sur les réseaux sociaux (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conférence en Recherche d'Infomations et Applications (CORIA), pp. 22, 2014.",
http://archive.ics.uci.edu/ml/datasets/Autism+Screening+Adult,234,Autism Screening Adult Data Set,../machine-learning-databases/00426/,N/A,704,Social,Integer,21,12/24/2017,Classification,Yes,59277,"Fadi Fayez ThabtahDepartment of Digital TechnologyManukau Institute of Technology,Auckland, New Zealandfadi.fayez '@' manukau.ac.nz ",See attached variables' description file ,See attached variables' description file ,"1) Tabtah, F. (2017). Autism Spectrum Disorder Screening: Machine Learning Adaptation and DSM-5 Fulfillment. Proceedings of the 1st International Conference on Medical and Health Informatics 2017, pp.1-6. Taichung City, Taiwan, ACM.2) Thabtah, F. (2017). ASDTests. A mobile app for ASD screening. www.asdtests.com [accessed December  20th, 2017].3) Thabtah, F. (2017). Machine Learning in Autistic Spectrum Disorder Behavioural Research: A Review. To Appear in Informatics for Health and Social Care Journal. December, 2017 (in press)","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Thoracic+Surgery+Data,235,Thoracic Surgery Data Data Set,../machine-learning-databases/00277/,Multivariate,470,Life,"Integer, Real",17,11/13/2013,Classification,N/A,100717,"Creators: Marek Lubicz (1), Konrad Pawelczyk (2), Adam Rzechonek (2), Jerzy Kolodziej (2)  -- (1) Wroclaw University of Technology, wybrzeze Wyspianskiego 27, 50-370, Wroclaw, Poland  -- (2) Wroclaw Medical University, wybrzeze L. Pasteura 1, 50-367 Wroclaw, Poland Donor: Maciej Zieba (maciej.zieba '@' pwr.wroc.pl), Jakub M. Tomczak (jakub.tomczak '@' pwr.wroc.pl), (+48) 71 320 44 53    Date: November, 2013","The data was collected retrospectively at Wroclaw Thoracic Surgery Centre for patients who underwent major lung resections for primary lung cancer in the years 2007â€“2011. The Centre is associated with the Department of Thoracic Surgery of the Medical University of Wroclaw and Lower-Silesian Centre for Pulmonary Diseases, Poland, while the research database constitutes a part of the National Lung Cancer Registry, administered by the Institute of Tuberculosis and Pulmonary Diseases in Warsaw, Poland.","1. DGN: Diagnosis - specific combination of ICD-10 codes for primary and secondary as well multiple tumours if any (DGN3,DGN2,DGN4,DGN6,DGN5,DGN8,DGN1)2. PRE4: Forced vital capacity - FVC (numeric)3. PRE5: Volume that has been exhaled at the end of the first second of forced expiration - FEV1 (numeric)4. PRE6: Performance status - Zubrod scale (PRZ2,PRZ1,PRZ0)5. PRE7: Pain before surgery (T,F)6. PRE8: Haemoptysis before surgery (T,F)7. PRE9: Dyspnoea before surgery (T,F)8. PRE10: Cough before surgery (T,F)9. PRE11: Weakness before surgery (T,F)10. PRE14: T in clinical TNM - size of the original tumour, from OC11 (smallest) to OC14 (largest) (OC11,OC14,OC12,OC13)11. PRE17: Type 2 DM - diabetes mellitus (T,F)12. PRE19: MI up to 6 months (T,F)13. PRE25: PAD - peripheral arterial diseases (T,F)14. PRE30: Smoking (T,F)15. PRE32: Asthma (T,F)16. AGE: Age at surgery (numeric)17. Risk1Y: 1 year survival period - (T)rue value if died (T,F) Class Distribution: the class value (Risk1Y) is binary valued.   Risk1Y Value:   Number of Instances:	T                  70	N                  400 Summary Statistics: 	Binary Attributes Distribution:	   PRE7 Value:   Number of Instances:		T              	31		N             	439	   PRE8 Value:   Number of Instances:		T              	68		N             	402	   PRE9 Value:   Number of Instances:		T              	31		N             	439	   PRE10 Value:   Number of Instances:		T              	323		N             	147	   PRE11 Value:   Number of Instances:		T              	78		N             	392			   PRE17 Value:   Number of Instances:		T              	35		N             	435		   PRE19 Value:   Number of Instances:		T              	2		N             	468		   PRE25 Value:   Number of Instances:		T              	8		N             	462	   PRE30 Value:   Number of Instances:		T              	386		N             	84				   PRE32 Value:   Number of Instances:		T              	368		N             	2		 	Nominal Attributes Distribution:	   DGN Value:   Number of Instances:		DGN3           349		DGN2           52		DGN4           47		DGN6           4		DGN5           15		DGN8           2				DGN1           1		   PRE6 Value:   Number of Instances:		PRZ2           27		PRZ1           313		PRZ0           130	   PRE14 Value:   Number of Instances:		OC11           177		OC14           17		OC12           257		OC13           19 	Numeric Attributes Statistics:		     Min   Max   Mean    SD          PRE4:    1.4   6.3   3.3     0.9       PRE5:    0.96  86.3  4.6     11.8       AGE:     21    87    52.5    8.7","ZiÄ™ba, M., Tomczak, J. M., Lubicz, M., & ÅšwiÄ…tek, J. (2013). Boosted SVM for extracting rules from imbalanced data in application to prediction of the post-operative life expectancy in the lung cancer patients. Applied Soft Computing. [Web Link]  - Results:  -- Boosted SVM for for imbalanced data gained the Gmean value equal 0.657,   -- Decision rules induced using Boosted SVM as an oracle gained the Gmean value equal 0.648.","ZiÄ™ba, M., Tomczak, J. M., Lubicz, M., & ÅšwiÄ…tek, J. (2013). Boosted SVM for extracting rules from imbalanced data in application to prediction of the post-operative life expectancy in the lung cancer patients. Applied Soft Computing. [Web Link]  BibTeX: @article{zieba2013boosted,  title={Boosted SVM for extracting rules from imbalanced data in application to prediction of the post-operative life expectancy in the lung cancer patients},  author={Zi{k{e}}ba, Maciej and Tomczak, Jakub M and Lubicz, Marek and {'S}wi{k{a}}tek, Jerzy},  journal={Applied Soft Computing},  year={2013},  publisher={Elsevier},  doi={[Web Link]}}",
http://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set,236,Diabetic Retinopathy Debrecen Data Set Data Set,../machine-learning-databases/00329/,Multivariate,1151,Life,"Integer, Real",20,11/3/2014,Classification,N/A,107541,"1. Dr. Balint Antal, Department of Computer Graphics and Image ProcessingFaculty of Informatics, University of Debrecen, 4010, Debrecen, POB 12, Hungaryantal.balint '@' inf.unideb.hu 2. Dr. Andras Hajdu, Department of Computer Graphics and Image ProcessingFaculty of Informatics, University of Debrecen, 4010, Debrecen, POB 12, Hungaryhajdu.andras '@' inf.unideb.hu","This dataset contains features extracted from the Messidor image set to predict whether an image contains signs of diabetic retinopathy or not. All features represent either a detected lesion, a descriptive feature of a anatomical part or an image-level descriptor. The underlying method image analysis and feature extraction as well as our classification technique is described in Balint Antal, Andras Hajdu: An ensemble-based system for automatic screening of diabetic retinopathy, Knowledge-Based Systems 60 (April 2014), 20-27. The image set (Messidor) is available at [Web Link].","0) The binary result of quality assessment. 0 = bad quality 1 = sufficient quality.1) The binary result of pre-screening, where 1 indicates severe retinal abnormality and 0 its lack.2-7) The results of MA detection. Each feature value stand for thenumber of MAs found at the confidence levels alpha = 0.5, . . . , 1, respectively.8-15) contain the same information as 2-7) for exudates. However,as exudates are represented by a set of points rather than the number ofpixels constructing the lesions, these features are normalized by dividing thenumber of lesions with the diameter of the ROI to compensate different imagesizes.16) The euclidean distance of the center ofthe macula and the center of the optic disc to provide important informationregarding the patientâ€™s condition. This featureis also normalized with the diameter of the ROI.17) The diameter of the optic disc.18) The binary result of the AM/FM-based classification.19) Class label. 1 = contains signs of DR (Accumulative label for the Messidor classes 1, 2, 3), 0 = no signs of DR.",Provide references to papers that have cited this data set in the past (if any).,"Please cite the following paper: Balint Antal, Andras Hajdu: An ensemble-based system for automatic screening of diabetic retinopathy, Knowledge-Based Systems 60 (April 2014), 20-27.The dataset is based on features extracted from the Messidor image dataset: [Web Link].",
http://archive.ics.uci.edu/ml/datasets/Energy+efficiency,237,Energy efficiency Data Set,../machine-learning-databases/00242/,Multivariate,768,Computer,"Integer, Real",8,11/30/2012,"Classification, Regression",N/A,306615,"The dataset was created by Angeliki Xifara (angxifara '@' gmail.com, Civil/Structural Engineer) and was processed by Athanasios Tsanas (tsanasthanasis '@' gmail.com, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).","We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.","The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses. Specifically:X1	Relative CompactnessX2	Surface AreaX3	Wall AreaX4	Roof AreaX5	Overall HeightX6	OrientationX7	Glazing AreaX8	Glazing Area Distributiony1	Heating Loady2	Cooling Load","A. Tsanas, A. Xifara: 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', Energy and Buildings, Vol. 49, pp. 560-567, 2012","A. Tsanas, A. Xifara: 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', Energy and Buildings, Vol. 49, pp. 560-567, 2012 (the paper can be accessed from [Web Link]) For further details on the data analysis methodology: A. Tsanas, 'Accurate telemonitoring of Parkinsonâ€™s disease symptom severity using nonlinear speech signal processing and statistical machine learning', D.Phil. thesis, University of Oxford, 2012 (which can be accessed from [Web Link])",
http://archive.ics.uci.edu/ml/datasets/BAUM-1,238,BAUM-1 Data Set,../machine-learning-databases/00473/,Time-Series,1184,Computer,N/A,N/A,11/9/2018,Classification,N/A,15585,"The database and baseline results have been published in the following paper:S. Zhalehpour, O. Onder, Z. Akhtar, C. E. Erdem, 'BAUM-1: A Spontaneous Audio-VÄ°sual Face Database of Affective and Mental States', IEEE Transactions on Affective Computing, Vol. 8, No.3, 2017.  The creators of the database are the authors of the above paper.  ","In order to download the database please send an e-mail to: s.zhalehpour '@' gmail.com orcigdem.erogluerdem '@' gmail.com  Relevant information can be found in the readme file. ","The dataset contains short video clips in MP4 format. The expressed emotional and mental states consist of happiness, anger, sadness, disgust, fear, surprise, boredom, contempt, confusion, neutral, thinking, concentrating, and bothered. "," Learning Affective Features With a Hybrid Deep Model for Audio-Visual Emotion RecognitionBy: Zhang, Shiqing; Zhang, Shiliang; Huang, Tiejun; et al.IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY  Volume: 28   Issue: 10   Special Issue: SI   Pages: 3030-3043   Published: OCT 2018  'Facial Expression Analysis under Partial Occlusion: A Survey'By: Zhang, Ligang; Verma, Brijesh; Tjondronegoro, Dian; et al.ACM COMPUTING SURVEYS  Volume: 51   Issue: 2     Article Number: 25   Published: JUN 2018  Speech Emotion Recognition Using Deep Convolutional Neural Network and Discriminant Temporal Pyramid MatchingBy: Zhang, Shiqing; Zhang, Shiliang; Huang, Tiejun; et al.IEEE TRANSACTIONS ON MULTIMEDIA  Volume: 20   Issue: 6   Pages: 1576-1590   Published: JUN 2018  IMPROVED AUDIO-VISUAL LAUGHTER DETECTION VIA MULTI-SCALE MULTI-RESOLUTION IMAGE TEXTURE FEATURES AND CLASSIFIER FUSIONBy: Akhtar, Zahid; Bedoya, Stefany; Falk, Tiago H.Conference: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) Location: Calgary, CANADA Date: APR 15-20, 2018 Sponsor(s): Inst Elect & Elect Engineers; Inst Elect & Elect Engineers Signal Proc Soc2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)  Pages: 3106-3110   Published: 2018","S. Zhalehpour, O. Onder, Z. Akhtar, C. E. Erdem, 'BAUM-1: A Spontaneous Audio-VÄ°sual Face Database of Affective and Mental States', IEEE Transactions on Affective Computing, Vol. 8, No.3, 2017. ",
http://archive.ics.uci.edu/ml/datasets/Breast+Cancer,239,Breast Cancer Data Set,../machine-learning-databases/breast-cancer/,Multivariate,286,Life,Categorical,9,7/11/1988,Classification,Yes,483461,"Creators: Matjaz Zwitter & Milan Soklic (physicians)Institute of Oncology University Medical CenterLjubljana, Yugoslavia Donors:  Ming Tan and Jeff Schlimmer (Jeffrey.Schlimmer '@' a.gp.cs.cmu.edu)","This is one of three domains provided by the Oncology Institute that has repeatedly appeared in the machine learning literature. (See also lymphography and primary-tumor.) This data set includes 201 instances of one class and 85 instances of another class.  The instances are described by 9 attributes, some of which are linear and some are nominal.","   1. Class: no-recurrence-events, recurrence-events   2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.   3. menopause: lt40, ge40, premeno.   4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59.   5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39.   6. node-caps: yes, no.   7. deg-malig: 1, 2, 3.   8. breast: left, right.   9. breast-quad: left-up, left-low, right-up,	right-low, central.  10. irradiat:	yes, no.","Michalski,R.S., Mozetic,I., Hong,J., & Lavrac,N. (1986). The Multi-Purpose Incremental Learning System AQ15 and its Testing Application to Three Medical Domains.  In Proceedings of the Fifth National Conference on Artificial Intelligence, 1041-1045, Philadelphia, PA: Morgan Kaufmann.[Web Link]  Clark,P. & Niblett,T. (1987). Induction in Noisy Domains.  In Progress in Machine Learning (from the Proceedings of the 2nd European Working Session on Learning), 11-30, Bled, Yugoslavia: Sigma Press.[Web Link]  Tan, M., & Eshelman, L. (1988). Using weighted networks to represent classification knowledge in noisy domains.  Proceedings of the Fifth International Conference on Machine Learning, 121-134, Ann Arbor, MI.[Web Link]  Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.[Web Link] ","This breast cancer domain was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and M. Soklic for providing the data.  Please include this citation if you plan to use this database.","Igor Fischer and Jan Poland. Amplifying the Block Matrix Structure for Spectral Clustering. Telecommunications Lab. 2005.  [View Context].Saher Esmeir and Shaul Markovitch. Lookahead-based algorithms for anytime induction of decision trees. ICML. 2004.  [View Context].Gavin Brown. Diversity in Neural Network Ensembles. The University of Birmingham. 2004.  [View Context].Kaizhu Huang and Haiqin Yang and Irwin King and Michael R. Lyu and Laiwan Chan. Biased Minimax Probability Machine for Medical Diagnosis. AMAI. 2004.  [View Context].Qingping Tao Ph. D. MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004.  [View Context].Fei Sha and Lawrence K. Saul and Daniel D. Lee. Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines. NIPS. 2002.  [View Context].Kristin P. Bennett and Ayhan Demiriz and Richard Maclin. Exploiting unlabeled data in ensemble methods. KDD. 2002.  [View Context].Baback Moghaddam and Gregory Shakhnarovich. Boosted Dyadic Kernel Discriminants. NIPS. 2002.  [View Context].András Antos and Balázs Kégl and Tamás Linder and Gábor Lugosi. Data-dependent margin-based generalization bounds for classification. Journal of Machine Learning Research, 3. 2002.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].Yongmei Wang and Ian H. Witten. Modeling for Optimal Probability Prediction. ICML. 2002.  [View Context].Remco R. Bouckaert. Accuracy bounds for ensembles under 0 { 1 loss. Xtal Mountain Information Technology & Computer Science Department, University of Waikato. 2002.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. Heterogeneous Forests of Decision Trees. ICANN. 2002.  [View Context].Hussein A. Abbass. An evolutionary artificial neural networks approach for breast cancer diagnosis. Artificial Intelligence in Medicine, 25. 2002.  [View Context].Bernhard Pfahringer and Geoffrey Holmes and Richard Kirkby. Optimizing the Induction of Alternating Decision Trees. PAKDD. 2001.  [View Context].Robert Burbidge and Matthew Trotter and Bernard F. Buxton and Sean B. Holden. STAR - Sparsity through Automated Rejection. IWANN (1). 2001.  [View Context].Bernhard Pfahringer and Geoffrey Holmes and Gabi Schmidberger. Wrapping Boosters against Noise. Australian Joint Conference on Artificial Intelligence. 2001.  [View Context].W. Nick Street and Yoo-Hyon Kim. A streaming ensemble algorithm (SEA) for large-scale classification. KDD. 2001.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].P. S and Bradley K. P and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Sally A. Goldman and Yan Zhou. Enhancing Supervised Learning with Unlabeled Data. ICML. 2000.  [View Context].Justin Bradley and Kristin P. Bennett and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Yuh-Jeng Lee. Smooth Support Vector Machines. Preliminary Thesis Proposal Computer Sciences Department University of Wisconsin. 2000.  [View Context].Petri Kontkanen and Petri Myllym and Tomi Silander and Henry Tirri and Peter Gr. On predictive distributions and Bayesian networks. Department of Computer Science, Stanford University. 2000.  [View Context].Kristin P. Bennett and Ayhan Demiriz and John Shawe-Taylor. A Column Generation Algorithm For Boosting. ICML. 2000.  [View Context].Matthew Mullin and Rahul Sukthankar. Complete Cross-Validation for Nearest Neighbor Classifiers. ICML. 2000.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Improved Generalization Through Explicit Optimization of Margins. Machine Learning, 38. 2000.  [View Context].Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. An Implementation of Logical Analysis of Data. IEEE Trans. Knowl. Data Eng, 12. 2000.  [View Context].Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining. Institute of Information Science. 1999.  [View Context].David M J Tax and Robert P W Duin. Support vector domain description. Pattern Recognition Letters, 20. 1999.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Ismail Taha and Joydeep Ghosh. Symbolic Interpretation of Artificial Neural Networks. IEEE Trans. Knowl. Data Eng, 11. 1999.  [View Context].Lorne Mason and Jonathan Baxter and Peter L. Bartlett and Marcus Frean. Boosting Algorithms as Gradient Descent. NIPS. 1999.  [View Context].Iñaki Inza and Pedro Larrañaga and Basilio Sierra and Ramon Etxeberria and Jose Antonio Lozano and Jos Manuel Peña. Representing the behaviour of supervised classification learning algorithms by Bayesian networks. Pattern Recognition Letters, 20. 1999.  [View Context].David W. Opitz and Richard Maclin. Popular Ensemble Methods: An Empirical Study. J. Artif. Intell. Res. (JAIR, 11. 1999.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Direct Optimization of Margins Improves Generalization in Combined Classifiers. NIPS. 1998.  [View Context].Richard Maclin. Boosting Classifiers Regionally. AAAI/IAAI. 1998.  [View Context].Huan Liu and Hiroshi Motoda and Manoranjan Dash. A Monotonic Measure for Optimal Feature Selection. ECML. 1998.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].W. Nick Street. A Neural Network Model for Prognostic Prediction. ICML. 1998.  [View Context].Pedro Domingos. Control-Sensitive Feature Selection for Lazy Learners. Artif. Intell. Rev, 11. 1997.  [View Context].Rudy Setiono and Huan Liu. NeuroLinear: From neural networks to oblique decision rules. Neurocomputing, 17. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. A Parametric Optimization Method for Machine Learning. INFORMS Journal on Computing, 9. 1997.  [View Context].Ismail Taha and Joydeep Ghosh. Characterization of the Wisconsin Breast cancer Database Using a Hybrid Symbolic-Connectionist System. Proceedings of ANNIE. 1996.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Jennifer A. Blue and Kristin P. Bennett. Hybrid Extreme Point Tabu Search. Department of Mathematical Sciences Rensselaer Polytechnic Institute. 1996.  [View Context].Pedro Domingos. Unifying Instance-Based and Rule-Based Induction. Machine Learning, 24. 1996.  [View Context].Erin J. Bredensteiner and Kristin P. Bennett. Feature Minimization within Decision Trees. National Science Foundation. 1996.  [View Context].Christophe Giraud and Tony Martinez and Christophe G. Giraud-Carrier. University of Bristol Department of Computer Science ILA: Combining Inductive Learning with Prior Knowledge and Reasoning. 1995.  [View Context].Ron Kohavi. A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection. IJCAI. 1995.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Karthik Ramakrishnan. UNIVERSITY OF MINNESOTA.  [View Context].Geoffrey I Webb. Learning Decision Lists by Prepending Inferred Rules. School of Computing and Mathematics Deakin University.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].M. V. Fidelis and Heitor S. Lopes and Alex Alves Freitas. Discovering Comprehensible Classification Rules with a Genetic Algorithm. UEPG, CPD CEFET-PR, CPGEI PUC-PR, PPGIA Praa Santos Andrade, s/n Av. Sete de Setembro.  [View Context].Chris Drummond and Robert C. Holte. C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling. Institute for Information Technology, National Research Council Canada.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].Maria Salamo and Elisabet Golobardes. Analysing Rough Sets weighting methods for Case-Based Reasoning Systems. Enginyeria i Arquitectura La Salle.  [View Context].G. Ratsch and B. Scholkopf and Alex Smola and K. -R Muller and T. Onoda and Sebastian Mika. Arc: Ensemble Learning in the Presence of Outliers. GMD FIRST.  [View Context].D. Randall Wilson and Roel Martinez. Improved Center Point Selection for Probabilistic Neural Networks. Proceedings of the International Conference on Artificial Neural Networks and Genetic Algorithms.  [View Context].Chiranjib Bhattacharyya. Robust Classification of noisy data using Second Order Cone Programming approach. Dept. Computer Science and Automation, Indian Institute of Science.  [View Context].K. A. J Doherty and Rolf Adams and Neil Davey. Unsupervised Learning with Normalised Data and Non-Euclidean Norms. University of Hertfordshire.  [View Context].Adam H. Cannon and Lenore J. Cowen and Carey E. Priebe. Approximate Distance Classification. Department of Mathematical Sciences The Johns Hopkins University.  [View Context].G. Ratsch and B. Scholkopf and Alex Smola and Sebastian Mika and T. Onoda and K. -R Muller. Robust Ensemble Learning for Data Mining. GMD FIRST, Kekul#estr.  [View Context].Andrew I. Schein and Lyle H. Ungar. A-Optimality for Active Learning of Logistic Regression Classifiers. Department of Computer and Information Science Levine Hall.  [View Context].Huan Liu. A Family of Efficient Rule Generators. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery. CEFET-PR, Curitiba.  [View Context].Paul D. Wilson and Tony R. Martinez. Combining Cross-Validation and Confidence to Measure Fitness. fonix corporation Brigham Young University.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context].Nikunj C. Oza and Stuart J. Russell. Online Bagging and Boosting. Computer Science Division University of California.  [View Context].Michael R. Berthold and Klaus--Peter Huber. From Radial to Rectangular Basis Functions: A new Approach for Rule Learning from Large Datasets. Institut fur Rechnerentwurf und Fehlertoleranz (Prof. D. Schmid) Universitat Karlsruhe.  [View Context].Bart Baesens and Stijn Viaene and Tony Van Gestel and J. A. K Suykens and Guido Dedene and Bart De Moor and Jan Vanthienen and Katholieke Universiteit Leuven. An Empirical Assessment of Kernel Type Performance for Least Squares Support Vector Machine Classifiers. Dept. Applied Economic Sciences.  [View Context].Rudy Setiono and Huan Liu. Neural-Network Feature Selector. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. An Ant Colony Based System for Data Mining: Applications to Medical Data. CEFET-PR, CPGEI Av. Sete de Setembro, 3165.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. A hybrid method for extraction of logical rules from data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Rudy Setiono. Extracting M-of-N Rules from Trained Neural Networks. School of Computing National University of Singapore.  [View Context].Jarkko Salojarvi and Samuel Kaski and Janne Sinkkonen. Discriminative clustering in Fisher metrics. Neural Networks Research Centre Helsinki University of Technology.  [View Context].Ayhan Demiriz and Kristin P. Bennett and John Shawe and I. Nouretdinov V.. Linear Programming Boosting via Column Generation. Dept. of Decision Sciences and Eng. Systems, Rensselaer Polytechnic Institute.  [View Context].Liping Wei and Russ B. Altman. An Automated System for Generating Comparative Disease Profiles and Making Diagnoses. Section on Medical Informatics Stanford University School of Medicine, MSOB X215.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Sherrie L. W and Zijian Zheng. A BENCHMARK FOR CLASSIFIER LEARNING. Basser Department of Computer Science The University of Sydney.  [View Context].John W. Chinneck. Fast Heuristics for the Maximum Feasible Subsystem Problem. Systems and Computer Engineering, Carleton University.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context].John G. Cleary and Leonard E. Trigg. Experiences with OB1, An Optimal Bayes Decision Tree Learner. Department of Computer Science University of Waikato.  [View Context].Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. Statistical methods for construction of neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Rong-En Fan and P. -H Chen and C. -J Lin. Working Set Selection Using the Second Order Information for Training SVM. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Rong Jin and Yan Liu and Luo Si and Jaime Carbonell and Alexander G. Hauptmann. A New Boosting Algorithm Using Input-Dependent Regularizer. School of Computer Science, Carnegie Mellon University.  [View Context].David Kwartowitz and Sean Brophy and Horace Mann. Session S2D Work In Progress: Establishing multiple contexts for student's progressive refinement of data mining.  [View Context].Geoffrey I Webb. Generality is more significant than complexity: Toward an alternative to Occam's Razor. School of Computing and Mathematics Deakin University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Cuff-Less+Blood+Pressure+Estimation,240,Cuff-Less Blood Pressure Estimation Data Set,../machine-learning-databases/00340/,Multivariate,12000,Life,Real,3,7/27/2015,"Classification, Regression",Yes,114087,"-- Creators: Mohamad Kachuee, Mohammad Mahdi Kiani, Hoda Mohammadzade, Mahdi Shabany             Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran-- Donor: Mohamad Kachuee (m.kachuee '@' gmail.com)-- Date: July, 2015","The main goal of this data set is providing clean and valid signals for designing cuff-less blood pressure estimation algorithms. The raw electrocardiogram (ECG), photoplethysmograph (PPG), and arterial blood pressure (ABP) signals are originally collected from the physionet.org and then some preprocessing and validation performed on them. (For more information about the process please refer to our paper)","The data set is in matlab's v7.3 mat file, accordingly it should be opened using new versions of matlab or HDF libraries in other environments.(Please refer to the Web for more information about this format)This database consist of a cell array of matrices, each cell is one record part.In each matrix each row corresponds to one signal channel: 1: PPG signal, FS=125Hz;  photoplethysmograph from fingertip2: ABP signal, FS=125Hz; invasive arterial blood pressure (mmHg)3: ECG signal, FS=125Hz; electrocardiogram from channel II","M. Kachuee, M. M. Kiani, H. Mohammadzade, M. Shabany, Cuff-Less High-Accuracy Calibration-Free Blood Pressure Estimation Using Pulse Transit Time, IEEE International Symposium on Circuits and Systems (ISCAS'15), 2015. A. Goldberger, L. Amaral, L. Glass, J. Hausdorff, P. Ivanov, R. Mark, J.Mietus, G. Moody, C. Peng and H. Stanley, â€œPhysiobank, physiotoolkit,and physionet components of a new research resource for complex physiologic signals,â€ Circulation, vol. 101, no. 23, pp. 215â€“220, 2000.","If you found this data set useful please cite the following:M. Kachuee, M. M. Kiani, H. Mohammadzade, M. Shabany, Cuff-Less High-Accuracy Calibration-Free Blood Pressure Estimation Using Pulse Transit Time, IEEE International Symposium on Circuits and Systems (ISCAS'15), 2015.",
http://archive.ics.uci.edu/ml/datasets/Sports+articles+for+objectivity+analysis,241,Sports articles for objectivity analysis Data Set,../machine-learning-databases/00450/,"Multivariate, Text",1000,Social,Integer,59,4/9/2018,Classification,N/A,34490,"Yara Rizk, American University of Beirut (yar01 '@' aub.edu.lb)Mariette Awad, American University of Beirut (mariette.awad '@' aub.edu.lb)",Some of the features are retrieved using the Stanford POS tagger and the tags are as defined in Penn Treebank Project:  [Web Link],"TextID	text file nameURL	link to articleLabel	objective vs. subjectivetotalWordsCount	total number of words in the articlesemanticobjscore	Frequency of words with an objective SENTIWORDNET scoresemanticsubjscore	Frequency of words with a subjective SENTIWORDNET scoreCC	Frequency of coordinating conjunctionsCD	Frequency of numerals and cardinalsDT	Frequency of determinersEX	Frequency of existential thereFW	Frequency of foreign wordsINs	Frequency of subordinating preposition or conjunctionJJ	Frequency of ordinal adjectives or numeralsJJR	Frequency of comparative adjectivesJJS	Frequency of superlative adjectivesLS	Frequency of list item markersMD	Frequency of modal auxiliariesNN	Frequency of singular common nounsNNP	Frequency of singular proper nounsNNPS	Frequency of plural proper nounsNNS	Frequency of plural common nounsPDT	Frequency of pre-determinersPOS	Frequency of genitive markersPRP	Frequency of personal pronounsPRP$	Frequency of possessive pronounsRB	Frequency of adverbsRBR	Frequency of comparative adverbsRBS	Frequency of superlative adverbsRP	Frequency of particlesSYM	Frequency of symbolsTOs	Frequency of 'to' as preposition or infinitive markerUH	Frequency of interjectionsVB	Frequency of base form verbsVBD	Frequency of past tense verbsVBG	Frequency of present participle or gerund verbsVBN	Frequency of past participle verbsVBP	Frequency of present tense verbs with plural 3rd person subjectsVBZ	Frequency of present tense verbs with singular 3rd person subjectsWDT	Frequency of WH-determinersWP	Frequency of WH-pronounsWP$	Frequency of possessive WH-pronounsWRB	Frequency of WH-adverbsbaseform	Frequency of infinitive verbs (base form verbs preceded by â€œtoâ€)Quotes	Frequency of quotation pairs in the entire articlequestionmarks	Frequency of questions marks in the entire articleexclamationmarks	Frequency of exclamation marks in the entire articlefullstops	Frequency of full stopscommas	Frequency of commassemicolon	Frequency of semicolonscolon	Frequency of colonsellipsis	Frequency of ellipsispronouns1st	Frequency of first person pronouns (personal and possessive)pronouns2nd	Frequency of second person pronouns (personal and possessive)pronouns3rd	Frequency of third person pronouns (personal and possessive)compsupadjadv	Frequency of comparative and superlative adjectives and adverbspast	Frequency of past tense verbs with 1st and 2nd person pronounsimperative	Frequency of imperative verbspresent3rd	Frequency of present tense verbs with 3rd person pronounspresent1st2nd	Frequency of present tense verbs with 1st and 2nd person pronounssentence1st	First sentence classsentencelast	Last sentence classtxtcomplexity	Text complexity score","Nadine Hajj, Yara Rizk, and Mariette Awad, 'A Subjectivity Classification Framework for Sports Articles using Cortical Algorithms for Feature Selection,' Springer Neural Computing and Applications, 2018. Yara Rizk, and Mariette Awad, 'Syntactic Genetic Algorithm for a Subjectivity Analysis of Sports Articles,' International Conference on Cybernetic Intelligent Systems, Limerick, Ireland, 2012.","Nadine Hajj, Yara Rizk, and Mariette Awad, 'A Subjectivity Classification Framework for Sports Articles using Cortical Algorithms for Feature Selection,' Springer Neural Computing and Applications, 2018. ",
http://archive.ics.uci.edu/ml/datasets/Tennis+Major+Tournament+Match+Statistics,242,Tennis Major Tournament Match Statistics Data Set,../machine-learning-databases/00300/,Multivariate,127,N/A,"Integer, Real",42,6/1/2014,"Classification, Regression, Clustering",Yes,100483,"Shruti JauhariDepartment of Computer ScienceRochester Institute of TechnologyRochester, NY 14623eMail: sxj6633 '@' rit.edu  Aniket MorankarDepartment of Computer ScienceRochester Institute of TechnologyRochester, NY 14623eMail: asm6887 '@' rit.edu  Ernest FokoueCenter for Quality of Applied StatisticsRochester Institute of TechnologyRochester, NY 14623eMail: ernest.fokoue '@' rit.edu Phone: 585 475 7525 or 575 643 5549",N/A,"Player 1              Name of Player 1Player 2              Name of Player 2Result                Result of the match (0/1) - Referenced on Player 1 is Result = 1 if Player 1 wins (FNL.1>FNL.2)FSP.1                 First Serve Percentage for player 1 (Real Number)FSW.1                 First Serve Won by player 1 (Real Number)SSP.1                 Second Serve Percentage for player 1 (Real Number)SSW.1                 Second Serve Won by player 1 (Real Number)ACE.1                 Aces won by player 1 (Numeric-Integer)DBF.1                 Double Faults committed by player 1 (Numeric-Integer)WNR.1                 Winners earned by player 1 (Numeric)UFE.1                 Unforced Errors committed by player 1 (Numeric)BPC.1                 Break Points Created by player 1   (Numeric)  BPW.1                 Break Points Won by player 1    (Numeric) NPA.1                 Net Points Attempted by player 1 (Numeric)NPW.1                 Net Points Won by player 1  (Numeric)      TPW.1                 Total Points Won by player 1 (Numeric)ST1.1                 Set 1 result for Player 1 (Numeric-Integer)ST2.1                 Set 2 Result for Player 1 (Numeric-Integer)ST3.1                 Set 3 Result for Player 1 (Numeric-Integer)ST4.1                 Set 4 Result for Player 1 (Numeric-Integer)ST5.1                 Set 5 Result for Player 1 (Numeric-Integer) FNL.1                 Final Number of Games Won by Player 1 (Numeric-Integer)FSP.2                 First Serve Percentage for player 2 (Real Number)FSW.2                 First Serve Won by player 2 (Real Number)SSP.2                 Second Serve Percentage for player 2 (Real Number)SSW.2                 Second Serve Won by player 2 (Real Number)ACE.2                 Aces won by player 2 (Numeric-Integer)DBF.2                 Double Faults committed by player 2 (Numeric-Integer)WNR.2                 Winners earned by player 2 (Numeric)UFE.2                 Unforced Errors committed by player 2 (Numeric)BPC.2                 Break Points Created by player 2   (Numeric)  BPW.2                 Break Points Won by player 2    (Numeric) NPA.2                 Net Points Attempted by player 2 (Numeric)NPW.2                 Net Points Won by player 2  (Numeric)      TPW.2                 Total Points Won by player 2 (Numeric)ST1.2                 Set 1 result for Player 2 (Numeric-Integer)ST2.2                 Set 2 Result for Player 2 (Numeric-Integer)ST3.2                 Set 3 Result for Player 2 (Numeric-Integer)ST4.2                 Set 4 Result for Player 2 (Numeric-Integer)ST5.2                 Set 5 Result for Player 2 (Numeric-Integer) FNL.2                 Final Number of Games Won by Player 2 (Numeric-Integer)Round                 Round of the tournament at which game is played (Numeric-Integer)",N/A,"If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Internet+Usage+Data,243,Internet Usage Data Data Set,../machine-learning-databases/internet_usage-mld/,Multivariate,10104,Computer,"Categorical, Integer",72,6/30/1999,N/A,No,115756,"Original Owner: Graphics, Visualization, & Usability CenterCollege of ComputingGeogia Institute of TechnologyAtlanta, GAhttp://www.gvu.gatech.edu/gvu/user_surveys/survey-1997-10/  Donor: Dr Di CookDepartment of StatisticsIowa State Universityhttp://www.public.iastate.edu/~dicook/ ","This data comes from a survey conducted by the Graphics and Visualization Unit at Georgia Tech October 10 to November 16, 1997. The full details of the survey are available here: [Web Link]  The particular subset of the survey provided here is the ""general demographics"" of internet users. The data have been recoded as entirely numeric, with an index to the codes described in the ""Coding"" file.  The full survey is available from the web site above, along with summaries, tables and graphs of their analyses. In addition there is information on other parts of the survey, including technology demographics and web commerce.  The data is stored in an ASCII files with one observation per line. Spaces separate fields. ",N/A,This data was used in the American Statistical Association Statistical Graphics and Computing Sections 1999 Data Exposition. ,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Qualitative_Bankruptcy,244,Qualitative_Bankruptcy Data Set,../machine-learning-databases/00281/,Multivariate,250,Computer,N/A,7,2/9/2014,Classification,N/A,80820,Source Information    -- Creator      :  Mr.A.Martin(jayamartin '@' yahoo.com)                          Mr.J.Uthayakumar (uthayakumar17691 '@' gmail.com)                          Mr.M.Nadarajan(nadaraj.muthuvel '@' gmail.com)    -- Guided By    :  Dr.V.Prasanna Venkatesan    -- Institution  :  Sri Manakula Vinayagar Engineering College and Pondicherry University    -- Country      :  India    -- Date         :  February 2014,"The parameters which we used for collecting the dataset is referred from the paper 'The discovery of expertsâ€™ decision rules from qualitative bankruptcy data using genetic algorithms' by Myoung-Jong Kim*, Ingoo Han.","Attribute Information: (P=Positive,A-Average,N-negative,B-Bankruptcy,NB-Non-Bankruptcy)      1. Industrial Risk: {P,A,N}     2. Management Risk: {P,A,N}     3. Financial Flexibility: {P,A,N}     4. Credibility: {P,A,N}     5. Competitiveness: {P,A,N}     6. Operating Risk: {P,A,N}     7. Class: {B,NB}","The parameters which we used for collecting the dataset is referred from the paper 'The discovery of expertsâ€™ decision rules from qualitative bankruptcy data using genetic algorithms' by Myoung-Jong Kim*, Ingoo Han.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Activity+recognition+with+healthy+older+people+using+a+batteryless+wearable+sensor,245,Activity recognition with healthy older people using a batteryless wearable sensor Data Set,../machine-learning-databases/00427/,Sequential,75128,Life,Real,9,12/12/2016,Classification,N/A,34214,"Roberto Luis Shinmoto Torres, University of Adelaide, roberto.shinmototorres '@' adelaide.edu.au Damith Ranasinghe, University of Adelaide, damith.ranasinghe '@' adelaide.edu.au. Renuka Visvanathan, University of Adelaide, renuka.visvanathan '@' adelaide.edu.au.","This dataset contains the motion data of 14 healthy older aged between 66 and 86 years old, performed broadly scripted activities using a batteryless, wearable sensor on top of their clothing at sternum level. Data is sparse and noisy due to the use of a passive sensor. Participants were allocated in two clinical room settings (S1 and S2). The setting of S1 (Room1) uses 4 RFID reader antennas around the room (one on ceiling level, and 3 on wall level) for the collection of data, whereas the room setting S2 (Room2) uses 3 RFID reader antennas (two at ceiling level and one at wall level) for the collection of motion data. The activities performed were:  walking to the chair,  sitting on the chair,  getting off the chair,  walking to bed,  lying on bed,  getting off the bed and  walking to the door. Hence the possible class labels assigned for every sensor observation are:- Sitting on bed- Sitting on chair- Lying on bed- Ambulating, where ambulating includes standing, walking around the room. ","The content of the file is as follows:Comma separated values (CSV) format.Column 1: Time in seconds Column 2: Acceleration reading in G for frontal axisColumn 3: Acceleration reading in G for vertical axisColumn 4: Acceleration reading in G for lateral axisColumn 5: Id of antenna reading sensorColumn 6: Received signal strength indicator (RSSI) Column 7: PhaseColumn 8: FrequencyColumn 9: Label of activity, 1: sit on bed, 2: sit on chair, 3: lying, 4: ambulatingIn addition, gender of participant is included in the last character of file name eg: d1p33F (F:female).","Wickramasinghe, A., Ranasinghe, D. C., Fumeaux, C., Hill, K. D., Visvanathan, R. (2016), 'Sequence Learning with Passive RFID Sensors for Real Time Bed-egress Recognition in Older People,' in IEEE Journal of Biomedical and Health Informatics , vol.PP, no.99, pp.1-1 Shinmoto Torres, R. L., Visvanathan, R., Hoskins, S., van den Hengel, A., Ranasinghe, D. C. (2016). Effectiveness of a batteryless and wireless wearable sensor system for identifying bed and chair exits in healthy older people. Sensors, 16(4), 546. Wickramasinghe, A., Ranasinghe, D. C. (2015, August). Recognising Activities in Real Time Using Body Worn Passive Sensors With Sparse Data Streams: To Interpolate or Not To Interpolate?. In proceedings of the 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services (pp. 21-30). ICST. Shinmoto Torres, R. L., Ranasinghe, D. C., Shi, Q. (2013, December). Evaluation of wearable sensor tag data segmentation approaches for real time activity classification in elderly. In International Conference on Mobile and Ubiquitous Systems: Computing, Networking, and Services (pp. 384-395). Springer International Publishing. Shinmoto Torres, R. L., Ranasinghe, D. C., Shi, Q., Sample, A. P. (2013, April). Sensor enabled wearable RFID technology for mitigating the risk of falls near beds. In 2013 IEEE International Conference on RFID (pp. 191-198). IEEE.","Shinmoto Torres, R. L., Ranasinghe, D. C., Shi, Q., Sample, A. P. (2013, April). Sensor enabled wearable RFID technology for mitigating the risk of falls near beds. In 2013 IEEE International Conference on RFID (pp. 191-198). IEEE.",
http://archive.ics.uci.edu/ml/datasets/WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset+,246,WISDM Smartphone and Smartwatch Activity and Biometrics Dataset  Data Set,../machine-learning-databases/00507/,"Multivariate, Time-Series",15630426,Computer,Real,6,10/6/2019,Classification,N/A,55928,"Dr. Gary Weiss, gaweiss '@' fordham.edu, Computer and Information Sciences Department, Fordham University.","For a detailed description of the dataset, please see the following pdf file that is stored with the data:  WISDM-dataset-description.pdf. The raw  accelerometer and gyroscope sensor data is collected from the smartphone and smartwatch at a rate of 20Hz. It is collected from 51 test subjects as they perform 18 activities for 3 minutes apiece. The sensor data for each device (phone, watch) and type of sensor (accelerometer, gyroscope) is stored in a different directory (so there are 4 data directories). In each directory there are 51 files corresponding to the 51 test subjects. The format of every entry is the same: . The descriptions of these attributes are provided with the attribute information. In addition to the raw time-series sensor data we also generate examples that describe the sensor data using a 10-second window. See the dataset description document for details. Although this data can most naturally be used for activity recognition, it can also be used to build behavioral biometric models since each sensor reading is associated with a specific subject.","subject-id: value from 1600- 1650 that identifies one of the 51 test subjectsactivity-code: character between 'A' and 'S' (no 'N') that identifies the activity. The mapping from code to activity is provided in the activity_key.txt file and in our dataset description document.timestamp: Unix time (integer)x: represents the sensor reading (accelerometer or gyroscope) for the x dimensiony: represents the sensor reading (accelerometer or gyroscope) for the y dimensionz: represents the sensor reading (accelerometer or gyroscope) for the z dimension","Gary M. Weiss, Kenichi Yoneda, and Thaier Hayajneh. Smartphone and Smartwatch-Based Biometrics Using Activities of Daily Living. IEEE Access, 7:133190-133202, Sept. 2019.","Please cite the IEEE Access article: Smartphone and Smartwatch-Based Biometrics Using Activities of Daily Living. IEEE Access, 7:133190-133202, Sept. 2019.",
http://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems,247,Condition monitoring of hydraulic systems Data Set,../machine-learning-databases/00447/,"Multivariate, Time-Series",2205,Computer,Real,43680,4/26/2018,"Classification, Regression",N/A,50265,"Creator: ZeMA gGmbH, Eschberger Weg 46, 66121 SaarbrÃ¼ckenContact: t.schneider '@' zema.de, s.klein '@' zema.de, m.bastuck '@' lmt.uni-saarland.de, info '@' lmt.uni-saarland.de","The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank [1], [2]. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied. ","The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank [1], [2]. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied.  Attribute Information:The data set contains raw process sensor data (i.e. without feature extraction) which are structured as matrices (tab-delimited) with the rows representing the cycles and the columns the data points within a cycle. The sensors involved are:Sensor		Physical quantity		Unit		Sampling ratePS1		Pressure			bar		100 HzPS2		Pressure			bar		100 HzPS3		Pressure			bar		100 HzPS4		Pressure			bar		100 HzPS5		Pressure			bar		100 HzPS6		Pressure			bar		100 HzEPS1		Motor power			W		100 HzFS1		Volume flow			l/min		10 HzFS2		Volume flow			l/min		10 HzTS1		Temperature			Â°C		1 HzTS2		Temperature			Â°C		1 HzTS3		Temperature			Â°C		1 HzTS4		Temperature			Â°C		1 HzVS1		Vibration			mm/s		1 HzCE		Cooling efficiency (virtual)	%		1 HzCP		Cooling power (virtual)		kW		1 HzSE		Efficiency factor		%		1 Hz The target condition values are cycle-wise annotated in â€˜profile.txtâ€˜ (tab-delimited). As before, the row number represents the cycle number. The columns are 1: Cooler condition / %:	3: close to total failure	20: reduced effifiency	100: full efficiency 2: Valve condition / %:	100: optimal switching behavior	90: small lag	80: severe lag	73: close to total failure 3: Internal pump leakage:	0: no leakage	1: weak leakage	2: severe leakage 4: Hydraulic accumulator / bar:	130: optimal pressure	115: slightly reduced pressure	100: severely reduced pressure	90: close to total failure 5: stable flag:	0: conditions were stable	1: static conditions might not have been reached yet","[1] Nikolai Helwig, Eliseo Pignanelli, Andreas SchÃ¼tze, â€˜Condition Monitoring of a Complex Hydraulic System Using Multivariate Statisticsâ€™, in Proc. I2MTC-2015 - 2015 IEEE International Instrumentation and Measurement Technology Conference, paper PPS1-39, Pisa, Italy, May 11-14, 2015, doi: 10.1109/I2MTC.2015.7151267.[2] N. Helwig, A. SchÃ¼tze, â€˜Detecting and compensating sensor faults in a hydraulic condition monitoring systemâ€™, in Proc. SENSOR 2015 - 17th International Conference on Sensors and Measurement Technology, oral presentation D8.1, Nuremberg, Germany, May 19-21, 2015, doi: 10.5162/sensor2015/D8.1.[3] Tizian Schneider, Nikolai Helwig, Andreas SchÃ¼tze, â€˜Automatic feature extraction and selection for classification of cyclical time series dataâ€™, tm - Technisches Messen (2017), 84(3), 198â€“206, doi: 10.1515/teme-2016-0072.","Nikolai Helwig, Eliseo Pignanelli, Andreas SchÃ¼tze, â€˜Condition Monitoring of a Complex Hydraulic System Using Multivariate Statisticsâ€™, in Proc. I2MTC-2015 - 2015 IEEE International Instrumentation and Measurement Technology Conference, paper PPS1-39, Pisa, Italy, May 11-14, 2015, doi: 10.1109/I2MTC.2015.7151267.",
http://archive.ics.uci.edu/ml/datasets/M.+Tuberculosis+Genes,248,M. Tuberculosis Genes Data Set,../machine-learning-databases/tb-mld/,Relational,N/A,Life,N/A,N/A,7/14/2001,N/A,N/A,37898,"  Ross D. King  Department of Computer Science,   University of Wales Aberystwyth,   SY23 3DB, Wales rdk '@' aber.ac.uk http://users.aber.ac.uk/rdk","The data was collected from several sources, including the Sanger Centre ([Web Link]) and SWISSPROT ([Web Link]). Structure prediction was made by PROF ([Web Link]). Homology search was made by PSI-BLAST ([Web Link]). The data is in Datalog format. Missing values are not explicit, but some genes have more relationships than others. Dependencies: M. tuberculosis genes (ORFs) are related to each other by the predicate tb_to_tb_evalue(TBNumber,E-value). They are related to other (SWISSPROT) proteins by the predicate e_val(AccNo,E-value). All the data for a single gene (ORF) is enclosed between delimiters of the form:    begin(model(TBNumber)).   end(model(TBNumber)). Other Relevant Information: The gene functional classes are in a hierarchy. See [Web Link].  There are two datalog files: tb_data.pl and ecoli_functions.pl 1. tb_functions.pl Lists classes and ORF functions. Lines are of the following form:    class([1,0,0,0],""Small-molecule metabolism "").   class([1,1,0,0],""Degradation "").   class([1,1,1,0],""Carbon compounds "").   Arguments are a list of 4 numbers (describing class at the 4 different levels), followed by a string class description. For example,    function(tb186,[1,1,1,0],'bglS',""beta-glucosidase"").  Arguments are ORF number, list of 4 class numbers, gene name (or null if no gene name) in single quotes, ORF description in double quotes. 2. tb_data.pl Data for each ORF (gene) is delimited by    begin(model(X)).   end(model(X)). where X is the ORF number. Other predicates are as follows (examples):    tb_protein(X).    % X is gene number   function(2,1,5,0,'gyrA','DNA gyrase subunit A').  % 4 levels of functional hierarchy, gene name, description   coding_region(7302,9815). % start,end. integers   tb_mol_wt(19934).  % integer   access(1,e,20). % int (position), {e,i,b}, int (length)    access_exposed(1,20). % int (position), int (length)    access_intermediate(26,1). % int (position), int (length)    access_burried(1,2). % int (position), int (length)    access_dist(b,42.8). % {e,i,b}, float (percentage)   sec_struc(1,c,23). % int (position), {a,b,c}, int (length)   sec_struc_coil(1,23). % int (position), int (length)   sec_struc_alpha(1,15). % int (position), int (length)   sec_struc_beta(1,6). % int (position), int (length)   struc_dist(a,32.1). % {a,b,c}, float (percentage)   sec_struc_conf(78.8). % float (confidence)   sec_struc_conf_alpha(88.9). % float (confidence)   sec_struc_conf_beta(58.0). % float (confidence)   sec_struc_conf_coil(77.7). % float (confidence)   psi_sequences_found(1,7). % how many found, which iteration   psi_sequences_found_again(2,7).  % how many found, which iteration   psi_sequences_found_new(2,0). % how many found, which iteration   amino_acid_ratio(a,11.2). % amino acid letter, float   amino_acid_pair_ratio(a,c,0.0). % amino acid letter, amino acid letter, float (out of 1000, ie 2.8 = 0.28%)   sequence_length(187).  % integer   tb_to_tb_evalue(tb3671,1.100000e-01). % ORF number, e-value (double)     e_val(p35925,7.0e-59). % SWISSPROT accession no, e-value (double)   species(p35925,'streptomyces_coelicolor'). % SWISSPROT acc no, string   classification(p35925,bacteria). % SWISSPROT acc no, name   mol_wt(p35925,19772). % SWISSPROT acc no, integer   keyword(p35925,'hypothetical_protein'). % SWISSPROT acc no, string   db_ref(p35925,embl,l27063,g436026,null). % SWISSPROT acc no, db id, primary id, secondary id, status id   signalip(c,35,no). % {c,y,s}, int (signal peptide c/y/s score), yes/no   signalip(ss,1,34,no). % ss, int, int, yes/no   signalip(cleavage,59,60). % cleavage, int/null, int/null   hydro_cons(-0.498,-0.474,0.624,3.248,0.278). % double, double, double, double, double   gene_name(p41514,'gyrb'). % SWISSPROT acc no, string",N/A,"King, R. and Karwath, A. and Clare, A. and Dehaspe, L. (2000). Genome Scale Prediction of Protein Functional Class from Sequence Using Data Mining, In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.[Web Link]   King, R. and Karwath, A. and Clare, A. and Dehaspe, L. (2000). Accurate prediction of protein functional class in the M. tuberculosis and E. coli genomes using data mining, Comparative and Functional Genomics, 17, pp 283--293.[Web Link]","Usage Restrictions: Copyright 2000 by R. D. King, A. Karwath, A. Clare, L. Dehaspe There are no restrictions. This data is provided ""as is"" and without any express or implied warranties, including, without limitation, the implied warranties of merchantibility and fitness for a particular purpose. Citation Requests: Please cite King~et. al (2000). Acknowledgements: This work was supported by the following grants: G78/6609, BIF08765, GR/L62849 and by PharmaDM, Ambachtenlaan, 54/D, B-3001 Leuven, Belgium.",
http://archive.ics.uci.edu/ml/datasets/Exasens,249,Exasens Data Set,../machine-learning-databases/00523/,Multivariate,399,Life,Integer,4,4/22/2020,"Classification, Clustering",Yes,2686,"Pouya Soltani Zarrin, soltani '@' ihp-microelectronics.com, IHPâ€“Leibniz-institute for innovative microelectronics, 15236 Frankfurt (Oder), GermanyNiels Roeckendorf, Research Center Borstelâ€“Leibniz Lung Center, Priority Area Asthma & Allergy, Division of Mucosal Immunology & Diagnostics, Member of Leibniz Health Technologies and German Center for Lung Research, 23845 Borstel, Germany","The Exasens dataset includes demographic information on 4 groups of saliva samples (COPD-Asthma-Infected-HC) collected in the frame of a joint research project, Exasens ([Web Link]), at the Research Center Borstel, BioMaterialBank Nord (Borstel, Germany). The sampling procedure of the patient materials was approved by the local ethics committee of the University of Luebeck under the approval number AZ-16-167 and a written informed consent was obtained from all subjects. A permittivity biosensor, developed at IHP Microelectronics (Frankfurt Oder, Germany), was used for the dielectric characterization of the saliva samples for classification purposes ([Web Link]).  Definition of 4 sample groups included within the Exasens dataset: (I) Outpatients and hospitalized patients with COPD without acute respiratory infection (COPD). (II) Outpatients and hospitalized patients with asthma without acute respiratory infections (Asthma). (III) Patients with respiratory infections, but without COPD or asthma (Infected). (IV) Healthy controls without COPD, asthma, or any respiratory infection (HC).","1- Diagnosis (COPD-HC-Asthma-Infected) 2- ID 3- Age 4- Gender (1=male, 0=female) 5- Smoking Status (1=Non-smoker, 2=Ex-smoker, 3=Active-smoker) 6- Saliva Permittivity: a) Imaginary part (Min(Î”)=Absolute minimum value, Avg.(Î”)=Average)   b) Real part (Min(Î”)=Absolute minimum value, Avg.(Î”)=Average) ","P. S. Zarrin, N. Roeckendorf, and C. Wenger. In-vitro Classification of Saliva Samples of COPD Patients and Healthy Controls Using Non-perceptron Machine Learning Tools. Annals of biomedical engineering, 2020. Soltani Zarrin, P.; Ibne Jamal, F.; Roeckendorf, N.; Wenger, C. Development of a Portable Dielectric Biosensor for Rapid Detection of Viscosity Variations and Its In Vitro Evaluations Using Saliva Samples of COPD Patients and Healthy Control. Healthcare 2019, 7, 11. Soltani Zarrin, P.; Jamal, F.I.; Guha, S.; Wessel, J.; Kissinger, D.; Wenger, C. Design and Fabrication of a BiCMOS Dielectric Sensor for Viscosity Measurements: A Possible Solution for Early Detection of COPD. Biosensors 2018, 8, 78. P.S. Zarrin and C. Wenger. Pattern Recognition for COPD Diagnostics Using an Artificial Neural Network and Its Potential Integration on Hardware-based Neuromorphic Platforms. Springer Lecture Notes in Computer Science (LNCS), Vol. 11731, pp. 284-288, 2019. Krause, T., Ramaker, K., RÃ¶ckendorf, N., Sinnecker, H. and Frey, A., 2016. Airway mucinsâ€“suitable biomarkers to predict an upcoming exacerbation in COPD and asthma?. Pneumologie, 70(07), p.P43.","The authors acknowledge the Federal Ministry for Education and Research (BMBF) of Germany for funding this work. The authors thank the BioMaterialBank Nord (BMB Nord), popgen 2.0 network (P2N), and the German Center for Lung Research for the collection of saliva samples and the staff at IHP and FZ Borstel-Leibniz Lung Center for their precious support with this work. In case of using the introduced Exasens dataset please cite the following papers:  P. S. Zarrin, N. Roeckendorf, and C. Wenger. In-vitro Classification of Saliva Samples of COPD Patients and Healthy Controls Using Non-perceptron Machine Learning Tools. Annals of biomedical engineering, 2020.",
http://archive.ics.uci.edu/ml/datasets/Leaf,250,Leaf Data Set,../machine-learning-databases/00288/,Multivariate,340,Computer,Real,16,2/24/2014,Classification,N/A,125370,"This dataset was created by Pedro F. B. Silva and AndrÃ© R. S. MarÃ§al using leaf specimens collected by Rubim Almeida da Silva at the Faculty of Science, University of Porto, Portugal.","For further details on this dataset and/or its attributes, please read the 'ReadMe.pdf' file included and/or consult the Master's Thesis 'Development of a System for Automatic Plant Species Recognition' available at [Web Link].","1. Class (Species)2. Specimen Number3. Eccentricity4. Aspect Ratio5. Elongation6. Solidity7. Stochastic Convexity8. Isoperimetric Factor9. Maximal Indentation Depth10. Lobedness11. Average Intensity12. Average Contrast13. Smoothness14. Third moment15. Uniformity16. Entropy",N/A,"The data included can be used for research and educational purposes only. All publications using this dataset should cite the following paper:'Evaluation of Features for Leaf Discrimination', Pedro F.B. Silva, Andre R.S. Marcal, Rubim M. Almeida da Silva (2013). Springer Lecture Notes in Computer Science, Vol. 7950, 197-204.",
http://archive.ics.uci.edu/ml/datasets/YearPredictionMSD,251,YearPredictionMSD Data Set,../machine-learning-databases/00203/,Multivariate,515345,N/A,Real,90,2/7/2011,Regression,N/A,177558,"This data is a subset of the Million Song Dataset:http://labrosa.ee.columbia.edu/millionsong/ a collaboration between LabROSA (Columbia University) and The Echo Nest.Prepared by T. Bertin-Mahieux <tb2332 '@' columbia.edu>","You should respect the following train / test split:train: first 463,715 examplestest: last 51,630 examplesIt avoids the 'producer effect' by making sure no songfrom a given artist ends up in both the train and test set.","90 attributes, 12 = timbre average, 78 = timbre covarianceThe first value is the year (target), ranging from 1922 to 2011.Features extracted from the 'timbre' features from The Echo Nest API.We take the average and covariance over all 'segments', each segmentbeing described by a 12-dimensional timbre vector.",see the website: [Web Link],"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Weight+Lifting+Exercises+monitored+with+Inertial+Measurement+Units,252,Weight Lifting Exercises monitored with Inertial Measurement Units Data Set,../machine-learning-databases/00273/,Multivariate,39242,Physical,Real,152,11/24/2013,Classification,Yes,44682,"Wallace Ugulino (wugulino '@' inf.puc-rio.br), Pontifical Catholic University of Rio de Janeiro (Brazil).Eduardo Velloso (e.velloso '@' lancaster.ac.uk), Lancaster University - UK.","Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.Read more: [Web Link]#ixzz2lZizjhaF","Each IMU has x, y, and z values + euler angles (roll, pitch and yaw). For each time window (1s of data), there are several statistics calculations, like Kurtosis, Variance, etc.",N/A,"Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.Read more: [Web Link]#ixzz2lZizjhaF",
http://archive.ics.uci.edu/ml/datasets/Educational+Process+Mining+%28EPM%29%3A+A+Learning+Analytics+Data+Set,253,Educational Process Mining (EPM): A Learning Analytics Data Set Data Set,../machine-learning-databases/00346/,"Multivariate, Sequential, Time-Series",230318,Computer,Integer,13,9/24/2015,"Classification, Regression, Clustering",N/A,99191,"Mehrnoosh Vahdat(1,2), Luca Oneto(1), Davide Anguita(1), Mathias Funk (2), and Matthias Rauterberg (2) 1 - Smartlab - Non-Linear Complex Systems LaboratoryDIBRIS - UniversitÃ   degli Studi di Genova, Genoa (I-16145), Italy. 2 - Department of Industrial Design, Eindhoven University of Technology, 5612AZ Eindhoven, The Netherlands la '@' smartlab.ws ","The experiments have been carried out with a group of 115 students of first-year, undergraduate Engineering major of the University of Genoa.  We carried out this study over a simulation environment named Deeds (Digital Electronics Education and Design Suite) which is used for e-learning in digital electronics. The environment provides learning materials through specialized browsers for the students, and asks them to solve various problems with different levels of difficulty. For more information about the Deeds simulator used for this course look at: [Web Link]  and to know more about the exercises contents of each session see 'exercises_info.txt'.  Our data set contains the students' time series of activities during six sessions of laboratory sessions of the course of digital electronics. There are 6 folders containing the studentsâ€™ data per session. Each 'Session' folder contains up to 99 CSV files each dedicated to a specific student log during that session. The number of files in each folder changes due to the number of students present in each session. Each file contains 13 features. See 'features_info.txt' for more details. For the details of activities performed by the students during the course, see 'activities_info.txt'  The data set includes the following files:========================================= - 'README.txt' - 'features_info.txt': contains information about the variables used on the feature vector. - 'features.txt': List of all features. - 'activities_info.txt': contains information about the variable 'activity'. - 'activities.txt': list of all activities. - 'exercises_info.txt': contains information about the variable 'exercise'. - 'grades_info.txt': contains information about the grade data.  Data: ====== - 'Processes': contains the data files from Session 1 to 6. - 'logs.txt': shows information about the log data per student Id. It shows whether a student has a log in each session (0: has no log, 1: has log). - 'final_grades.xlsx': contains the results of the final exam in two sheets. - 'intermediate_grades.xlsx': contains the grades for the students' assignments per session. - 'final_exam.pdf': shows the content of the final exam (original in Italian). - 'final_exam_ENG.pdf': shows the content of the final exam translated in English. Notes: ====== For more information about this data set please look at:  www.la.smartlab.wsla '@' smartlab.ws","The features selected for this data set come from pre-processing of data collected through a logging program.  Due to ethical reasons and to ensure the anonymity of our users, we cannot share the original log files, instead, we share the data transformed and cleaned in an appropriate format. The original logs contain the logging data of client system per approximately a second, while the features are calculated in order to be allocated to a particular activity.  The features are selected and presented in a suitable format for Process Mining. In this sense, the data is presented per session, per student, and per exercise. Each CSV file belongs to a specific session and a specific student (named by the student Id). Each file contains several exercises of that session presented in 'exercise' feature. Each 'exercise' contains activities, which start-time, end-time, and other features are allocated to that. For further information about each feature, see 'features_info.txt'.","M. Vahdat, L. Oneto, A. Ghio, G. Donzellini, D. Anguita, M. Funk, M. Rauterberg.: A learning analytics methodology to profile students behavior and explore interactions with a digital electronics simulator. In: de Freitas, S., Rensing, C., Ley, T., Munoz-Merino, P.J. (eds.) EC-TEL 2014. LNCS, vol. 8719, pp. 596â€“597. Springer (2014). M. Vahdat, A. Ghio, L. Oneto, D. Anguita, M. Funk, M. Rauterberg, Advances in learning analytics and educational data mining, in: European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (2015).","M. Vahdat, L. Oneto, D. Anguita, M. Funk, M. Rauterberg.: A learning analytics approach to correlate the academic achievements of students with interaction data from an educational simulator. In: G. Conole et al. (eds.): EC-TEL 2015, LNCS 9307, pp. 352-366. Springer (2015).DOI: 10.1007/978-3-319-24258-3 26",
http://archive.ics.uci.edu/ml/datasets/Dynamic+Features+of+VirusShare+Executables,254,Dynamic Features of VirusShare Executables Data Set,../machine-learning-databases/00413/,"Multivariate, Time-Series",107888,Computer,Integer,482,11/29/2017,"Classification, Regression",N/A,29847,"Huynh Ngoc Anhhu0002nh '@' e.ntu.edu.sg Nanyang Technological University","This dataset contains the dynamic features of 107,888 executables, collected by VirusShare from Nov/2010 to Jul/2014. The features were extracted from the artifacts generated by the executables in the Cukoo Sandbox. Please refer to the paper for more details regarding data collection and feature extraction.",The full set of features is available at [Web Link];,"@inproceedings{DBLP:conf/dis/AnhNA17,  author    = {Huynh Ngoc Anh and               Wee Keong Ng and               Kanishka Ariyapala},  title     = {A New Adaptive Learning Algorithm and Its Application to Online Malware               Detection},  booktitle = {Discovery Science - 20th International Conference, {DS} 2017, Kyoto,               Japan, October 15-17, 2017, Proceedings},  pages     = {18--32},  year      = {2017},  crossref  = {DBLP:conf/dis/2017},  url       = {[Web Link]},  doi       = {10.1007/978-3-319-67786-6_2},  timestamp = {Mon, 18 Sep 2017 13:52:15 +0200},  biburl    = {[Web Link]},  bibsource = {dblp computer science bibliography, [Web Link]}}","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/El+Nino,255,El Nino Data Set,../machine-learning-databases/el_nino-mld/,Spatio-temporal,178080,Physical,"Integer, Real",12,6/30/1999,N/A,Yes,99495,"Original Owner: Pacific Marine Environmental LaboratoryNational Oceanic and Atmospheric AdministrationUS Department of Commercehttp://www.pmel.noaa.gov/  Donor: Dr Di CookDepartment of StatisticsIowa State Universitydicook '@' iastate.edu http://www.public.iastate.edu/~dicook/ ","This data was collected with the Tropical Atmosphere Ocean (TAO) array which was developed by the international Tropical Ocean Global Atmosphere (TOGA) program. The TAO array consists of nearly 70 moored buoys spanning the equatorial Pacific, measuring oceanographic and surface meteorological variables critical for improved detection, understanding and prediction of seasonal-to-interannual climate variations originating in the tropics, most notably those related to the El Nino/Southern Oscillation (ENSO) cycles.  The moorings were developed by National Oceanic and Atmospheric Administration's (NOAA) Pacific Marine Environmental Laboratory (PMEL). Each mooring measures air temperature, relative humidity, surface winds, sea surface temperatures and subsurface temperatures down to a depth of 500 meters and a few a of the buoys measure currents, rainfall and solar radiation. The data from the array, and current updates, can be viewed on the web at the this address .  The El Nino/Southern Oscillation (ENSO) cycle of 1982-1983, the strongest of the century, created many problems throughout the world. Parts of the world such as Peru and the Unites States experienced destructive flooding from increased rainfalls while the western Pacific areas experienced drought and devastating brush fires. The ENSO cycle was neither predicted nor detected until it was near its peak. This highlighted the need for an ocean observing system (i.e. the TAO array) to support studies of large scale ocean-atmosphere interactions on seasonal-to-interannual time scales.  The TAO array provides real-time data to climate researchers, weather prediction centers and scientists around the world. Forcasts for tropical Pacific Ocean temperatures for one to two years in advance can be made using the ENSO cycle data. These forcasts are possible because of the moored buoys, along with drifting buoys, volunteer ship temperature probes, and sea level measurements.  Research questions of interest include:  - How can the data be used to predict weather conditions throughout the world? - How do the variables relate to each other? - Which variables have a greater effect on the climate variations? - Does the amount of movement of the buoy effect the reliability of the data? - When performing an analysis of the data, one should pay attention the possible affect of autocorrelation. Using a multiple regression approach to model the data would require a look at autoregression since the weather statistics of the previous days will affect today's weather.  The data is stored in an ASCII files with one observation per line. Spaces separate fields and periods (.) denote missing values.  More information and data from the TAO array can be found at the Pacific Marine Environmental Laboratory TAO data webpage: [Web Link]  Information on storm data is available here: [Web Link]. This site contains data from January 1994 to April 1998 in a chronological listing by state provided by the National Weather Service. The data includes hurricanes, tornadoes, thunderstorms, hail, floods, drought conditions, lightning, high winds, snow, and temperature extremes.  Hurricane tracking data for the Atlantic is available here: [Web Link]. The site contains a map showing the paths of the Atlantic hurricanes and also includes the storms winds (in knots), pressure (in millibars), and the category of the storm based on Saffir-Simpson scale.  Another site of interest related to the ENSO cyles is available here: [Web Link]. This site contains information on twelve areas of the world that have demonstrated ENSO-precipitation relationships. Included in the site are maps of the areas and time series plots of actual daily precipitation and accumulated normal precipitation for the areas. ","The data consists of the following variables: date, latitude, longitude, zonal winds (west<0, east>0), meridional winds (south<0, north>0), relative humidity, air temperature, sea surface temperature and subsurface temperatures down to a depth of 500 meters. Data taken from the buoys from as early as 1980 for some locations. Other data that was taken in various locations are rainfall, solar radiation, current levels, and subsurface temperatures.  The latitude and longitude in the data showed that the bouys moved around to different locations. The latitude values stayed within a degree from the approximate location. Yet the longitude values were sometimes as far as five degrees off of the approximate location.  Looking at the wind data, both the zonal and meridional winds fluctuated between -10 m/s and 10 m/s. The plot of the two wind variables showed no linear relationship. Also, the plots of each wind variable against the other three meteorolgical data showed no linear relationships.  The relative humidity values in the tropical Pacific were typically between 70% and 90%.  Both the air temperature and the sea surface temperature fluctuated between 20 and 30 degrees Celcius. The plot of the two temperatures variables shows a positive linear relationship existing. The two temperatures when each plotted against time also have similar plot designs. Plots of the other meteorological variables against the temperature variables showed no linear relationship.  There are missing values in the data. As mentioned earlier, not all buoys are able to measure currents, rainfall, and solar radiation, so these values are missing dependent on the individual buoy. The amount of data available is also dependent on the buoy, as certain buoys were commissioned earlier than others.  All readings were taken at the same time of day.  ",N/A,"Please refer to the Machine Learning
Repository's citation policy","Stephen D. Bay and Dennis F. Kibler and Michael J. Pazzani and Padhraic Smyth. The UCI KDD Archive of Large Data Sets for Data Mining Research and Experimentation. SIGKDD Explorations, 2. 2000.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Z-Alizadeh+Sani,256,Z-Alizadeh Sani Data Set,../machine-learning-databases/00412/,N/A,303,Life,"Integer, Real",56,11/17/2017,Classification,N/A,21616,"Provide the names, email addresses, institutions, and other contact information of the donors and creators of the data set. Name:Dr Zahra Alizadeh Sani,Associate Professor of cardiology,email:Drzas '@' rhc.ac.ir,institution: Cardiovascular Imaging Department, Rajaei Cardiovascular, Medical & Research Center, Iran University , Tehran, Iran.Post code:1996911151website: http://dralizadehsani.rhc.ac.ir/Files/Forms/2016-11-13_01.46.29_dr.alizadeh.CV.pdf  Name:Roohallah Alizadehsani, PhD studentemail: alizadeh_roohallah '@' yahoo.com institution: Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Victoria 3217, Australia.website: http://ce.sharif.ir/~ralizadeh/  Name: Mohamad Roshanzamir, PhD candidateemail: mohamad.roshanzamir '@' ec.iut.ac.ir institution: Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran.","Each patient could be in two possible categories CAD or Normal. A patient is categorized as CAD, if his/her diameter narrowing is greater than or equal to 50%, and otherwise as Normal .","The Z-Alizadeh Sani dataset contains the records of 303 patients, each of which have 54 features.The features are arranged in four groups: demographic, symptom and examination, ECG, and laboratory and echo features.","R. Alizadehsani, J. Habibi, M. J. Hosseini, H. Mashayekhi, R. Boghrati, A. Ghandeharioun, et al., 'A data mining approach for diagnosis of coronary artery disease,' Computer Methods and Programs in Biomedicine, vol. 111, pp. 52-61, 2013/07/01/ 2013. R. Alizadehsani, J. Habibi, B. Bahadorian, H. Mashayekhi, A. Ghandeharioun, R. Boghrati, et al., 'Diagnosis of Coronary Arteries Stenosis Using Data Mining,' Journal of Medical Signals and Sensors, vol. 2, pp. 153-159, Jul-Sep R. Alizadehsani, M. J. Hosseini, Z. A. Sani, A. Ghandeharioun, and R. Boghrati, 'Diagnosis of Coronary Artery Disease Using Cost-Sensitive Algorithms,' in 2012 IEEE 12th International Conference on Data Mining Workshops, 2012, pp. 9-16. Z. Arabasadi, R. Alizadehsani, M. Roshanzamir, H. Moosaei, and A. A. Yarifard, 'Computer aided decision making for heart disease detection using hybrid neural network-Genetic algorithm,' Computer Methods and Programs in Biomedicine, vol. 141, pp. 19-26, 2017/04/01/ 2017. R. Alizadehsani, J. Habibi, Z. Alizadeh Sani, H. Mashayekhi, R. Boghrati, A. Ghandeharioun, et al., 'Diagnosing Coronary Artery Disease via Data Mining Algorithms by Considering Laboratory and Echocardiography Features,' Research in Cardiovascular Medicine, vol. 2, pp. 133-139, 07/31 R. Alizadehsani, J. Habibi, M. J. Hosseini, R. Boghrati, A. Ghandeharioun, B. Bahadorian, et al., 'Diagnosis of coronary artery disease using data mining techniques based on symptoms and ecg features,' European Journal of Scientific Research, vol. 82, pp. 542-553, 2012. R. Alizadehsani, M. H. Zangooei, M. J. Hosseini, J. Habibi, A. Khosravi, M. Roshanzamir, et al., 'Coronary artery disease detection using computational intelligence methods,' Knowledge-Based Systems, vol. 109, pp. 187-197, 2016/10/01/ 2016. R. Alizadehsani, J. Habibi, Z. A. Sani, H. Mashayekhi, R. Boghrati, A. Ghandeharioun, et al., 'Diagnosis of Coronary Artery Disease Using Data mining based on Lab Data and Echo Features,' Journal of Medical and Bioengineering, vol. 1, 2012. A. Roohallah, H. Mohammad Javad, B. Reihane, G. Asma, K. Fahime, and S. Zahra Alizadeh, 'Exerting Cost-Sensitive and Feature Creation Algorithms for Coronary Artery Disease Diagnosis,' International Journal of Knowledge Discovery in Bioinformatics (IJKDB), vol. 3, pp. 59-79, 2012. R. Alizadehsani, M. J. Hosseini, Z. Alizadehsani, M. H. Mohammadi, O. Barati, and F. Khozeimeh, 'System for determining the need for Angiography in patients with symptoms of Coronary Artery disease,' ed: Google Patents, 2014. F. BabiÄ, J. OlejÃ¡r, Z. VantovÃ¡, and J. ParaliÄ, 'Predictive and Descriptive Analysis for Heart Disease Diagnosis,' presented at the Federated Conference on Computer Science and Information Systems, 2017. LOHITA, Kodali et al. Performance Analysis of Various Data Mining Techniques in the Prediction of Heart Disease. Indian Journal of Science and Technology, [S.l.], dec. 2015. ISSN 0974 -5645. Available at: <[Web Link]>. Date accessed: 17 Nov. 2017. [Web Link]. J. BektaÅŸ, T. IbrikÃ§i, and I. Ã–zcan, 'Classification of Real Imbalanced Cardiovascular Data Using Feature Selection and Sampling Methods: A Case Study with Neural Networks and Logistic Regression,' International Journal on Artificial Intelligence Tools, 2017. C. Yadav, S. Lade, and M. K. Suman, 'Predictive Analysis for the Diagnosis of Coronary Artery Disease using Association Rule Mining,' International Journal of Computer Applications, vol. 87, 2014.  ","Z-Alizadeh Sani Dataset User Agreement I agree with following items. â€¢	To cite  Z-Alizadeh Sani Dataset in any paper of mine or my collaborators that makes any use of the database. The reference is: 1.	R. Alizadehsani et al., â€œA data mining approach for diagnosis of coronary artery disease,â€ Computer Methods and Programs in Biomedicine, vol.111, no.1, pp.52-61, Jul. 2013.2.	R. Alizadehsani, M.H. Zangooei, M.J. Hosseini, J. Habibi, A. Khosravi, M. Roshanzamir, F. Khozeimeh, N. Sarrafzadegan, S. Nahavandi, Coronary artery disease detection using computational intelligence methods, Knowledge-Based Systems, 109 (2016) 187-1973.	Z. Arabasadi, R. Alizadehsani, M. Roshanzamir, H. Moosaei, and A. A. Yarifard, 'Computer aided decision making for heart disease detection using hybrid neural network-Genetic algorithm,' Computer Methods and Programs in Biomedicine, vol. 141, pp. 19-26, 2017/04/01/ 2017. â€¢	To use the dataset for research purposes only.",
http://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength,257,Concrete Compressive Strength Data Set,../machine-learning-databases/concrete/compressive/,Multivariate,1030,Physical,Real,9,8/3/2007,Regression,N/A,206112,"Original Owner and DonorProf. I-Cheng YehDepartment of Information Management Chung-Hua University, Hsin Chu, Taiwan 30067, R.O.C.e-mail:icyeh '@' chu.edu.tw TEL:886-3-5186511 Date Donated: August 3, 2007","Number of instances 	1030Number of Attributes	9Attribute breakdown	8 quantitative input variables, and 1 quantitative output variableMissing Attribute Values	None ","Given are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database.  Name -- Data Type -- Measurement -- Description Cement (component 1) -- quantitative -- kg in a m3 mixture -- Input VariableBlast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input VariableFly Ash (component 3) -- quantitative  -- kg in a m3 mixture -- Input VariableWater  (component 4) -- quantitative  -- kg in a m3 mixture -- Input VariableSuperplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input VariableCoarse Aggregate  (component 6) -- quantitative -- kg in a m3 mixture -- Input VariableFine Aggregate (component 7)	 -- quantitative  -- kg in a m3 mixture -- Input VariableAge -- quantitative  -- Day (1~365) -- Input VariableConcrete compressive strength -- quantitative -- MPa -- Output Variable ","Main1.	I-Cheng Yeh, ""Modeling of strength of high performance concrete using artificial neural networks,"" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998). Others2.	I-Cheng Yeh, ""Modeling Concrete Strength with Augment-Neuron Networks,"" J. of Materials in Civil Engineering, ASCE, Vol. 10, No. 4, pp. 263-268 (1998).3.	I-Cheng Yeh, ""Design of High Performance Concrete Mixture Using Neural Networks,""  J. of Computing in Civil Engineering, ASCE, Vol. 13, No. 1, pp. 36-42 (1999).4.	I-Cheng Yeh, ""Prediction of Strength of Fly Ash and Slag Concrete By The Use of Artificial Neural Networks,"" Journal of the Chinese Institute of Civil and Hydraulic Engineering, Vol. 15, No. 4, pp. 659-663 (2003).5.	I-Cheng Yeh, ""A mix Proportioning Methodology for Fly Ash and Slag Concrete Using Artificial Neural Networks,"" Chung Hua Journal of Science and Engineering, Vol. 1, No. 1, pp. 77-84 (2003).6.	Yeh, I-Cheng, ""Analysis of strength of concrete using design of experiments and neural networks,"" Journal of Materials in Civil Engineering, ASCE, Vol.18, No.4, pp.597-604 (2006).","NOTE: Reuse of this database is unlimited with retention of copyright notice for Prof. I-Cheng Yeh and the following published paper: I-Cheng Yeh, ""Modeling of strength of high performance concrete using artificial neural networks,"" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998).",
http://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014,258,ElectricityLoadDiagrams20112014 Data Set,../machine-learning-databases/00321/,Time-Series,370,Computer,Real,140256,3/13/2015,"Regression, Clustering",N/A,73895,"Artur Trindade, artur.trindade '@' elergone.pt, Elergone, NORTE-07-0202-FEDER-038564Data type: TSTask: regression, clusteringNumber of Instances (records in your data set):370Number of Attributes (fields within each record):140256","Data set has no missing values.Values are in kW of each 15 min. To convert values in kWh values must be divided by 4.Each column represent one client. Some clients were created after 2011. In these cases consumption were considered zero.All time labels report to Portuguese hour. However all days present 96 measures (24*4). Every year in March time change day (which has only 23 hours) the values between 1:00 am and 2:00 am are zero for all points. Every year in October time change day (which has 25 hours) the values between 1:00 am and 2:00 am aggregate the consumption of two hours.","Data set were saved as txt using csv format, using semi colon (;).First column present date and time as a string with the following format 'yyyy-mm-dd hh:mm:ss'Other columns present float values with consumption in kW",Provide references to papers that have cited this data set in the past (if any).,"If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set,259,Real estate valuation data set Data Set,../machine-learning-databases/00477/,Multivariate,414,Business,"Integer, Real",7,8/18/2018,Regression,N/A,72976,"Original Owner and DonorName: Prof. I-Cheng YehInstitutions: Department of Civil Engineering, Tamkang University, Taiwan.Email: 140910 '@' mail.tku.edu.tw TEL: 886-2-26215656 ext. 3181 Date Donated: Aug. 18, 2018","The market historical data set of real estate valuation are collected from Sindian Dist., New Taipei City, Taiwan. The â€œreal estate valuationâ€ is a regression problem. The data set was randomly split into the training data set (2/3 samples) and the testing data set (1/3 samples).","The inputs are as followsX1=the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)X2=the house age (unit: year)X3=the distance to the nearest MRT station (unit: meter)X4=the number of convenience stores in the living circle on foot (integer)X5=the geographic coordinate, latitude. (unit: degree)X6=the geographic coordinate, longitude. (unit: degree) The output is as followY= house price of unit area (10000 New Taiwan Dollar/Ping, where Ping is a local unit, 1 Ping = 3.3 meter squared)","Yeh, I. C., & Hsu, T. K. (2018). Building real estate valuation models with comparative approach through case-based reasoning. Applied Soft Computing, 65, 260-271.","Yeh, I. C., & Hsu, T. K. (2018). Building real estate valuation models with comparative approach through case-based reasoning. Applied Soft Computing, 65, 260-271.",
http://archive.ics.uci.edu/ml/datasets/NoisyOffice,260,NoisyOffice Data Set,../machine-learning-databases/00318/,Multivariate,216,Computer,Real,216,1/3/2015,"Classification, Regression",N/A,66866,"M.J. Castro-Bleda (1), S. España-Boquera (1), J. Pastor-Pellicer (1), F. Zamora-Martinez (2) mcastro '@' dsic.upv.es, sespana '@' dsic.upv.es, jpastor '@' dsic.upv.es, francisco.zamora '@' uch.ceu.es(1) Departamento de Sistemas Informáticos  y Computación, Universitat Politècnica  de València, Valencia, Spain(2) Departamento de Ciencias Físicas, Matemáticas y de la Computación, Universidad CEU Cardenal Herrera, Alfara del Patriarca, València, Spain","AIMS AND PURPOSES This corpus is intended to do cleaning (or binarization) and enhancement of noisy grayscale printed text images using supervised learning methods. To this end, noisy images and their corresponding cleaned or binarized ground truth are provided. Double resolution ground truth images are also provided in order to test superresolution methods. CORPUS DIRECTORIES STRUCTURE SimulatedNoisyOffice folder has been prepared for training, validation and test of supervised methods. RealNoisyOffice folder is provided for subjective evaluation. .|-- RealNoisyOffice|   |-- real_noisy_images_grayscale|   `-- real_noisy_images_grayscale_doubleresolution`-- SimulatedNoisyOffice    |-- clean_images_binaryscale    |-- clean_images_grayscale    |-- clean_images_grayscale_doubleresolution    `-- simulated_noisy_images_grayscale RealNoisyOffice- real_noisy_images_grayscale: 72 grayscale images of scanned 'noisy' images.- real_noisy_images_grayscale_doubleresolution: idem, double resolution. SimulatedNoisyOffice- simulated_noisy_images_grayscale: 72 grayscale images of scanned 'simulated noisy' images for training, validation and test.- clean_images_grayscale_doubleresolution: Grayscale ground truth of the images with double resolution.- clean_images_grayscale: Grayscale ground truth of the images with smoothing on the borders (normal resolution).- clean_images_binary: Binary ground truth of the images (normal resolution). DESCRIPTION Every file is a printed text image following the pattern FontABC_NoiseD_EE.png: A) Size of the font: footnote size (f), normal size (n) o large size (L). B) Font type: typewriter (t), sans serif (s) or roman (r).  C) Yes/no emphasized font (e/m). D) Type of noise: folded sheets (Noise f), wrinkled sheets (Noise w), coffee stains (Noise c), and footprints (Noise p). E) Data set partition: training (TR), validation (VA), test (TE), real (RE). For each type of font, one type of Noise: 17 files * 4 types of noise = 72 images. OTHER INFORMATION 200 ppi => normal resolution400 ppi => double resolution","The format of each file is the following: Grayscale PNG files ([Web Link]). The ground truth is also provided as grayscale PNG files, and for the binary version the values are saturated to 0 and 255.","J. L. Adelantado­Torres, J. Pastor­Pellicer, and M. J. Castro­Bleda. Una aplicación móvil para la captura ymejora de imágenes de textos, in: V Jornadas TIMM (Tratamiento de la Información Multilingüe yMultimodal), Red temática TIMM (Tratamiento de Información Multilingüe y Multimodal), Sevilla, 2014. M. J. Castro­Bleda, S. España­Boquera and F. Zamora­Martinez. Encyclopedia of Artificial Intelligence,chapter Behaviour­based Clustering of Neural Networks, pages 144­151, Information Science Reference,2009. F. Zamora­Martinez, S. España­Boquera and M. J. Castro­Bleda. Behaviour­based Clustering of NeuralNetworks applied to Document Enhancement, in: Computational and Ambient Intelligence, pages 144­151,Springer, 2007.","Please refer to the Machine Learning Repository's citation policy [Web Link].For the database:F. Zamora-Martinez, S. España-Boquera and M. J. Castro-Bleda, Behaviour-based Clustering of Neural Networks applied to Document Enhancement, in: Computational and Ambient Intelligence, pages 144-151, Springer, 2007.",
http://archive.ics.uci.edu/ml/datasets/YouTube+Comedy+Slam+Preference+Data,261,YouTube Comedy Slam Preference Data Data Set,../machine-learning-databases/00223/,Text,1138562,Computer,N/A,3,4/10/2012,Classification,N/A,92322,"Provided by Google, Inc. Please contact duhadway '@' google.com if you have any questions.","YouTube Comedy Slam ([Web Link]) is a video discovery experiment running on YouTube's version of labs (called TestTube) for a few months in 2011 and 2012. In this experiment, a pair of videos were shown to the user and the user was asked to vote for the video that they found funnier. Left/right positions of the videos were randomly selected before being presented to the user to eliminate position bias. Videos were selected from a large pool of weekly updated sets of videos. One of the outcomes of this experiment is a training dataset for automatically predicting which video would be deemed funnier by users using a variety of features.  For example, uploader supplied metadata and/or user comments on watch pages of these videos could be used as features. See [Web Link] for more detail. The attached dataset includes roughly 1.7 million preference votes. The votes were recorded chronologically. The first 80% are provided here as the training dataset and the remaining 20% as the testing dataset. Each line in this dataset corresponds to one vote over a pair of YouTube videos. Each video is represented by its YouTube video ID. For example, the watch page URL for video ID 'txqiwrbYGrs' is [Web Link]. User preference over a pair of videos is presented in the form of string â€œleftâ€ if the left video was deemed funnier, and â€œrightâ€ otherwise. This user vote should be used as ground truth for both training and testing. Evaluation should be based on average accuracy in predicting this preference over the testing partition (provided). Any other information about the vote (e.g. ID of the user) is not provided.",Each row in this text file represents one anonymous user vote. Each line contains three comma-separated fields. The first two fields are YouTube video IDs. The third field is either 'left' or 'right'. Left indicates the first video from the pair was voted to be funnier than the second. Right indicates the opposite preference.,N/A,"Sanketh Shetty, 'Quantifying comedy on YouTube: why the number of oâ€™s in your LOL matter,' Google Research Blog, [Web Link].",
http://archive.ics.uci.edu/ml/datasets/Bank+Marketing,262,Bank Marketing Data Set,../machine-learning-databases/00222/,Multivariate,45211,Business,Real,17,2/14/2012,Classification,N/A,1238325,"[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014","The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. There are four datasets: 1) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs). 4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). The smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM). The classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).","Input variables:   # bank client data:   1 - age (numeric)   2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')   3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)   4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')   5 - default: has credit in default? (categorical: 'no','yes','unknown')   6 - housing: has housing loan? (categorical: 'no','yes','unknown')   7 - loan: has personal loan? (categorical: 'no','yes','unknown')   # related with the last contact of the current campaign:   8 - contact: contact communication type (categorical: 'cellular','telephone')    9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')  10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')  11 - duration: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.   # other attributes:  12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)  13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  14 - previous: number of contacts performed before this campaign and for this client (numeric)  15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')   # social and economic context attributes  16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)  17 - cons.price.idx: consumer price index - monthly indicator (numeric)       18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)       19 - euribor3m: euribor 3 month rate - daily indicator (numeric)  20 - nr.employed: number of employees - quarterly indicator (numeric)  Output variable (desired target):  21 - y - has the client subscribed a term deposit? (binary: 'yes','no')","S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimaraes, Portugal, October, 2011. EUROSIS.  [bank.zip]","This dataset is public available for research. The details are described in [Moro et al., 2014]. Please include this citation if you plan to use this database: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014",
http://archive.ics.uci.edu/ml/datasets/A+study+of++Asian+Religious+and+Biblical+Texts,263,A study of  Asian Religious and Biblical Texts Data Set,../machine-learning-databases/00512/,"Multivariate, Text",590,Social,Integer,8265,12/24/2019,"Classification, Clustering",N/A,16938,"Preeti SahCollege of Computing and Information Sciences Rochester Institute of TechnologyRochester, NY 14623Email:ks3911 '@' rit.edu   Ernest FokoueSchool of Mathematical SciencesRochester Institute of TechnologyRochester, NY 14623Email: epfeqa '@' rit.edu","Most of the sacred texts in this dataset were collected from Project Gutenberg. We herein provide the raw texts along with our pre-processed Document Term Matrices (DTM). For more details, please contact the authors",The attributes are just the words from the bag of words preprocessing of the  mini-corpus made up of the 8 religious books considered in this study. There are 8265 words used,"@misc{sah2019asian,    title={What do Asian Religions Have in Common? An Unsupervised Text Analytics Exploration},    author={Preeti Sah and Ernest FokouÃ©},    year={2019},    eprint={1912.10847},    archivePrefix={arXiv},    primaryClass={cs.CL}}","@misc{sah2019asian, title={What do Asian Religions Have in Common? An Unsupervised Text Analytics Exploration},    author={Preeti Sah and Ernest FokouÃ©},    year={2019},    eprint={1912.10847},    archivePrefix={arXiv},    primaryClass={cs.CL}}",
http://archive.ics.uci.edu/ml/datasets/Economic+Sanctions,264,Economic Sanctions Data Set,../machine-learning-databases/undocumented/pazzani/,Domain-Theory,N/A,Financial,N/A,N/A,N/A,N/A,N/A,59299,"Michael Pazzanipazzani '@' ICS.UCI.EDU",I think you'll find some limited documentation on Mike's database in his papers.  His dissertation would be a good reference (UCLA).  Perhaps pages 152-153 in the EWSL-1988 proceedings should help with understanding the data format.  Pages 713-718 of IJCAI-1989 should help even more.,N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",Sally Jo Cunningham. Dataset cataloging metadata for machine learning applications and research. Department of Computer Science University of Waikato.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Ozone+Level+Detection,265,Ozone Level Detection Data Set,../machine-learning-databases/ozone/,"Multivariate, Sequential, Time-Series",2536,Physical,Real,73,4/21/2008,Classification,Yes,138784,"Kun Zhang, zhang.kun05 '@' gmail.com, Department of Computer Science, Xavier University of LousianaWei Fan, wei.fan '@' gmail.com,  IBM T.J.Watson ResearchXiaoJing Yuan, xyuan '@' uh.edu, Engineering Technology Department, College of Technology, University of Houston","For a list of attributes, please refer to those two .names files.  They use the following naming convention: All the attribute start with T means the temperature measured at different time throughout the day; and those starts with WS indicate the wind speed at various time. WSR_PK:     continuous. peek wind speed -- resultant (meaning average of wind vector) WSR_AV:     continuous. average wind speed T_PK:     continuous. Peak TT_AV:     continuous. Average TT85:     continuous. T at 850 hpa level (or about 1500 m height)RH85:     continuous. Relative Humidity at 850 hpaU85:     continuous. (U wind - east-west direction wind at 850 hpa)V85:     continuous. V wind - N-S direction wind at 850HT85:     continuous. Geopotential height at 850 hpa, it is about the same as height at low altitudeT70:     continuous. T at 700 hpa level (roughly 3100 m height) RH70:     continuous.U70:     continuous.V70:     continuous.HT70:     continuous. T50:     continuous. T at 500 hpa level (roughly at 5500 m height) RH50:     continuous.U50:     continuous.V50:     continuous.HT50:     continuous. KI:     continuous. K-Index [Web Link] TT:     continuous. T-Totals [Web Link] SLP:     continuous. Sea level pressureSLP_:     continuous. SLP change from previous day Precp:    continuous. -- precipitation","The following are specifications for several most important attributes that are highly valued by Texas Commission on Environmental Quality (TCEQ). More details can be found in the two relevant papers. O 3 - Local ozone peak predictionUpwind - Upwind ozone background levelEmFactor - Precursor emissions related factorTmax - Maximum temperature in degrees FTb - Base temperature where net ozone production begins (50 F)SRd - Solar radiation total for the dayWSa - Wind speed near sunrise (using 09-12 UTC forecast mode)WSp - Wind speed mid-day (using 15-21 UTC forecast mode)  Please refer to those two .names files.","Forecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008. Discusses details about the dataset, its use as well as various experiments (both cross-validation and streaming) using many state-of-the-art methods.A shorter version of the paper (does not contain some detailed experiments as the journal paper above) is in: Forecasting Skewed Biased Stochastic Ozone Days: Analyses and Solutions. ICDM 2006: 753-764","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/YouTube+Multiview+Video+Games+Dataset,266,YouTube Multiview Video Games Dataset Data Set,../machine-learning-databases/00269/,"Multivariate, Text",120000,Computer,"Integer, Real",1000000,10/16/2013,"Classification, Clustering",Yes,128065," Omid Madani , madani '@' google.com, Google Inc.","Please see the README for the details on the data organization, and so on.",Please see the README.,"[Provide references to papers that have cited this data set in the past (if any).] Our recent work used a close version of this dataset: On Using Nearly-Independent Feature Families for High Precision and Confidence, in Machine Learning Journal, 2013 (please see the citation request) and an earlier version in Asian Conference on Machine Learning (ACML 2012): On Using Nearly-Independent Feature Families for High Precision and Confidence. O. Madani, M. Georg, and D. Ross. ACML 2012. "," Please cite the following (also specified in the README): @article{madaniEtAl2013MLJ,  title= {On Using Nearly-Independent Feature Families for High Precision and Confidence}  author = {Omid Madani and Manfred Georg and David A. Ross},  journal = {Machine Learning},  year = {2013},  volume = {92},  pages = {457-477},  note = {published online 30 May 2013, [Web Link]},} ",
http://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation,267,QSAR biodegradation Data Set,../machine-learning-databases/00254/,Multivariate,1055,N/A,"Integer, Real",41,6/21/2013,Classification,N/A,47400,"Kamel Mansouri, Tine Ringsted, Davide Ballabio (davide.ballabio '@' unimib.it), Roberto Todeschini, Viviana Consonni, Milano Chemometrics and QSAR Research Group (http://michem.disat.unimib.it/chm/), UniversitÃ  degli Studi Milano â€“ Bicocca, Milano (Italy)","The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group (UniversitÃ  degli Studi Milano â€“ Bicocca, Milano, Italy). The research leading to these results has received funding from the European Communityâ€™s Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.","41 molecular descriptors and 1 experimental class:1) SpMax_L: Leading eigenvalue from Laplace matrix2) J_Dz(e): Balaban-like index from Barysz matrix weighted by Sanderson electronegativity3) nHM: Number of heavy atoms4) F01[N-N]: Frequency of N-N at topological distance 15) F04[C-N]: Frequency of C-N at topological distance 46) NssssC: Number of atoms of type ssssC7) nCb-: Number of substituted benzene C(sp2)8) C%: Percentage of C atoms9) nCp: Number of terminal primary C(sp3)10) nO: Number of oxygen atoms11) F03[C-N]: Frequency of C-N at topological distance 312) SdssC: Sum of dssC E-states13) HyWi_B(m): Hyper-Wiener-like index (log function) from Burden matrix weighted by mass14) LOC: Lopping centric index15) SM6_L: Spectral moment of order 6 from Laplace matrix16) F03[C-O]: Frequency of C - O at topological distance 317) Me: Mean atomic Sanderson electronegativity (scaled on Carbon atom)18) Mi: Mean first ionization potential (scaled on Carbon atom)19) nN-N: Number of N hydrazines20) nArNO2: Number of nitro groups (aromatic)21) nCRX3: Number of CRX322) SpPosA_B(p): Normalized spectral positive sum from Burden matrix weighted by polarizability23) nCIR: Number of circuits24) B01[C-Br]: Presence/absence of C - Br at topological distance 125) B03[C-Cl]: Presence/absence of C - Cl at topological distance 326) N-073: Ar2NH / Ar3N / Ar2N-Al / R..N..R27) SpMax_A: Leading eigenvalue from adjacency matrix (Lovasz-Pelikan index)28) Psi_i_1d: Intrinsic state pseudoconnectivity index - type 1d29) B04[C-Br]: Presence/absence of C - Br at topological distance 430) SdO: Sum of dO E-states31) TI2_L: Second Mohar index from Laplace matrix32) nCrt: Number of ring tertiary C(sp3)33) C-026: R--CX--R34) F02[C-N]: Frequency of C - N at topological distance 235) nHDon: Number of donor atoms for H-bonds (N and O)36) SpMax_B(m): Leading eigenvalue from Burden matrix weighted by mass37) Psi_i_A: Intrinsic state pseudoconnectivity index - type S average38) nN: Number of Nitrogen atoms39) SM6_B(m): Spectral moment of order 6 from Burden matrix weighted by mass40) nArCOOR: Number of esters (aromatic)41) nX: Number of halogen atoms42) experimental class: ready biodegradable (RB) and not ready biodegradable (NRB)","Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878","Please, cite the following paper if you publish results based on the QSAR biodegradation dataset: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878",
http://archive.ics.uci.edu/ml/datasets/Cargo+2000+Freight+Tracking+and+Tracing,268,Cargo 2000 Freight Tracking and Tracing Data Set,../machine-learning-databases/00382/,"Multivariate, Sequential",3942,Business,Integer,98,11/3/2016,"Classification, Regression",Yes,42627,"Andreas Metzger (andreas.metzger '@' paluno.uni-due.de)paluno (The Ruhr Institute for Software Technology) University of Duisburg-Essen GerlingstraÃŸe 16 45127 Essen, Germany",A description of the underlying Cargo 2000 standard and the processes reflected in the data set can be found at [Web Link].,"nr - unique id for process instance of overall process  -  domain: [1â€¦3942] i1_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 1 - domain: [1..14664]i1_rcs_p - planned duration (minutes) of incoming transport leg 1 (RCS: Freight Check in) - domain: [LONGINT]i1_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCS: Freight Check in) - domain: [LONGINT]i1_dep_1_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [LONGINT]i1_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [LONGINT]i1_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [100â€¦816]i1_rcf_1_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [LONGINT]i1_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [LONGINT]i1_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [100â€¦816]i1_dep_2_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [LONGINT]i1_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [LONGINT]i1_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [100â€¦816]i1_rcf_2_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [LONGINT]i1_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [LONGINT]i1_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [100â€¦816]i1_dep_3_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [LONGINT]i1_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [LONGINT]i1_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [100â€¦816]i1_rcf_3_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [LONGINT]i1_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [LONGINT]i1_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [100â€¦816]i1_dlv_p - planned duration (minutes) of incoming transport leg 1 (DLV: Freight Delivery) - domain: [LONGINT]i1_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DLV: Freight Delivery) - domain: [LONGINT]i1_hops - number of segments (hops) in the transport leg of incoming transport leg 1 - domain: [1..4] i2_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 2    - domain: [1..14664]i2_rcs_p - planned duration (minutes) of incoming transport leg 2 (RCS: Freight Check in) - domain: [LONGINT]i2_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCS: Freight Check in) - domain: [LONGINT]i2_dep_1_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [LONGINT]i2_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [LONGINT]i2_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [100â€¦816]i2_rcf_1_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [LONGINT]i2_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [LONGINT]i2_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [100â€¦816]i2_dep_2_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [LONGINT]i2_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [LONGINT]i2_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [100â€¦816]i2_rcf_2_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [LONGINT]i2_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [LONGINT]i2_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [100â€¦816]i2_dep_3_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [LONGINT]i2_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [LONGINT]i2_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [100â€¦816]i2_rcf_3_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [LONGINT]i2_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [LONGINT]i2_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [100â€¦816]i2_dlv_p - planned duration (minutes) of incoming transport leg 2 (DLV: Freight Delivery) - domain: [LONGINT]i2_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DLV: Freight Delivery) - domain: [LONGINT]i2_hops - number of segments (hops) in the transport leg of incoming transport leg 2 - domain: [1..4] i3_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 3    - domain: [1..14664]i3_rcs_p - planned duration (minutes) of incoming transport leg 3 (RCS: Freight Check in) - domain: [LONGINT]i3_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCS: Freight Check in) - domain: [LONGINT]i3_dep_1_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [LONGINT]i3_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [LONGINT]i3_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [100â€¦816]i3_rcf_1_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [LONGINT]i3_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [LONGINT]i3_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [100â€¦816]i3_dep_2_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [LONGINT]i3_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [LONGINT]i3_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [100â€¦816]i3_rcf_2_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [LONGINT]i3_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [LONGINT]i3_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [100â€¦816]i3_dep_3_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [LONGINT]i3_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [LONGINT]i3_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [100â€¦816]i3_rcf_3_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [LONGINT]i3_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [LONGINT]i3_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [100â€¦816]i3_dlv_p - planned duration (minutes) of incoming transport leg 3 (DLV: Freight Delivery) - domain: [LONGINT]i3_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DLV: Freight Delivery) - domain: [LONGINT]i3_hops - number of segments (hops) in the transport leg of incoming transport leg 3 - domain: [1..4] o_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of outgoing transport leg    - domain: [1..14664]o_rcs_p - planned duration (minutes) of outgoing transport leg (RCS: Freight Check in) - domain: [LONGINT]o_rcs_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCS: Freight Check in) - domain: [LONGINT]o_dep_1_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 1) - domain: [LONGINT]o_dep_1_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 1) - domain: [LONGINT]o_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 1) - domain: [100â€¦816]o_rcf_1_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [LONGINT]o_rcf_1_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [LONGINT]o_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [100â€¦816]o_dep_2_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 2) - domain: [LONGINT]o_dep_2_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 2) - domain: [LONGINT]o_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 2) - domain: [100â€¦816]o_rcf_2_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [LONGINT]o_rcf_2_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [LONGINT]o_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [100â€¦816]o_dep_3_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 3) - domain: [LONGINT]o_dep_3_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 3) - domain: [LONGINT]o_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 3) - domain: [100â€¦816]o_rcf_3_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [LONGINT]o_rcf_3_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [LONGINT]o_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [100â€¦816]o_dlv_p - planned duration (minutes) of outgoing transport leg (DLV: Freight Delivery) - domain: [LONGINT]o_dlv_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DLV: Freight Delivery) - domain: [LONGINT]o_hops - number of segments (hops) in the transport leg of outgoing transport leg - domain: [1..4] legs - number of incoming transport legs of overall process    - domain: [1..3]","A. Metzger, P. Leitner, D. Ivanovic, E. Schmieders, R. Franklin, M. Carro, S. Dustdar, and K. Pohl, â€œComparing and combining predictive business process monitoring techniques,â€ IEEE Trans. on Systems Man Cybernetics: Systems, vol. 45, no. 2, pp. 276â€“290, 2015. [Web Link]  Z. Feldmann, F. Fournier, R. Franklin, and A. Metzger, â€œIndustry article: Proactive event processing in action: A case study on the proactive management of transport processes,â€ in Proceedings of the Seventh ACM International Conference on Distributed Event-Based Systems, DEBS 2013, Arlington, Texas, USA, S. Chakravarthy, S. Urban, P. Pietzuch, E. Rundensteiner, and S. Dietrich, Eds. ACM, 2013, pp. 97â€“106. [Web Link] ","A. Metzger, P. Leitner, D. Ivanovic, E. Schmieders, R. Franklin, M. Carro, S. Dustdar, and K. Pohl, â€œComparing and combining predictive business process monitoring techniques,â€ IEEE Trans. on Systems Man Cybernetics: Systems, vol. 45, no. 2, pp. 276â€“290, 2015. [Web Link]",
http://archive.ics.uci.edu/ml/datasets/CSM+%28Conventional+and+Social+Media+Movies%29+Dataset+2014+and+2015,269,CSM (Conventional and Social Media Movies) Dataset 2014 and 2015 Data Set,../machine-learning-databases/00424/,Multivariate,217,Computer,Integer,12,10/11/2017,"Classification, Regression",Yes,30471,"Mehreen AhmedDepartment of Computer Software EngineeringNational University of Sciences and Technology (NUST),Islamabad, Pakistanmahreenmcs '@' gmail.com","Year:2014 and 2015Source: Twitter,YouTube,IMDB",Provide information about each attribute in your data set.,"Ahmed M, Jahangir M, Afzal H, Majeed A, Siddiqi I. Using Crowd-source based features from social media and Conventional features to predict the movies popularity. InSmart City/SocialCom/SustainCom (SmartCity), 2015 IEEE International Conference on 2015 Dec 19 (pp. 273-278). IEEE.","Please cite this paper:Ahmed M, Jahangir M, Afzal H, Majeed A, Siddiqi I. Using Crowd-source based features from social media and Conventional features to predict the movies popularity. InSmart City/SocialCom/SustainCom (SmartCity), 2015 IEEE International Conference on 2015 Dec 19 (pp. 273-278). IEEE.",
http://archive.ics.uci.edu/ml/datasets/Twitter+Data+set+for+Arabic+Sentiment+Analysis,270,Twitter Data set for Arabic Sentiment Analysis Data Set,../machine-learning-databases/00293/,Text,2000,Social,N/A,2,4/11/2014,Classification,N/A,90919,"N. A. Abdulla, naabdulla11 '@' cit.just.edu.jo"," --- By using a tweet crawler, we collect 2000 labelled tweets (1000 positive tweets and 1000 negative ones)       on various topics such as: politics and arts. These tweets include opinions written in both       Modern Standard Arabic (MSA) and the Jordanian dialect.    --- The selected tweets convey some kind of feelings (positive or negative) and the objective of our model is        to extract valuable information from such tweets in order to determine the sentiment orientation of the inputted text.       The months-long annotation process of the tweets is manually conducted mainly by two human experts       (native speakers of Arabic). If both experts agree on the label of a certain tweet, then the tweet is assigned this label.       Otherwise, a third expert is consulted to break the tie.     --- Predicted attribute: class of opinion polarity.","1. Tweet as a string vector   2. class:       -- Positive polarity      -- Negative poalrity Summary Statistics:	 			        Positive	Negative          	Total tweets		        1000	        1000	Total words		        7189	        9769	Avg. words in each tweet        7.19	        9.97	Avg. characters in each tweet	40.04	        59.02","Abdulla N. A., Mahyoub N. A., Shehab M., Al-Ayyoub M.,â€œArabic Sentiment Analysis: Corpus-based and Lexicon-basedâ€,IEEE conference on Applied Electrical Engineering and Computing Technologies (AEECT 2013),December 3-12, 2013, Amman, Jordan. (Accepted for Publication).",Please cite the above paper if you utilize the data set.,
http://archive.ics.uci.edu/ml/datasets/Soybean+%28Large%29,271,Soybean (Large) Data Set,../machine-learning-databases/soybean/,Multivariate,307,Life,Categorical,35,7/11/1988,Classification,Yes,127503,"Origin: R.S. Michalski and R.L. Chilausky ""Learning by Being Told and Learning from Examples: An Experimental Comparison of the Two Methods of Knowledge Acquisition in the Context of Developing an Expert System for Soybean Disease Diagnosis"", International Journal of Policy Analysis and Information Systems, Vol. 4, No. 2, 1980. Donor:  Ming Tan & Jeff Schlimmer (Jeff.Schlimmer%cs.cmu.edu)","There are 19 classes, only the first 15 of which have been used in prior work. The folklore seems to be that the last four classes are unjustified by the data since they have so few examples. There are 35 categorical attributes, some nominal and some ordered.  The value ""dna'' means does not apply.  The values for attributes are encoded numerically, with the first value encoded as ""0,'' the second as ""1,'' and so forth.  An unknown values is encoded as ""?''.","    -- 19 Classes     diaporthe-stem-canker, charcoal-rot, rhizoctonia-root-rot,     phytophthora-rot, brown-stem-rot, powdery-mildew,     downy-mildew, brown-spot, bacterial-blight,     bacterial-pustule, purple-seed-stain, anthracnose,     phyllosticta-leaf-spot, alternarialeaf-spot,     frog-eye-leaf-spot, diaporthe-pod-&-stem-blight,     cyst-nematode, 2-4-d-injury, herbicide-injury.	     1. date:		april,may,june,july,august,september,october,?.    2. plant-stand:	normal,lt-normal,?.    3. precip:		lt-norm,norm,gt-norm,?.    4. temp:		lt-norm,norm,gt-norm,?.    5. hail:		yes,no,?.    6. crop-hist:	diff-lst-year,same-lst-yr,same-lst-two-yrs,                        same-lst-sev-yrs,?.    7. area-damaged:	scattered,low-areas,upper-areas,whole-field,?.    8. severity:	minor,pot-severe,severe,?.    9. seed-tmt:	none,fungicide,other,?.   10. germination:	90-100%,80-89%,lt-80%,?.   11. plant-growth:	norm,abnorm,?.   12. leaves:		norm,abnorm.   13. leafspots-halo:	absent,yellow-halos,no-yellow-halos,?.   14. leafspots-marg:	w-s-marg,no-w-s-marg,dna,?.   15. leafspot-size:	lt-1/8,gt-1/8,dna,?.   16. leaf-shread:	absent,present,?.   17. leaf-malf:	absent,present,?.   18. leaf-mild:	absent,upper-surf,lower-surf,?.   19. stem:		norm,abnorm,?.   20. lodging:    	yes,no,?.   21. stem-cankers:	absent,below-soil,above-soil,above-sec-nde,?.   22. canker-lesion:	dna,brown,dk-brown-blk,tan,?.   23. fruiting-bodies:	absent,present,?.   24. external decay:	absent,firm-and-dry,watery,?.   25. mycelium:	absent,present,?.   26. int-discolor:	none,brown,black,?.   27. sclerotia:	absent,present,?.   28. fruit-pods:	norm,diseased,few-present,dna,?.   29. fruit spots:	absent,colored,brown-w/blk-specks,distort,dna,?.   30. seed:		norm,abnorm,?.   31. mold-growth:	absent,present,?.   32. seed-discolor:	absent,present,?.   33. seed-size:	norm,lt-norm,?.   34. shriveling:	absent,present,?.   35. roots:		norm,rotted,galls-cysts,?.","Tan, M., & Eshelman, L. (1988). Using weighted networks to represent classification knowledge in noisy domains.  Proceedings of the Fifth International Conference on Machine Learning (pp. 121-134). Ann Arbor, Michigan: Morgan Kaufmann.[Web Link]  Fisher,D.H. & Schlimmer,J.C. (1988). Concept Simplification and Predictive Accuracy. Proceedings of the Fifth International Conference on Machine Learning (pp. 22-28). Ann Arbor, Michigan: Morgan Kaufmann.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].Rich Caruana and Alexandru Niculescu-Mizil. An Empirical Evaluation of Supervised Learning for ROC Area. ROCAI. 2004.  [View Context].Prem Melville and Raymond J. Mooney. Diverse ensembles for active learning. ICML. 2004.  [View Context].Rich Caruana and Alexandru Niculescu-Mizil and Geoff Crew and Alex Ksikes. Ensemble selection from libraries of models. ICML. 2004.  [View Context].Rich Caruana and Alexandru Niculescu-Mizil. Data Mining in Metric Space: An Empirical Analysis of Supervised Learning Performance Criteria. ROCAI. 2004.  [View Context].Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Geoffrey Holmes and Bernhard Pfahringer and Richard Kirkby and Eibe Frank and Mark A. Hall. Multiclass Alternating Decision Trees. ECML. 2002.  [View Context].Subramani Mani and Marco Porta and Suzanne McDermott. Building Bayesian Network Models in Medicine: the MENTOR Experience. Center for Biomedical Informatics University of Pittsburgh. 2002.  [View Context].Marco Porta and Subramani Mani and Suzanne McDermott. MENTOR: Building Bayesian Network Models in Medicine CSCE Technical Report TR-2002-016. Department of Computer Science and Engineering University of South Carolina. 2002.  [View Context].Bianca Zadrozny. Reducing multiclass to binary by coupling probability estimates. NIPS. 2001.  [View Context].Rudy Setiono. Feedforward Neural Network Construction Using Cross Validation. Neural Computation, 13. 2001.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Kiri Wagstaff and Claire Cardie. Clustering with Instance-level Constraints. ICML. 2000.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Manoranjan Dash and Huan Liu. Hybrid Search of Feature Subsets. PRICAI. 1998.  [View Context].Huan Liu and Rudy Setiono. Incremental Feature Selection. Appl. Intell, 9. 1998.  [View Context].Hendrik Blockeel and Luc De Raedt and Jan Ramon. Top-Down Induction of Clustering Trees. ICML. 1998.  [View Context].Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF. Appl. Intell, 7. 1997.  [View Context].Nir Friedman and Dan Geiger and Moisés Goldszmidt. Bayesian Network Classifiers. Machine Learning, 29. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Guszti Bartfai. VICTORIA UNIVERSITY OF WELLINGTON Te Whare Wananga o te Upoko o te Ika a Maui. Department of Computer Science PO Box 600. 1996.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Christophe Giraud and Tony Martinez and Christophe G. Giraud-Carrier. University of Bristol Department of Computer Science ILA: Combining Inductive Learning with Prior Knowledge and Reasoning. 1995.  [View Context].Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. Exploiting Upper Approximation in the Rough Set Methodology. KDD. 1995.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Ron Kohavi. A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection. IJCAI. 1995.  [View Context].Thomas G. Dietterich and Ghulum Bakiri. Solving Multiclass Learning Problems via Error-Correcting Output Codes. CoRR, csAI/9501101. 1995.  [View Context].Geoffrey I. Webb. OPUS: A systematic search algorithm and its application to categorical attribute-value datadriven machine learning. School of Computing and Mathematics, Deakin University. 1993.  [View Context].Perry Moerland. Mixtures of latent variable models for density estimation and classification. E S E A R C H R E P R O R T I D I A P D a l l e M o l l e I n s t i t u t e f o r Pe r cep t ua l A r t i f i c i a l Intelligence .  [View Context].Suresh K. Choubey and Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. A comparison of feature selection algorithms in the context of rough classifiers.  [View Context].Takao Mohri and Hidehiko Tanaka. An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes. Information Engineering Course, Faculty of Engineering The University of Tokyo.  [View Context].Nikunj C. Oza and Stuart J. Russell. Online Bagging and Boosting. Computer Science Division University of California.  [View Context].Perry Moerland. A Comparison of Mixture Models for Density Estimation. IDIAP.  [View Context].Zhi-Hua Zhou and Yang Yu. Ensembling Local Learners Through Multimodal Perturbation.  [View Context].Geoffrey I Webb. Generality is more significant than complexity: Toward an alternative to Occam's Razor. School of Computing and Mathematics Deakin University.  [View Context].Sherrie L. W and Zijian Zheng. A BENCHMARK FOR CLASSIFIER LEARNING. Basser Department of Computer Science The University of Sydney.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context].Prem Melville and Raymond J. Mooney. Proceedings of the 21st International Conference on Machine Learning. Department of Computer Sciences.  [View Context].Jarinee Chattratichart and John Darlington and Moustafa Ghanem and Yang Guo and Harold Huning and Martin Kohler and Janjao Sutiwaraphun and Hing Wing and Dan Yang. Large Scale Data Mining: The Challenges and The Solutions. Department of Computing.  [View Context].Daichi Mochihashi and Gen-ichiro Kikui and Kenji Kita. Learning Nonstructural Distance Metric by Minimum Cluster Distortions. ATR Spoken Language Translation research laboratories.  [View Context].Miguel Moreira and Alain Hertz and Eddy Mayoraz. Data binarization by discriminant elimination. Proceedings of the ICML-99 Workshop: From Machine Learning to.  [View Context].Igor Kononenko and Edvard Simec. Induction of decision trees using RELIEFF. University of Ljubljana, Faculty of electrical engineering & computer science.  [View Context].BayesianClassifi552 Pat Langley and Wayne Iba. In Proceedings of the Tenth National ConferenceonArtifi256 Intelligence( 42840. Lambda Kevin Thompson.  [View Context].YongSeog Kim and W. Nick Street and Filippo Menczer. Optimal Ensemble Construction via Meta-Evolutionary Ensembles. Business Information Systems, Utah State University.  [View Context].Iñaki Inza and Pedro Larraaga and Basilio Sierra. Bayesian networks for feature subset selection. Department of Computer Sciences and Artificial Intelligence.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Activity+Recognition+from+Single+Chest-Mounted+Accelerometer,272,Activity Recognition from Single Chest-Mounted Accelerometer Data Set,../machine-learning-databases/00287/,"Univariate, Sequential, Time-Series",N/A,N/A,Real,N/A,3/2/2014,"Classification, Clustering",N/A,110972,Uncalibrated Accelerometer Data are collected from 15 participantes performing 7 activities.  The dataset provides challenges for identification and authentication of people using motion patterns.,"   --- The dataset collects data from a wearable accelerometer mounted on the chest   --- Sampling frequency of the accelerometer: 52 Hz   --- Accelerometer Data are Uncalibrated   --- Number of Participants: 15   --- Number of Activities: 7   --- Data Format: CSV","   --- Data are separated by participant   --- Each file contains the following information       ---- sequential number, x acceleration, y acceleration, z acceleration, label    --- Labels are codified by numbers       --- 1: Working at Computer       --- 2: Standing Up, Walking and Going updown stairs       --- 3: Standing       --- 4: Walking       --- 5: Going UpDown Stairs       --- 6: Walking and Talking with Someone       --- 7: Talking while Standing","   --- Casale, P. Pujol, O. and Radeva, P.        'BeaStreamer-v0.1: a new platform for Multi-Sensors Data Acquisition in Wearable Computing Applications',        CVCRD09, ISBN: 978-84-937261-1-9, 2009       available on [Web Link]     --- Casale, P. Pujol, O. and Radeva, P.        'Human activity recognition from accelerometer data using a wearable device',        IbPRIA'11, 289-296, Springer-Verlag, 2011       available on [Web Link]    --- Casale, P. Pujol, O. and Radeva, P.        'Personalization and user verification in wearable systems using biometric walking patterns'       Personal and Ubiquitous Computing, 16(5), 563-580, 2012       available on [Web Link]","Casale, P. Pujol, O. and Radeva, P.        'Personalization and user verification in wearable systems using biometric walking patterns'       Personal and Ubiquitous Computing, 16(5), 563-580, 2012",
http://archive.ics.uci.edu/ml/datasets/Trains,273,Trains Data Set,../machine-learning-databases/trains/,Multivariate,10,N/A,Categorical,32,6/24/1994,Classification,N/A,154933,"Original owners:  Ryszard S. Michalski (michalski '@' aic.gmu.edu) and Robert Stepp Donor:  GMU, Center for AI, Software Librarian, Eric E. Bloedorn (bloedorn '@' aic.gmu.edu) ","Notes: - Additional ""background"" knowledge is supplied that provides a partial ordering on some of the attribute values. - We are providing this dataset both in its original form and in a form similar to the more typical propositional datasets in our repository. Since the trains dataset records relations between attributes, this transformation was somewhat challenging.  However, it may shed some insight on this problem for people who are more familiar with the simple one-instance-per-line dataset format. Hierarchy of values: if (cshape is one of {openrect,opentrap,ushaped,dblopnrect}then cshape is opentop if (cshape is one of {hexagon,ellipse,closedrect,jaggedtop,slopetop, engine}then cshape closedtop Prediction task: Determine concise decision rules distinguishing trains traveling east from those traveling west."," The following format was used for the ""transformed"" dataset representation as found in trains.transformed.data (one instance per line):   1. Number_of_cars (integer in [3-5])  2. Number_of_different_loads (integer in [1-4])  3-22: 5 attributes for each of cars 2 through 5: (20 attributes total)    - num_wheels (integer in [2-3])    - length (short or long)        - shape (closedrect, dblopnrect, ellipse, engine, hexagon, jaggedtop, openrect, opentrap, slopetop, ushaped)    - num_loads (integer in [0-3])    - load_shape (circlelod, hexagonlod, rectanglod, trianglod)  23-32: 10 Boolean attributes describing whether 2 types of loads are on adjacent cars of the train    - Rectangle_next_to_rectangle (0 if false, 1 if true)    - Rectangle_next_to_triangle (0 if false, 1 if true)    - Rectangle_next_to_hexagon (0 if false, 1 if true)    - Rectangle_next_to_circle (0 if false, 1 if true)    - Triangle_next_to_triangle (0 if false, 1 if true)    - Triangle_next_to_hexagon (0 if false, 1 if true)    - Triangle_next_to_circle (0 if false, 1 if true)    - Hexagon_next_to_hexagon (0 if false, 1 if true)    - Hexagon_next_to_circle (0 if false, 1 if true)    - Circle_next_to_circle (0 if false, 1 if true)  33. Class attribute (east or west)   The number of cars vary between 3 and 5.  Therefore, attributes referring to properties of cars that do not exist (such as the 5 attriubutes for the ""5th"" car when the train has fewer than 5 cars) are assigned a value of ""-"".","R.S. Michalski and  J.B. Larson ""Inductive Inference of VL Decision Rules"" In Proceedings of the Workshop in Pattern-Directed Inference Systems, Hawaii, May 1977.[Web Link]  Stepp, R.E. and Michalski, R.S. ""Conceptual Clustering: Inventing Goal-Oriented Classifications of Structured Objects""  In R.S. Michalski, J.G. Carbonell, and T.M. Mitchell (Eds.) ""Machine Learning: An Artificial Intelligence Approach, Volume II"".  Los Altos, Ca: Morgan Kaufmann.[Web Link] ","Please refer to the Machine Learning
Repository's citation policy",Daan Fierens and Jan Ramon and Hendrik Blockeel and Maurice Bruynooghe. A Comparison of Approaches for Learning Probability Trees. Department of Computer Science.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Connect-4,274,Connect-4 Data Set,../machine-learning-databases/connect-4/,"Multivariate, Spatial",67557,Game,Categorical,42,2/4/1995,Classification,No,162184,"Original Owners of Database:  John Tromp (tromp '@' cwi.nl) Donor:  John Tromp (tromp '@' cwi.nl)","This database contains all legal 8-ply positions in the game of connect-4 in which neither player has won yet, and in which the next move is not forced. x is the first player; o the second. The outcome class is the game theoretical value for the first player.","Attribute Information: (x=player x has taken, o=player o has taken, b=blank) The board is numbered like:6 . . . . . . .5 . . . . . . .4 . . . . . . .3 . . . . . . .2 . . . . . . .1 . . . . . . . a b c d e f g     1. a1: {x,o,b}    2. a2: {x,o,b}    3. a3: {x,o,b}    4. a4: {x,o,b}    5. a5: {x,o,b}    6. a6: {x,o,b}    7. b1: {x,o,b}    8. b2: {x,o,b}    9. b3: {x,o,b}   10. b4: {x,o,b}   11. b5: {x,o,b}   12. b6: {x,o,b}   13. c1: {x,o,b}   14. c2: {x,o,b}   15. c3: {x,o,b}   16. c4: {x,o,b}   17. c5: {x,o,b}   18. c6: {x,o,b}   19. d1: {x,o,b}   20. d2: {x,o,b}   21. d3: {x,o,b}   22. d4: {x,o,b}   23. d5: {x,o,b}   24. d6: {x,o,b}   25. e1: {x,o,b}   26. e2: {x,o,b}   27. e3: {x,o,b}   28. e4: {x,o,b}   29. e5: {x,o,b}   30. e6: {x,o,b}   31. f1: {x,o,b}   32. f2: {x,o,b}   33. f3: {x,o,b}   34. f4: {x,o,b}   35. f5: {x,o,b}   36. f6: {x,o,b}   37. g1: {x,o,b}   38. g2: {x,o,b}   39. g3: {x,o,b}   40. g4: {x,o,b}   41. g5: {x,o,b}   42. g6: {x,o,b}   43. Class: {win,loss,draw}",N/A,"Please refer to the Machine Learning
Repository's citation policy",Alan Burton and Paul H J Kelly. Performance Prediction of Paging Workloads Using Lightweight Tracing. IPDPS. 2003.  [View Context].Shi Zhong and Weiyu Tang and Taghi M. Khoshgoftaar. Boosted Noise Filters for Identifying Mislabeled Data. Department of Computer Science and Engineering Florida Atlantic University.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29,275,Audiology (Standardized) Data Set,../machine-learning-databases/audiology/,Multivariate,226,Life,Categorical,69,8/18/1992,Classification,Yes,105605,"Original Version:     (a) Original Owner: Professor Jergen at Baylor College of Medicine    (b) Donor: Bruce Porter (porter '@' fall.cs.utexas.EDU) Standardized Version:     (a) Donor: Ross Quinlan","This database is a standardized version of the original audiology database (see audiology.* in this directory).  The non-standard set of attributes have been converted to a standard set of attributes according to the rules that follow. * Each property that appears anywhere in the original .data or .test file has been represented as a separate attribute in this file. * A property such as age_gt_60 is represented as a boolean attribute with values f and t. * In most cases, a property of the form x(y) is represented as a discrete attribute x() whose possible values are the various y's; air() is an example.  There are two exceptions:** when only one value of y appears anywhere, e.g. static(normal). In this case, x_y appears as a boolean attribute.** when one case can have two or more values of x, e.g. history(..). All possible values of history are treated as separate boolean attributes. * Since boolean attributes only appear as positive conditions, each boolean attribute is assumed to be false unless noted as true.  The value of multi-value discrete attributes taken as unknown (""?"") unless a value is specified. * The original case identifications, p1 to p200 in the .data file and t1 to t26 in the .test file, have been added as a unique identifier attribute.  [Note: in the original .data file, p165 has a repeated specification of o_ar_c(normal); p166 has repeated specification of speech(normal) and conflicting values air(moderate) and air(mild).  No other problems with the original data were noted.]","   age_gt_60:		     f, t.   air():		     mild,moderate,severe,normal,profound.   airBoneGap:		     f, t.   ar_c():		     normal,elevated,absent.   ar_u():		     normal,absent,elevated.   bone():		     mild,moderate,normal,unmeasured.   boneAbnormal:	     f, t.   bser():		     normal,degraded.   history_buzzing:	     f, t.   history_dizziness:	     f, t.   history_fluctuating:	     f, t.   history_fullness:	     f, t.   history_heredity:	     f, t.   history_nausea:	     f, t.   history_noise:	     f, t.   history_recruitment:	     f, t.   history_ringing:	     f, t.   history_roaring:	     f, t.   history_vomiting:	     f, t.   late_wave_poor:	     f, t.   m_at_2k:		     f, t.   m_cond_lt_1k:	     f, t.   m_gt_1k:		     f, t.   m_m_gt_2k:		     f, t.   m_m_sn:		     f, t.   m_m_sn_gt_1k:	     f, t.   m_m_sn_gt_2k:	     f, t.   m_m_sn_gt_500:	     f, t.   m_p_sn_gt_2k:	     f, t.   m_s_gt_500:		     f, t.   m_s_sn:		     f, t.   m_s_sn_gt_1k:	     f, t.   m_s_sn_gt_2k:	     f, t.   m_s_sn_gt_3k:	     f, t.   m_s_sn_gt_4k:	     f, t.   m_sn_2_3k:		     f, t.   m_sn_gt_1k:		     f, t.   m_sn_gt_2k:		     f, t.   m_sn_gt_3k:		     f, t.   m_sn_gt_4k:		     f, t.   m_sn_gt_500:		     f, t.   m_sn_gt_6k:		     f, t.   m_sn_lt_1k:		     f, t.    m_sn_lt_2k:		     f, t.   m_sn_lt_3k:		     f, t.   middle_wave_poor:	     f, t.   mod_gt_4k:		     f, t.   mod_mixed:		     f, t.   mod_s_mixed:		     f, t.   mod_s_sn_gt_500:	     f, t.   mod_sn:		     f, t.   mod_sn_gt_1k:	     f, t.   mod_sn_gt_2k:	     f, t.   mod_sn_gt_3k:	     f, t.   mod_sn_gt_4k:	     f, t.   mod_sn_gt_500:	     f, t.   notch_4k:		     f, t.   notch_at_4k:		     f, t.   o_ar_c():		     normal,elevated,absent.   o_ar_u():		     normal,absent,elevated.   s_sn_gt_1k:		     f, t.   s_sn_gt_2k:		     f, t.   s_sn_gt_4k:		     f, t.   speech():		     normal,good,very_good,very_poor,poor,unmeasured.   static_normal:	     f, t.   tymp():		     a,as,b,ad,c.   viith_nerve_signs:        f, t.   wave_V_delayed:	     f, t.   waveform_ItoV_prolonged:  f, t.   indentifier               (unique for each instance)    class:                                               cochlear_unknown,mixed_cochlear_age_fixation,poss_central                             mixed_cochlear_age_otitis_media,mixed_poss_noise_om,                             cochlear_age,normal_ear,cochlear_poss_noise,cochlear_age_and_noise,                             acoustic_neuroma,mixed_cochlear_unk_ser_om,conductive_discontinuity,                             retrocochlear_unknown,conductive_fixation,bells_palsy,                             cochlear_noise_and_heredity,mixed_cochlear_unk_fixation,                             otitis_media,possible_menieres,possible_brainstem_disorder,                             cochlear_age_plus_poss_menieres,mixed_cochlear_age_s_om,                             mixed_cochlear_unk_discontinuity,mixed_poss_central_om","Bareiss, E. Ray, & Porter, Bruce (1987).  Protos: An Exemplar-Based Learning Apprentice.  In the Proceedings of the 4th International Workshop on Machine Learning, 12-23, Irvine, CA: Morgan Kaufmann.[Web Link]",WARNING: This database should be credited to the original owner whenever used for any publication whatsoever.,"Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Marcus Hutter and Marco Zaffalon. Distribution of Mutual Information from Complete and Incomplete Data. CoRR, csLG/0403025. 2004.  [View Context].Richard Nock and Marc Sebban and David Bernard. A SIMPLE LOCALLY ADAPTIVE NEAREST NEIGHBOR RULE WITH APPLICATION TO POLLUTION FORECASTING. International Journal of Pattern Recognition and Artificial Intelligence Vol. 2003.  [View Context].Alexander K. Seewald. How to Make Stacking Better and Faster While Also Taking Care of an Unknown Weakness. ICML. 2002.  [View Context].Alexander K. Seewald and Johann Petrak and Gerhard Widmer. Hybrid Decision Tree Learners with Alternative Leaf Classifiers: An Empirical Study. FLAIRS Conference. 2001.  [View Context].Wai Lam and Kin Keung and Charles X. Ling. PR 1527. Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong. 2001.  [View Context].Jihoon Yang and Rajesh Parekh and Vasant Honavar. DistAl: An inter-pattern distance-based constructive learning algorithm. Intell. Data Anal, 3. 1999.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Pedro Domingos. Unifying Instance-Based and Rule-Based Induction. Machine Learning, 24. 1996.  [View Context].Thomas G. Dietterich and Ghulum Bakiri. Solving Multiclass Learning Problems via Error-Correcting Output Codes. CoRR, csAI/9501101. 1995.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].D. Randall Wilson and Roel Martinez. Improved Center Point Selection for Probabilistic Neural Networks. Proceedings of the International Conference on Artificial Neural Networks and Genetic Algorithms.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Geoffrey I Webb. Learning Decision Lists by Prepending Inferred Rules. School of Computing and Mathematics Deakin University.  [View Context].Mohammed Waleed Kadous and Claude Sammut. The University of New South Wales School of Computer Science and Engineering Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series.  [View Context].Mohammed Waleed Kadous. Expanding the Scope of Concept Learning Using Metafeatures. School of Computer Science and Engineering, University of New South Wales.  [View Context].Jerome H. Friedman and Ron Kohavi and Youngkeol Yun. To appear in AAAI-96 Lazy Decision Trees. Statistics Department and Stanford Linear Accelerator Center Stanford University.  [View Context].Alexander K. Seewald. Meta-Learning for Stacked Classification. Austrian Research Institute for Artificial Intelligence.  [View Context].Bernhard Pfahringer and Ian H. Witten and Philip Chan. Improving Bagging Performance by Increasing Decision Tree Diversity. Austrian Research Institute for AI.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008,276,Diabetes 130-US hospitals for years 1999-2008 Data Set,../machine-learning-databases/00296/,Multivariate,100000,Life,Integer,55,5/3/2014,"Classification, Clustering",Yes,313855,"The data are submitted on behalf of the Center for Clinical and Translational Research, Virginia Commonwealth University, a recipient of NIH CTSA grant UL1 TR00058 and a recipient of the CERNER data. John Clore (jclore '@' vcu.edu), Krzysztof J. Cios (kcios '@' vcu.edu), Jon DeShazo (jpdeshazo '@' vcu.edu), and Beata Strack (strackb '@' vcu.edu). This data is a de-identified abstract of the Health Facts database (Cerner Corporation, Kansas City, MO).","The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. Information was extracted from the database for encounters that satisfied the following criteria.(1)	It is an inpatient encounter (a hospital admission).(2)	It is a diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a diagnosis.(3)	The length of stay was at least 1 day and at most 14 days.(4)	Laboratory tests were performed during the encounter.(5)	Medications were administered during the encounter.The data contains such attributes as patient number, race, gender, age, admission type, time in hospital, medical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis, number of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in the year before the hospitalization, etc.","Detailed description of all the atrributes is provided in Table 1 Beata Strack, Jonathan P. DeShazo, Chris Gennings,  Juan L. Olmo, Sebastian Ventura,  Krzysztof J. Cios, and John N. Clore, “Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,” BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.[Web Link]","Beata Strack, Jonathan P. DeShazo, Chris Gennings,  Juan L. Olmo, Sebastian Ventura,  Krzysztof J. Cios, and John N. Clore, “Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,” BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.[Web Link]","Please cite:Beata Strack, Jonathan P. DeShazo, Chris Gennings,  Juan L. Olmo, Sebastian Ventura,  Krzysztof J. Cios, and John N. Clore, “Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,” BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014. [Web Link]",
http://archive.ics.uci.edu/ml/datasets/Balance+Scale,277,Balance Scale Data Set,../machine-learning-databases/balance-scale/,Multivariate,625,Social,Categorical,4,4/22/1994,Classification,No,255105,"Generated to model psychological experiments reported by Siegler, R. S. (1976).Three Aspects of Cognitive Development.  Cognitive Psychology, 8, 481-520. Donor:  Tim Hume (hume '@' ics.uci.edu)","This data set was generated to model psychological experimental results.  Each example is classified as having the balance scale tip to the right, tip to the left, or be balanced.  The attributes are the left weight, the left distance, the right weight, and the right distance.  The correct way to find the class is the greater of  (left-distance * left-weight) and (right-distance * right-weight).  If they are equal, it is balanced.","	1. Class Name: 3 (L, B, R)	2. Left-Weight: 5 (1, 2, 3, 4, 5)	3. Left-Distance: 5 (1, 2, 3, 4, 5)	4. Right-Weight: 5 (1, 2, 3, 4, 5)	5. Right-Distance: 5 (1, 2, 3, 4, 5)","Klahr, D., & Siegler, R.S. (1978).  The Representation of Children's Knowledge.  In H. W. Reese & L. P. Lipsitt (Eds.), Advances in Child Development and Behavior, pp. 61-116.  New York: Academic Press [Web Link]  Langley,P. (1987).  A General Theory of Discrimination Learning.  In D. Klahr, P. Langley, & R. Neches (Eds.), Production System Models of Learning and Development, pp. 99-161. Cambridge, MA: MIT Press[Web Link]  Newell, A. (1990).  Unified Theories of Cognition. Cambridge, MA: Harvard University Press[Web Link]  McClelland, J.L. (1988).  Parallel Distibuted Processing: Implications for Cognition and Development.  Technical Report AIP-47, Department of Psychology, Carnegie-Mellon University [Web Link]  Shultz, T., Mareschal, D., & Schmidt, W. (1994).  Modeling Cognitive Development on Balance Scale Phenomena. Machine Learning, Vol. 16, pp. 59-88.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Zhi-Hua Zhou and Yuan Jiang and Shifu Chen. Extracting symbolic rules from trained neural network ensembles. AI Commun, 16. 2003.  [View Context].Jianbin Tan and David L. Dowe. MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes. Australian Conference on Artificial Intelligence. 2003.  [View Context].Peter Sykacek and Stephen J. Roberts. Adaptive Classification by Variational Kalman Filtering. NIPS. 2002.  [View Context].Remco R. Bouckaert. Accuracy bounds for ensembles under 0 { 1 loss. Xtal Mountain Information Technology & Computer Science Department, University of Waikato. 2002.  [View Context].Nir Friedman and Moisés Goldszmidt and Thomas J. Lee. Bayesian Network Classification with Continuous Attributes: Getting the Best of Both Discretization and Parametric Fitting. ICML. 1998.  [View Context].Hirotaka Inoue and Hiroyuki Narihisa. Experiments with an Ensemble Self-Generating Neural Network. Okayama University of Science.  [View Context].Alexander K. Seewald. Meta-Learning for Stacked Classification. Austrian Research Institute for Artificial Intelligence.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Stock+portfolio+performance,278,Stock portfolio performance Data Set,../machine-learning-databases/00390/,Multivariate,315,Business,Real,12,4/22/2016,Regression,N/A,64432,"Name: I-Cheng Yehemail addresses: (1) 140910 '@' mail.tku.edu.tw (2) icyeh '@' chu.edu.tw institutions: (1) Department of Information Management, Chung Hua University, Taiwan. (2) Department of Civil Engineering, Tamkang University, Taiwan.other contact information: 886-2-26215656 ext. 3181","There are three disadvantages of weighted scoring stock selection models. First, they cannot identify the relations between weights of stock-picking concepts and performances of portfolios. Second, they cannot systematically discover the optimal combination for weights of concepts to optimize the performances. Third, they are unable to meet various investorsâ€™ preferences. This study aims to more efficiently construct weighted scoring stock selection models to overcome these disadvantages. Since the weights of stock-picking concepts in a weighted scoring stock selection model can be regarded as components in a mixture, we used the simplex centroid mixture design to obtain the experimental sets of weights. These sets of weights are simulated with US stock market historical data to obtain their performances. Performance prediction models were built with the simulated performance data set and artificial neural networks. Furthermore, the optimization models to reflect investorsâ€™ preferences were built up, and the performance prediction models were employed as the kernel of the optimization models so that the optimal solutions can now be solved with optimization techniques. The empirical values of the performances of the optimal weighting combinations generated by the optimization models showed that they can meet various investorsâ€™ preferences and outperform those of S&Pâ€™s 500 not only during the training period but also during the testing period.","The inputs are the weights of the stock-picking concepts as followsX1=the weight of the Large B/P conceptX2=the weight of the Large ROE conceptX3=the weight of the Large S/P conceptX4=the weight of the Large Return Rate in the last quarter conceptX5=the weight of the Large Market Value conceptX6=the weight of the Small systematic Risk concept The outputs are the investment performance indicators (normalized) as followsY1=Annual ReturnY2=Excess ReturnY3=Systematic RiskY4=Total RiskY5=Abs. Win RateY6=Rel. Win Rate","[1] Liu, Y. C., & Yeh, I. C. Using mixture design and neural networks to build stock selection decision support systems. Neural Computing and Applications, 1-15. (Print ISSN 0941-0643, Online ISSN 1433-3058, First online: 16 November 2015, DOI 10.1007/s00521-015-2090-x)[2] Yeh, I. C., & Cheng, W. L. (2010). â€œFirst and second order sensitivity analysis of MLP,â€ Neurocomputing, Vol. 73, No. 10, pp. 2225-2233.[3] Yeh, I. C. and Hsu, T. K. (2011). â€œGrowth Value Two-Factor Model,â€ Journal of Asset Management, Vol. 11, No. 6, pp. 435-451.","Liu, Y. C., & Yeh, I. C. Using mixture design and neural networks to build stock selection decision support systems. Neural Computing and Applications, 1-15. (Print ISSN 0941-0643, Online ISSN 1433-3058, First online: 16 November 2015, DOI 10.1007/s00521-015-2090-x)",
http://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition,279,OPPORTUNITY Activity Recognition Data Set,../machine-learning-databases/00226/,"Multivariate, Time-Series",2551,Computer,Real,242,6/9/2012,Classification,Yes,98464,"Daniel Roggen, Wearable Computing Laboratory ETH Zurich, droggen '@' gmail.com Alberto Calatroni, Wearable Computing Laboratory ETH Zurich, calatroni.alberto '@' gmail.com Long-Van Nguyen-Dinh, Wearable Computing Laboratory ETH ZurichRicardo Chavarriaga, Chair in Non-Invasive Brain-Machine Interface, EPFL, ricardo.chavarriaga '@' epfl.ch Hesam Sagha, Chair in Non-Invasive Brain-Machine Interface, EPFL, hesam.sagha '@' epfl.ch Sundara Tejaswi Digumarti, Chair in Non-Invasive Brain-Machine Interface, EPFL","The OPPORTUNITY Dataset for Human Activity Recognition from Wearable, Object, and Ambient Sensors is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc). A subset of this dataset was used for the ""OPPORTUNITY Activity Recognition Challenge"" organized for the 2011 IEEE conf on Systems, Man and Cybernetics Workshop on ""Robust machine learning techniques for human activity recognition"".  The dataset comprises the readings of motion sensors recorded while users executed typical daily activities:  * Body-worn sensors: 7 inertial measurement units, 12 3D acceleration sensors, 4 3D localization information  * Object sensors: 12 objects with 3D acceleration and 2D rate of turn  * Ambient sensors: 13 switches and 8 3D acceleration sensors  * Recordings: 4 users, 6 runs per users. Of these, 5 are Activity of Daily Living runs characterized by a natural execution of daily activities. The 6th run is a ""drill"" run, where users execute a scripted sequence of activities.   * Annotations/classes: the activities of the user in the scenario are annotated on different levels: ""modes of locomotion"" classes; low-level actions relating 13 actions to 23 objects; 17 mid-level gesture classes; and 5 high-level activity classes ** Recording scenario ** The activity recognition environment and scenario has been designed to generate many activity primitives, yet in a realistic manner. Subjects operated in a room simulating a studio flat with a deckchair, a kitchen, doors giving access to the outside, a coffee machine, a table and a chair. We achieved a natural execution of activities by instructing users to follow a high-level script but leaving them free interpretation as how to achieve the high-level goals. We furthermore encouraged them to perform as naturally as possible with all the variations they were used to. For each subject we recorded 6 different runs. Five of them, termed activity of daily living (ADL), followed a given scenario as detailed below. The remaining one, a drill run, was designed to generate a large number of activity instances. The ADL run consists of temporally unfolding situations. In each situation (e.g. preparing sandwich), a large number of action primitives occur (e.g. reach for bread, move to bread cutter, operate bread cutter). * ADL run * The ADL run consists of temporally unfolding situations:     Start: lying on the deckchair, get up    Groom: move in the room, check that all the objects are in the right places in the drawers and on shelves    Relax: go outside and have a walk around the building    Prepare coffee: prepare a coffee with milk and sugar using the coffee machine    Drink coffee: take coffee sips, move around in the environment    Prepare sandwich: include bread, cheese and salami, using the bread cutter and various knifes and plates    Eat sandwich    Cleanup: put objects used to original place or dish washer, cleanup the table    Break: lie on the deckchair * Drill run * The drill run consists of 20 repetitions of the following sequence of activities:     Open then close the fridge    Open then close the dishwasher    Open then close 3 drawers (at different heights)    Open then close door 1    Open then close door 2    Toggle the lights on then off    Clean the table    Drink while standing    Drink while seated ** Annotations ** The annotations are done on five Â‘tracksÂ’. One track contains modes of locomotion (e.g. sitting, standing, walking). Two other tracks indicate the actions of the left and right hand (e.g. reach, grasp, release), and to which object they apply (e.g. milk, switch, door).The fourth track indicates the high level activities (e.g. prepare sandwich). The high level activities relate to the situations indicated in the description of the ADL runs as follows (in parenthesis the number of the situations indicated above): relaxing (1, 9), early morning (2, 3), coffee time (4, 5), sandwich time (6, 7), cleanup (8). The mid-level gesture annotations is generated automatically from the low-level hand actions. It comprises coarser characterization of the user's activities. For instance the low-level annotations 'reach door' and 'open door' are combined into a single 'open door' mid-level annotation. Here, the mid-level annotations comprise actions of the left and right hand indiscriminately. However, in practice, the users mostly interacted with the environment with their right hand. We recommend to use the mid-level annotations in first attempts to use this dataset. ** Applications ** This dataset offers a rich playground to assess methods such as, e.g:   * Classification, (semi-) supervised machine learning  * Automatic segmentation  * Unsupervised structure discovery  * Data imputation  * Multi-modal sensor fusion  * Sensor network research  * Transfer learning, multitask learning  * Sensor selection  * Feature extraction  * Classifier calibration and adaptation  * ... ** Baseline benchmarks ** Baseline benchmarks for the OPPORTUNITY Activity Recognition Challenge subset of the dataset are available in reference [2]. Scripts to replicate the benchmarks are provided in the package.","The dataset comprises the readings of motion sensors recorded while users executed typical daily activities. The detailed format is described in the package. The attributes correspond to raw sensor readings. There is a total of 242 attributes. * Body-worn sensors (145 attributes) * The body-worn sensors include 7 inertial measurement units and 12 3D acceleration sensors. The inertial measurement units provide readings of: 3D acceleration, 3D rate of turn, 3D magnetic field, and orientation of the sensor with respect to a world coordinate system in quaternions. Five sensors are on the upper body and two are mounted on the user's shoes. The acceleration sensors provide 3D acceleration. They are mounted on the upper body, hip and leg. Four tags for an ultra-wideband localization system are placed on the left/right front/back side of the shoulder.   * Object sensors (60 attributes) * 12 objects are instrumented with wireless sensors measuring 3D acceleration and 2D rate of turn. This allows to detect which objects are used, and possibly also the kind of usage that is made of them. * Ambient sensors (37 attributes) * Ambient sensors include 13 switches and 8 3D acceleration sensors in drawers, kitchen appliances and doors. The reed switches are placed in triplets on the fridge, dishwasher and drawer 2 and drawer 3. They may be used to detect three states of the furniture element: closed, half open, and fully open.  The acceleration sensors may allow to assess if an element of furniture is used, and whether it may be opened or closed.","**First party**[1] Daniel Roggen, Alberto Calatroni, Mirco Rossi, Thomas Holleczek, Gerhard Tröster, Paul Lukowicz, Gerald Pirkl, David Bannach, Alois Ferscha, Jakob Doppler, Clemens Holzmann, Marc Kurz, Gerald Holl, Ricardo Chavarriaga, Hesam Sagha, Hamidreza Bayati, and José del R. Millán. ""Collecting complex activity data sets in highly rich networked sensor environments"" In Seventh International Conference on Networked Sensing Systems (INSS’10), Kassel, Germany, 6 2010.[2] Hesam Sagha, Sundara Tejaswi Digumarti, José del R. Millán, Ricardo Chavarriaga, Alberto Calatroni, Daniel Roggen, Gerhard Tröster. Benchmarking classification techniques using the Opportunity human activity dataset. IEEE International Conference on Systems, Man, and Cybernetics, Anchorage, AK, USA, October 9-12, 2011[3] Video presenting the dataset: [Web Link] [4] R. Chavarriaga et al. Ensemble creation and reconfiguration for activity recognition: An information theoretic approach. IEEE Conf Systems, Man, and Cybernetics (SMC), 2011[5] H. Sagha et al. Detecting anomalies to improve classification performance in an opportunistic sensor network, 7th IEEE International Workshop on Sensor Networks and Systems for Pervasive Computing (PerSens), 2011.[6] A. Calatroni et al., Automatic transfer of activity recognition capabilities between body-worn motion sensors: Training newcomers to recognize locomotion, 8th International Conference on Networked Sensing Systems (INSS), 2011[7] M. Kurz et al. Dynamic Quantification of Activity Recognition Capabilities in Opportunistic Systems. Fourth Conference on Context Awareness for Proactive Systems, 2011[8] H. Sagha et al. Detecting and rectifying anomalies in Opportunistic sensor networks. International Conference on Body Sensor Networks (BSN), 2011[9] R. Chavarriaga et al. Robust activity recognition for assistive technologies: Benchmarking ML techniques, Workshop on Machine Learning for Assistive Technologies at the 24th Annual Conference on Neural Information Processing Systems (NIPS), 2010.[10] P. Lukowicz et al. Recording a complex, multi modal activity data set for context recognition 1st Workshop on Context-Systems Design, Evaluation and Optimisation at ARCS, 2010, 2010[11] R. Chavarriaga, H. Sagha, A. Calatroni, S. Digumarti, G. Tröster, J. del R. Millán, D. Roggen. The Opportunity challenge: A benchmark database for on-body sensor-based activity recognition, Pattern Recognition Letters, 2013[12] L.-V. Nguyen-Dinh, D. Roggen, A. Calatroni, G. Tröster. Improving online gesture recognition with template matching methods in accelerometer data, Proc 12th Int Conf on Intelligent Systems Design and Applications, 2012 **Third party**Here are a few of the papers from third parties using the OPPORTUNITY dataset: [100] T. Plötz, N. Y.  Hammerla, P. Olivier. Feature Learning for Activity Recognition in Ubiquitous Computing, IJCAI, 2011[101] A. Manzoor et al., Identifying Important Action Primitives for High Level Activity Recognition, Proc. European Conference on Smart Sensing and Context (EuroSSC), 2010[102] T. Ploetz, N. Hammerla, A. Rozga, A. Reavis, N. Call, G. Abowd. Automatic Assessment of Problem Behavior in Individuals with Developmental Disabilities. Proc. 14th Int Conf on Ubiquitous Computing, 2012.[103] D. Gordon, J. Czerny, M. Beigl. Activity Recognition for Creatures of Habit: Energy-Efficient Embedded Classification using Prediction. Personal and Ubiquitous Computing, 2013.","Use of this dataset in publications must be acknowledged by referencing the following publication [1] or [2]. We recommend to refer to this dataset as the ""OPPORTUNITY Activity Recognition Dataset"" in publications.We also appreciate if you drop us an email (daniel.roggen '@' ieee.org) to inform us of any publication using this dataset, so we can point to your publication on our webpage. Reference [1] details the overall dataset, the scenario, the multimodality and sensor networking aspects of the setup, quality metrics, and best practices for the recording of complex multimodal activity datasets. Reference [2] provides the performance of a baseline activity recognition system on the OPPORTUNITY dataset, which can be used as a benchmark performance. [1] Daniel Roggen, Alberto Calatroni, Mirco Rossi, Thomas Holleczek, Gerhard Tröster, Paul Lukowicz, Gerald Pirkl, David Bannach, Alois Ferscha, Jakob Doppler, Clemens Holzmann, Marc Kurz, Gerald Holl, Ricardo Chavarriaga, Hesam Sagha, Hamidreza Bayati, and José del R. Millàn. ""Collecting complex activity data sets in highly rich networked sensor environments"" In Seventh International Conference on Networked Sensing Systems (INSS’10), Kassel, Germany, 2010. [2] Ricardo Chavarriaga, Hesam Sagha, Alberto Calatroni, Sundaratejaswi Digumarti, Gerhard Tröster, José del R. Millán, Daniel Roggen. ""The Opportunity challenge: A benchmark database for on-body sensor-based activity recognition"", Pattern Recognition Letters, 2013",
http://archive.ics.uci.edu/ml/datasets/Wearable+Computing%3A+Classification+of+Body+Postures+and+Movements+%28PUC-Rio%29,280,Wearable Computing: Classification of Body Postures and Movements (PUC-Rio) Data Set,../machine-learning-databases/00250/,Sequential,165632,Computer,"Integer, Real",18,4/9/2013,Classification,N/A,58904,"Pontifical Catholic University of Rio de Janeiro (PUC-Rio)Research Group: Groupware@LESContact: wugulino '@' inf.puc-rio.br http://groupware.les.inf.puc-rio.br/har","IMPORTANT: we have lower performance on 'leave-one-subject-out' tests. The performance baseline index we established is for 10-fold cross-validation tests. Therefore, there's much more space for optimization in subject independent tests. If you need more information, please send us an e-mail. Licensing: You are free to use this dataset for any purpose. This dataset is licensed under the Creative Commons license (CC BY-SA). The CC BY-SA license means you can remix, tweak, and build upon this work even for commercial purposes, as long as you credit the authors of the original work and you license your new creations under the identical terms we are licensing to you. This license is often compared to 'copyleft' free and open source software licenses. All new works based on this dataset will carry the same license, so any derivatives will also allow commercial use.","Detailed information in: [Web Link] user (text)gender (text) age (integer)how_tall_in_meters (real) weight	(int) body_mass_index	(real)x1 (type int, contains the read value of the axis 'x' of the 1st accelerometer, mounted on waist)y1 (type int, contains the read value of the axis 'y' of the 1st accelerometer, mounted on waist)z1 (type int, contains the read value of the axis 'z' of the 1st accelerometer, mounted on waist)x2 (type int, contains the read value of the axis 'x' of the 2nd accelerometer, mounted on the left thigh)	y2 (type int, contains the read value of the axis 'y' of the 2nd accelerometer, mounted on the left thigh)		z2 (type int, contains the read value of the axis 'z' of the 2nd accelerometer, mounted on the left thigh)	x3 (type int, contains the read value of the axis 'x' of the 3rd accelerometer, mounted on the right ankle)	y3 (type int, contains the read value of the axis 'y' of the 3rd accelerometer, mounted on the right ankle)		z3 (type int, contains the read value of the axis 'z' of the 3rd accelerometer, mounted on the right ankle)	x4 (type int, contains the read value of the axis 'x' of the 4th accelerometer, mounted on the right upper-arm)		y4 (type int, contains the read value of the axis 'y' of the 4th accelerometer, mounted on the right upper-arm)			z4 (type int, contains the read value of the axis 'z' of the 4th accelerometer, mounted on the right upper-arm)		","Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6. Available at: [Web Link] ","If you use this dataset, please cite the paper above (Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements). We can also provide more information if you need, just drop us a line (wugulino 'at' inf 'dot' puc-rio 'dot' br).",
http://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc-Mag,281,UJIIndoorLoc-Mag Data Set,../machine-learning-databases/00343/,"Multivariate, Sequential, Time-Series",40000,Computer,"Integer, Real",13,9/10/2015,"Classification, Regression, Clustering",N/A,42843,"DonorsDavid Rambla, JoaquÃ­n Torres-Sospedra, RaÃºl Montoliu, Oscar Belmonte and JoaquÃ­n HuertaInstitute of New Imaging Technologies, Universitat Jaume I, CastellÃ³n, Spain ContactJoaquÃ­n Torres-Sospedra jtorres +@+ uji.es Raul Montoliu montoliu +@+ uji.es ","Indoor localization is a key topic for mobile computing. However, it is still very difficult for the mobile sensing community to compare state-of-art Indoor Positioning Systems due to the scarcity of publicly available databases. Magnetic field-based methods are becoming an important trend in this research field. Here, we present UJIIndoorLoc-Mag database, which can be used to compare magnetic field-based indoor localization methods. It consists of 270 continuous samples for training and 11 for testing. Each sample comprises a set of discrete captures taken along a corridor (or an intersection) with a period of 0.1 seconds. In total, there are almost 40.000 discrete captures, where each one contains features obtained from the magnetometer, the accelerometer and the orientation sensor of the device. Data has been stored as a simple text file as follows:  ts_1	mx_1	my_1	mz_1	ax_1	ay_1	az_1	ox_1	oy_1	oz_1â€¦									ts_n	mx_n	my_n	mz_n	ax_n	ay_n	az_n	ox_n	oy_n	oz_n lat_1	lon_1	lat_2	lon_2	FS_1	LS_1				â€¦									lat_m	lon_m	lat_m+1	lon_m+1	FS_m	LS_m				 Where n is the number of samples collected in the trajectory at a 0.1 seconds frequency and m is the number of segments (corridors) in the trajectory. Each sample contains the timestamp ts and the values from magnetometer, accelerometer and orientation sensors in the three axes, which are denoted with mx, my, mz, ax, ay, az, ox, oy and oz. Finally, lat_i and lon_i corresponds to the coordinates (latitude & longitude in decimal degrees) of the initial, intermediate (intersections) and final points. A trajectory with m corridors has m+1 points. FS_i and LS_i state for the i-th trajectoryâ€™s first and last sample respectively in the full sequence of samples collected during the trajectory mapping.  According to the previous structure, the text files are composed by two well-differentiated parts separated by the row indicating the number of segments in the trajectory: 1) the sequence of discrete samples taken during the trajectory mapping, and 2) the configuration data.  The first part contains the timestamp (the UNIX time format in milliseconds) and the vector data from magnetometer (Androidâ€™s TYPE_MAGNETIC_FIELD), accelerometer (TYPE_LINEAR_ACCELERATION) and orientation (TYPE_ORIENTATION) sensors. The accelerometerâ€™s values do not include the gravity force to have a better representation of userâ€™s real movement.  The second part contains the information about location of initial, intermediate and ending points Moreover, the samples can be associated to corridor segments and, moreover, information about turnings is also provided in all the samples. The database consists of 281 continuous samples, 270 are for training and 11 for testing. They have been stored as independent text files. The training ones are grouped into two main categories â€œlinesâ€ and â€œcurvesâ€. - The â€œlinesâ€ group has 80 files and they stand for the single corridor case. The format for filename is â€œlXX_ZZ.txtâ€ where XX stands for the number of corridor & orientation (n or r) and ZZ stands for repetition. Example: l3r_03.txt- The â€œcurvesâ€ group has 190 files and they stand for all possible trajectories considering two connected corridors only. The format for that groupâ€™s filename is â€œcXXYY_ZZ.txtâ€ where XX and YY stand for the number of corridor & orientation for the first and second corridors in the two corridors trajectory, and ZZ stands for repetition. Example: c5n1r_05.txt- The testing filesâ€™ filename format is â€œttPP.txtâ€ where PP stands for the complex testing trajectory number. Example: tt03.txt","Each discrete sample contains.1- Timestamp[2,3,4] - Magnetometer values on the x,y,z axes[4,5,6] - Accelerometer values on the x,y,z axes[7,8,9] - Orientation sensor values on the x,y,z axesn your data set.","JoaquÃ­n Torres-Sospedra, David Rambla, Raul Montoliu, Oscar Belmonte, and JoaquÃ­n Huerta.UJIIndoorLoc-Mag: A New Database for Magnetic Field-Based Localization ProblemsProceedings of the Sixth International Conference on Indoor Positioning and Indoor Navigation (IPIN 2015), 13-16 October 2015, Banff, Alberta, Canada","JoaquÃ­n Torres-Sospedra, David Rambla, Raul Montoliu, Oscar Belmonte, and JoaquÃ­n Huerta.UJIIndoorLoc-Mag: A New Database for Magnetic Field-Based Localization ProblemsProceedings of the Sixth International Conference on Indoor Positioning and Indoor Navigation (IPIN 2015), 13-16 October 2015, Banff, Alberta, Canada",
http://archive.ics.uci.edu/ml/datasets/Pseudo+Periodic+Synthetic+Time+Series,282,Pseudo Periodic Synthetic Time Series Data Set,../machine-learning-databases/synthetic-mld/,"Univariate, Time-Series",100000,N/A,N/A,N/A,2/8/1999,N/A,N/A,45606,"Eamonn J. Keogh and Michael J. PazzaniDepartment of Information and Computer ScienceUniversity of California, Irvine, California 92697 USAeamonn '@' ics.uci.edu, pazzani '@' ics.uci.edu ","This data set is designed for testing indexing schemes in time series databases. It is a much larger dataset than has been used in any published study (That we are currently aware of). It contains one million data points. The data has been split into 10 sections to facilitate testing (see below). We recommend building the index with 9 of the 100,000-datapoint sections, and randomly extracting a query shape from the 10th section. (Some previously published work seems to have used queries that were also used to build the indexing structure. This will produce optimistic results) The data are interesting because they have structure at different resolutions. Each of the 10 sections where generated by independent invocations of the function: (see equation.gif) Where rand(x) produces a random integer between zero and x. The data appears highly periodic, but never exactly repeats itself. This feature is designed to challenge the indexing structure. The time series are ploted here: (ts1-5.gif), (ts6-10.gif)","The data is stored in one ASCII file. There are 10 columns, 100,000 rows. All data points are in the range -0.5 to +0.5. Rows are separated by carriage returns, columns by spaces. ","Eamonn J. Keogh, Michael J. Pazzani: (1999). An indexing scheme for similarity search in large time series databases. The 11th International Conference on Scientific and Statistical Database Management. Cleveland, Ohio.[Web Link]  Sanghyun Park, Dongwon Lee, and Wesley W. Chu. ""Fast Retrieval of Similar Subsequences in Long Sequence Databases"", In 3rd IEEE Knowledge and Data Engineering Exchange Workshop (KDEX), Chicago, IL, USA, November, 1999[Web Link]","Freely available for research use.",
http://archive.ics.uci.edu/ml/datasets/Lymphography,283,Lymphography Data Set,../machine-learning-databases/lymphography/,Multivariate,148,Life,Categorical,18,11/1/1988,Classification,No,89642,"Donors:  1. Igor Kononenko, University E.KardeljFaculty for electrical engineeringTrzaska 2561000 Ljubljana (tel.: (38)(+61) 265-161 2. Bojan CestnikJozef Stefan InstituteJamova 3961000 LjubljanaYugoslavia (tel.: (38)(+61) 214-399 ext.287) ",This is one of three domains provided by the Oncology Institute that has repeatedly appeared in the machine learning literature. (See also breast-cancer and primary-tumor.),"--- NOTE: All attribute values in the database have been entered as numeric values corresponding to their index in the list of attribute values for that attribute domain as given below.    1. class: normal find, metastases, malign lymph, fibrosis    2. lymphatics: normal, arched, deformed, displaced    3. block of affere: no, yes    4. bl. of lymph. c: no, yes    5. bl. of lymph. s: no, yes    6. by pass: no, yes    7. extravasates: no, yes    8. regeneration of: no, yes    9. early uptake in: no, yes   10. lym.nodes dimin: 0-3   11. lym.nodes enlar: 1-4   12. changes in lym.: bean, oval, round   13. defect in node: no, lacunar, lac. marginal, lac. central   14. changes in node: no, lacunar, lac. margin, lac. central   15. changes in stru: no, grainy, drop-like, coarse, diluted, reticular, stripped, faint,    16. special forms: no, chalices, vesicles   17. dislocation of: no, yes   18. exclusion of no: no, yes   19. no. of nodes in: 0-9, 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, >=70","Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.[Web Link]  Clark,P. & Niblett,T. (1987). Induction in Noisy Domains.  In I.Bratko & N.Lavrac (Eds.) Progress in Machine Learning, 11-30, Sigma Press.[Web Link]  Michalski,R., Mozetic,I. Hong,J., & Lavrac,N. (1986).  The Multi-Purpose Incremental Learning System AQ15 and its Testing Applications to Three Medical Domains.  In Proceedings of the Fifth National Conference on Artificial Intelligence, 1041-1045. Philadelphia, PA: Morgan Kaufmann.[Web Link]","This lymphography domain was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and M. Soklic for providing the data.  Please include this citation if you plan to use this database.","Marcus Hutter and Marco Zaffalon. Distribution of Mutual Information from Complete and Incomplete Data. CoRR, csLG/0403025. 2004.  [View Context].Marco Zaffalon and Marcus Hutter. Robust Feature Selection by Mutual Information Distributions. CoRR, csAI/0206006. 2002.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].Thomas G. Dietterich. An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization. Machine Learning, 40. 2000.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Mark A. Hall and Lloyd A. Smith. Feature Selection for Machine Learning: Comparing a Correlation-Based Filter Approach to the Wrapper. FLAIRS Conference. 1999.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].Pedro Domingos. Control-Sensitive Feature Selection for Lazy Learners. Artif. Intell. Rev, 11. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context].Geoffrey I Webb. Learning Decision Lists by Prepending Inferred Rules. School of Computing and Mathematics Deakin University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Multimodal+Damage+Identification+for+Humanitarian+Computing,284,Multimodal Damage Identification for Humanitarian Computing Data Set,../machine-learning-databases/00456/,"Multivariate, Text",5879,Social,Integer,N/A,6/1/2018,Classification,N/A,11981,"Hussein Mouzannar, American University of Beirut (hmm46 '@' aub.edu.lb)Yara Rizk, American University of Beirut (yar01 '@' aub.edu.lb)Mariette Awad, American University of Beirut (mariette.awad '@' aub.edu.lb)",Samples were retrieved from social media posts including Instagram and Twitter. ,640x640 RGB images and raw text,"Hussein Mouzannar, Yara Rizk, and Mariette Awad, 'Damage Identification inSocial Media Posts using Multimodal Deep Learning,' The 15th InternationalConference on Information Systems for Crisis Response and Management(ISCRAM), Rochester, USA, May 20-23, 2018, pp. 529-543.Hadi S. Jomaa, Yara Rizk, and Mariette Awad, 'Semantic and Visual Cuesfor Humanitarian Computing of Natural Disaster Damage Images,' The 12thInternational Conference on Signal Image Technology & Internet Systems (SITIS),Naples, Italy, Nov. 28-Dec. 1 2016.","Hussein Mouzannar, Yara Rizk, and Mariette Awad, 'Damage Identification inSocial Media Posts using Multimodal Deep Learning,' The 15th InternationalConference on Information Systems for Crisis Response and Management(ISCRAM), Rochester, USA, May 20-23, 2018, pp. 529-543.",
http://archive.ics.uci.edu/ml/datasets/MSNBC.com+Anonymous+Web+Data,285,MSNBC.com Anonymous Web Data Data Set,../machine-learning-databases/msnbc-mld/,Sequential,989818,Computer,Categorical,N/A,N/A,N/A,N/A,81499,David Heckerman (heckerma '@' microsoft.com),"The data comes from Internet Information Server (IIS) logs for msnbc.com and news-related portions of msn.com for the entire day of September, 28, 1999 (Pacific Standard Time). Each sequence in the dataset corresponds to page views of a user during that twenty-four hour period. Each event in the sequence corresponds to a user's request for a page. Requests are not recorded at the finest level of detail---that is, at the level of URL, but rather, they are recorded at the level of page category (as determined by a site administrator). The categories are ""frontpage"", ""news"", ""tech"", ""local"", ""opinion"", ""on-air"", ""misc"", ""weather"", ""health"", ""living"", ""business"", ""sports"", ""summary"", ""bbs"" (bulletin board service), ""travel"", ""msn-news"", and ""msn-sports"". Any page requests served via a caching mechanism were not recorded in the server logs and, hence, not present in the data. Other Relevant Information:     * Number of users: 989818    * Average number of vitis per user: 5.7    * Number of URLs per category: 10 to 5000","Each category is associated--in order--with an integer starting with ""1"". For example, ""frontpage"" is associated with 1, ""news"" with 2, and ""tech"" with 3. Each row below ""% Sequences:"" describes the hits--in order--of a single user. For example, the first user hits ""frontpage"" twice, and the second user hits ""news"" once.","I. Cadez, D. Heckerman, C. Meek, P. Smyth, S. White, ""Visualization of navigation patterns on a Web site using model-based clustering,"" Journal of Data Mining and Knowledge Discovery.[Web Link]",This data is avaliable thanks to msnbc.com,
http://archive.ics.uci.edu/ml/datasets/Perfume+Data,286,Perfume Data Data Set,../machine-learning-databases/00303/,"Univariate, Domain-Theory",560,Computer,Integer,2,7/22/2014,"Classification, Clustering",N/A,141055,"Prof. Dr. Bekir KARLIK, bkarlik '@' selcuk.edu.tr, Department of Computer Engineering, Selcuk University, Konya-Turkey Assoc. Prof. Dr. Yousif Al-Bastaki, Department of Computer Science, Bahrain University, Kingdom of Bahrain","The data set gathered when we were working at project for Bahrain university between 2002 and 2003.","The data was obtained from 20 different perfumes by using a handheld odor meter(OMX-GR sensor). Names of these perfumes are: ajayeb, ajmal, amreaj, aood, asgar_ali, bukhoor, burberry, dehenalaod, junaid, kausar, rose, solidmusk, TeaTreeOil, raspberry, RoseMusk, strawberry, constrected2, carolina_herrera, oudh_ma'alattar, constrected1. Each column represent a measurement and there were 28 takes (one each second) ","1- KARLIK Bekir, BASTAKI Yousif, Ã¢â‚¬Å“Real Time Monitoring Odor Sensing System Using OMX-GR Sensor and Neural NetworkÃ¢â‚¬Â, WSEAS Transactions on Electronics, issue 2, vol.1, pp.337-342, April, 2004 2- TEMEL Turgay and KARLIK Bekir, Ã¢â‚¬Å“An Improved Odor Recognition System Using Learning Vector Quantization with a New Discriminant AnalysisÃ¢â‚¬Â, Neural Network World, vol. 17(4), pp. 287-294, 2007 3- KARLIK Bekir and YUKSEK Kemal Ã¢â‚¬Å“Fuzzy Clustering Neural Networks for Real Time Odor Recognition SystemÃ¢â‚¬Â, Journal of Automated Methods and Management in Chemistry, Dec. 2007 Article ID 38405, [Web Link] 4- AL-BASTAKI, Yousif, 'An Artificial Neural Networks-Based on-Line Monitoring Odor Sensing System', Journal of Computer Science , vol. 5, no. 11, pp. 878-882, 2009.","1- KARLIK Bekir, BASTAKI Yousif, Ã¢â‚¬Å“Real Time Monitoring Odor Sensing System Using OMX-GR Sensor and Neural NetworkÃ¢â‚¬Â, WSEAS Transactions on Electronics, issue 2, vol.1, pp.337-342, April, 2004 2- TEMEL Turgay and KARLIK Bekir, Ã¢â‚¬Å“An Improved Odor Recognition System Using Learning Vector Quantization with a New Discriminant AnalysisÃ¢â‚¬Â, Neural Network World, vol. 17(4), pp. 287-294, 2007 3- KARLIK Bekir and YUKSEK Kemal Ã¢â‚¬Å“Fuzzy Clustering Neural Networks for Real Time Odor Recognition SystemÃ¢â‚¬Â, Journal of Automated Methods and Management in Chemistry, Dec. 2007 Article ID 38405, [Web Link]. ",
http://archive.ics.uci.edu/ml/datasets/seismic-bumps,287,seismic-bumps Data Set,../machine-learning-databases/00266/,Multivariate,2584,N/A,Real,19,4/3/2013,Classification,N/A,65730,"Provide the names, email addresses, institutions, and other contact information of the donors and creators of the data set. Marek Sikora^{1,2} (marek.sikora '@' polsl.pl), Lukasz Wrobel^{1} (lukasz.wrobel '@' polsl.pl)(1) Institute of Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland(2) Institute of Innovative Technologies EMAG, 40-189 Katowice, Poland","Mining activity was and is always connected with the occurrence of dangers which are commonly called mining hazards. A special case of such threat is a seismic hazard which frequently occurs in many underground mines. Seismic hazard is the hardest detectable and predictable of natural hazards and in this respect it is comparable to an earthquake. More and more advanced seismic and seismoacoustic monitoring systems allow a better understanding rock mass processes and definition of seismic hazard prediction methods. Accuracy of so far created methods is however far from perfect. Complexity of seismic processes and big disproportion between the number of low-energy seismic events and the number of high-energy phenomena (e.g. > 10^4J) causes the statistical techniques to be insufficient to predict seismic hazard. Therefore, it is essential to search for new opportunities of better hazard prediction, also using machine learning methods. In seismic hazard assessment data clustering techniques can be applied (Lesniak A., Isakow Z.: Space-time clustering of seismic events and hazard assessment in the Zabrze-Bielszowice coal mine, Poland. Int. Journal of Rock Mechanics and Mining Sciences, 46(5), 2009, 918-928), and for prediction of seismic tremors artificial neural networks are used (Kabiesz, J.: Effect of the form of data on the quality of mine tremors hazard forecasting using neural networks. Geotechnical and Geological Engineering, 24(5), 2005, 1131-1147). In the majority of applications, the results obtained by mentioned methods are reported in the form of two states which are interpreted as 'hazardous' and 'non-hazardous'. Unbalanced distribution of positive ('hazardous state') and negative ('non-hazardous state') examples is a serious problem in seismic hazard prediction. Currently used methods are still insufficient to achieve good sensitivity and specificity of predictions. In the paper (Bukowska M.: The probability of rockburst occurrence in the Upper Silesian Coal Basin area dependent on natural mining conditions. Journal of Mining Sciences, 42(6), 2006, 570-577) a number of factors having an effect on seismic hazard occurrence was proposed, among other factors, the occurrence of tremors with energy > 10^4J was listed. The task of seismic prediction can be defined in different ways, but the main aim of all seismic hazard assessment methods is to predict (with given precision relating to time and date) of increased seismic activity which can cause a rockburst. In the data set each row contains a summary statement about seismic activity in the rock mass within one shift (8 hours). If decision attribute has the value 1, then in the next shift any seismic bump with an energy higher than 10^4 J was registered. That task of hazards prediction bases on the relationship between the energy of recorded tremors and seismoacoustic activity with the possibility of rockburst occurrence. Hence, such hazard prognosis is not connected with accurate rockburst prediction. Moreover, with the information about the possibility of hazardous situation occurrence, an appropriate supervision service can reduce a risk of rockburst (e.g. by distressing shooting) or withdraw workers from the threatened area. Good prediction of increased seismic activity is therefore a matter of great practical importance.   The presented data set is characterized by unbalanced distribution of positive and negative examples. In the data set there are only 170 positive examples representing class 1.","Attribute information:1. seismic: result of shift seismic hazard assessment in the mine working obtained by the seismic method (a - lack of hazard, b - low hazard, c - high hazard, d - danger state);2. seismoacoustic: result of shift seismic hazard assessment in the mine working obtained by the seismoacoustic method;3. shift: information about type of a shift (W - coal-getting, N -preparation shift);4. genergy: seismic energy recorded within previous shift by the most active geophone (GMax) out of geophones monitoring the longwall;5. gpuls: a number of pulses recorded within previous shift by GMax;6. gdenergy: a deviation of energy recorded within previous shift by GMax from average energy recorded during eight previous shifts;7. gdpuls: a deviation of a number of pulses recorded within previous shift by GMax from average number of pulses recorded during eight previous shifts;8. ghazard: result of shift seismic hazard assessment in the mine working obtained by the seismoacoustic method based on registration coming form GMax only;9. nbumps: the number of seismic bumps recorded within previous shift;10. nbumps2: the number of seismic bumps (in energy range [10^2,10^3)) registered within previous shift;11. nbumps3: the number of seismic bumps (in energy range [10^3,10^4)) registered within previous shift;12. nbumps4: the number of seismic bumps (in energy range [10^4,10^5)) registered within previous shift;13. nbumps5: the number of seismic bumps (in energy range [10^5,10^6)) registered within the last shift;14. nbumps6: the number of seismic bumps (in energy range [10^6,10^7)) registered within previous shift;15. nbumps7: the number of seismic bumps (in energy range [10^7,10^8)) registered within previous shift;16. nbumps89: the number of seismic bumps (in energy range [10^8,10^10)) registered within previous shift;17. energy: total energy of seismic bumps registered within previous shift;18. maxenergy: the maximum energy of the seismic bumps registered within previous shift;19. class: the decision attribute - '1' means that high energy seismic bump occurred in the next shift ('hazardous state'), '0' means that no high energy seismic bumps occurred in the next shift  ('non-hazardous state').",N/A,"Citation requestSikora M., Wrobel L.: Application of rule induction algorithms for analysis of data collected by seismic hazard monitoring systems in coal mines. Archives of Mining Sciences, 55(1), 2010, 91-114.",
http://archive.ics.uci.edu/ml/datasets/Cervical+cancer+%28Risk+Factors%29,288,Cervical cancer (Risk Factors) Data Set,../machine-learning-databases/00383/,Multivariate,858,Life,"Integer, Real",36,3/3/2017,Classification,Yes,122086,"Kelwin Fernandes (kafc _at_ inesctec _dot_ pt) - INESC TEC & FEUP, Porto, Portugal. Jaime S. Cardoso - INESC TEC & FEUP, Porto, Portugal. Jessica Fernandes - Universidad Central de Venezuela, Caracas, Venezuela.","The dataset was collected at 'Hospital Universitario de Caracas' in Caracas, Venezuela. The dataset comprises demographic information, habits, and historic medical records of 858 patients. Several patients decided not to answer some of the questions because of privacy concerns (missing values).","(int) Age(int) Number of sexual partners(int) First sexual intercourse (age)(int) Num of pregnancies(bool) Smokes(bool) Smokes (years)(bool) Smokes (packs/year)(bool) Hormonal Contraceptives(int) Hormonal Contraceptives (years)(bool) IUD(int) IUD (years)(bool) STDs(int) STDs (number)(bool) STDs:condylomatosis(bool) STDs:cervical condylomatosis(bool) STDs:vaginal condylomatosis(bool) STDs:vulvo-perineal condylomatosis(bool) STDs:syphilis(bool) STDs:pelvic inflammatory disease(bool) STDs:genital herpes(bool) STDs:molluscum contagiosum(bool) STDs:AIDS(bool) STDs:HIV(bool) STDs:Hepatitis B(bool) STDs:HPV(int) STDs: Number of diagnosis(int) STDs: Time since first diagnosis(int) STDs: Time since last diagnosis(bool) Dx:Cancer(bool) Dx:CIN(bool) Dx:HPV(bool) Dx(bool) Hinselmann: target variable(bool) Schiller: target variable(bool) Cytology: target variable(bool) Biopsy: target variable","Kelwin Fernandes, Jaime S. Cardoso, and Jessica Fernandes. 'Transfer Learning with Partial Observability Applied to Cervical Cancer Screening.' Iberian Conference on Pattern Recognition and Image Analysis. Springer International Publishing, 2017.","Kelwin Fernandes, Jaime S. Cardoso, and Jessica Fernandes. 'Transfer Learning with Partial Observability Applied to Cervical Cancer Screening.' Iberian Conference on Pattern Recognition and Image Analysis. Springer International Publishing, 2017.",
http://archive.ics.uci.edu/ml/datasets/DeliciousMIL%3A+A+Data+Set+for+Multi-Label+Multi-Instance+Learning+with+Instance+Labels,289,DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels Data Set,../machine-learning-databases/00418/,Text,12234,Computer,Integer,8519,10/27/2016,Classification,N/A,17999,"Hossein Soleimani, School of Electrical Engineering and Computer Science, Pennsylvania State University, PA, USAhsoleimani '@' psu.edu https://hsoleimani.github.io  David J. Miller,School of Electrical Engineering and Computer Science, Pennsylvania State University, PA, USA, djmiller '@' engr.psu.edu  Creators of DeliciousT140 dataset:Arkaitz Zubiaga, Alberto P. GarcÂ´Ä±a-Plaza, VÂ´Ä±ctor Fresno, and Raquel MartÂ´Ä±nez,Dpto. Lenguajes y Sistemas Informaticos Â´ Universidad Nacional de Educacion a DistanciaÂ´ Madrid, Spain","This dataset provides ground-truth class labels to evaluate performance of multi-instance learning models on both instance-level and bag-level label predictions. DeliciousMIL was first used in [1] to evaluate performance of MLTM, a multi-label multi-instance learning method, for document classification and sentence labeling. Multi-instance learning is a special class of weakly supervised machine learning methods where the learner receives a collection of labeled bags each containing multiple instances. A bag is set to have a particular class label if and only if at least one of its instances has that class label. DeliciousMIL consists of a subset of tagged web pages from the social bookmarking site delicious.com. The original web pages were obtained from DeliciousT140 dataset, which was collected by [2] from the delicious.com in June 2008. Users of the website delicious.com bookmarked each page with word tags. From this dataset, we extracted text parts of each web page and chose 20 common tags as class labels. These class labels are:reference, design, programming, internet, computer, web, java, writing, English, grammar, style, language, books, education, philosophy, politics, religion, science, history, and culture. We randomly selected 12234 pages and randomly divided them into 8251 training and 3983 test documents. We also applied Porter stemming and standard stopword removal.  Each text document is a bag within a multi-instance learning framework consisting of multiple sentences (instances). The goal is to predict document-level and sentence-level class labels on the test set using a model which is trained given only the document-level class labels in the training set.To evaluate performance of such a model, we have manually labeled 1468 randomly selected sentences from the test documents. Please see [1] for more information. ","1) train-data.dat and test-data.dat:These files contain the bag-of-word representation of the training and test documents. Each line is of the form:  sentence_1 sentence_2 â€¦ sentence_{Sd} where Sd is the number of sentences in document d. Each sentence s is in the following format:  w_{1s} w_{2s} â€¦ w_{L_s s} where L_s is the number of words in sentence s, and w_{is} is an integer which indexes the i-th term in sentence s.  2) vocabs.txt: This file contains the list of words used for indexing the document representations in data files. Each line contains: word, index. 3) train-label.dat and test-label.dat:Each file contains a D by C binary matrix where D is the number of documents in every file and C=20 is the number of classes. The element b_{dc} is 1 if class c is present in document d and zero otherwise. 4) test-sentlabel.dat, labeled_test_sentences.dat: test-sentlabel.dat: This file contains class labels for sentences of the test documents. Each line d is of the form: ...  where y_{scd} is the binary indicator of class c for sentence s of document d. y_{scd} is 1 if class c present in sentence s and zero otherwise. Note that only 1468 sentences are randomly selected and manually labeled. For the rest of the sentences that are unlabeled, we set y_{scd}=-1.  labeled_test_sentences.dat: This file only contains the class labels for the 1468 sentences which are manually labeled. Each line of this file is of the form: d s y_{s1d} y_{s2d} â€¦ y_{sCd} where d and s are respectively document and sentence indices.  4) labels.txt: This contains the list of all class labels in this dataset. Each line is of the form: label, index. Please see [Web Link] for example python code for reading these files.","[1] Hossein Soleimani and David J. Miller. 2016. Semi-supervised Multi-Label Topic Models for Document Classification and Sentence Labeling. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (CIKM '16). ACM, New York, NY, USA, 105-114. DOI: [Web Link]. [2] Arkaitz Zubiaga, Alberto P. GarcÃ­a-Plaza, VÃ­ctor Fresno, and Raquel MartÃ­nez. 2009. Content-Based Clustering for Tag Cloud Visualization. In Proceedings of the 2009 International Conference on Advances in Social Network Analysis and Mining (ASONAM '09). IEEE Computer Society, Washington, DC, USA, 316-319. DOI=[Web Link]","If you use DeliciousMIL, please cite: Hossein Soleimani and David J. Miller. 2016. Semi-supervised Multi-Label Topic Models for Document Classification and Sentence Labeling. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (CIKM '16). ACM, New York, NY, USA, 105-114. DOI: [Web Link].",
http://archive.ics.uci.edu/ml/datasets/Data+for+Software+Engineering+Teamwork+Assessment+in+Education+Setting,290,Data for Software Engineering Teamwork Assessment in Education Setting Data Set,../machine-learning-databases/00393/,"Sequential, Time-Series",74,Computer,"Integer, Real",102,6/29/2017,Classification,Yes,34643,"Prof. D. Petkovic (SFSU) Petkovic '@' sfsu.edu; Prof. Rainer Todtenhoefer (Fulda University, Germany); Prof. Shihong Huang (FAU)","The data can be used to try to predict student learning in SE teamwork based on observation of their team activity  **** README FILE from the submitted data ZIP **** #  San Francisco State University#  Software Engineering Team Assessment and Prediction (SETAP) Project#  Machine Learning Training Data File Version 0.7#  ====================================================================##  Copyright 2000-2017 by San Francisco State University, Dragutin#  Petkovic, and Marc Sosnick-Perez.##  CONTACT#  -------#  Professor Dragutin Petkovic:  petkovic '@' sfsu.edu ##  LICENSE#  -------#  This data is released under the Creative Commons Attribution-#  NonCommercial 4.0 International license.  For more information,#  please see#  [Web Link].##  The research that has made this data possible has been funded in#  part by NSF grant NSF-TUES1140172.##  YOUR FEEDBACK IS WELCOME#  ------------------------#  We are interested in how this data is being used.  If you use it in#  a research project, we would like to know how you are using the#  data.  Please contact us at petkovic '@' sfsu.edu. ###  FILES INCLUDED IN DISTRIBUTION PACKAGE#  ======================================#  This archive contains the data collected by the SETAP Project.###  More data about the SETAP project, data collection, and description#  and use of machine learning to analyze the data can be found in the#  following paper:##  D. Petkovic, M. Sosnick-Perez, K. Okada, R. Todtenhoefer, S. Huang,#  N. Miglani, A. Vigil: 'Using the Random Forest Classifier to Assess#  and Predict Student Learning of Software Engineering Teamwork'.#  Frontiers in Education FIE 2016, Erie, PA, 2016####  See DATA DESCRIPTION below for more information about the data.  The#  README file (which you are reading) contains project information#  such as data collection techniques, data organization and field#  naming convention.  In addition to the README file, the archive#  contains a number of .csv files.  Each of these CSV files contains#  data aggregated by team from the project (see below), paired with#  that team's outcome for either the process or product component of#  the team's evaluation.  The files are named using the following#  convention:##                  setap[Process|Product]T[1-11].csv##  For example, the file setapProcessT5.csv contains the data for all#  teams for time interval 5, paired with the outcome data for the#  Process component of the team's evaluation.##  Detailed information about the exact format of the .csv file may be#  found in the csv files themselves.###  DATA DESCRIPTION#  ====================================================================#  The following is a detailed description of the data contained in the#  accompanying files.##  INTRODUCTION#  ------------##  The data contained in these files were collected over a period of#  several semesters from students engaged in software engineering#  classes at San Francisco State University (class sections of CSC#  640, CSC 648 and CSC 848).  All students consented to this data#  being shared for research purposes provided no uniquely identifiable#  information was contained in the distributed files.  The information#  was collected through various means, with emphasis being placed on#  the collection of objective, quantifiable information.  For more#  information on the data collection procedures, please see the paper#  referenced above.###  PRIVACY#  -------#  The data contained in this file does not contain any information#  which may be individually traced to a particular student who#  participated in the study.###  BRIEF DESCRIPTION OF DATA SOURCES AND DERIVATIONS#  -------------------------------------------------#  SAMs (Student Activity Measure) are collected for each student team#  member during their participation in a software engineering class.#  Student teams work together on a final class project, and comprise#  5-6 students.  Teams that are made up of students from only one#  school are labeled local teams.  Teams made up of students from more#  than one school are labeled global teams.  SAMs are collected from:#  weekly timecards, instructor observations, and software engineering#  tool usage logs.  SAMs are then aggregated by team and time interval#  (see next section) into TAMs (Team Activity Measure).  Outcomes are#  determined at the end of the semester through evaluation of student#  team work in two categories:  software engineering process (how well#  the team applied best software engineering practices), and software#  engineering product (the quality of the finished product the team#  produced).  Thus for each team, two outcomes are determined, process#  and product, respectively.  Outcomes are classified into two class#  grades, A or F.  A represents teams that are at or above#  expectations, F represents teams that are below expectations or need#  attention.  For more information, please see the paper referenced#  above.##  The SE process and SE product outcomes represent ML training classes#  and are to be considered separately, e.g. one should train ML for SE#  process separately from training for SE product.##  TIME INTERVALS FOR WHICH DATA IS COLLECTED#  ------------------------------------------#  Data collected continuously throughout the semester are aggregated#  into different time intervals for the semester's project reflecting#  different dynamics of teamwork during the class.  Time intervals#  represent time periods in which a milestone was developed by each#  team.  A milestone represents a major deliverable point in the class#  for all student teams.  The milestones are roughly divided into the#  following topics:##            M1 - high level requirements and specs#            M2 - more detailed requirements and specs#            M3 - first prototype#            M4 - beta release#            M5 - final delivery##  Time intervals are combinations of the time in which milestones are#  being produced.  Time intervals are used in research only.##  In addition to time intervals corresponding to milestones, a number#  of time intervals combining multiple T1-T5 time intervals have been#  calculated.  This was done to group student activities into design#  vs. implementation phases which have different dynamics.##  These time intervals are defined as follows:##      Time Interval        Corresponding Milestone Periods in Class#    -----------------    --------------------------------------------#           0               Milestone 0#           1               Milestone 1#           2               Milestone 2#           3               Milestone 3#           4               Milestone 4#           5               Milestone 5#           6               Milestone 1 - Milestone 2 inclusive#           7               Milestone 1 - Milestone 3 inclusive#           8               Milestone 1 - Milestone 4 inclusive#           9               Milestone 1 - Milestone 5 inclusive#          10               Milestone 4 - Milestone 5 inclusive#          11               Milestone 3 - Milestone 5 inclusive####  SETAP PROJECT OVERALL DATA STATISTICS#  ================================================================== #  The following is a set of statistics about the entire dataset which#  may be useful in the configuration of machine learning methods.##  This data was collected only from students at SFSU.  Global teams#  represent only the data from the SFSU student portion of the team.##  GENERAL STATISTICS#  ------------------#                       Number of semesters: 7#                            First semester: Fall 2012#                             Last semester: Fall 2015#                        Number of students: 383#                            Class sections: 18##                    Number of TAM features: 115#         Number of class labels (outcomes): 2##                     Issues closed on time:   202#                        Issues closed late: +  53#                                            -------#                              Total issues:   255##  TEAM COMPOSITION STATISTCS#  --------------------------#      Local Teams:    59#     Global Teams: +  15#                   ------#            Total:    74 Teams##  OUTCOME (CLASSIFICATION) STATISTICS#  -----------------------------------#   Total Outcomes: 74##                Proces               Product#           ------------------  ------------------#  outcome:      A       F           A       F#                49      25          42     32##  TAM FEATURE NAMING CONVENTION#  -----------------------------#  A systematic approach to aggregating and naming TAM features was#  developed.  By using this systematic approach, TAM feature names are#  produced that are human understandable and intuitive and related to#  aggregation method.###  There are a number of base TAM which are then aggregated into#  aggregated TAM.##  BASE TAM#  --------##  General TAM#  -----------#  The following TAMs are collected for each team: Year, semester,#  timeInterval, teamNumber, semesterId, teamMemberCount,#  femaleTeamMembersPercent, teamLeadGender, teamDistribution##  Calculated TAM#  --------------#  For each team, TAM were calculated from SAMs for every time interval#  Ti.  The core TAM variables where for each we compute as applicable:#  count, average, standard deviation over weeks, over students etc.##  TAMs collected by Weekly Time Cards (WTS) TAM#  ---------------------------------------------#  teamMemberResponseCount, meetingHours, inPersonMeetingHours.#  nonCodingDeliverablesHours, codingDeliverablesHours, helpHours,#  globalLeadAdminHours, LeadAdminHoursResponseCount,#  GlobalLeadAdminHoursResponseCount##  TAMs collected  by Tool Logs (TL) TAM#  -------------------------------------#  commitCount, uniqueCommitMessageCount, uniqueCommitMessagePercent,#  CommitMessageLength##  Collected by Instructor Observations (IO) TAMs#  ------------------------------------------------#  issueCount, onTimeIssueCount, lateIssueCount###  AGGREGATED TAM#  --------------##  Several aggregation method and derived variable names for TAMs#  reflect how the core TAM variables were aggregated in final TAM#  measures for each time interval Ti:##  Let VAR be the core TAM variable above. The naming conventions and#  aggregation operators to obtain TAMs for each time interval Ti were#  as follows:##  Total - total sum of VAR in the time interval Ti#  Average - average of VAR in the time interval#  StandardDeviation - SD of variable in time interval#  Count - count of events measured by VAR (e.g. missed#  checkpoints) in time interval#  AverageByWeek - total sum/count of VAR in the time interval#  divided by weeks in time interval#  StandradDeviationByWeek - the standard devation of the weekly#  total of VAR taken over the time interval#  AverageByStudent - total count/sum of VAR in time interval,#  divided by number of students in the team#  StandardDeviation ByStudent - standard deviation of  VAR in the#  time interval, over students in the team###  NULL VALUES#  -----------#  NULL values are used in the training data to indicate that no SAMs#  were recorded in that particular time period, week, or for that#  student.##  Frequently TAM features involving teamLeadHours or globalTeamLead#  hours will result in a NULL for a particular training sample.  For#  local team leads, that usually means that the local team lead did#  not complete any timecard surveys for the aggregation in quesiton.#  While for global team lead TAM features this may also be the case,#  the more usual cause of NULLS in global team lead TAM features comes#  from the fact that most teams are not global, and therefore this#  statistic was not gathered for these teams.##  It is left to the individual researcher to decide how to accomodate#  NULL values, and the data is included in this file.  Though these#  may not be useful for machine learning directly, valuable#  information can be obatined with some processing.##  TAM FEATURES#  ------------#  The following is a list of tam features available in the data files.#  The TAM feature names are listed in the order in which the data#  appear in each training sample, i.e. the first feature corresponds#  to the first column, the second feature corresponds to the second#  column, etc.##  The first sample line in the data section of the data file is not a#  true sample, but consists of TAM feature names, which allows for#  easy import into spreadsheets and for human readability.##  The final two TAM features (columns) are the outcome data for#  process and product, and are the last two columns in each sample#  row.  The training sample data follow the header comment section.###  TAM FEATURE LIST#  ----------------#  year#  semester#  timeInterval#  teamNumber#  semesterId#  teamMemberCount#  femaleTeamMembersPercent#  teamLeadGender#  teamDistribution#  teamMemberResponseCount#  meetingHoursTotal#  meetingHoursAverage#  meetingHoursStandardDeviation#  inPersonMeetingHoursTotal#  inPersonMeetingHoursAverage#  inPersonMeetingHoursStandardDeviation#  nonCodingDeliverablesHoursTotal#  nonCodingDeliverablesHoursAverage#  nonCodingDeliverablesHoursStandardDeviation#  codingDeliverablesHoursTotal#  codingDeliverablesHoursAverage#  codingDeliverablesHoursStandardDeviation#  helpHoursTotal#  helpHoursAverage#  helpHoursStandardDeviation#  leadAdminHoursResponseCount#  leadAdminHoursTotal#  leadAdminHoursAverage#  leadAdminHoursStandardDeviation#  globalLeadAdminHoursResponseCount#  globalLeadAdminHoursTotal#  globalLeadAdminHoursAverage#  globalLeadAdminHoursStandardDeviation#  averageResponsesByWeek#  standardDeviationResponsesByWeek#  averageMeetingHoursTotalByWeek#  standardDeviationMeetingHoursTotalByWeek#  averageMeetingHoursAverageByWeek#  standardDeviationMeetingHoursAverageByWeek#  averageInPersonMeetingHoursTotalByWeek#  standardDeviationInPersonMeetingHoursTotalByWeek#  averageInPersonMeetingHoursAverageByWeek#  standardDeviationInPersonMeetingHoursAverageByWeek#  averageNonCodingDeliverablesHoursTotalByWeek#  standardDeviationNonCodingDeliverablesHoursTotalByWeek#  averageNonCodingDeliverablesHoursAverageByWeek#  standardDeviationNonCodingDeliverablesHoursAverageByWeek#  averageCodingDeliverablesHoursTotalByWeek#  standardDeviationCodingDeliverablesHoursTotalByWeek#  averageCodingDeliverablesHoursAverageByWeek#  standardDeviationCodingDeliverablesHoursAverageByWeek#  averageHelpHoursTotalByWeek#  standardDeviationHelpHoursTotalByWeek#  averageHelpHoursAverageByWeek#  standardDeviationHelpHoursAverageByWeek#  averageLeadAdminHoursResponseCountByWeek#  standardDeviationLeadAdminHoursResponseCountByWeek#  averageLeadAdminHoursTotalByWeek#  standardDeviationLeadAdminHoursTotalByWeek#  averageGlobalLeadAdminHoursResponseCountByWeek#  standardDeviationGlobalLeadAdminHoursResponseCountByWeek#  averageGlobalLeadAdminHoursTotalByWeek#  standardDeviationGlobalLeadAdminHoursTotalByWeek#  averageGlobalLeadAdminHoursAverageByWeek#  standardDeviationGlobalLeadAdminHoursAverageByWeek#  averageResponsesByStudent#  standardDeviationResponsesByStudent#  averageMeetingHoursTotalByStudent#  standardDeviationMeetingHoursTotalByStudent#  averageMeetingHoursAverageByStudent#  standardDeviationMeetingHoursAverageByStudent#  averageInPersonMeetingHoursTotalByStudent#  standardDeviationInPersonMeetingHoursTotalByStudent#  averageInPersonMeetingHoursAverageByStudent#  standardDeviationInPersonMeetingHoursAverageByStudent#  averageNonCodingDeliverablesHoursTotalByStudent#  standardDeviationNonCodingDeliverablesHoursTotalByStudent#  averageNonCodingDeliverablesHoursAverageByStudent#  standardDeviationNonCodingDeliverablesHoursAverageByStudent#  averageCodingDeliverablesHoursTotalByStudent#  standardDeviationCodingDeliverablesHoursTotalByStudent#  averageCodingDeliverablesHoursAverageByStudent#  standardDeviationCodingDeliverablesHoursAverageByStudent#  averageHelpHoursTotalByStudent#  standardDeviationHelpHoursTotalByStudent#  averageHelpHoursAverageByStudent#  standardDeviationHelpHoursAverageByStudent#  commitCount#  uniqueCommitMessageCount#  uniqueCommitMessagePercent#  commitMessageLengthTotal#  commitMessageLengthAverage#  commitMessageLengthStandardDeviation#  averageCommitCountByWeek#  standardDeviationCommitCountByWeek#  averageUniqueCommitMessageCountByWeek#  standardDeviationUniqueCommitMessageCountByWeek#  averageUniqueCommitMessagePercentByWeek#  standardDeviationUniqueCommitMessagePercentByWeek#  averageCommitMessageLengthTotalByWeek#  standardDeviationCommitMessageLengthTotalByWeek#  averageCommitCountByStudent#  standardDeviationCommitCountByStudent#  averageUniqueCommitMessageCountByStudent#  standardDeviationUniqueCommitMessageCountByStudent#  averageUniqueCommitMessagePercentByStudent#  standardDeviationUniqueCommitMessagePercentByStudent#  averageCommitMessageLengthTotalByStudent#  standardDeviationCommitMessageLengthTotalByStudent#  averageCommitMessageLengthAverageByStudent#  standardDeviationCommitMessageLengthAverageByStudent#  averageCommitMessageLengthStandardDeviationByStudent#  issueCount#  onTimeIssueCount#  lateIssueCount#  processLetterGrade#  productLetterGrade ",See above,"D. Petkovic, M. Sosnick-PÃ©rez, K. Okada, R. Todtenhoefer, S. Huang, N. Miglani, A. Vigil: â€œUsing the Random Forest Classifier to Assess and Predict Student Learning of Software Engineering Teamworkâ€ Frontiers in Education FIE 2016, Erie, PA, 2016",Please cite above FIE paper,
http://archive.ics.uci.edu/ml/datasets/MicroMass,291,MicroMass Data Set,../machine-learning-databases/00253/,Multivariate,931,Life,Real,1300,8/12/2013,Classification,N/A,47083,"Pierre Mahé, pierre.mahe '@' biomerieux.com, bioMérieuxJean-Baptiste Veyrieras, jean-baptiste.veyrieras '@' biomerieux.com, bioMérieux","This MALDI-TOF dataset consists in:A) A reference panel of 20 Gram positive and negative bacterial species covering 9 genera among which several species are known to be hard to discriminate by mass spectrometry (MALDI-TOF). Each species was represented by 11 to 60 mass spectra obtained from 7 to 20 bacterial strains, constituting altogether a dataset of 571 spectra obtained from 213 strains. The spectra were obtained according to the standard culture-based workflow used in clinical routine in which the microorganism was first grown on an agar plate for 24 to 48 hours, before a portion of colony was picked, spotted on a MALDI slide and a mass spectrum was acquired. B) Based on this reference panel, a dedicated in vitro mock-up mixture dataset was constituted. For that purpose we considered 10 pairs of species of various taxonomic proximity:   * 4 mixtures, labelled A, B, C and D, involved species that belong to the same genus,   * 2 mixtures, labelled E and F, involved species that belong to distinct genera, but to the same Gram type,   * 4 mixtures, labelled G, H, I and J, involved species that belong to distinct Gram types.Each mixture was represented by 2 pairs of strains, which were mixed according to the following 9 concentration ratios : 1:0, 10:1, 5:1, 2:1, 1:1, 1:2, 1:5, 1:10, 0:1. Two replicate spectra were acquired for each concentration ratio and each couple of strains, leading altogether to a dataset of 360 spectra, among which 80 are actually pure sample spectra.",Provide information about each attribute in your data set.,"Mahé et al. (2014). Automatic identification of mixed bacterial species fingerprints in a MALDI-TOF mass-spectrum. Bioinformatics.Vervier et al., A benchmark of support vector machines strategies for microbial identification by mass-spectrometry data, submitted","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Nettalk+Corpus%29,292,Connectionist Bench (Nettalk Corpus) Data Set,../machine-learning-databases/undocumented/connectionist-bench/nettalk/,Multivariate,20008,N/A,Categorical,4,N/A,N/A,N/A,46748,"The data set was contributed to the benchmark collection by Terry Sejnowski, now at the Salk Institute and the University of California at San Deigo.  The data set was developed in collaboration with Charles Rosenberg of Princeton.  Approximately 250 person-hours went into creating and testing this database.","This is an updated and corrected version of the data set used by Sejnowski and Rosenberg in their influential study of speech generation using a neural network [1].  The file ""nettalk.data"" contains a list of 20,008 English words, along with a phonetic transcription for each word. The task is to train a network to produce the proper phonemes, given a string of letters as input.  This is an example of an input/output mapping task that exhibits strong global regularities, but also a large number of more specialized rules and exceptional cases. Please see original readme file for more information.","The pronouncing dictionary was created to study the translation process between written English, using graphemes or letters as units, and spoken English, using phonemes as units. The dictionary includes 20008 aligned letter and phonetic representations with stresses. The dictionary contains four tab separated fields of information for each word.  The fields are: 	1) a letter representation	2) a phonemic representation	3) stress and syllabic structure	4) an integer indicating foreign and irregular words Please see original readme file for more information.","Sejnowski, T.J., and Rosenberg, C.R. (1987).  ""Parallel networks that learn to pronounce English text"" in Complex Systems, 1, 145-168.[Web Link]","Copyright (C) 1988 by Terrence J. Sejnowski.  Permission is hereby given to use the included data for non-commercial research purposes.  Contact The Johns Hopkins University, Cognitive Science Center, Baltimore MD, USA for information on commercial use.","Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Kai Ming Ting and Boon Toh Low. Model Combination in the Multiple-Data-Batches Scenario. ECML. 1997.  [View Context].Steven Salzberg. On Comparing Classifiers: Pitfalls to Avoid and a Recommended Approach. Data Min. Knowl. Discov, 1. 1997.  [View Context].Thomas G. Dietterich and Ghulum Bakiri. Solving Multiclass Learning Problems via Error-Correcting Output Codes. CoRR, csAI/9501101. 1995.  [View Context].Dietrich Wettschereck and David W. Aha. Weighting Features. ICCBR. 1995.  [View Context].Kai Ming Ting and Boon Toh Low. Theory Combination: an alternative to Data Combination. University of Waikato.  [View Context].Sherrie L. W and Zijian Zheng. A BENCHMARK FOR CLASSIFIER LEARNING. Basser Department of Computer Science The University of Sydney.  [View Context].Steve Whittaker and Loren G. Terveen and Bonnie A. Nardi. Let's stop pushing the envelope and start addressing it: a reference task agenda for HCI. a Senior Research Scientist in the Human Computer Interaction Department of AT&T LabsResearch.  [View Context].Rong Jin and Yan Liu and Luo Si and Jaime Carbonell and Alexander G. Hauptmann. A New Boosting Algorithm Using Input-Dependent Regularizer. School of Computer Science, Carnegie Mellon University.  [View Context].Wl/odzisl/aw Duch and Jerzy J. Korczak. Optimization and global minimization methods suitable for neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Rayid Ghani. KDD Project Report Using Error-Correcting Codes for Efficient Text Classification with a Large Number of Categories. Center for Automated Learning and Discovery, School of Computer Science, Carnegie Mellon University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/MEU-Mobile+KSD,293,MEU-Mobile KSD Data Set,../machine-learning-databases/00399/,Multivariate,2856,Computer,"Integer, Real",71,5/14/2016,Classification,N/A,12518,"Ms. Noor Al-Obaidi, noor_mahmood_2012 '@' hotmail.com, Middle East University, Faculty of Information Technology, Amman, Jordan. ","The dataset is used in the evaluation of EER, FRR and FAR metrics using a new anomaly detector model (Med-Min-Diff). The typed text in the experiment is the password '.tie5Roanl'.","The measured features (attributes) are Hold (H), Up-Down (UD), Down-Down (DD), Pressure (P), Finger-Area (A), Averages of Hold (AH), Pressure (AP) and Finger Area (AFA). There are 71 features because each feature has a set of feature elements corresponding to the typed characters. ","1. Master thesis from Middle East University in Jordan, May 2016 (A New Statistical Anomaly Detector Model for Keystroke Dynamics on Touch Mobile Devices)>2. Paper: 'Statistical Median-Based Classifier Model for Keystroke Dynamics on Mobile Devices', Sixth International Conference on Digital Information Processing and Communications (ICDIPC), April 2016.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Vicon+Physical+Action+Data+Set,294,Vicon Physical Action Data Set Data Set,../machine-learning-databases/00214/,Time-Series,3000,Physical,Real,27,7/27/2011,Classification,N/A,52601,"Theo TheodoridisSchool of Computer Science and Electronic EngineeringUniversity of EssexWivenhoe Park, Colchester, CO4 3SQ, UKttheod '@' gmail.com http://sites.google.com/site/ttheod/","1. Protocol:   Seven male and three female subjects (age 25 to 30), who have experienced aggression in scenarios such   as physical fighting, took part in the experiment. Throughout 20 individual experiments, each subject   had to perform ten normal and ten aggressive activities. Regarding the rights of the subjects involved,   ethical regulations have been followed based on the code of ethics of the British psychological society,   which explains the ethical legislations to conduct statistical experiments using human subjects. For safety   precaution issues, boxing hand wraps have been given to the subjects, and for the warm up the subjects   were instructed to familiarise with the bag by having a number of trial runs. The subjects were aware that   since their involvement in this series of experiments was voluntary, it was made clear that they could   withdraw at any time from the study. 2. Instrumentation:   The Essex robotic arena was the main experimental hall where the data collection took place. With area   4x5.5m, the ten subjects expressed normal and aggressive physical activities at random locations. For the   normal actions, a human partner has been used as a focus target attracting the attention from the subjects   so as to perform more realistic activity. For the aggressive actions, the subjects made use of a professional   kick-boxing standing bag, 1.75m tall, with a human figure drawn on its body. The bag has cylindrical shape   made from soft material, which could bounce when hit. All the activities have been recorded from random   starting positions so that to have a variety of spatial 3D data. The subjectsâ€™ performance has been recorded   by the Viconâ€™s nine ubiquitous cameras, interfacing human activity with spatial coordinate points. Based on   this context, the data acquisition process involved four reflectable markers placed on the forearms (elbows   and wrists), four on the forelegs (knees and ankles), and one on the top of the head. 3. Data Setup:   Each experimental trial has been taken separately for each physical activity. The duration of each action   was approximately ~10 seconds per subject, which corresponds to a time series of ~3000 samples, with   sampling frequency of 200Hz. Within this performance time, approximately 15 action trajectories were   extracted counting in average 15 normal (ex: handshaking), and 15 aggressive (ex: punching) actions.","Each file in the dataset contains in overall 28 columns (the 1st is a counter), and is organised as follows: +---------+-------+---------------+---------------------+---------------------+---------------------+| Segment | Head  |     L-Arm     |        R-Arm        |        L-Leg        |        R-Leg        |+---------+-------+-------+-------+----------+----------+----------+----------+----------+----------+| Marker  | m1    | m2    | m3    | m4       | m5       | m6       | m7       | m8       | m9       || Coords  | x y z | x y z | x y z | x  y  z  | x  y  z  | x  y  z  | x  y  z  | x  y  z  | x  y  z  || Column  | 1,2,3 | 4,5,6 | 7,8,9 | 10,11,12 | 13,14,15 | 16,17,18 | 19,20,21 | 22,23,24 | 25,26,27 |+---------+-------+-------+-------+----------+----------+----------+----------+----------+----------+ Segment: A segment defines a body segment or limb.         - Head	 - Left arm (L-Arm)	 - Right arm (R-Arm)	 - Left leg (L-Leg)	 - Right leg (R-Leg) Marker:  A pair of markers (except the head) is attached at each body segment for 3D data acquisition.	 - Arm markers: wrist (WRS), elbow (ELB)	 - Leg markers: ankle (ANK), knee (KNE) Coords:  The 3 coordinates (x,y,z) define the 3D position of each marker in space.	 - x: The x coordinate	 - y: The y coordinate	 - z: The z coordinate","1. T. Theodoridis and H. Hu, Classifying Aggressive Actions of 3D Human Models Using   Dynamic ANNs for Mobile Robot Surveillance, IEEE International Conference on Robotics   and Biomimetics (Robio-2007), Dec. 15-18, 2007, pp. 371-376. 2. T. Theodoridis, A. Agapitos, H. Hu, and S. M. Lucas, Ubiquitous Robotics in Physical   Human Action Recognition: A Comparison Between Dynamic ANNs and GP, IEEE International   Conference on Robotics and Automation (ICRA-2008), May 19-23, 2008, pp. 3064-3069. 3. T. Theodoridis and H. Hu, A Fuzzy-Convolution Model for Physical Action and Behaviour   Pattern Recognition of 3D Time Series, IEEE Int. Conference on Robotics and Biomimetics   (Robio-2008), Feb. 21-26, 2009, pp. 407-412. 4. T. Theodoridis, A. Agapitos, H. Hu, and S. M. Lucas, Mechanical Feature Attributes for   Modeling and Pattern Classification of Physical Activities, IEEE International Conference   in Information and Automation (ICIA-2009), June 22-24, 2009, pp. 528-533. 5. T. Theodoridis, A. Agapitos, H. Hu, and S. M. Lucas, A QA-TSK Fuzzy Model versus Evolutionary   Decision Trees Towards Nonlinear Action Pattern Recognition, IEEE International Conference in   Information and Automation (ICIA-2010), June 20-23, 2010, pp. 1813-1818. 6. T. Theodoridis, P. Theodorakopoulos, and H. Hu, Evolving Aggressive Biomechanical Models with   Genetic Programming, IEEE/RSJ International Conference on Intelligent Robots and Systems,   (IROS-2010), Oct. 18-22, 2010, pp. 2495-2500. 7. T. Theodoridis, A. Agapitos, and H. Hu, A Gaussian Groundplan Projection Area Model for   Evolving Probabilistic Classifiers, GECCO Genetic and Evolutionary Computation Conference   (GECCO-2011), Jul. 12-16, 2011, pp. 1339-1346.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor,295,Dodgers Loop Sensor Data Set,../machine-learning-databases/event-detection/,"Multivariate, Time-Series",50400,N/A,"Categorical, Integer",3,12/1/2006,N/A,Yes,74324,"Creator and Maintainer:Jon HutchinsUCIjohutchi '@' uci.edu  Donor: PeMS","This loop sensor data was collected for the Glendale on ramp for the 101 North freeway in Los Angeles.  It is close enough to the stadium to see unusual traffic after a Dodgers game, but not so close and heavily used by game traffic so that the signal for the extra traffic is overly obvious. NOTE: This is an on ramp near the stadium so event traffic BEGINS at or near the END of the event time. The observations were taken over 25 weeks, 288 time slices per day (5 minute count aggregates).   The goal is to predict the presence of a baseball game at Dodgers stadium ","1.  Date: MM/DD/YY2.  Time: (H)H:MM (military time)3.  Count: Number of cars measured for the previous five minutesRows: Each five minute time slice is represented by one row  For .events file:1.  Date: MM/DD/YY2.  Begin event time: HH:MM:SS (military) 3.  End event time: HH:MM:SS (military)4.  Game attendance5.  Away team6.  W/L score","""Adaptive event detection with time-varying Poisson processes""A. Ihler, J. Hutchins, and P. SmythProceedings of the 12th ACM SIGKDD Conference (KDD-06), August 2006.","These loop sensor measurements were obtained from the Freeway Performance Measurement System (PeMS), ""[Web Link]""  Please include this citation if you plan to use this database.",
http://archive.ics.uci.edu/ml/datasets/Balloons,296,Balloons Data Set,../machine-learning-databases/balloons/,Multivariate,16,Social,Categorical,4,N/A,Classification,No,288293,Michael Pazzani (pazzani '@' ics.uci.edu),"There are four data sets representing different conditions of an experiment. All have the same attributes. a. adult-stretch.data  Inflated is true if age=adult or act=stretch b. adult+stretch.data  Inflated is true if age=adult and act=stretch c. small-yellow.data   Inflated is true if (color=yellow and size = small) or d. small-yellow+adult-stretch.data  Inflated is true if (color=yellow and size = small) or (age=adult and act=stretch)","(Classes Inflated T or F) Color:             yellow, purplesize:              large, smallact:               stretch, dipage:               adult, childinflated:          T, F","Pazzani, M. (1991). The influence of prior knowledge on concept acquisition: Experimental and computational results. Journal of Experimental Psychology: Learning, Memory & Cognition, 17, 3,  416-432.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",Ron Kohavi and George H. John and Richard Long and David Manley and Karl Pfleger. MLC++: A Machine Learning Library in C. ICTAI. 1994.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Character+Font+Images,297,Character Font Images Data Set,../machine-learning-databases/00417/,Multivariate,745000,Computer,"Integer, Real",411,8/14/2016,Classification,N/A,33009,"Richard Lyman459 Monterey AvenueLos Gatos, California 95030408 399 6303richard.r.lyman '@' gmail.com","The data set consists of images from 153 character fonts. Some fonts were scanned from a variety of devices: hand scanners, desktop scanners or cameras.  Other fonts were computer generated.  The .zip file contains .csv, comma delimited files, one for each font.  Each .csv file has a header row with the data set attribute names.  The Handprint images differ slightly from the standard MNIST dataset.  ","field       Type    Unique  Example          Descriptionfont        string  153    â€˜timesâ€™           font familyfontVariant string  248    â€˜times new romanâ€™ If the font image was from a scanner,                                              the fontVariant is â€œscannedâ€ otherwise it is the font name.m_label     integer 11597  33 to 65535       The character value, for instance 48 for the digit, â€˜0â€™strength    real    2      .4                A value 0 to 1, indicating normal or bolditalic      integer 2      1                 A flag, if 1, the image was computer generated with the an italic font.m_top       integer        13                The topmost black pixel row index in the original image from which the image was cutm_left      integer        43                The leftmost black pixel column index in the original image from which the image was cutoriginalH   integer        30                The original height of the image in pixelsoriginalW   integer        36                The original width of the image in pixelsh           integer 1      20                The image height in this sample, always 20w           integer 1      20                The image width in this sample, always 20r0c0        integer        0                 Row 0 Column 0 pixel value, 0 to 255, white is 0, 255 is blackr0c1        integer        255               Row 0, Column 1 pixel value, 0 to 255â€¦ 397       integer        0                 397 pixel values, 0 to 255r19c19      integer        255               Row 19, Column 19 pixel value, 0 to 255","A utility Python program for accessing this data set, script files, and approximately 40 machine learning programs adapted from the book, â€œPython Machine Learningâ€ by Sebastian Raschka, can be found at: [Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Japanese+Credit+Screening,298,Japanese Credit Screening Data Set,../machine-learning-databases/credit-screening,"Multivariate, Domain-Theory",125,Financial,"Categorical, Real, Integer",N/A,3/19/1992,Classification,N/A,107379,"Creator:  Chiharu Sano  Donor:  Chiharu Sanocsano '@' bonnie.ICS.UCI.EDU","Examples represent positive and negative instances of people who were and were not  granted credit. The theory was generated by talking to the individuals at a Japanese company that grants credit.",N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy","Chris Drummond and Robert C. Holte. C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling. Institute for Information Technology, National Research Council Canada.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Forest+type+mapping,299,Forest type mapping Data Set,../machine-learning-databases/00333/,Multivariate,326,Life,N/A,27,5/25/2015,Classification,N/A,58991,"Brian Johnsonjohnson '@' iges.or.jp Institute for Global Environmental Strategies ","This data set contains training and testing data from a remote sensing study which mapped different forest types based on their spectral characteristics at visible-to-near infrared wavelengths, using ASTER satellite imagery. The output (forest type map) can be used to identify and/or quantify the ecosystem services (e.g. carbon storage, erosion protection) provided by the forest.","Class: 's' ('Sugi' forest), 'h' ('Hinoki' forest), 'd' ('Mixed deciduous' forest), 'o' ('Other' non-forest land)b1 - b9: ASTER image bands containing spectral information in the green, red, and near infrared wavelengths for three dates (Sept. 26, 2010; March 19, 2011; May 08, 2011.pred_minus_obs_S_b1 - pred_minus_obs_S_b9: Predicted spectral values (based on spatial interpolation) minus actual spectral values for the 's' class (b1-b9).pred_minus_obs_H_b1 - pred_minus_obs_H_b9: Predicted spectral values (based on spatial interpolation) minus actual spectral values for the 'h' class (b1-b9).","Johnson, B., Tateishi, R., Xie, Z., 2012. Using geographically-weighted variables for image classification. Remote Sensing Letters, 3 (6), 491-499.","Johnson, B., Tateishi, R., Xie, Z., 2012. Using geographically-weighted variables for image classification. Remote Sensing Letters, 3 (6), 491-499.",
http://archive.ics.uci.edu/ml/datasets/Dexter,300,Dexter Data Set,../machine-learning-databases/dexter/,Multivariate,2600,N/A,Integer,20000,2/29/2008,Classification,N/A,103395,"a.	Original ownersThe original data set we used is a subset of the well-known Reuters text categorization benchmark. The data was originally collected and labeled by Carnegie Group, Inc. and Reuters, Ltd. in the course of developing the CONSTRUE text categorization system.  It is hosted by the UCI KDD repository: http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html. David D. Lewis is hosting valuable resources about this data (see http://www.daviddlewis.com/resources/testcollections/reuters21578/). We used the “corporate acquisition” text classification class pre-processed by Thorsten Joachims <thorsten '@' joachims.org>. The data is one of the examples of the software package SVM-Light., see http://svmlight.joachims.org/. The example can be downloaded from ftp://ftp-ai.cs.uni-dortmund.de/pub/Users/thorsten/svm_light/examples/example1.tar.gz. b.	Donor of databaseThis version of the database was prepared for the NIPS 2003 variable and feature selection benchmark by Isabelle Guyon, 955 Creston Road, Berkeley, CA 94708, USA (isabelle '@' clopinet.com).","The original data were formatted by Thorsten Joachims in the “bag-of-words” representation. There were 9947 features (of which 2562 are always zeros for all the examples) representing frequencies of occurrence of word stems in text. The task is to learn which Reuters articles are about 'corporate acquisitions'. We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. DEXTER -- Positive ex. -- Negative ex. -- Total		   Training set --150 -- 150 -- 300		   Validation set -- 150 -- 150 -- 300		   Test set -- 1000 -- 1000 -- 2000		   All -- 1300 -- 1300 -- 2600		  Number of variables/features/attributes:Real: 9947Probes: 10053Total: 20000 This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link]. All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge. The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link]. The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a sparse matrix, patterns in lines, features in columns: feature number followed by value).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).",We do not provide feature information to avoid biasing feature selection.,"The best challenge entrants wrote papers collected in the book:Isabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer. [Web Link]  See also:Isabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 1438–1444.and the associated technical report:Isabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report. [Web Link].","Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge. In: NIPS. [Web Link].",
http://archive.ics.uci.edu/ml/datasets/Diabetes,301,Diabetes Data Set,../machine-learning-databases/diabetes/,"Multivariate, Time-Series",N/A,Life,"Categorical, Integer",20,N/A,N/A,N/A,490983,"Michael Kahn, MD, PhD, Washington University, St. Louis, MO","Diabetes patient records were obtained from two sources:  an automatic electronic recording device and paper records.  The automatic device had an internal clock to timestamp events, whereas the paper records only provided ""logical time"" slots (breakfast, lunch, dinner, bedtime).  For paper records, fixed times were assigned to breakfast (08:00), lunch (12:00), dinner (18:00), and bedtime (22:00).  Thus paper records have fictitious uniform recording times whereas electronic records have more realistic time stamps. Diabetes files consist of four fields per record.  Each field is separated by a tab and each record is separated by a newline. File Names and format:(1) Date in MM-DD-YYYY format(2) Time in XX:YY format(3) Code(4) Value The Code field is deciphered as follows: 33 = Regular insulin dose34 = NPH insulin dose35 = UltraLente insulin dose48 = Unspecified blood glucose measurement57 = Unspecified blood glucose measurement58 = Pre-breakfast blood glucose measurement59 = Post-breakfast blood glucose measurement60 = Pre-lunch blood glucose measurement61 = Post-lunch blood glucose measurement62 = Pre-supper blood glucose measurement63 = Post-supper blood glucose measurement64 = Pre-snack blood glucose measurement65 = Hypoglycemic symptoms66 = Typical meal ingestion67 = More-than-usual meal ingestion68 = Less-than-usual meal ingestion69 = Typical exercise activity70 = More-than-usual exercise activity71 = Less-than-usual exercise activity72 = Unspecified special event ","Diabetes files consist of four fields per record.  Each field is separated by a tab and each record is separated by a newline. File Names and format:(1) Date in MM-DD-YYYY format(2) Time in XX:YY format(3) Code(4) Value",N/A,"Please refer to the Machine Learning
Repository's citation policy","Prem Melville and Raymond J. Mooney. Diverse ensembles for active learning. ICML. 2004.  [View Context].Jeroen Eggermont and Joost N. Kok and Walter A. Kosters. Genetic Programming for data classification: partitioning the search space. SAC. 2004.  [View Context].Zhi-Hua Zhou and Yuan Jiang. NeC4.5: Neural Ensemble Based C4.5. IEEE Trans. Knowl. Data Eng, 16. 2004.  [View Context].Zhihua Zhang and James T. Kwok and Dit-Yan Yeung. Parametric Distance Metric Learning with Label Information. IJCAI. 2003.  [View Context].Michael L. Raymer and Travis E. Doom and Leslie A. Kuhn and William F. Punch. Knowledge discovery in medical and biological datasets using a hybrid Bayes classifier/evolutionary algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B, 33. 2003.  [View Context].Eibe Frank and Mark Hall. Visualizing Class Probability Estimators. PKDD. 2003.  [View Context].Krzysztof Krawiec. Genetic Programming-based Construction of Features for Machine Learning and Knowledge Discovery Tasks. Institute of Computing Science, Poznan University of Technology. 2002.  [View Context].Ilya Blayvas and Ron Kimmel. Multiresolution Approximation for Classification. CS Dept. Technion. 2002.  [View Context].Peter Sykacek and Stephen J. Roberts. Adaptive Classification by Variational Kalman Filtering. NIPS. 2002.  [View Context].Kristin P. Bennett and Ayhan Demiriz and Richard Maclin. Exploiting unlabeled data in ensemble methods. KDD. 2002.  [View Context].Marina Skurichina and Ludmila Kuncheva and Robert P W Duin. Bagging and Boosting for the Nearest Mean Classifier: Effects of Sample Size on Diversity and Accuracy. Multiple Classifier Systems. 2002.  [View Context].Robert Burbidge and Matthew Trotter and Bernard F. Buxton and Sean B. Holden. STAR - Sparsity through Automated Rejection. IWANN (1). 2001.  [View Context].Jochen Garcke and Michael Griebel and Michael Thess. Data Mining with Sparse Grids. Computing, 67. 2001.  [View Context].Peter L. Hammer and Alexander Kogan and Bruno Simeone and Sandor Szedm'ak. R u t c o r Research R e p o r t. Rutgers Center for Operations Research Rutgers University. 2001.  [View Context].Chris Drummond and Robert C. Holte. Exploiting the Cost (In)sensitivity of Decision Tree Splitting Criteria. ICML. 2000.  [View Context].Mark A. Hall. Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning. ICML. 2000.  [View Context].Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. An Implementation of Logical Analysis of Data. IEEE Trans. Knowl. Data Eng, 12. 2000.  [View Context].Simon Tong and Daphne Koller. Restricted Bayes Optimal Classifiers. AAAI/IAAI. 2000.  [View Context].Marina Skurichina and Robert P W Duin. Boosting in Linear Discriminant Analysis. Multiple Classifier Systems. 2000.  [View Context].Iñaki Inza and Pedro Larrañaga and Basilio Sierra and Ramon Etxeberria and Jose Antonio Lozano and Jos Manuel Peña. Representing the behaviour of supervised classification learning algorithms by Bayesian networks. Pattern Recognition Letters, 20. 1999.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Stavros J. Perantonis and Vassilis Virvilis. Input Feature Extraction for Multilayered Perceptrons Using Supervised Principal Component Analysis. Neural Processing Letters, 10. 1999.  [View Context].Art B. Owen. Tubular neighbors for regression and classification. Stanford University. 1999.  [View Context].Wojciech Kwedlo and Marek Kretowski. Discovery of Decision Rules from Databases: An Evolutionary Approach. PKDD. 1998.  [View Context].Thomas G. Dietterich. Approximate Statistical Test For Comparing Supervised Classification Learning Algorithms. Neural Computation, 10. 1998.  [View Context].Huan Liu and Rudy Setiono. Feature Transformation and Multivariate Decision Tree Induction. Discovery Science. 1998.  [View Context].Jan C. Bioch and D. Meer and Rob Potharst. Bivariate Decision Trees. PKDD. 1997.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. A Parametric Optimization Method for Machine Learning. INFORMS Journal on Computing, 9. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Jennifer A. Blue and Kristin P. Bennett. Hybrid Extreme Point Tabu Search. Department of Mathematical Sciences Rensselaer Polytechnic Institute. 1996.  [View Context].Peter D. Turney. Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm. CoRR, csAI/9503102. 1995.  [View Context].Lena Kallin. Receiver operating characteristic (ROC) analysis Evaluating discriminance effects among decision support systems. Contents 1 The Theory of Receiver Operating Characteristic Curves 5.  [View Context].Rong-En Fan and P. -H Chen and C. -J Lin. Working Set Selection Using the Second Order Information for Training SVM. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Lawrence O. Hall and Nitesh V. Chawla and Kevin W. Bowyer. Combining Decision Trees Learned in Parallel. Department of Computer Science and Engineering, ENB 118 University of South Florida.  [View Context].Ahmed Hussain Khan and Intensive Care. Multiplier-Free Feedforward Networks. 174.  [View Context].Andrew Watkins and Jon Timmis and Lois C. Boggess. Artificial Immune Recognition System (AIRS): An ImmuneInspired Supervised Learning Algorithm. (abw5,jt6@kent.ac.uk) Computing Laboratory, University of Kent.  [View Context].Adil M. Bagirov and John Yearwood. A new nonsmooth optimization algorithm for clustering. Centre for Informatics and Applied Optimization, School of Information Technology and Mathematical Sciences, University of Ballarat.  [View Context].Stefan R uping. A Simple Method For Estimating Conditional Probabilities For SVMs. CS Department, AI Unit Dortmund University.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Rudy Setiono and Huan Liu. Neural-Network Feature Selector. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context].Michael Lindenbaum and Shaul Markovitch and Dmitry Rusakov. Selective Sampling Using Random Field Modelling.  [View Context].Prem Melville and Raymond J. Mooney. Proceedings of the 21st International Conference on Machine Learning. Department of Computer Sciences.  [View Context].Fran ois Poulet. Cooperation between automatic algorithms, interactive algorithms and visualization tools for Visual Data Mining. ESIEA Recherche.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].Liping Wei and Russ B. Altman. An Automated System for Generating Comparative Disease Profiles and Making Diagnoses. Section on Medical Informatics Stanford University School of Medicine, MSOB X215.  [View Context].Ilya Blayvas and Ron Kimmel. INVITED PAPER Special Issue on Multiresolution Analysis Machine Learning via Multiresolution Approximation.  [View Context].YongSeog Kim and W. Nick Street and Filippo Menczer. Optimal Ensemble Construction via Meta-Evolutionary Ensembles. Business Information Systems, Utah State University.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. THE SEPARABILITY OF SPLIT VALUE CRITERION. Department of Computer Methods, Nicolaus Copernicus University.  [View Context].Ilya Blayvas and Ron Kimmel. Efficient Classification via Multiresolution Training Set Approximation. CS Dept. Technion.  [View Context].Hussein A. Abbass. Pareto Neuro-Evolution: Constructing Ensemble of Neural Networks Using Multi-objective Optimization. Artificial Life and Adaptive Robotics (A.L.A.R.) Lab, School of Information Technology and Electrical Engineering, Australian Defence Force Academy.  [View Context].Matthias Scherf and W. Brauer. Feature Selection by Means of a Feature Weighting Approach. GSF - National Research Center for Environment and Health.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/E.+Coli+Genes,302,E. Coli Genes Data Set,../machine-learning-databases/ecoli-mld/,Relational,N/A,Life,N/A,N/A,7/14/2001,N/A,Yes,48095,"Original Owner and Donor:   Ross D. King  Department of Computer Science,   University of Wales Aberystwyth,   SY23 3DB, Wales rdk '@' aber.ac.uk http://users.aber.ac.uk/rdk ","The data was collected from several sources, including GenProtEC ([Web Link]) and SWISSPROT ([Web Link]). Structure prediction was made by PROF ([Web Link]). Homology search was provided by PSI-BLAST ([Web Link]).  The data is in Datalog format. Missing values are not explicit, but some genes have more relationships than others.  E. coli genes (ORFs) are related to each other by the predicate ecoli_to_ecoli(EcoliNumber,E-value,Psi-blast_iteration). They are related to other (SWISSPROT) proteins by the predicate e_val(AccNo,E-value). All the data for a single gene (ORF) is enclosed between delimiters of the form:  begin(model(EcoliNumber)).end(model(EcoliNumber)).  The gene functional classes are in a hierarchy. See [Web Link] (note: the classes may have changed since original data collection).  There are two datalog files: ecoli_data.pl and ecoli_functions.pl  1. ecoli_functions.pl Lists classes and ORF functions. Lines are of the following form:     class(5,1,1,'Colicin-related functions').   class(5,1,'Laterally acquirred elements').   class(5,'Extrachromosomal').  Arguments are up to 3 numbers (describing class at up to 3 different levels), followed by a string class description. For example:     function(ecoli210,7,0,0,'b0217','putative aminopeptidase'). Arguments are ORF number, exactly 3 class numbers, gene name (or blattner number if no gene name), ORF description.  2. ecoli_data.pl Data for each ORF (gene) is delimited by     begin(model(ecoliX)).   end(model(ecoliX)). where X is the ORF number. Other predicates are as follows (examples):    ecoli_orf(ecoliX).    % X is ORF number   ecoli_mol_wt(176624.1).  % float   ecoli_theo_pI(5.81).     %float   ecoli_atomic_comp(c,7940).   % {c,h,n,o,s} , int   ecoli_aliphatic_index(69.57). % float   ecoli_hydro(-0.549).          % float   sec_struc(1,c,2).           % int (start), {a,b,c}, int (length)   sec_struc_coil(1,2).        % int (start), int (length)   sec_struc_beta(1,5).        % int (start), int (length)   sec_struc_alpha(1,7).       % int (start), int (length)   sequence_length(255).       % int   amino_acid_ratio(a,8.9).    % amino_acid_char, float   amino_acids(ecoli3013,a,70). % ORF_num, amino_acid_char, int   amino_acid_pair_ratio(a,a,9.0). % amino_acid_char, amino_acid_char, float   amino_acid_pairs(a,a,7).    % amino_acid_char, amino_acid_char, int   ecoli_to_ecoli(1170,1.0e-105,5).  % ORF_num, double (e-value), int (iteration)    e_val(o42893,2.0e-99).  % accession_number, double (e-value)   psi_iter(o42893,5).     % accession_number, int (iteration)   species(p52494,'candida_albicans__yeast_').  % accession_number, string   mol_wt(p52494,104022). % accession_number, int    classification(p52494,candida).  % accession_number, name   keyword(p25195,'plasmid').   % accession_number, string ",N/A,"King, R. and Karwath, A. and Clare, A. and Dehaspe, L. (2001). The Utility of Different Representations of Protein Sequence for Predicting Functional Class, Bioinformatics, 17(5), pages 445--454. [Web Link]","Usage Restrictions:Copyright 2000 by R. D. King, A. Karwath, A. Clare, L. Dehaspe  There are no restrictions data usage. This data is provided ""as is"" and without any express or implied warranties, including, without limitation, the implied warranties of merchantibility and fitness for a particular purpose.  Citation Requests:Please cite King et al. (2000).  Acknowledgements:This work was supported by the following grants: G78/6609, BIF08765, GR/L62849 and by PharmaDM, Ambachtenlaan, 54/D, B-3001 Leuven, Belgium ","Aik Choon Tan and David Gilbert. An Empirical Comparison of Supervised Machine Learning Techniques in Bioinformatics. APBC. 2003.  [View Context].Mukund Deshpande and George Karypis. Evaluation of Techniques for Classifying Biological Sequences. PAKDD. 2002.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Paul Horton and Kenta Nakai. Better Prediction of Protein Cellular Localization Sites with the it k Nearest Neighbors Classifier. ISMB. 1997.  [View Context].Andrew Watkins and Jon Timmis and Lois C. Boggess. Artificial Immune Recognition System (AIRS): An ImmuneInspired Supervised Learning Algorithm. (abw5,jt6@kent.ac.uk) Computing Laboratory, University of Kent.  [View Context].Gaurav Marwah and Lois C. Boggess. Artificial Immune Systems for Classification : Some Issues. Department of Computer Science Mississippi State University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/SPECTF+Heart,303,SPECTF Heart Data Set,../machine-learning-databases/spect/,Multivariate,267,Life,Integer,44,10/1/2001,Classification,No,93748,"Original owners:  1. Krzysztof J. Cios, Lukasz A. KurganUniversity of Colorado at Denver, Denver, CO 80217, U.S.A.Krys.Cios '@' cudenver.edu  2. Lucy S. GoodendayMedical College of Ohio, OH, U.S.A. Donors:  Lukasz A.Kurgan, Krzysztof J. Cios","The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 77.0% accurate (as compared with cardilogists' diagnoses).  SPECTF is a good data set for testing ML algorithms; it has 267 instances that are descibed by 45 attributes. Predicted attribute: OVERALL_DIAGNOSIS (binary)  NOTE: See the SPECT heart data for binary data for the same classification task.","   1.   OVERALL_DIAGNOSIS: 0,1 (class attribute, binary)   2.   F1R:   continuous (count in ROI (region of interest) 1 in rest)   3.   F1S:   continuous (count in ROI 1 in stress)   4.   F2R:   continuous (count in ROI 2 in rest)   5.   F2S:   continuous (count in ROI 2 in stress)   6.   F3R:   continuous (count in ROI 3 in rest)   7.   F3S:   continuous (count in ROI 3 in stress)   8.   F4R:   continuous (count in ROI 4 in rest)   9.   F4S:   continuous (count in ROI 4 in stress)   10.  F5R:   continuous (count in ROI 5 in rest)   11.  F5S:   continuous (count in ROI 5 in stress)   12.  F6R:   continuous (count in ROI 6 in rest)   13.  F6S:   continuous (count in ROI 6 in stress)   14.  F7R:   continuous (count in ROI 7 in rest)   15.  F7S:   continuous (count in ROI 7 in stress)   16.  F8R:   continuous (count in ROI 8 in rest)   17.  F8S:   continuous (count in ROI 8 in stress)   18.  F9R:   continuous (count in ROI 9 in rest)   19.  F9S:   continuous (count in ROI 9 in stress)   20.  F10R:  continuous (count in ROI 10 in rest)   21.  F10S:  continuous (count in ROI 10 in stress)   22.  F11R:  continuous (count in ROI 11 in rest)   23.  F11S:  continuous (count in ROI 11 in stress)   24.  F12R:  continuous (count in ROI 12 in rest)   25.  F12S:  continuous (count in ROI 12 in stress)   26.  F13R:  continuous (count in ROI 13 in rest)   27.  F13S:  continuous (count in ROI 13 in stress)   28.  F14R:  continuous (count in ROI 14 in rest)   29.  F14S:  continuous (count in ROI 14 in stress)   30.  F15R:  continuous (count in ROI 15 in rest)   31.  F15S:  continuous (count in ROI 15 in stress)   32.  F16R:  continuous (count in ROI 16 in rest)   33.  F16S:  continuous (count in ROI 16 in stress)   34.  F17R:  continuous (count in ROI 17 in rest)   35.  F17S:  continuous (count in ROI 17 in stress)   36.  F18R:  continuous (count in ROI 18 in rest)   37.  F18S:  continuous (count in ROI 18 in stress)   38.  F19R:  continuous (count in ROI 19 in rest)   39.  F19S:  continuous (count in ROI 19 in stress)   40.  F20R:  continuous (count in ROI 20 in rest)   41.  F20S:  continuous (count in ROI 20 in stress)   42.  F21R:  continuous (count in ROI 21 in rest)   43.  F21S:  continuous (count in ROI 21 in stress)   44.  F22R:  continuous (count in ROI 22 in rest)   45.  F22S:  continuous (count in ROI 22 in stress)   - all continuous attributes have integer values from the 0 to 100   - dataset is divided into:	-- training data (""SPECTF.train"" 80 instances)	-- testing data (""SPECTF.test"" 187 instances)","Kurgan, L.A., Cios, K.J., Tadeusiewicz, R., Ogiela, M. & Goodenday, L.S. ""Knowledge Discovery Approach to Automated Cardiac SPECT Diagnosis"" Artificial Intelligence in Medicine, vol. 23:2, pp 149-169, Oct 2001[Web Link]  Cios, K.J., Wedding, D.K. & Liu, N. CLIP3: cover learning using integer programming. Kybernetes, 26:4-5, pp 513-536, 1997 Cios K. J. & Kurgan L. Hybrid Inductive Machine Learning: An Overview of CLIP Algorithms,  In: Jain L.C., and Kacprzyk J. (Eds). New Learning Paradigms in Soft Computing, Physica-Verlag (Springer), 2001[Web Link]","Please refer to the Machine Learning
Repository's citation policy",Carlotta Domeniconi and Bojun Yan. Nearest Neighbor Ensemble. ICPR (1). 2004.  [View Context].
http://archive.ics.uci.edu/ml/datasets/LSVT+Voice+Rehabilitation,304,LSVT Voice Rehabilitation Data Set,../machine-learning-databases/00282/,Multivariate,126,Life,Real,309,2/19/2014,Classification,N/A,34377,The dataset was created by Athanasios Tsanas (tsanasthanasis '@' gmail.com) of the University of Oxford.,"The original paper demonstrated that it is possible to correctly replicate the experts' binary assessment with approximately 90% accuracy using both 10-fold cross-validation and leave-one-subject-out validation. We experimented with both random forests and support vector machines, using standard approaches for optimizing the SVM's hyperparameters. It will be interesting if researchers can improve on this finding using advanced machine learning tools. Details for the dataset can be found on the following paper.A. Tsanas, M.A. Little, C. Fox, L.O. Ramig: â€œObjective automatic assessment of rehabilitative speech treatment in Parkinsonâ€™s diseaseâ€, IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014 A freely available preprint is availabe from the first author's website.","Each attribute (feature) corresponds to the application of a speech signal processing algorithm which aims to characterise objectively the signal. These algorithms include standard perturbation analysis methods, wavelet-based features, fundamental frequency-based features, and tools used to mine nonlinear time-series. Because of the extensive number of attributes we refer the interested readers to the relevant papers for further details.","The dataset was introduced in:A. Tsanas, M.A. Little, C. Fox, L.O. Ramig: â€œObjective automatic assessment of rehabilitative speech treatment in Parkinsonâ€™s diseaseâ€, IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014  Further details about the speech signal processing algorithms can be found in: A. Tsanas, Accurate telemonitoring of Parkinsonâ€™s disease symptom severity using nonlinear speech signal processing and statistical machine learning, D.Phil. (Ph.D.) thesis, University of Oxford, UK, 2012 A. Tsanas, M.A. Little, P.E. McSharry, L.O. Ramig: â€œNonlinear speech analysis algorithms mapped to a standard metric achieve clinically useful quantification of average Parkinsonâ€™s disease symptom severityâ€, Journal of the Royal Society Interface, Vol. 8, pp. 842-855, 2011  A. Tsanas, M.A. Little, P.E. McSharry, L.O. Ramig: â€œNew nonlinear markers and insights into speech signal degradation for effective tracking of Parkinsonâ€™s disease symptom severityâ€, International Symposium on Nonlinear Theory and its Applications (NOLTA), pp. 457-460, Krakow, Poland, 5-8 September 2010   Preprints are available on the first author's website.","If you use this dataset, please cite the following paper:A. Tsanas, M.A. Little, C. Fox, L.O. Ramig: â€œObjective automatic assessment of rehabilitative speech treatment in Parkinsonâ€™s diseaseâ€, IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014",
http://archive.ics.uci.edu/ml/datasets/Student+Academics+Performance,305,Student Academics Performance Data Set,../machine-learning-databases/00467/,Multivariate,300,Computer,N/A,22,9/16/2018,Classification,N/A,64126,"Dr Sadiq Hussain, Dibrugarh University, Dibrugarh, Assam, India, sadiq '@' dibru.ac.in",Student Academic Performance Dataset,"@ATTRIBUTE ge  {M,F}@ATTRIBUTE cst {G,ST,SC,OBC,MOBC}@ATTRIBUTE tnp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE twp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE iap {Best,Vg,Good,Pass,Fail}@ATTRIBUTE esp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE arr {Y,N}@ATTRIBUTE ms  {Married,Unmarried}@ATTRIBUTE ls  {T,V}@ATTRIBUTE as  {Free,Paid}@ATTRIBUTE fmi {Vh,High,Am,Medium,Low}@ATTRIBUTE fs  {Large,Average,Small}@ATTRIBUTE fq  {Il,Um,10,12,Degree,Pg}@ATTRIBUTE mq  {Il,Um,10,12,Degree,Pg}@ATTRIBUTE fo  {Service,Business,Retired,Farmer,Others}@ATTRIBUTE mo  {Service,Business,Retired,Housewife,Others}@ATTRIBUTE nf  {Large,Average,Small}@ATTRIBUTE sh  {Good,Average,Poor}@ATTRIBUTE ss  {Govt,Private}@ATTRIBUTE me  {Eng,Asm,Hin,Ben}@ATTRIBUTE tt  {Large,Average,Small}@ATTRIBUTE atd {Good,Average,Poor}","Hussain S, Dahan N.A, Ba-Alwi F.M, Ribata N. Educational Data Mining and Analysis of Studentsâ€™ Academic Performance Using WEKA. Indonesian Journal of Electrical Engineering and Computer Science. 2018; Vol. 9, No. 2. February. pp. 447~459","Hussain S, Dahan N.A, Ba-Alwi F.M, Ribata N. Educational Data Mining and Analysis of Studentsâ€™ Academic Performance Using WEKA. Indonesian Journal of Electrical Engineering and Computer Science. 2018; Vol. 9, No. 2. February. pp. 447~459",
http://archive.ics.uci.edu/ml/datasets/2.4+GHZ+Indoor+Channel+Measurements,306,2.4 GHZ Indoor Channel Measurements Data Set,../machine-learning-databases/00480/,Multivariate,7840,Computer,Real,5,11/30/2018,Classification,N/A,57409,"Mohamed AlHajri, Massachusetts Institute of Technology, malhajri '@' mit.edu Nazar Ali, Khalifa University, nazar.ali '@' ku.ac.ae Raed Shubair, Massachusetts Institute of Technology, rshubair '@' mit.edu","Abstract: The frequency domain measurement of the scattering parameter, S21, of the wireless channel was carried out using the ZVB14 Vector Network Analyzer (VNA) from Rhode and Schwartz. The measurement system consists of the VNA, low loss RF cables, and omnidirectional antennas at the transmitter and receiver ends. The transmitter and receiver heights were fixed at 1.5 m. A program script was written for the VNA to measure 10 consecutive sweeps: each sweep contains 601 frequency sample points with spacing of 0.167 MHz to cover a 100 MHz band centered at 2.4 GHz. The settings provided a high time-domain resolution of 10 nsec (inverse of the bandwidth) and a time span of (0.167 MHz) = 5.99 Î¼sec . The measurements were designed to examine the WiFi bands specifically, channels 1, 6, and 11 in the IEEE 802.11 standard. The frequency domain channel measurements were conducted at Khalifa University campus in Sharjah, UAE. The measurements were done in 4 different locations:1- Lab139 (highly cluttered)2- Corridor_rm155 (medium cluttered) [with wall from one side and windows from the   other side].3- Main_Lobby (low cluttered)4- Sports_Hall (open space). Instructions: ---------------------------------------------------------------------------------------------------------------Details of the dataset:The frequency domain measurement of the scattering parameter, S21, of the wireless channel was carried out using the ZVB14 Vector Network Analyzer (VNA) from Rhode and Schwartz. The measurement system consists of the VNA, low loss RF cables, and omnidirectional antennas at the transmitter and receiver ends. The transmitter and receiver heights were fixed at 1.5 m. A program script was written for the VNA to measure 10 consecutive sweeps: each sweep contains 601 frequency sample points with spacing of 0.167 MHz to cover a 100 MHz band centered at 2.4 GHz. The settings provided a high time-domain resolution of 10 nsec (inverse of the bandwidth) and a time span of (0.167 MHz) = 5.99Î¼sec . The measurements were designed to examine the WiFi bands specifically, channels 1, 6, and 11 in the IEEE 802.11 standard. The frequency domain channel measurements were conducted at Khalifa University campus in Sharjah, UAE. The measurements were done in 4 different locations:1- Lab139 (highly cluttered) 2- Corridor_rm155 (medium cluttered) [with wall from one side and windows from the other side].3- Main_Lobby (low cluttered) 4- Sports_Hall (open space).  The layout of the floor plan is shown in Floor_Plan.pdf where the red circle represents the transmitter and the green circle represent the receiver location. The square area was divided into uniform grids with a spacing of one wavelength (12.5 cm) that resulted in a total number of 196 points to capture the small-scale variations. The database was measured under a stationary scenario where there were no movements around the Tx/Rx at the time of measurements. This is achieved since the survey is conducted during low-activity time. This gives a total of 1960 samples because each point has 10 measurements.  In the case of Lab139 there is one set of measurements where the furthest point between the Tx/Rx is 7.1m and then the  receiver will moved across the uniform grid. This gives a total of 1960 points. In the case of Corridor_rm155 there are three set of measurements where the furthest point between Tx/Rx is 7.1m and this gives a total of 1960 points. In the case of Main_Lobby there are three set of measurements where the furthest point between Tx/Rx is 7.1m  and this gives a total of 1960 points. In the case of Sport_Hall there is one set of measurements where the furthest point between the Tx/Rx is 7.1m and this gives a total of 1960 points. filename format (environment_Tx/Rx(separation)) i.e Corridor_rm155_7.1 : The environment is a narrow corridor with walls from one side and window from the other side and the Tx/Rx maximum separation is 7.1m and as the receiver is moved across the uniform grid it decreases. Each file will Loc_xxxx and this will resemble the location of the receiver and each location have ten measurements. The flow ofnumbers on the uniform grid is shown in Flow_of_Numbering.pdf---------------------------------------------------------------------------------------------------------------------Questions:Feel free to reach me at my email:malhajri '@' mit.edu mialhajri1 '@' gmail.com ---------------------------------------------------------------------------------------------------------------Citation:If you will use this dataset please cite the following document:1- First paper@inproceedings{alhajri2016classification,  title={Classification of indoor environments based on spatial correlation of rf channel fingerprints},  author={Alhajri, MI and Alsindi, N and Ali, NT and Shubair, RM},  booktitle={Antennas and Propagation (APSURSI), 2016 IEEE International Symposium on},  pages={1447--1448},  year={2016},}2- Second paper@article{alhajri2018classification,  title={Classification of Indoor Environments for IoT Applications: A Machine Learning Approach},  author={AlHajri, Mohamed Ibrahim and Ali, Nazar T and Shubair, Raed M},  journal={IEEE Antennas and Wireless Propagation Letters},  year={2018},  publisher={IEEE}} ","This dataset have 5 attributes:1- Frequency2- Real part of S11 parameter3- Imaginary part of S11 parameter4- Real part of S21 parameter5- Imaginary part of S21 parameter","Salahat, Ehab, Ahmed Kulaib, Nazar Ali, and Raed Shubair. 'Investigation of wireless channel asymmetry in indoor environments.' arXiv preprint [Web Link] (2017).AlHajri, Mohamed Ibrahim, Nazar T. Ali, and Raed M. Shubair. 'Classification of Indoor Environments for IoT Applications: A Machine Learning Approach.' IEEE Antennas and Wireless Propagation Letters (2018).Salahat, Ehab, Ahmed Kulaib, Nazar Ali, and Raed Shubair. 'Exploring symmetry in wireless propagation channels.' In Networks and Communications (EuCNC), 2017 European Conference on, pp. 1-6. IEEE, 2017.Sattarian, Mahbubeh, Javad Rezazadeh, Reza Farahbakhsh, and Alireza Bagheri. 'Indoor navigation systems based on data mining techniques in internet of things: a survey.' Wireless Networks (2018): 1-18.","If you will use this dataset please cite the following document:1- First paper@inproceedings{alhajri2016classification,  title={Classification of indoor environments based on spatial correlation of rf channel fingerprints},  author={Alhajri, MI and Alsindi, N and Ali, NT and Shubair, RM},  booktitle={Antennas and Propagation (APSURSI), 2016 IEEE International Symposium on},  pages={1447--1448},  year={2016},}2- Second paper@article{alhajri2018classification,  title={Classification of Indoor Environments for IoT Applications: A Machine Learning Approach},  author={AlHajri, Mohamed Ibrahim and Ali, Nazar T and Shubair, Raed M},  journal={IEEE Antennas and Wireless Propagation Letters},  year={2018},  publisher={IEEE}}",
http://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+,307,Occupancy Detection  Data Set,../machine-learning-databases/00357/,"Multivariate, Time-Series",20560,Computer,Real,7,2/29/2016,Classification,N/A,141182,"Luis Candanedo, luismiguel.candanedoibarra '@' umons.ac.be, UMONS.","Three data sets are submitted, for training and testing. Ground-truth occupancy was obtained from time stamped pictures that were taken every minute.For the journal publication, the processing R scripts can be found in:[Web Link] ","date time year-month-day hour:minute:secondTemperature, in CelsiusRelative Humidity, %Light, in Lux CO2, in ppmHumidity Ratio, Derived quantity from temperature and relative humidity, in kgwater-vapor/kg-airOccupancy, 0 or 1, 0 for not occupied, 1 for occupied status","Accurate occupancy detection of an office room from light, temperature, humidity and CO2 measurements using statistical learning models. Luis M. Candanedo, VÃ©ronique Feldheim. Energy and Buildings. Volume 112, 15 January 2016, Pages 28-39.","Please cite the following publication:Accurate occupancy detection of an office room from light, temperature, humidity and CO2 measurements using statistical learning models. Luis M. Candanedo, VÃ©ronique Feldheim. Energy and Buildings. Volume 112, 15 January 2016, Pages 28-39.",
http://archive.ics.uci.edu/ml/datasets/Wine+Quality,308,Wine Quality Data Set,../machine-learning-databases/wine-quality/,Multivariate,4898,Business,Real,12,10/7/2009,"Classification, Regression",N/A,1267393,"Paulo Cortez, University of Minho, Guimarães, Portugal, http://www3.dsi.uminho.pt/pcortez A. Cerdeira, F. Almeida, T. Matos and J. Reis, Viticulture Commission of the Vinho Verde Region(CVRVV), Porto, Portugal @2009","The two datasets are related to red and white variants of the Portuguese ""Vinho Verde"" wine. For more details, consult: [Web Link] or the reference [Cortez et al., 2009].  Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).These datasets can be viewed as classification or regression tasks.  The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.","For more information, read [Cortez et al., 2009].Input variables (based on physicochemical tests):   1 - fixed acidity   2 - volatile acidity   3 - citric acid   4 - residual sugar   5 - chlorides   6 - free sulfur dioxide   7 - total sulfur dioxide   8 - density   9 - pH   10 - sulphates   11 - alcoholOutput variable (based on sensory data):    12 - quality (score between 0 and 10)","P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties.In Decision Support Systems, Elsevier, 47(4):547-553, 2009. Available at: [Web Link] ","Please include this citation if you plan to use this database: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.",
http://archive.ics.uci.edu/ml/datasets/Solar+Flare,309,Solar Flare Data Set,../machine-learning-databases/solar-flare/,Multivariate,1389,Physical,Categorical,10,3/1/1989,Regression,No,149151,"Donor:  Gary Bradshaw <gbradshaw '@' clipr.colorado.EDU>","Notes:    -- The database contains 3 potential classes, one for the number of times a certain type of solar flare occured in a 24 hour period.   -- Each instance represents captured features for 1 active region on the sun.   -- The data are divided into two sections. The second section (flare.data2) has had much more error correction applied to the it, and has consequently been treated as more reliable.","   1. Code for class (modified Zurich class)  (A,B,C,D,E,F,H)   2. Code for largest spot size              (X,R,S,A,H,K)   3. Code for spot distribution              (X,O,I,C)   4. Activity                                (1 = reduced, 2 = unchanged)   5. Evolution                               (1 = decay, 2 = no growth, 3 = growth)   6. Previous 24 hour flare activity code    (1 = nothing as big as an M1, 2 = one M1, 3 = more activity than one M1)   7. Historically-complex                    (1 = Yes, 2 = No)   8. Did region become historically complex  on this pass across the sun's disk (1 = yes, 2 = no)    9. Area                                    (1 = small, 2 = large)  10. Area of the largest spot                (1 = <=5, 2 = >5)  From all these predictors three classes of flares are predicted, which are represented in the last three columns.   11. C-class flares production by this region in the following 24 hours (common flares); Number  12. M-class flares production by this region in the following 24 hours (moderate flares);   Number  13. X-class flares production by this region in the following 24 hours (severe flares); Number ",N/A,"Please refer to the Machine Learning
Repository's citation policy","Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. DeEPs: A New Instance-based Discovery and Classification System. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001.  [View Context].Nir Friedman and Daphne Koller. Being Bayesian about Network Structure. UAI. 2000.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao. Instance-Based Classification by Emerging Patterns. PKDD. 2000.  [View Context].Sally A. Goldman and Yan Zhou. Enhancing Supervised Learning with Unlabeled Data. ICML. 2000.  [View Context].Christophe G. Giraud-Carrier and Tony R. Martinez. An Integrated Framework for Learning and Reasoning. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Nir Friedman and Daphne Koller (koller@cs. stanford. edu. A Bayesian Approach to Structure Discovery in Bayesian Networks. School of Computer Science & Engineering Hebrew University.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Page+Blocks+Classification,310,Page Blocks Classification Data Set,../machine-learning-databases/page-blocks/,Multivariate,5473,Computer,"Integer, Real",10,7/1/1995,Classification,No,97928,"Original Owner: Donato MalerbaDipartimento di InformaticaUniversity of Barivia Orabona 470126 Bari - Italyphone: +39 - 80 - 5443269fax: +39 - 80 - 5443196malerbad '@' vm.csata.it  Donor:  Donato Malerba",The 5473 examples comes from 54 distinct documents. Each observation concerns one block. All attributes are numeric. Data are in a format readable by C4.5.,"   height:   integer.         | Height of the block.   lenght:   integer.     | Length of the block.    area:     integer.    | Area of the block (height * lenght);   eccen:    continuous.  | Eccentricity of the block (lenght / height);   p_black:  continuous.  | Percentage of black pixels within the block (blackpix / area);   p_and:    continuous.        | Percentage of black pixels after the application of the Run Length Smoothing Algorithm (RLSA) (blackand / area);   mean_tr:  continuous.      | Mean number of white-black transitions (blackpix / wb_trans);   blackpix: integer.    | Total number of black pixels in the original bitmap of the block.   blackand: integer.        | Total number of black pixels in the bitmap of the block after the RLSA.   wb_trans: integer.          | Number of white-black transitions in the original bitmap of the block.","Malerba, D., Esposito, F., and Semeraro, G. ""A Further Comparison of Simplification Methods for Decision-Tree Induction."" In D. Fisher and H. Lenz (Eds.), ""Learning  from Data: Artificial Intelligence and Statistics V"", Lecture Notes in Statistics, Springer Verlag, Berlin, 1995.[Web Link]  Esposito F., Malerba D., & Semeraro G. Multistrategy Learning for Document Recognition. Applied Artificial Intelligence, 8, pp. 33-84, 1994[Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Steven Eschrich and Nitesh V. Chawla and Lawrence O. Hall. Generalization Methods in Bioinformatics. BIOKDD. 2002.  [View Context].Adil M. Bagirov and Julien Ugon. An algorithm for computation of piecewise linear function separating two sets. CIAO, School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Geographical+Original+of+Music,311,Geographical Original of Music Data Set,../machine-learning-databases/00315/,Multivariate,1059,N/A,Real,68,10/18/2014,"Classification, Regression",N/A,86578,"Creators:Fang Zhou (fang.zhou '@' nottingham.edu.cn)The University of Nottinghan, Ningbo, China Donors of the Dataset:Fang Zhou (fang.zhou '@' nottingham.edu.cn)Claire Q (eskoala '@' gmail.com)Ross D. King (ross.king '@' manchester.ac.uk)"," The dataset was built from a personal collection of 1059 tracks covering 33 countries/area. The music used is traditional, ethnic or `world' only, as classified by the publishers of the product on which it appears. Any Western music is not included because its influence is global - what we seek are the aspects of music that most influence location. Thus, being able to specify a location with strong influence on the music is central.  The geographical location of origin was manually collected the information from the CD sleeve notes, and when this information was inadequate we searched other information sources. The location data is limited in precision to the country of origin.   The country of origin was determined by the artist's or artists' main country/area of residence.  Any track that had ambiguous origin is not included.  We have taken the position of each country's capital city (or the province of the area) by latitude and longitude as the absolute point of origin. The program MARSYAS[1] was used to extract audio features from the wave files. We used the default MARSYAS settings in single vector format (68 features) to estimate the performance with basic timbal information covering the entire length of each track. No feature weighting or pre-filtering was applied. All features were transformed to have a mean of 0, and a standard deviation of 1. We also investigated the utility of adding chromatic attributes. These describe the notes of the scale being used. This is especially important as a distinguishing feature in geographical ethnomusicology. The chromatic features provided by MARSYAS are 12 per octave - Western tuning, but it may be possible to tell something from how similar to or different from Western tuning the music is. [1] G. Tzanetakis and P. Cook, â€œMARSYAS: a framework for audio analysis,â€ Organised Sound, vol. 4, pp. 169â€“175, 2000. ","The dataset is present in two files, where each file corresponds to a different feature sets. Both files contain the audio features of 1059 tracks. In the 'default_features_1059_tracks.txt' file, the first 68 columns are audio features of the track, and the last two columns are the origin of the music, represented by latitude and longitude. In the 'default_plus_chromatic_features_1059_tracks.txt' file, the first 116 columns are audio features of the track, and the last two columns are the origin of the music.","The description of music collection and audio features can be found in: Fang Zhou, Claire Q and Ross. D. KingPredicting the Geographical Origin of Music, ICDM, 2014","The following citation is requested if you use the dataset:  Fang Zhou, Claire Q and Ross. D. KingPredicting the Geographical Origin of Music, ICDM, 2014",
http://archive.ics.uci.edu/ml/datasets/Autistic+Spectrum+Disorder+Screening+Data+for+Adolescent+++,312,Autistic Spectrum Disorder Screening Data for Adolescent    Data Set,../machine-learning-databases/00420/,Multivariate,104,Life,Integer,21,12/24/2017,Classification,Yes,30147,"Provide the names, email addresses, institutions, and other contact information of the donors and creators of the data set.",See description file ,See description file ,"1) Tabtah, F. (2017). Autism Spectrum Disorder Screening: Machine Learning Adaptation and DSM-5 Fulfillment. Proceedings of the 1st International Conference on Medical and Health Informatics 2017, pp.1-6. Taichung City, Taiwan, ACM.2) Thabtah, F. (2017). ASDTests. A mobile app for ASD screening. www.asdtests.com [accessed December  20th, 2017].3) Thabtah, F. (2017). Machine Learning in Autistic Spectrum Disorder Behavioural Research: A Review. Informatics for Health and Social Care Journal. December, 2017 (in press)","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Horse+Colic,313,Horse Colic Data Set,../machine-learning-databases/horse-colic/,Multivariate,368,Life,"Categorical, Integer, Real",27,8/6/1989,Classification,Yes,147494,"Creators:  Mary McLeish & Matt CecileDepartment of Computer ScienceUniversity of GuelphGuelph, Ontario, Canada N1G 2W1mdmcleish '@' water.waterloo.edu  Donor: Will Taylor (taylor '@' pluto.arc.nasa.gov)","2 data files:       -- horse-colic.data: 300 training instances      -- horse-colic.test: 68 test instances Possible class attributes: 24 (whether lesion is surgical)     -- others include: 23, 25, 26, and 27 Many Data types: (continuous, discrete, and nominal)","  1:  surgery?          1 = Yes, it had surgery          2 = It was treated without surgery   2:  Age           1 = Adult horse          2 = Young (< 6 months)   3:  Hospital Number           - numeric id          - the case number assigned to the horse (may not be unique if the horse is treated > 1 time)   4:  rectal temperature          - linear          - in degrees celsius.          - An elevated temp may occur due to infection.          - temperature may be reduced when the animal is in late shock          - normal temp is 37.8          - this parameter will usually change as the problem progresses, eg. may start out normal, then become elevated because of the lesion, passing back through the normal range as the horse goes into shock  5:  pulse           - linear          - the heart rate in beats per minute          - is a reflection of the heart condition: 30 -40 is normal for adults          - rare to have a lower than normal rate although athletic horses may have a rate of 20-25          - animals with painful lesions or suffering from circulatory shock may have an elevated heart rate   6:  respiratory rate          - linear          - normal rate is 8 to 10          - usefulness is doubtful due to the great fluctuations   7:  temperature of extremities          - a subjective indication of peripheral circulation          - possible values:               1 = Normal               2 = Warm               3 = Cool               4 = Cold          - cool to cold extremities indicate possible shock          - hot extremities should correlate with an elevated rectal temp.   8:  peripheral pulse          - subjective          - possible values are:               1 = normal               2 = increased               3 = reduced               4 = absent          - normal or increased p.p. are indicative of adequate circulation while reduced or absent indicate poor perfusion   9:  mucous membranes          - a subjective measurement of colour          - possible values are:               1 = normal pink               2 = bright pink               3 = pale pink               4 = pale cyanotic               5 = bright red / injected               6 = dark cyanotic          - 1 and 2 probably indicate a normal or slightly increased circulation          - 3 may occur in early shock          - 4 and 6 are indicative of serious circulatory compromise          - 5 is more indicative of a septicemia  10: capillary refill time          - a clinical judgement. The longer the refill, the poorer the circulation          - possible values               1 = < 3 seconds               2 = >= 3 seconds  11: pain - a subjective judgement of the horse's pain level          - possible values:               1 = alert, no pain               2 = depressed               3 = intermittent mild pain               4 = intermittent severe pain               5 = continuous severe pain          - should NOT be treated as a ordered or discrete variable!          - In general, the more painful, the more likely it is to require surgery          - prior treatment of pain may mask the pain level to some extent  12: peristalsis                                        - an indication of the activity in the horse's gut. As the gut becomes more distended or the horse becomes more toxic, the activity decreases          - possible values:               1 = hypermotile               2 = normal               3 = hypomotile               4 = absent  13: abdominal distension          - An IMPORTANT parameter.          - possible values               1 = none               2 = slight               3 = moderate               4 = severe          - an animal with abdominal distension is likely to be painful and have reduced gut motility.          - a horse with severe abdominal distension is likely to require surgery just tio relieve the pressure  14: nasogastric tube          - this refers to any gas coming out of the tube          - possible values:               1 = none               2 = slight               3 = significant          - a large gas cap in the stomach is likely to give the horse discomfort  15: nasogastric reflux          - possible values               1 = none               2 = > 1 liter               3 = < 1 liter          - the greater amount of reflux, the more likelihood that there is some serious obstruction to the fluid passage from the rest of the intestine  16: nasogastric reflux PH          - linear          - scale is from 0 to 14 with 7 being neutral          - normal values are in the 3 to 4 range  17: rectal examination - feces          - possible values               1 = normal               2 = increased               3 = decreased               4 = absent          - absent feces probably indicates an obstruction  18: abdomen          - possible values               1 = normal               2 = other               3 = firm feces in the large intestine               4 = distended small intestine               5 = distended large intestine          - 3 is probably an obstruction caused by a mechanical impaction and is normally treated medically          - 4 and 5 indicate a surgical lesion  19: packed cell volume          - linear          - the # of red cells by volume in the blood          - normal range is 30 to 50. The level rises as the circulation becomes compromised or as the animal becomes dehydrated.  20: total protein          - linear          - normal values lie in the 6-7.5 (gms/dL) range          - the higher the value the greater the dehydration  21: abdominocentesis appearance          - a needle is put in the horse's abdomen and fluid is obtained from            the abdominal cavity          - possible values:               1 = clear               2 = cloudy               3 = serosanguinous          - normal fluid is clear while cloudy or serosanguinous indicates a compromised gut  22: abdomcentesis total protein          - linear          - the higher the level of protein the more likely it is to have a compromised gut. Values are in gms/dL  23: outcome          - what eventually happened to the horse?          - possible values:               1 = lived               2 = died               3 = was euthanized  24: surgical lesion?          - retrospectively, was the problem (lesion) surgical?          - all cases are either operated upon or autopsied so that this value and the lesion type are always known          - possible values:               1 = Yes               2 = No  25, 26, 27: type of lesion          - first number is site of lesion               1 = gastric               2 = sm intestine               3 = lg colon               4 = lg colon and cecum               5 = cecum               6 = transverse colon               7 = retum/descending colon               8 = uterus               9 = bladder               11 = all intestinal sites               00 = none          - second number is type               1 = simple               2 = strangulation               3 = inflammation               4 = other          - third number is subtype               1 = mechanical               2 = paralytic               0 = n/a          - fourth number is specific code               1 = obturation               2 = intrinsic               3 = extrinsic               4 = adynamic               5 = volvulus/torsion               6 = intussuption               7 = thromboembolic               8 = hernia               9 = lipoma/slenic incarceration               10 = displacement               0 = n/a 28: cp_data          - is pathology data present for this case?               1 = Yes               2 = No          - this variable is of no significance since pathology data is not included or collected for these cases",N/A,"Please refer to the Machine Learning
Repository's citation policy","Julie Greensmith. New Frontiers For An Artificial Immune System. Digital Media Systems Laboratory HP Laboratories Bristol. 2003.  [View Context].Richard Nock and Marc Sebban and David Bernard. A SIMPLE LOCALLY ADAPTIVE NEAREST NEIGHBOR RULE WITH APPLICATION TO POLLUTION FORECASTING. International Journal of Pattern Recognition and Artificial Intelligence Vol. 2003.  [View Context].Mukund Deshpande and George Karypis. Using conjunction of attribute values for classification. CIKM. 2002.  [View Context].Huan Liu and Hiroshi Motoda and Lei Yu. Feature Selection with Selective Sampling. ICML. 2002.  [View Context].Marc Sebban and Richard Nock and Stéphane Lallich. Stopping Criterion for Boosting-Based Data Reduction Techniques: from Binary to Multiclass Problem. Journal of Machine Learning Research, 3. 2002.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Eibe Frank and Ian H. Witten. Generating Accurate Rule Sets Without Global Optimization. ICML. 1998.  [View Context].Gabor Melli. A Lazy Model-Based Approach to On-Line Classification. University of British Columbia. 1989.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].James J. Liu and James Tin and Yau Kwok. An Extended Genetic Rule Induction Algorithm. Department of Computer Science Wuhan University.  [View Context].H. Altay G uvenir and Aynur Akkus. WEIGHTED K NEAREST NEIGHBOR CLASSIFICATION ON FEATURE PROJECTIONS. Department of Computer Engineering and Information Science Bilkent University.  [View Context].Kai Ming Ting and Ian H. Witten. Stacked Generalization: when does it work. Department of Computer Science University of Waikato.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Motion+Capture+Hand+Postures,314,Motion Capture Hand Postures Data Set,../machine-learning-databases/00405/,Multivariate,78095,Computer,Real,38,1/27/2017,"Classification, Clustering",Yes,29244,"[1] A. Gardner, R. R. Selmic, J. Kanno    Louisiana Tech University andrew.gardner1 '@' ieee.org, rselmic '@' latech.edu, jkanno '@' latech.edu [2] C. A. Duncan    Quinnipiac University christian.duncan '@' quinnipiac.edu","A Vicon motion capture camera system was used to record 12 users performing 5 hand postures with markers attached to a left-handed glove.  A rigid pattern of markers on the back of the glove was used to establish a local coordinate system for the hand, and 11 other markers were attached to the thumb and fingers of the glove. 3 markers were attached to the thumb with one above the thumbnail and the other two on the knuckles. 2 markers were attached to each finger with one above the fingernail and the other on the joint between the proximal and middle phalanx. The 11 markers not part of the rigid pattern were unlabeled; their positions were not explicitly tracked. Consequently, there is no a priori correspondence between the markers of two given records. In addition, due to the resolution of the capture volume and self-occlusion due to the orientation and configuration of the hand and fingers, many records have missing markers. Extraneous markers were also possible due to artifacts in the Vicon software's marker reconstruction/recording process and other objects in the capture volume. As a result, the number of visible markers in a record varied considerably. The data presented here is already partially preprocessed. First, all markers were transformed to the local coordinate system of the record containing them. Second, each transformed marker with a norm greater than 200 millimeters was pruned. Finally, any record that contained fewer than 3 markers was removed. The processed data has at most 12 markers per record and at least 3. For more information, see 'Attribute Information'. Due to the manner in which data was captured, it is likely that for a given record and user there exists a near duplicate record originating from the same user. We recommend therefore to evaluate classification algorithms on a leave-one-user-out basis wherein each user is iteratively left out from training and used as a test set. One then tests the generalization of the algorithm to new users. A 'User' attribute is provided to accomodate this strategy.  This dataset may be used for a variety of tasks, the most obvious of which is posture recognition via classification. One may also attempt user identification. Alternatively, one may perform clustering (constrained or unconstrained) to discover marker distributions either as an attempt to predict marker identities or obtain statistical descriptions/visualizations of the postures. In previous work, we randomly sampled without replacement a constant number (e.g. 75) of records per class per user in order to balance classes. A mirror of the dataset may currently be obtained at [Web Link] by following the Postures link.","Data is provided as a CSV file. A header provides the name of each attribute. An initial dummy record composed entirely of 0s should be ignored. A question mark '?' is used to indicate a missing value. A record corresponds to a single instant or frame as recorded by the camera system. 'Class' - Integer. The class ID of the given record. Ranges from 1 to 5 with 1=Fist(with thumb out), 2=Stop(hand flat), 3=Point1(point with pointer finger), 4=Point2(point with pointer and middle fingers), 5=Grab(fingers curled as if to grab).'User' - Integer. The ID of the user that contributed the record. No meaning other than as an identifier.'Xi' - Real. The x-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Yi' - Real. The y-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Zi' - Real. The z-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11. Each record is a set. The i-th marker of a given record does not necessarily correspond to the i-th marker of a different record. One may randomly permute the visible (i.e. not missing) markers of a given record without changing the set that the record represents. For the sake of convenience, all visible markers of a given record are given a lower index than any missing marker. A class is not guaranteed to have even a single record with all markers visible.","A. Gardner, J. Kanno, C. A. Duncan, and R. Selmic. 'Measuring distance between unordered sets of different sizes,' in 2014 IEEE Conference on Computer Vision and Pattern Recognition(CVPR), June 2014, pp. 137-143.A. Gardner, C. A. Duncan, J. Kanno, and R. Selmic. '3D hand posture recognition from small unlabeled point sets,' in 2014 IEEE International Conference on Systems, Man and Cybernetics (SMC), Oct 2014, pp. 164-169.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Qualitative+Structure+Activity+Relationships,315,Qualitative Structure Activity Relationships Data Set,../machine-learning-databases/qsar/,Domain-Theory,N/A,Physical,N/A,N/A,N/A,N/A,N/A,27106,"Ross D. KingBiomolecular Modelling LaboratoryImperial Cancer Research FundP.O. Box 12344 Lincoln's Inn FieldsLondon WC2A 3PXU.K.+44-71-242-0200 x3023rd_king '@' icrf.ac.uk",N/A,N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+exposed+to+turbulent+gas+mixtures,316,Gas sensor array exposed to turbulent gas mixtures Data Set,../machine-learning-databases/00309/,"Multivariate, Time-Series",180,Computer,Real,150000,10/10/2014,"Classification, Regression",N/A,41327,"Creators: Jordi Fonollosa (fonollosa '@'ucsd.edu) BioCircutis Institute University of California San Diego San Diego, California, USA  Donors of the Dataset: Jordi Fonollosa (fonollosa '@'ucsd.edu) Irene Rodriguez-Lujan (irrodriguezlujan '@' ucsd.edu) Marco Trincavelli (marco.trincavelli '@' oru.se) Alexander Vergara Ramon Huerta (rhuerta '@' ucsd.edu) ","A chemical detection platform composed of 8 chemo-resistive gas sensors was exposed to turbulent gas mixtures generated naturally in a wind tunnel. The acquired time series of the sensors are provided. The experimental setup was designed to test gas sensors in realistic environments. Traditionally, chemical detection systems based on chemo-resistive sensors include a gas chamber to control the sample air flow and minimize turbulence. Instead, we utilized a wind tunnel with two independent gas sources that generate two gas plumes. The plumes get naturally mixed along a turbulent flow and reproduce the gas concentration fluctuations observed in natural environments. Hence, the gas sensors can capture the spatio-temporal information contained in the gas plumes. a) Chemical detection platform:The chemical detection platform was composed of 8 MOX gas sensors that generate a time-dependent multivariate response to the different gas stimuli. The utilized sensors were made commercially available by Figaro (TGS2611, TGS2612, TGS2610, TGS2600, TGS2602 TGS2620). The operating temperature of the sensors was controlled by the built-in heater, which was kept at a constant voltage of 5V. The detection platform also includes Temperature and Relative Humidity sensors. The generated sensors' responses were acquired at a sampling rate of 20 ms for the whole duration of the experiment. b) Wind tunnel:In order to generate two independent gas plumes in an open environment, we built a 2.5 m x 1.2 m x 0.4 m wind tunnel facility with two gas sources (labeled as source1 and source2). Each source was controlled independently to release the selected volatiles at different flow rates, which generated different concentration levels in the sensors' position. The wind generator created a turbulent flow that constantly displaced the introduced volatiles towards the exhaust outlet. c) Experimental protocol:We exposed the detection unit to mixtures of Ethylene with Methane or Carbon Monoxide. The mixtures were originated releasing Ethylene at source1 and releasing Methane / Carbon Monoxide at source2. Each volatile was released at four different flows (zero z, low l, medium m, and high h), providing up to 30 different mixture configurations: 15 mixtures of Ethylene with CO (h+h, h+m, h+l, â€¦, z+h, z+m, z+l) and 15 mixtures of Ethylene with Methane. Each configuration was repeated 6 times. Hence, the complete dataset was composed of 180 measurements, which were performed in a random order.  By means of a GCMS system, the mean concentration levels at the sensors' location were estimated: Ethylene (l: 31 ppm, m: 46 ppm, h: 96 ppm), CO (l: 270 ppm, m: 397 ppm, h: 460 ppm), Methane (l: 51 ppm, m: 115 ppm, h: 131 ppm). It is worth noting that GC-MS systems only provide the mean value of the concentration and are not sensitive to concentration fluctuations. Each measurement, which had a total duration of 300 seconds, was performed as follows: Initially no gas was released and clean air flowed along the wind tunnel. 60 seconds after, both sources started to release the corresponding volatile at the specified flow rate. The duration of the gas release was 180 s. Finally, the system acquired the recovery to the baseline for another 60 s. ","The dataset is presented in 180 text files, where each file corresponds to a different measurement. The filenames identify the measurements as follows: The first 3 characters of the filename are a local identifier, which is not related to the order of the measurements; characters 5-8 indicate the concentration level of Ethylene released at source2 (n: zero, L: Low, M: Medium, H: High); the last 4 characters indicate the gas released at source1 (Me: Methane, CO: Carbon Monoxide) and the concentration level.  For example, file 007_Et_L_Me_H contains time series acquired when Ethylene was released at Low concentration (31 ppm, mean concentration) and Methane at High concentration (131 ppm, mean concentration).  Each file includes the acquired time series, presented in 11 columns: Time (s), Temperature (oC), Relative Humidity (%), and the readings of the 8 gas sensors: TGS2600, TGS2602, TGS2602, TGS2620, TGS2612, TGS2620, TGS2611, TGS2610. The readings can be converted to sensor resistance by Rs(KOhm)=10*(3110-A)/A, where A is the acquired value. The raw acquired time series are provided, and also time series down sampled at 100 ms.","The description of the experimental setup and chemical detection platform can be found in [1].  The wind tunnel was adapted from a previous setup to include two independent gas sources. See [2] for additional details on the experimental setup. [1]: Jordi Fonollosa, Irene RodrÃ­guez-Lujan, Marco Trincavelli, Alexander Vergara and Ramon HuertaChemical discrimination in turbulent gas mixtures with MOX sensors validated by gas chromatography-mass spectrometry. Sensors 2014.  [2]: Vergara, Alexander, Jordi Fonollosa, Jonas Mahiques, Marco Trincavelli, Nikolai Rulkov, and Ramon Huerta. 'On the performance of gas sensor arrays in open sampling systems using Inhibitory Support Vector Machines.' Sensors and Actuators B: Chemical 185 (2013): 462-477.","The following citation is requested if you use the dataset:  Jordi Fonollosa, Irene Rodriguez-Lujan, Marco Trincavelli, Alexander Vergara and Ramon HuertaChemical discrimination in turbulent gas mixtures with MOX sensors validated by gas chromatography-mass spectrometry. Sensors 2014. ",
http://archive.ics.uci.edu/ml/datasets/Mturk+User-Perceived+Clusters+over+Images,317,Mturk User-Perceived Clusters over Images Data Set,../machine-learning-databases/00416/,"Multivariate, Text",180,Computer,Integer,500,11/2/2016,Clustering,N/A,8734,"Shan-Hung WuAssociate Professor, CS, National Tsing Hua University(NTHU) Email: shwu [AT] cs.nthu.edu.tw ","This dataset was collected by Shan-Hung Wu and DataLab members at National Tsing Hua University, Taiwan. It random sampled 180 images from the NUS-WIDE image database.  Each image has 500 features consisting of the bag of words based on SIFT descriptions. With a series of experiments on the Amazon Mechanical Turk platform, there are 325 user-perceived clusters from 100 users and their corresponding descriptions. Dataset spec 1: - #Image: 180 - #Cluster: 325 (may be created by different users)- #User: 100 - |Vocabulary of supervision|: 108  - cluster_data.csv : 325 clusters x 180 images	- 'cluster_data.csv' is an indicator matrix. M_(i,j) = 1 if image_j belongs to cluster_i. Note: Clusters may be created by different users.  - cluster_userIndex.csv : 325 clusters x 1 userIndex(0-99)	- 'cluster_userIndex.csv' is an vector where V_i = k if cluster_i is grouped by user_k. - data_feature.csv : 180 images x 500 features	- Each row is 500 features vector consisting of the bag of words based on SIFT descriptions. All 180 images are sampled from NUS-WIDE dataset.	- Reference: [Web Link]  - supervision_cluster_matrix.csv : 108 bag of words x 183 clusters	- We parse the raw supervisions and merge similar words into 108 dimensions. Each row is a description of corresponding cluster. - perception_words.csv : 108 perception words	- Vocabulary of perception words .      Dataset spec 2(Raw data): - cluster_list.csv:	-FileName: ['UserId'], ['ImageId Cluster'], ['Description']	-['UserId']: Specify the user who created the cluster.	-['ImageId Cluster']: Image ids in the cluster which are separated by ';'.	-['Description']: A sentence or some keywords describe the images in the cluster by user.	- 325 records(clusters) in total.		",As the above.,"Learning User Perceived Clusters with Feature-Level SupervisionTing-Yu Cheng, ; Kuan-Hua Lin, ; Xinyang Gong, Baidu Inc.; Kang-Jun Liu, ; Shan-Hung Wu*, National Tsing Hua University","Please include this citation if you use this dataset. Learning User Perceived Clusters with Feature-Level SupervisionTing-Yu Cheng, ; Kuan-Hua Lin, ; Xinyang Gong, Baidu Inc.; Kang-Jun Liu, ; Shan-Hung Wu*, National Tsing Hua University",
http://archive.ics.uci.edu/ml/datasets/Pioneer-1+Mobile+Robot+Data,318,Pioneer-1 Mobile Robot Data Data Set,../machine-learning-databases/pioneer-mld/,"Multivariate, Time-Series",N/A,Computer,"Categorical, Real",N/A,1/28/1999,N/A,N/A,39123,"Matthew D. Schmill, Paul R. CohenExperimental Knowledge Systems Laboratory Department of Computer Science Box 34610 University of Massachusetts, Amherst Amherst, MA 01003-4610 schmill '@' cs.umass.edu, cohen '@' cs.umass.edu","The data were collected over a series of specifically designed trials. Our hope was to cover most of the types of sensory interactions that a Pioneer might be reasonably expected to encounter: things like passing by visible objects, pushing visible objects, crashing into walls, etc. Many of these interactions are repeated throughout the dataset. This data was collected to serve as the basis for work in learning and conceptual development. Our first goal was to be able to have the robot cluster these experiences by their dynamics on their own into clusters of experiences with a common outcome. Each data file contains time series data in which each row of data corresponds to a single observation of the sensor array. Included in each row are two additional variables, 'id' and 'description', which indicate the experience number that the observation belongs to, and a description of that experience, respectively. Observations within an experience are taken every 100ms.  The data is stored in three text files: one file for experiences in which the Pioneer was moving in a straight line, one in which it was turning in place, and one in which it was raising or lowering its gripper. The description variable is a string of symbols. The string breaks down as follows: ""u"" or ""o"" -  unobstructed or obstructed""x.xs""     -  activity lasted x.x secondsactivity   -  the activity and speed, if applicable, i.e. move100 = move forward at 100mm/secvisual     -  objects in the visual array are listed in sequence. ""cAHEAD"" indicates an object visible to channel c directly AHEAD of the Pioneer.[visual.X] -  visual descriptions followed by a '.' and one character indicate that something special happens with the visible object. .V means the object Vanishes from sight during the activity. .D indicates that the object is Discovered (becomes visible) during the activity. .P indicates that the object is pushed.  An example: ""u-3.5s-retr-100-aRIGHT.D""  An unobstructed retreat (move) at -100 mm/sec for 3.5 seconds with an object being discovered in channel A. It should be noted that, particularly with respect to the visual channels, the description may not be 100% accurate. Since the visual channels respond to colors that they are trained on (visual a=red, visual b=yellow, visual c=blue), it was possible, but infrequent, for some extraneous object in the environment generated a response in visual channels that were not supposed to show activity in a particular trial. Rows are seperated by carriage returns, columns by commas. ","TRIAL-ID	: categorical, the trial id of the experience that the observation belongs toDESCRIPTION	: a symbolic description of the experience designTIME-SECS	: a reading of the Pioneer's internal clock, in secondsBATTERY-LEVEL	: a reading of battery level, in voltsSONAR-0		: sonar depth reading, in mm, of the left (90) pointing sonarSONAR-1		: sonar depth reading, in mm, of a (15) pointing sonarSONAR-2 	: sonar depth reading, in mm, of a (7.5) pointing sonarSONAR-3 	: sonar depth reading, in mm, of a forward (0) pointing sonarSONAR-4 	: sonar depth reading, in mm, of a (-7.5) pointing sonarSONAR-5 	: sonar depth reading, in mm, of a (-15) pointing sonarSONAR-6 	: sonar depth reading, in mm, of a right (-90) pointing sonarHEADING		: heading reading, in degrees, from the robot's ""true north""R-WHEEL-VEL	: right wheel velocity, in mm/secL-WHEEL-VEL	: left wheel velocity, in mm/secTRANS-VEL	: translational velocity, mm/secROT-VEL		: rotational velocity, mm/secR-STALL		: right wheel stall sensor, binary (0/1)L-STALL		: left wheel stall sensor, binary (0/1)ROBOT-STATUS	: robot status, 2.0 = stationary, 3.0 = movingGRIP-STATE	: gripper stateGRIP-FRONT-BEAM : gripper break beam, binary, 1.0 = brokenGRIP-REAR-BEAM	: gripper break beam, binary, 1.0 = brokenGRIP-BUMPER	: gripper bumper, binary, 1.0 = in contactVIS-A-AREA	: area of dominant visible object for channel A, in pixelsVIS-A-X		: X location of object in channel A on image plane, -140 ... 140VIS-A-Y		: Y location of channel A on image planeVIS-A-H		: height of object in channel A on plane, in pixelsVIS-A-W		: width of object in A on image plane, in pixelsVIS-A-DIST	: distance to object in channel A, in mmVIS-B-AREA	: area of dominant visible object for channel B, in pixelsVIS-B-X		: X location of object in channel B on image plane, -140 ... 140VIS-B-Y		: Y location of channel B on image planeVIS-B-H		: height of object in channel B on plane, in pixelsVIS-B-W		: width of object in B on image plane, in pixelsVIS-B-DIST	: distance to object in channel B, in mmVIS-C-AREA	: area of dominant visible object for channel C, in pixelsVIS-C-X		: X location of object in channel C on image plane, -140 ... 140VIS-C-Y		: Y location of channel C on image planeVIS-C-H		: height of object in C on image plane, in pixelsVIS-C-W		: width of object in C on image plane, in pixelsVIS-C-DIST	: distance to object in channel C, in mm For the visual variables, when there is no visible object, width = 0, height = 0, area = 0, distance = 10000.0, Y = 0, X = 140.0. The sonars report 5201.0 as their maximum distance. ","Oates, Tim; Schmill, Matthew D. and Cohen, Paul R. Identifying Qualitatively Different Experiences: Experiments with a Mobile Robot.[Web Link]  Schmill, Matthew D.; Oates, Tim; and Cohen, Paul R. Learned Models for Continuous Planning. Seventh International Workshop on Artificial Intelligence and Statistics. [Web Link]","The work represented here was funded by DARPA contracts F49620-97-1-0485 and N66001-96-C-8504. For research use only. ",
http://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter,319,Health News in Twitter Data Set,../machine-learning-databases/00438/,Text,58000,Computer,Real,25000,2/19/2018,Clustering,N/A,48814,"Amir Karami  karami '@' sc.edu University of South Carolina","Each file is related to one Twitter account of a news agency. For example, bbchealth.txt is related to BBC health news. Each line contains tweet id|date and time|tweet. The separator is '|'. This text data has been used to evaluate the performance of topic models on short text data. However, it can be used for other tasks such as clustering. ",N/A,"Karami, A., Gangopadhyay, A., Zhou, B., & Kharrazi, H. (2017). Fuzzy approach topic discovery in health and medical corpora. International Journal of Fuzzy Systems, 1-12.","Karami, A., Gangopadhyay, A., Zhou, B., & Kharrazi, H. (2017). Fuzzy approach topic discovery in health and medical corpora. International Journal of Fuzzy Systems, 1-12.",
http://archive.ics.uci.edu/ml/datasets/DGP2+-+The+Second+Data+Generation+Program,320,DGP2 - The Second Data Generation Program Data Set,../machine-learning-databases/dgp-2/,Data-Generator,N/A,N/A,Real,N/A,N/A,N/A,N/A,31648,"Powell BenedictUniversity of Illinois at UrbanaInductive Learning GroupBeckman InstituteUrbana, IL 61801tel: (217) 244-1620E-mail: benedict '@' cs.uiuc.edu","DGP/2 is an improvement of DGP.  It allows for additional parameters and automates the setting of the standard deviation parameter, which is not easily done by the user.  In particular, DGP/2 allows for variation in the number of instances, the number of features, the range of feature values, the number of peaks, the percent of positive instances desired and a radius around the peaks that these instances will fall within (this controls instance density, and determines the standard deviation value for the normal distribution function).",N/A,"Benedict, P.A., The Use of Synthetic Data in Dynamic Bias Selection, Proc. Of the 6th Aerospace Applications of Artificial Intelligence Conference, Dayton, Ohio, October, 1990. Ehrenfeucht, A., Haussler, D., Kearns, M,  Valiant, L. A general lower bound on the number of examples needed for learning.  Proc. Computational Learning Theory, 1988, 139-154.[Web Link]  Kononenko, I., Bratko, I., Roskar, E., Experiments in Automatic Learning of Medical Diagnostic Rules (Ljubljana, Yugoslavia: Jozef Stefan Institute, 1984).[Web Link]  Michalski, R.S., Mozetic, I., Hong, J., Lavrac, N., The Multipurpose Incremental Learning System AQ15 and Its Testing Application to Three Medical Domains, Proc. Of the Fifth National Conference on Artificial Intelligence, Pp. 1041-1045, Morgan Kaufman, Los Altos, Ca, 1986.[Web Link]  Mitchell, T. M. The need for biases in learning generalizations.  Technical Report CBM-TR-117, May 1980.[Web Link]  Rendell, L.A., A New Basis for State Space Learning Systems and a Successful Implementation, Artificial Intelligence 20(1983):369-392.[Web Link]  Rendell, L. A.,  Cho, H. H. The effect of data character on empirical  concept learning in  Proc. Fifth International Conference on Artificial Intelligence Applications, March, 1989.[Web Link]  Rendell, L. A., Benedict, P. A., Cho, H. H.,  Seshu, Improving the design of rule-learning systems,  Proceedings of the Seventh  International Conference on Expert Systems and their Applications, June, 1988. Rendell, L.,  Seshu, R., Learning hard concepts through constructive induction: framework and rationale, Computational Intelligence, 1990.[Web Link]  Rendell, L. A., Seshu, R. M.,  Tcheng, D. K. Layered concept learning and dynamically-variable bias management.  Proceedings of the Tenth  International Joint Conference on Artificial Intelligence, 1987.[Web Link]  Russell, S.,  Grosof, B. Declarative bias: An overview, in P. Benjamin  (Ed.), Change of Representation and Inductive Bias. Kluwer Academic  Press, 1990.[Web Link]  Utgoff, P. E. Shift of bias for inductive concept learning.  Machine Learning: An Artificial Intelligence Approach,  1986,  III.[Web Link]  Utgoff, P. E.,  Mitchell, T. M., Acquisition of appropriate bias for inductive concept learning,  Proc. National Conference on Artificial  Intelligence, 1982.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Quality+Assessment+of+Digital+Colposcopies,321,Quality Assessment of Digital Colposcopies Data Set,../machine-learning-databases/00384/,Multivariate,287,Life,Real,69,3/8/2017,Classification,N/A,19579,"Kelwin Fernandes (kafc _at_ inesctec _dot_ pt) - INESC TEC & FEUP, Porto, Portugal.Jaime S. Cardoso - INESC TEC & FEUP, Porto, Portugal.Jessica Fernandes - Universidad Central de Venezuela, Caracas, Venezuela.","* The dataset was acquired and annotated by professional physicians at 'Hospital Universitario de Caracas'.* The subjective judgments (target variables) were originally done in an ordinal manner (poor, fair, good, excellent) and was discretized in two classes (bad, good).* Images were randomly sampled from the original colposcopic sequences (videos).* The original images and the manual segmentations are included in the 'images' directory.* The dataset has three modalities (i.e. Hinselmann, Green, Schiller).* The target variables are expert::X (X in 0,...,5) and consensus.","Three modalities: hinselmann, green, schiller.Number of Attributes: 69 (62 predictive attributes, 7 target variables) cervix_area: image area with cervix.os_area: image area with external os.walls_area: image area with vaginal walls.speculum_area: image area with the speculum.artifacts_area: image area with artifacts.cervix_artifacts_area: cervix area with the artifacts.os_artifacts_area: external os area with the artifacts.walls_artifacts_area: vaginal walls with the artifacts.speculum_artifacts_area: speculum area with the artifacts.cervix_specularities_area: cervix area with the specular reflections.os_specularities_area: external os area with the specular reflections.walls_specularities_area: vaginal walls area with the specular reflections.speculum_specularities_area: speculum area with the specular reflections.specularities_area: total area with specular reflections.area_h_max_diff: maximum area differences between the four cervix quadrants.rgb_cervix_r_mean: average color information in the cervix (R channel).rgb_cervix_r_std: stddev color information in the cervix (R channel).rgb_cervix_r_mean_minus_std: (avg - stddev) color information in the cervix (R channel).rgb_cervix_r_mean_plus_std: (avg + stddev) information in the cervix (R channel).rgb_cervix_g_mean: average color information in the cervix (G channel).rgb_cervix_g_std: stddev color information in the cervix (G channel).rgb_cervix_g_mean_minus_std: (avg - stddev)  color information in the cervix (G channel).rgb_cervix_g_mean_plus_std: (avg + stddev) color information in the cervix (G channel).rgb_cervix_b_mean: average color information in the cervix (B channel).rgb_cervix_b_std: stddev color information in the cervix (B channel).rgb_cervix_b_mean_minus_std: (avg - stddev) color information in the cervix (B channel).rgb_cervix_b_mean_plus_std: (avg + stddev) color information in the cervix (B channel).rgb_total_r_mean: average color information in the image (B channel).rgb_total_r_std: stddev color information in the image (R channel).rgb_total_r_mean_minus_std: (avg - stddev) color information in the image (R channel).rgb_total_r_mean_plus_std: (avg + stddev) color information in the image (R channel).rgb_total_g_mean: average color information in the image (G channel).rgb_total_g_std: stddev color information in the image (G channel).rgb_total_g_mean_minus_std: (avg - stddev) color information in the image (G channel).rgb_total_g_mean_plus_std: (avg + stddev) color information in the image (G channel).rgb_total_b_mean: average color information in the image (B channel).rgb_total_b_std: stddev color information in the image (B channel).rgb_total_b_mean_minus_std: (avg - stddev) color information in the image (B channel).rgb_total_b_mean_plus_std: (avg + stddev) color information in the image (B channel).hsv_cervix_h_mean: average color information in the cervix (H channel).hsv_cervix_h_std: stddev color information in the cervix (H channel).hsv_cervix_s_mean: average color information in the cervix (S channel).hsv_cervix_s_std: stddev color information in the cervix (S channel).hsv_cervix_v_mean: average color information in the cervix (V channel).hsv_cervix_v_std: stddev color information in the cervix (V channel).hsv_total_h_mean: average color information in the image (H channel).hsv_total_h_std: stddev color information in the image (H channel).hsv_total_s_mean: average color information in the image (S channel).hsv_total_s_std: stddev color information in the image (S channel).hsv_total_v_mean: average color information in the image (V channel).hsv_total_v_std: stddev color information in the image (V channel).fit_cervix_hull_rate: Coverage of the cervix convex hull by the cervix.fit_cervix_hull_total: Image coverage of the cervix convex hull.fit_cervix_bbox_rate: Coverage of the cervix bounding box by the cervix.fit_cervix_bbox_total: Image coverage of the cervix bounding box.fit_circle_rate: Coverage of the cervix circle by the cervix.fit_circle_total: Image coverage of the cervix circle.fit_ellipse_rate: Coverage of the cervix ellipse by the cervix.fit_ellipse_total: Image coverage of the cervix ellipse.fit_ellipse_goodness: Goodness of the ellipse fitting.dist_to_center_cervix: Distance between the cervix center and the image center.dist_to_center_os: Distance between the cervical os center and the image center.experts::0: subjective assessment of the Expert 0 (target variable).experts::1: subjective assessment of the Expert 1 (target variable).experts::2: subjective assessment of the Expert 2 (target variable).experts::3: subjective assessment of the Expert 3 (target variable).experts::4: subjective assessment of the Expert 4 (target variable).experts::5: subjective assessment of the Expert 5 (target variable).consensus: subjective assessment of the consensus (target variable).","Fernandes, Kelwin, Jaime S. Cardoso, and Jessica Fernandes. 'Transfer Learning with Partial Observability Applied to Cervical Cancer Screening.' Iberian Conference on Pattern Recognition and Image Analysis. Springer International Publishing, 2017.","Fernandes, Kelwin, Jaime S. Cardoso, and Jessica Fernandes. 'Transfer Learning with Partial Observability Applied to Cervical Cancer Screening.' Iberian Conference on Pattern Recognition and Image Analysis. Springer International Publishing, 2017.",
http://archive.ics.uci.edu/ml/datasets/Artificial+Characters,322,Artificial Characters Data Set,../machine-learning-databases/artificial-characters/,Multivariate,6000,Computer,"Categorical, Integer, Real",7,7/1/1992,Classification,No,245703,"Original Owners of Database: 1. H. Altay Guvenir, PhD., Bilkent University,Department of Computer Engineering and Information Science,06533 Ankara, TurkeyPhone: +90 (312) 266 4133Email: guvenir '@' cs.bilkent.edu.tr  2. Burak Acar, M.S.,Bilkent University, EE Eng. Dept. 06533 Ankara, TurkeyEmail: buraka '@' ee.bilkent.edu.tr  3. Haldun Muderrisoglu, M.D., Ph.D., Baskent University, School of MedicineAnkara, Turkey Donor:  H. Altay GuvenirBilkent University,Department of Computer Engineering and Information Science,06533 Ankara, TurkeyPhone: +90 (312) 266 4133Email: guvenir '@' cs.bilkent.edu.tr","This database has been artificially generated by using a first order theory which describes the structure of ten capital letters of the English alphabet and a random choice theorem prover which accounts for etherogeneity in the instances. The capital letters represented are the following: A, C, D, E, F, G, H, L, P, R. Each instance is structured and is described by a set of segments (lines) which resemble the way an automatic program would segment an image. Each instance is stored in a separate file whose format is the following: CLASS OBJNUM TYPE XX1 YY1 XX2 YY2 SIZE DIAG where CLASS is an integer number indicating the class as described below, OBJNUM is an integer identifier of a segment (starting from 0) in the instance and the remaining columns represent attribute values. For further details, contact the author.","      TYPE: the first attribute describes the type of segment and is always set to the string ""line"". Its C language type is char.       XX1,YY1,XX2,YY2: these attributes contain the initial and final coordinates of a segment in a cartesian plane. Their C language type is int.       SIZE: this is the length of a segment computed by using the geometric distance between two points A(X1,Y1) and B(X2,Y2). Its C language type is float.       DIAG: this is the length of the diagonal of the smallest rectangle which includes the picture of the character. The value of this attribute is the same in each object. Its C language type is float.","M. Botta, A. Giordana, L. Saitta: ""Learning Fuzzy Concept Definitions"", IEEE-Fuzzy Conference, 1993.[Web Link]  M. Botta, A. Giordana: ""Learning Quantitative Feature in a Symbolic Environment"", LNAI 542, 1991, pp. 296-305.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Robot+Execution+Failures,323,Robot Execution Failures Data Set,../machine-learning-databases/robotfailure-mld/,"Multivariate, Time-Series",463,Physical,Integer,90,4/23/1999,Classification,N/A,101354,"Original Owner and Donor: Luis Seabra Lopes and Luis M. Camarinha-MatosUniversidade Nova de Lisboa, Monte da Caparica, Portugal","The donation includes 5 datasets, each of them defining a different learning problem:     * LP1: failures in approach to grasp position    * LP2: failures in transfer of a part    * LP3: position of part after a transfer failure    * LP4: failures in approach to ungrasp position    * LP5: failures in motion with part In order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].","All features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms. Each example is described as follows:                  class                 Fx1	Fy1	Fz1	Tx1	Ty1	Tz1                 Fx2	Fy2	Fz2	Tx2	Ty2	Tz2                 ......                 Fx15	Fy15	Fz15	Tx15	Ty15	Tz15 where Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features. ","Seabra Lopes, L. (1997) ""Robot Learning at the Task Level: a Study in the Assembly Domain"", Ph.D. thesis, Universidade Nova de Lisboa, Portugal.[Web Link]  Seabra Lopes, L. and L.M. Camarinha-Matos (1998) Feature Transformation Strategies for a Robot Learning Problem, ""Feature Extraction, Construction and Selection. A Data Mining Perspective"", H. Liu and H. Motoda (edrs.), Kluwer Academic Publishers.[Web Link]  Camarinha-Matos, L.M., L. Seabra Lopes, and J. Barata (1996) Integration and Learning in Supervision of Flexible Assembly Systems, ""IEEE Transactions on Robotics and Automation"", 12 (2), 202-219. [Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results,324,Dota2 Games Results Data Set,../machine-learning-databases/00367/,Multivariate,102944,Game,N/A,116,8/14/2016,Classification,N/A,99610,stephen.tridgell '@' sydney.edu.au,"Dota 2 is a popular computer game with two teams of 5 players. At the start of the game each player chooses a unique hero with different strengths and weaknesses. The dataset is reasonably sparse as only 10 of 113 possible heroes are chosen in a given game. All games were played in a space of 2 hours on the 13th of August, 2016The data was collected using: [Web Link]",Each row of the dataset is a single game with the following features (in the order in the vector):1. Team won the game (1 or -1)2. Cluster ID (related to location)3. Game mode (eg All Pick)4. Game type (eg. Ranked)5 - end: Each element is an indicator for a hero. Value of 1 indicates that a player from team '1' played as that hero and '-1' for the other team. Hero can be selected by only one player each game. This means that each row has five '1' and five '-1' values.The hero to id mapping can be found here: [Web Link],N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Optical+Interconnection+Network+,325,Optical Interconnection Network  Data Set,../machine-learning-databases/00449/,Multivariate,640,Computer,"Integer, Real",10,3/29/2018,"Classification, Regression",N/A,25363,"Cigdem Inan ACI- Mersin University, Dept of Computer Engineering, caci '@' mersin.edu.trMehmet Fatih AKAY- Cukurova University, Dept of Computer Engineering, mfakay '@' cu.edu.tr"," All simulations have done under the software named OPNET Modeler. Message passing is used as the communication mechanism in which any processor can submit to the network a point-to-point message destined at any other processor. M/M/1 queue is considered in the calculations which consist of a First-in First-Out buffer with packet arriving randomly according to a Poisson arrival process, and a processor, that retrieves packets from the buffer at a specified service rate. In all simulations, it is assumed that the processor at each node extracts a packet from an input queue, processes it for a period of time and when that period expires, it generates an output data message. The size of each input queue is assumed as infinite. A processor becomes idle only when all its input queues are empty. ","The summary of the attributes is given below. Please read the paper ([Web Link]) for detailed descriptions of the attributes.  Node Number: The number of the nodes in the network. (8x8 or 4x4). Thread Number: The number of threads in each node at the beginning of the simulation. Spatial Distribution: The performance of the network is evaluated using synthetic traffic workloads. Uniform (UN), Hot Region (HR), Bit reverse (BR) and Perfect Shuffle (PS) traffic models have been included. Temporal Distribution: Temporal distribution of packet generation is implemented by independent traffic sources. In our simulations, we utilized clientâ€“server traffic (i.e., a server node sends packets to respond to the reception of packets from clients) and asynchronous traffic (i.e., initially, all nodes generate traffic independently of the others; as time progresses, traffic generation at the source/destination nodes dependson the receipt of messages from destination/source nodes). T/R: Message transfer time (T ) Uniformly distributed with mean in range from 20 to 100 clock cycles. Thread run time (R) Exponentially distributed with a mean of 100 clock cycles. Processor Utilization: The average processor utilization measures the percent of time that threads are running in the processor. Channel Waiting Time: Average waiting time of a packet at the output channel queue until it is serviced by the channel. Input Waiting Time: Average waiting time of a packet until it is serviced by the processor. Network Response Time: The time between a request message is enqueued at the output channel and the corresponding data message is received in the input queue. Channel Utilization: The percent of time that the channel is busy transferring packets to the network.      ","M.F. Akay, CÂ¸.I. Aci, F. Abut, Predicting the Performance Measures of a 2-Dimensional Message Passing Multiprocessor Architecture by Using Machine Learning Methods. Neural Network World 71(5):1907-1931. DOI: 10.14311/NNW.2015.25.013.","AcÄ±, Ã‡.Ä°. & Akay, M.F. A hybrid congestion control algorithm for broadcast-based architectures with multiple input queues. J Supercomput (2015) 71: 1907. [Web Link]",
http://archive.ics.uci.edu/ml/datasets/KASANDR,326,KASANDR Data Set,../machine-learning-databases/00385/,Multivariate,17764280,Life,Integer,2158859,5/16/2017,Causal-Discovery,N/A,33836,"Massih-Reza AminiUniv. Grenoble Alpes, CNRS/LIGmassih-reza.amini '@' univ-grenoble-alpes.fr  Charlotte LaclauUniv. Grenoble Alpes, CNRS/LIGcharlotte.laclau '@' univ-grenoble-alpes.fr  Sumit SidanaUniv. Grenoble Alpes, CNRS/LIGsumit.sidana '@' imag.fr","We created this data by sampling and processing the www.kelkoo.com logs. The data records offers which were clicked (or shown) to the users of the www.kelkoo.com (and partners) in Germany as well as meta-information of these users and offers and the objective is to predict if a given user will click on a given offer.","userid offerid countrycode category merchant utcdate implicit-feedback  1. train_de.csv (3,14 GB)Instances: 15,844,718Attributes: 2,299,713userid: Categorical, 291,485offerid: Categorical, 2,158,859countrycode: Categorical, 1 (de - Germany)category: Integer, 271merchant: Integer, 703utcdate: Timestamp, 2016-06-01 02:00:17.0 to 2016-06-14 23:52:51.0implicit feedback (click): Binary, 0 or 1 2. test_de.csv (381,3 MB)Instances: 1,919,562Attributes: 2,299,713userid: Categorical, 278,293offerid: Categorical, 380,803countrycode: Categorical, 1category: Integer, 267merchant: Integer, 738utcdate: Timestamp, 2016-06-14 23:52:51.0 to 2016-07-01 01:59:36.0implicit feedback (click): Binary, 0 or 1","Sumit Sidana, Charlotte Laclau, Massih-Reza Amini, Gilles Vandelle, and Andre Bois-Crettez. 'KASANDR: A Large-Scale Dataset with Implicit Feedback for Recommendation',  SIGIR 2017.","If you publish results based on this data set, please acknowledge its use, by referring to:Sumit Sidana, Charlotte Laclau, Massih-Reza Amini, Gilles Vandelle, and Andre Bois-Crettez. 'KASANDR: A Large-Scale Dataset with Implicit Feedback for Recommendation',  SIGIR 2017.",
http://archive.ics.uci.edu/ml/datasets/Wine,327,Wine Data Set,../machine-learning-databases/wine/,Multivariate,178,Physical,"Integer, Real",13,7/1/1991,Classification,No,1452842,"Original Owners: Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy. Donor: Stefan Aeberhard, email: stefan '@' coral.cs.jcu.edu.au","These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.  I think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.)  I lost it, and b.), I would not know which 13 variables are included in the set. The attributes are (dontated by Riccardo Leardi, riclea '@' anchem.unige.it )1) Alcohol2) Malic acid3) Ash4) Alcalinity of ash  5) Magnesium6) Total phenols7) Flavanoids8) Nonflavanoid phenols9) Proanthocyanins10)Color intensity11)Hue12)OD280/OD315 of diluted wines13)Proline  In a classification context, this is a well posed problem with ""well behaved"" class structures. A good data set for first testing of a new classifier, but not very challenging.           ","All attributes are continuous No statistics available, but suggest to standardise variables for certain uses (e.g. for us with classifiers which are NOT scale invariant) NOTE: 1st attribute is class identifier (1-3)","   (1)   S. Aeberhard, D. Coomans and O. de Vel,   Comparison of Classifiers in High Dimensional Settings,   Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of   Mathematics and Statistics, James Cook University of North Queensland.   (Also submitted to Technometrics).    The data was used with many others for comparing various    classifiers. The classes are separable, though only RDA    has achieved 100% correct classification.   (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))   (All results using the leave-one-out technique)      (2)    S. Aeberhard, D. Coomans and O. de Vel,   ""THE CLASSIFICATION PERFORMANCE OF RDA""   Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of   Mathematics and Statistics, James Cook University of North Queensland.   (Also submitted to Journal of Chemometrics).    Here, the data was used to illustrate the superior performance of   the use of a new appreciation function with RDA. ","Please refer to the Machine Learning
Repository's citation policy","Ping Zhong and Masao Fukushima. A Regularized Nonsmooth Newton Method for Multi-class Support Vector Machines. 2005.  [View Context].Igor Fischer and Jan Poland. Amplifying the Block Matrix Structure for Spectral Clustering. Telecommunications Lab. 2005.  [View Context].Agapito Ledezma and Ricardo Aler and Araceli Sanchís and Daniel Borrajo. Empirical Evaluation of Optimized Stacking Configurations. ICTAI. 2004.  [View Context].Jianbin Tan and David L. Dowe. MML Inference of Oblique Decision Trees. Australian Conference on Artificial Intelligence. 2004.  [View Context].Sugato Basu. Semi-Supervised Clustering with Limited Background Knowledge. AAAI. 2004.  [View Context].Stefan Mutter and Mark Hall and Eibe Frank. Using Classification to Evaluate the Output of Confidence-Based Association Rule Mining. Australian Conference on Artificial Intelligence. 2004.  [View Context].Jennifer G. Dy and Carla Brodley. Feature Selection for Unsupervised Learning. Journal of Machine Learning Research, 5. 2004.  [View Context].Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].Mikhail Bilenko and Sugato Basu and Raymond J. Mooney. Integrating constraints and metric learning in semi-supervised clustering. ICML. 2004.  [View Context].Michael L. Raymer and Travis E. Doom and Leslie A. Kuhn and William F. Punch. Knowledge discovery in medical and biological datasets using a hybrid Bayes classifier/evolutionary algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B, 33. 2003.  [View Context].Jeremy Kubica and Andrew Moore. Probabilistic Noise Identification and Data Cleaning. ICDM. 2003.  [View Context].Sugato Basu. Also Appears as Technical Report, UT-AI. PhD Proposal. 2003.  [View Context].Mukund Deshpande and George Karypis. Using conjunction of attribute values for classification. CIKM. 2002.  [View Context].Petri Kontkanen and Jussi Lahtinen and Petri Myllymaki and Tomi Silander and Henry Tirri. Proceedings of Pre- and Post-processing in Machine Learning and Data Mining: Theoretical Aspects and Applications, a workshop within Machine Learning and Applications. Complex Systems Computation Group (CoSCo). 1999.  [View Context].Ethem Alpaydin. Voting over Multiple Condensed Nearest Neighbors. Artif. Intell. Rev, 11. 1997.  [View Context].Georg Thimm and E. Fiesler. Optimal Setting of Weights, Learning Rate, and Gain. E S E A R C H R E P R O R T I D I A P. 1997.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Pedro Domingos. Unifying Instance-Based and Rule-Based Induction. Machine Learning, 24. 1996.  [View Context].Georg Thimm and Emile Fiesler. IDIAP Technical report High Order and Multilayer Perceptron Initialization. IEEE Transactions. 1994.  [View Context].Denver Dash and Gregory F. Cooper. Model Averaging with Discrete Bayesian Network Classifiers. Decision Systems Laboratory Intelligent Systems Program University of Pittsburgh.  [View Context].Ping Zhong and Masao Fukushima. Second Order Cone Programming Formulations for Robust Multi-class Classification.  [View Context].Aynur Akku and H. Altay Guvenir. Weighting Features in k Nearest Neighbor Classification on Feature Projections. Department of Computer Engineering and Information Science Bilkent University.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context].Stefan Aeberhard and Danny Coomans and De Vel. THE PERFORMANCE OF STATISTICAL PATTERN RECOGNITION METHODS IN HIGH DIMENSIONAL SETTINGS. James Cook University.  [View Context].Pramod Viswanath and M. Narasimha Murty and Shalabh Bhatnagar. Partition Based Pattern Synthesis Technique with Efficient Algorithms for Nearest Neighbor Classification. Department of Computer Science and Automation, Indian Institute of Science.  [View Context].Yin Zhang and W. Nick Street. Bagging with Adaptive Costs. Management Sciences Department University of Iowa Iowa City.  [View Context].Daichi Mochihashi and Gen-ichiro Kikui and Kenji Kita. Learning Nonstructural Distance Metric by Minimum Cluster Distortions. ATR Spoken Language Translation research laboratories.  [View Context].Abdelhamid Bouchachia. RBF Networks for Learning from Partially Labeled Data. Department of Informatics, University of Klagenfurt.  [View Context].Erin J. Bredensteiner and Kristin P. Bennett. Multicategory Classification by Support Vector Machines. Department of Mathematics University of Evansville.  [View Context].K. A. J Doherty and Rolf Adams and Neil Davey. Unsupervised Learning with Normalised Data and Non-Euclidean Norms. University of Hertfordshire.  [View Context].Stefan Aeberhard and O. de Vel and Danny Coomans. New Fast Algorithms for Variable Selection based on Classifier Performance. James Cook University.  [View Context].Georg Thimm and Emile Fiesler. High Order and Multilayer Perceptron Initialization.  [View Context].Pramod Viswanath and M. Narasimha Murty and Shalabh Bhatnagar. A pattern synthesis technique to reduce the curse of dimensionality effect. E-mail.  [View Context].Chih-Wei Hsu and Cheng-Ru Lin. A Comparison of Methods for Multi-class Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Petri Kontkanen and Jussi Lahtinen and Petri Myllymaki and Tomi Silander and Henry Tirri. USING BAYESIAN NETWORKS FOR VISUALIZING HIGH-DIMENSIONAL DATA. Complex Systems Computation Group (CoSCo).  [View Context].Perry Moerland and E. Fiesler and I. Ubarretxena-Belandia. Incorporating LCLV Non-Linearities in Optical Multilayer Neural Networks. Preprint of an article published in Applied Optics.  [View Context].Matthias Scherf and W. Brauer. Feature Selection by Means of a Feature Weighting Approach. GSF - National Research Center for Environment and Health.  [View Context].Wl/odzisl/aw Duch. Coloring black boxes: visualization of neural network decisions. School of Computer Engineering, Nanyang Technological University.  [View Context].H. Altay Guvenir. A Classification Learning Algorithm Robust to Irrelevant Features. Bilkent University, Department of Computer Engineering and Information Science.  [View Context].Christian Borgelt and Rudolf Kruse. Speeding Up Fuzzy Clustering with Neural Network Techniques. Research Group Neural Networks and Fuzzy Systems Dept. of Knowledge Processing and Language Engineering, School of Computer Science Otto-von-Guericke-University of Magdeburg.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Chess+%28Domain+Theories%29,328,Chess (Domain Theories) Data Set,../machine-learning-databases/chess/domain-theories/,Domain-Theory,N/A,Game,N/A,N/A,N/A,N/A,N/A,52200,"1. ""chess_flann_new"" and ""chess_flann_wyl"" written by flann '@' cs.orst.edu  2. ""chess_russel_wyl"" originally written by Stuart Russell in MRS, then translated into prolog by flann '@' cs.orst.edu  3. ""chess_vijay_1"", ""chess_vijay_2"" and ""chess_vijay_3"" written by vijay '@' cs.orst.edu","The six encoding are briefly described below: 1) chess_flann_new: Written by flann '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check. 2) chess_flann_wyl: Written by flann '@' cs.orst.edu. Employs a relational representation for states, with each square given a unique name and square connectivity computed by an enumeration of connected relations. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check. 3) chess_russell_wyl: Originally written by Stuart Russell in MRS, translated into prolog by flann '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by determining whether the moving side is in check. If the moving side is in check, moves are generated that destroy the check threat. If the moving side is not in check, moves are generated that do not create a check threat. Note that if the moving side is in check from multiple threats then the domain theory generates incorrect moves. 4) chess_vijay_1: Written by vijay '@' cs.orst.edu. Employs a relational representation for states, with each square given a unique name and square connectivity computed by an enumeration of connected relations. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check. 5) chess_vijay_2: Written by vijay '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check. 6) chess_vijay_3: Written by vijay '@' cs.orst.edu. Employs a special linear representation for states, with each square designated by a single number and square connectivity computed by a single delta value. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check. Each domain theory includes a sample state called state1 that describes the board position illustrated as Figure 4(d) in Flann and Dietterich, ""A study of explanation-based methods for inductive learning"" in Machine Learning, 4 187-226. See file test_domain_theories for an example of loading and running the domain theories. In addition to the domain theories, a file called support_code is included that contains some useful prolog routines. One routine takes a generic chess board description and a domain theory name, and produces a prolog state description suitable for use with the given domain theory. See file test_domain_theories for an example of generating state descriptions.",N/A,"Flann and Dietterich, ""A study of explanation-based methods for inductive learning"", Machine Learning, 4 187-226. [Web Link]","Please refer to the Machine Learning
Repository's citation policy","Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/KDD+Cup+1998+Data,329,KDD Cup 1998 Data Data Set,../machine-learning-databases/kddcup98-mld/,Multivariate,191779,N/A,"Categorical, Integer",481,7/20/1998,Regression,Yes,78103,"Ismail ParsaEpsilon50 Cambridge StreetBurlington MA 01803 USATEL: (781) 685-6734FAX: (781) 685-0806 ",Please see associated text files in the download folder.,N/A,N/A,"The KDD-CUP-98 data set and the accompanying documentation are now available for general use with the following restrictions:    1. The users of the data must notify Ismail Parsa (iparsa '@' epsilon.com) and Ken Howes (khowes '@' epsilon.com) in the event they produce results, visuals or tables, etc. from the data and send a note that includes a summary of the final result.   2. The authors of published and/or unpublished articles that use the KDD-Cup-98 data set must also notify the individuals listed above and send a copy of their published and/or unpublished work.   3. If you intend to use this data set for training or educational purposes, you must not reveal the name of the sponsor PVA (Paralyzed Veterans of America) to the trainees or students. You are allowed to say ""a national veterans organization""...  For more information regarding the KDD-Cup (including the list of the participants and the results), please visit the KDD-Cup-98 web page at: [Web Link]. While there, scroll down to Data Mining Presentations where you will find the KDD-Cup-98 web page. ","Chris Giannella and Bassem Sayrafi. An Information Theoretic Histogram for Single Dimensional Selectivity Estimation. Department of Computer Science, Indiana University Bloomington.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/EMG+dataset+in+Lower+Limb,330,EMG dataset in Lower Limb Data Set,../machine-learning-databases/00278/,"Multivariate, Time-Series",132,Computer,Real,5,2/5/2014,N/A,N/A,49428,"Samples obtained with the aid of:BatallÃ³n de sanidad (BASAN)  Universidad Militar Nueva Granada  â€“ BogotÃ¡ (samples July 2012).Carrera 7 No 52-48, BogotÃ¡.TecnoParque SENA nodo Manizales (samples march - july 2013).Km 10 route to Magdalena, Manizales.Ph.D Oscar Fernando Aviles Sanchez       oscfer '@' gmail.comUniversidad MIlitar Nueva GranadaPh.D Jose Luis Rodriguez Sotelo              jdw.siul '@' gmail.comMg. Marcelo Herrera Gonzales                 marhego '@' gmail.comMg. Gustavo Adolfo Martínez Hernandez   gamhet2 '@' gmail.comUniversidad Autonoma de Manizales","2.	Information database: 2.1.	Protocol:22 male subjects , 11 with different knee abnormalities previously diagnosed by a professional. They undergo three movements to analyze the behavior associated with the knee muscle , gait , leg extension from a sitting position , and flexion of the leg up. The acquisition process was conducted with 4 electrodes ( Vastus Medialis , semitendinosus , biceps femoris and rectus femoris ) and the goniometer in the knee .2.2.	InstrumentationDatalog equipment was used MWX8 by Biometrics of 8 digital channels and 4 analog channels , of which 4 for sampling were used SEMG and 1 for goniometry, these data were acquired directly to the computer MWX8 internal storage with microSD card and transmitted in Real-time Datalog software through bluetooth adapter , 14-bit resolution and sampling frequency of 1000Hz .2.3.	Data configuration:The total number of electrodes is 4, corresponding to the time series one for each channel (1 to 4). Each series contains ~ 5 shares or motion repetitions for each subject.","Each data file contains 5 columns, organized as follows.Segment	Lower LimbChannel	Ch1	Ch2	Ch3	Ch4	Ch5Muscle	RF	BF	VM	ST	FXColumn	0	1	2	3	4",Provide references to papers that have cited this data set in the past (if any).,"If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+,331,Cryotherapy Dataset  Data Set,../machine-learning-databases/00429/,Univariate,90,Life,"Integer, Real",7,1/4/2018,Classification,N/A,42897,"Name: Fahime Khozeimeh, MDemail: fahime.khozeime '@' yahoo.com institution: Faculty of  Medicine, Mashhad University of Medical Sciences, Mashhad, Iran. Name: Pouran Layegh, Professor of Dermatologyemail: layeghpo '@' mums.ac.ir institution: Mashhad University of Medical Sciences, Mashhad, Iranwebsite: http://research.mums.ac.ir/webdocument/load.action?webdocument_code=8001&masterCode=8000703  Name:Roohallah Alizadehsani, PhD studentemail: alizadeh_roohallah '@' yahoo.cominstitution: Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Victoria 3217, Australia.website: http://ce.sharif.ir/~ralizadeh/  Name: Mohamad Roshanzamir, PhD candidateemail: mohamad.roshanzamir '@' ec.iut.ac.irinstitution: Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran. ",Provide all relevant information about your data set.,Provide information about each attribute in your data set.,"1. F. Khozeimeh, R. Alizadehsani, M. Roshanzamir, A. Khosravi, P. Layegh, and S. Nahavandi, 'An expert system for selecting wart treatment method,' Computers in Biology and Medicine, vol. 81, pp. 167-175, 2/1/ 2017.2. F. Khozeimeh, F. Jabbari Azad, Y. Mahboubi Oskouei, M. Jafari, S. Tehranian, R. Alizadehsani, et al., 'Intralesional immunotherapy compared to cryotherapy in the treatment of warts,' International Journal of Dermatology, 2017, DOI: 10.1111/ijd.135353. Intralesional immunotherapy with Candida antigen compared to cryotherapy in the treatment of warts. M Teimoorian, F Khozeimeh, P Layegh, R AlizadehsaniAmerican Academy of Dermatology, 2016","1. F. Khozeimeh, R. Alizadehsani, M. Roshanzamir, A. Khosravi, P. Layegh, and S. Nahavandi, 'An expert system for selecting wart treatment method,' Computers in Biology and Medicine, vol. 81, pp. 167-175, 2/1/ 2017.2. F. Khozeimeh, F. Jabbari Azad, Y. Mahboubi Oskouei, M. Jafari, S. Tehranian, R. Alizadehsani, et al., 'Intralesional immunotherapy compared to cryotherapy in the treatment of warts,' International Journal of Dermatology, 2017, DOI: 10.1111/ijd.13535",
http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection,332,SMS Spam Collection Data Set,../machine-learning-databases/00228/,"Multivariate, Text, Domain-Theory",5574,Computer,Real,N/A,6/22/2012,"Classification, Clustering",N/A,310824,"Tiago A. Almeida (talmeida  ufscar.br)Department of Computer ScienceFederal University of Sao Carlos (UFSCar)Sorocaba, Sao Paulo - Brazil JosÃ© MarÃ­a GÃ³mez Hidalgo (jmgomezh  yahoo.es)R&D Department OptenetLas Rozas, Madrid - Spain","This corpus has been collected from free or free for research sources at the Internet: -> A collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages. The Grumbletext Web site is: [Web Link].-> A subset of 3,375 SMS randomly chosen ham messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The NUS SMS Corpus is avalaible at: [Web Link].-> A list of 450 SMS ham messages collected from Caroline Tag's PhD Thesis available at [Web Link].-> Finally, we have incorporated the SMS Spam Corpus v.0.1 Big. It has 1,002 SMS ham messages and 322 spam messages and it is public available at: [Web Link]. This corpus has been used in the following academic researches: [1] GÃ³mez Hidalgo, J.M., Cajigas Bringas, G., Puertas Sanz, E., Carrero GarcÃ­a, F. Content Based SMS Spam Filtering. Proceedings of the 2006 ACM Symposium on Document Engineering (ACM DOCENG'06), Amsterdam, The Netherlands, 10-13, 2006. [2] Cormack, G. V., GÃ³mez Hidalgo, J. M., and Puertas SÃ¡nz, E. Feature engineering for mobile (SMS) spam filtering.  Proceedings of the 30th Annual international ACM Conference on Research and Development in information Retrieval (ACM SIGIR'07), New York, NY, 871-872, 2007. [3] Cormack, G. V., GÃ³mez Hidalgo, J. M., and Puertas SÃ¡nz, E. Spam filtering for short messages. Proceedings of the 16th ACM Conference on Information and Knowledge Management (ACM CIKM'07). Lisbon, Portugal, 313-320, 2007.","The collection is composed by just one text file, where each line has the correct class followed by the raw message. We offer some examples bellow: ham   What you doing?how are you?ham   Ok lar... Joking wif u oni...ham   dun say so early hor... U c already then say...ham   MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*ham   Siva is in hostel aha:-.ham   Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor.spam  FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStopspam  Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. Bspam  URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU Note: the messages are not chronologically sorted.","We offer a comprehensive study of this corpus in the following paper. This work presents a number of statistics, studies and baseline results for several machine learning methods. Almeida, T.A., GÃ³mez Hidalgo, J.M., Yamakami, A. Contributions to the Study of SMS Spam Filtering: New Collection and Results. Proceedings of the 2011 ACM Symposium on Document Engineering (DOCENG'11), Mountain View, CA, USA, 2011.","If you find this dataset useful, you make a reference to our paper and the web page: [Web Link] in your papers, research, etc;Send us a message to talmeida  ufscar.br or jmgomezh  yahoo.es in case you make use of the corpus. We would like to thank Min-Yen Kan and his team for making the NUS SMS Corpus available.",
http://archive.ics.uci.edu/ml/datasets/Greenhouse+Gas+Observing+Network,333,Greenhouse Gas Observing Network Data Set,../machine-learning-databases/00328/,"Multivariate, Time-Series",2921,Physical,Real,5232,4/16/2015,Regression,N/A,56093,"D. Lucas (ddlucas .at. alum.mit.edu), Lawrence Livermore National Laboratory. This data was created under work funded by the National Institute of Standards and Technology and Laboratory Directed Research and Development projects at the Lawrence Livermore National Laboratory. The work was performed under the auspices of the US Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344, and is released under UCRL number LLNL-MISC-668913. ","This data set contains time series of greenhouse gas (GHG) concentrations at 2921 grid cells in California created using simulations of the Weather Research and Forecast model with Chemistry (WRF-Chem). Each grid cell covers an area of 12 km by 12 km, and there is one data file per grid cell. Each file contains 16 time series of GHG concentrations. The data points in the time series are spaced 6 hours apart (4 samples per day) over the period May 10 â€“ July 31, 2010. The first 15 rows are time series of GHG tracers released from 14 distinct spatial regions in California and one outside of California. The last row corresponds to the time series of â€œsynthetic GHG observationsâ€ generated with EDGAR emissions of HFC-134a scaled by a factor 0.7 and with noise added. Using this data, the goals are to (1) use inverse methods to determine the optimal values of the weights in the weighted sum of 15 tracers that best matches the synthetic observations, (2) and use optimization methods to determine the best locations to observe GHGs to constrain the inversion. We used a Bayesian method for (1) and genetic algorithms for (2).  Further details about the data and methods are given in the publication 'Designing optimal greenhouse gas observing networks that consider performance and cost,' Geoscientific Instrumentation Methods and Data Systems.","Each file in the data set is labeled ghg.gid.siteWXYZ.dat, where WXYZ is an integer location ID described in our manuscript. At each location,        Rows 1-15: GHG concentrations of tracers emitted from regions 1-15        Row 16: GHG concentrations of synthetic observations        Columns 1-327: GHG concentrations every 6 hours from May 10 â€“ July 31, 2010. All GHG concentrations are in units of parts per trillion.","Lucas, D. D., Yver Kwok, C., Cameron-Smith, P., Graven, H., Bergmann, D., Guilderson, T. P Weiss, R., and Keeling, R.: 'Designing optimal greenhouse gas observing networks that consider performance and cost,' Geoscientific Instrumentation Methods and Data Systems, (2015). [[Web Link]]",Please cite our final paper in Geoscientific Instrumentation Methods and Data Systems.,
http://archive.ics.uci.edu/ml/datasets/Las+Vegas+Strip,334,Las Vegas Strip Data Set,../machine-learning-databases/00397/,N/A,504,Business,Integer,20,7/23/2017,"Classification, Regression",N/A,93577,"S.Moro, P.Rita, J.Coelho (ISCTE-IUL)",All the 504 reviews were collected between January and August of 2015.,"The dataset contains 504 records and 20 tuned features (as of â€œstatus = includedâ€, from Table 1 of the article mentioned below),24 per hotel (two per each month, randomly selected), regarding the year of 2015.The CSV contains a header, with the names of the columns corresponding to the features marked as â€œstatus = includedâ€, from Table 1 of the aforementioned article.","Moro, S., Rita, P., & Coelho, J. (2017). Stripping customers' feedback on hotels through data mining: The case of Las Vegas Strip. Tourism Management Perspectives, 23, 41-52.","If you intend to use this dataset on your research, please cite the following work:Moro, S., Rita, P., & Coelho, J. (2017). Stripping customers' feedback on hotels through data mining: The case of Las Vegas Strip. Tourism Management Perspectives, 23, 41-52.",
http://archive.ics.uci.edu/ml/datasets/Liver+Disorders,335,Liver Disorders Data Set,../machine-learning-databases/liver-disorders/,Multivariate,345,Life,"Categorical, Integer, Real",7,5/15/1990,N/A,No,179051,"Creators:  BUPA Medical Research Ltd. Donor:  Richard S. Forsyth8 Grosvenor AvenueMapperley ParkNottingham NG3 5DX0602-621676","The first 5 variables are all blood tests which are thought to be sensitive to liver disorders that might arise from excessive alcohol consumption. Each line in the dataset constitutes the record of a single male individual.Important note: The 7th field (selector) has been widely misinterpreted in the past as a dependent variable representing presence or absence of a liver disorder. This is incorrect [1]. The 7th field was created by BUPA researchers as a train/test selector. It is not suitable as a dependent variable for classification. The dataset does not contain any variable representing presence or absence of a liver disorder. Researchers who wish to use this dataset as a classification benchmark should follow the method used in experiments by the donor (Forsyth & Rada, 1986, Machine learning: applications in expert systems and information retrieval) and others (e.g. Turney, 1995, Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm), who used the 6th field (drinks), after dichotomising, as a dependent variable for classification. Because of widespread misinterpretation in the past, researchers should take care to state their method clearly.",1. mcv mean corpuscular volume2. alkphos alkaline phosphotase3. sgpt alanine aminotransferase4. sgot aspartate aminotransferase5. gammagt gamma-glutamyl transpeptidase6. drinks number of half-pint equivalents of alcoholic beverages drunk per day7. selector field created by the BUPA researchers to split the data into train/test sets,"McDermott & Forsyth 2016, Diagnosing a disorder in a classification benchmark, Pattern Recognition Letters, Volume 73.","Please refer to the Machine Learning
Repository's citation policy","Zhi-Hua Zhou and Yuan Jiang. NeC4.5: Neural Ensemble Based C4.5. IEEE Trans. Knowl. Data Eng, 16. 2004.  [View Context].Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].Glenn Fung and M. Murat Dundar and Jinbo Bi and Bharat Rao. A fast iterative algorithm for fisher discriminant using heterogeneous kernels. ICML. 2004.  [View Context].Jochen Garcke and Michael Griebel. Classification with sparse grids using simplicial basis functions. Intell. Data Anal, 6. 2002.  [View Context].Michail Vlachos and Carlotta Domeniconi and Dimitrios Gunopulos and George Kollios and Nick Koudas. Non-linear dimensionality reduction techniques for classification and visualization. KDD. 2002.  [View Context].Xavier Llor and David E. Goldberg and Ivan Traus and Ester Bernad i Mansilla. Accuracy, Parsimony, and Generality in Evolutionary Learning Systems via Multiobjective Selection. IWLCS. 2002.  [View Context].Jochen Garcke and Michael Griebel and Michael Thess. Data Mining with Sparse Grids. Computing, 67. 2001.  [View Context].Jochen Garcke and Michael Griebel. Data mining with sparse grids using simplicial basis functions. KDD. 2001.  [View Context].Petri Kontkanen and Jussi Lahtinen and Petri Myllymäki and Henry Tirri. Unsupervised Bayesian visualization of high-dimensional data. KDD. 2000.  [View Context].Carlotta Domeniconi and Jing Peng and Dimitrios Gunopulos. An Adaptive Metric Machine for Pattern Classification. NIPS. 2000.  [View Context].Guido Lindner and Rudi Studer. AST: Support for Algorithm Selection with a CBR Approach. PKDD. 1999.  [View Context].Iñaki Inza and Pedro Larrañaga and Basilio Sierra and Ramon Etxeberria and Jose Antonio Lozano and Jos Manuel Peña. Representing the behaviour of supervised classification learning algorithms by Bayesian networks. Pattern Recognition Letters, 20. 1999.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. A Parametric Optimization Method for Machine Learning. INFORMS Journal on Computing, 9. 1997.  [View Context].Jennifer A. Blue and Kristin P. Bennett. Hybrid Extreme Point Tabu Search. Department of Mathematical Sciences Rensselaer Polytechnic Institute. 1996.  [View Context].Peter D. Turney. Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm. CoRR, csAI/9503102. 1995.  [View Context].Gabor Melli. A Lazy Model-Based Approach to On-Line Classification. University of British Columbia. 1989.  [View Context].Aynur Akku and H. Altay Guvenir. Weighting Features in k Nearest Neighbor Classification on Feature Projections. Department of Computer Engineering and Information Science Bilkent University.  [View Context].Greg Ridgeway. The State of Boosting. Department of Statistics University of Washington.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Adil M. Bagirov and John Yearwood. A new nonsmooth optimization algorithm for clustering. Centre for Informatics and Applied Optimization, School of Information Technology and Mathematical Sciences, University of Ballarat.  [View Context].H. Altay G uvenir and Aynur Akkus. WEIGHTED K NEAREST NEIGHBOR CLASSIFICATION ON FEATURE PROJECTIONS. Department of Computer Engineering and Information Science Bilkent University.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context].David R. Musicant. DATA MINING VIA MATHEMATICAL PROGRAMMING AND MACHINE LEARNING. Doctor of Philosophy (Computer Sciences) UNIVERSITY.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits,336,Pen-Based Recognition of Handwritten Digits Data Set,../machine-learning-databases/pendigits/,Multivariate,10992,Computer,Integer,16,7/1/1998,Classification,No,226756,"E. Alpaydin, Fevzi. AlimogluDepartment of Computer EngineeringBogazici University, 80815 Istanbul Turkeyalpaydin '@' boun.edu.tr","We create a digit database by collecting 250 samples from 44 writers. The samples written by 30 writers are used for training, cross-validation and writer dependent testing, and the digits written by the other 14 are used for writer independent testing. This database is also available in the UNIPEN format. We use a WACOM PL-100V pressure sensitive tablet with an integrated LCD display and a cordless stylus. The input and display areas are located in the same place. Attached to the serial port of an Intel 486 based PC, it allows us to collect handwriting samples. The tablet sends $x$ and $y$ tablet coordinates and pressure level values of the pen at fixed time intervals (sampling rate) of 100 miliseconds.  These writers are asked to write 250 digits in random order inside boxes of 500 by 500 tablet pixel resolution.  Subject are monitored only during the first entry screens. Each screen contains five boxes with the digits to be written displayed above. Subjects are told to write only inside these boxes.  If they make a mistake or are unhappy with their writing, they are instructed to clear the content of a box by using an on-screen button. The first ten digits are ignored because most writers are not familiar with this type of input devices, but subjects are not aware of this.  In our study, we use only ($x, y$) coordinate information. The stylus pressure level values are ignored. First we apply normalization to make our representation invariant to translations and scale distortions. The raw data that we capture from the tablet consist of integer values between 0 and 500 (tablet input box resolution). The new coordinates are such that the coordinate which has the maximum range varies between 0 and 100. Usually $x$ stays in this range, since most characters are taller than they are wide.   In order to train and test our classifiers, we need to represent digits as constant length feature vectors. A commonly used technique leading to good results is resampling the ( x_t, y_t) points. Temporal resampling (points regularly spaced in time) or spatial resampling (points regularly spaced in arc length) can be used here. Raw point data are already regularly spaced in time but the distance between them is variable. Previous research showed that spatial resampling to obtain a constant number of regularly spaced points on the trajectory yields much better performance, because it provides a better alignment between points. Our resampling algorithm uses simple linear interpolation between pairs of points. The resampled digits are represented as a sequence of T points ( x_t, y_t )_{t=1}^T, regularly spaced in arc length, as opposed to the input sequence, which is regularly spaced in time. So, the input vector size is 2*T, two times the number of points resampled. We considered spatial resampling to T=8,12,16 points in our experiments and found that T=8 gave the best trade-off between accuracy and complexity.","All input attributes are integers in the range 0..100.The last attribute is the class code 0..9","F. Alimoglu (1996) Combining Multiple Classifiers for Pen-Based Handwritten Digit Recognition, MSc Thesis, Institute of Graduate Studies in Science and Engineering, Bogazici University. [Web Link] [Web Link]  F. Alimoglu, E. Alpaydin, ""Methods of Combining Multiple Classifiers Based on Different Representations for Pen-based Handwriting Recognition,"" Proceedings of the Fifth Turkish Artificial Intelligence and Artificial Neural Networks Symposium (TAINN 96), June 1996, Istanbul, Turkey. [Web Link] [Web Link]","Please refer to the Machine Learning
Repository's citation policy","Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.  [View Context].Mikhail Bilenko and Sugato Basu and Raymond J. Mooney. Integrating constraints and metric learning in semi-supervised clustering. ICML. 2004.  [View Context].Fabian Hoti and Lasse Holmström. A semiparametric density estimation approach to pattern classification. Pattern Recognition, 37. 2004.  [View Context].Dennis DeCoste. Anytime Query-Tuned Kernel Machines via Cholesky Factorization. SDM. 2003.  [View Context].Greg Hamerly and Charles Elkan. Learning the k in k-means. NIPS. 2003.  [View Context].Thomas Serafini and G. Zanghirati and Del Zanna and T. Serafini and Gaetano Zanghirati and Luca Zanni. DIPARTIMENTO DI MATEMATICA. Gradient Projection Methods for. 2003.  [View Context].Manoranjan Dash and Huan Liu and Peter Scheuermann and Kian-Lee Tan. Fast hierarchical clustering and its validation. Data Knowl. Eng, 44. 2003.  [View Context].Marina Meila and Michael I. Jordan. Learning with Mixtures of Trees. Journal of Machine Learning Research, 1. 2000.  [View Context].Ethem Alpaydin. Combined 5 x 2 cv F Test for Comparing Supervised Classification Learning Algorithms. Neural Computation, 11. 1999.  [View Context].Georg Thimm and Emile Fiesler. IDIAP Technical report High Order and Multilayer Perceptron Initialization. IEEE Transactions. 1994.  [View Context].Georg Thimm and Emile Fiesler. High Order and Multilayer Perceptron Initialization.  [View Context].Adil M. Bagirov and Julien Ugon. An algorithm for computation of piecewise linear function separating two sets. CIAO, School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context].Perry Moerland. Mixtures of latent variable models for density estimation and classification. E S E A R C H R E P R O R T I D I A P D a l l e M o l l e I n s t i t u t e f o r Pe r cep t ua l A r t i f i c i a l Intelligence .  [View Context].Luca Zanni. An Improved Gradient Projection-based Decomposition Technique for Support Vector Machines. Dipartimento di Matematica, Universitdi Modena e Reggio Emilia.  [View Context].Adil M. Bagirov and John Yearwood. A new nonsmooth optimization algorithm for clustering. Centre for Informatics and Applied Optimization, School of Information Technology and Mathematical Sciences, University of Ballarat.  [View Context].Ahmed Hussain Khan and Intensive Care. Multiplier-Free Feedforward Networks. 174.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq,337,gene expression cancer RNA-Seq Data Set,../machine-learning-databases/00401/,Multivariate,801,Life,Real,20531,6/9/2016,"Classification, Clustering",N/A,59319,"Samuele Fiorini, samuele.fiorini '@' dibris.unige.it, University of Genoa, redistributed under Creative Commons license (http://creativecommons.org/licenses/by/3.0/legalcode) from https://www.synapse.org/#!Synapse:syn4301332.",Samples (instances) are stored row-wise. Variables (attributes) of each sample are RNA-Seq gene expression levels measured by illumina HiSeq platform.,"A dummy name (gene_XX) is given to each attribute. Check the original submission ([Web Link]#!Synapse:syn4301332), or the platform specs for the complete list of probes name. The attributes are ordered consitently with the original submission.","Weinstein, John N., et al. 'The cancer genome atlas pan-cancer analysis project.' Nature genetics 45.10 (2013): 1113-1120.",The original data set (hosted at [Web Link]#!Synapse:syn4301332) is maintained by the cancer genome atlas pan-cancer analysis project.,
http://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset,338,TV News Channel Commercial Detection Dataset Data Set,../machine-learning-databases/00326/,Multivariate,129685,Computer,Real,12,3/27/2015,"Classification, Clustering",N/A,72227,"Dr. Prithwijit Guha , Raghvendra D. Kannao and Ravishankar SoniMultimedia Analytics Lab, Department of Electrical and Electronics Engineering, Indian Institute of Technology, Guwahati, Indiardkannao '@' gmail.com , prithwijit.guha '@' gmail.com ","Automatic identification of commercial blocks in news videos finds a lot of applications in the domain of television broadcast analysis and monitoring. Commercials occupy almost 40-60%  of total air time. Manual segmentation of commercials from thousands of TV news channels is time consuming, and economically infeasible hence prompts the need for machine learning based Method. Classifying TV News commercials is a semantic video classification problem. TV News commercials on particular news channel are combinations of video shots uniquely characterized by audio-visual presentation. Hence various audio visual features extracted from video shots are widely used for TV commercial classification.  Indian News channels do not follow any particular news presentation format, have large variability and  dynamic nature presenting a challenging machine learning problem.  Features from 150 Hours of broadcast news videos from 5 different ( 3 Indian and  2 International News channels)  news channels. Viz. CNNIBN, NDTV 24X7, TIMESNOW, BBC and CNN are presented in this dataset.  Videos are recorded at resolution of 720 X 576 at 25 fps  using a DVR and set top box. 3 Indian channels are recorded concurrently while 2 International are recorded together. Feature file preserves the order of occurrence of shots.  ","Video shots are used as unit for generating instances. Broadcast News videos are segmented into video shots using RGB Colour Histogram matching Between consecutive video frames. From each video shot we have extracted 7 Audio ( viz. Short term energy,  zero crossing rate, Spectral Centroid, spectral Flux, spectral Roll off frequency, fundamental frequency and MFCC Bag of Audio Words) and 5 visual Features ( viz. Video shot length, Screen Text Distribution,  Motion Distribution, Frame Difference Distribution, Edge Change Ratio) from each video shot. Details of each extracted feature are as follows.Audio Features :- In general to attract viewer's attention TV commercials have higher audio amplitude, appropriate background music ( comparatively higher frequencies) as well as sharp transitions from one music to other or music to speech etc. We try to capture these properties by using low level audio features -- Short Time Energy (STE) ,  Zero Crossing Rate (ZCR), Spectral Centroid, Spectral Flux,  Spectral Roll-Off Frequency and Fundamental Frequency.  All of these short term audio features are calculated with audio frame size of 20 msec at 8000Hz sampling Frequency.  The Mean and standard deviation of all audio feature values are calculated over the shot, generating a 2D vector for each feature. The MFCC Bag of Audio Words have been successfully used in several existing speech/audio processing applications. This motivated us to compute the MFCC coefficients along with Delta and Delta-Delta Cepstrum from 150 hours of audio tracks. These coefficients are clustered into 4000 groups which form the Audio words. Each shot is then represented as a  4000 Dimensional Bag of Audio Words by forming the normalized histograms of the MFCC's extracted from 20 ms windows with overlap of 10 ms in the shots.  Video Features : Commercial video shots are usually short in length, fast visual transitions with peculiar placement of overlaid text bands. Video Shot Length is directly used as one of the feature. Placement of overlaid text bands is represented by  15 dimensional overlaid Text Distribution. To calculate Text Distribution feature, video frame is divided into a grid of size 5 X 3( 15 grid blocks).  The text distribution feature is obtained by averaging the fraction of text area present in a grid block over all frames of the shot. Motion Distribution, Frame Change Distribution and Edge Change Ratio captures the dynamic nature of the commercial shots. Motion Distribution is obtained by first computing dense optical flow (Horn-Schunk formulation) followed by  construction of a distribution of flow magnitudes over the entire shot with 40 uniformly divided bins in range of [0, 40]. Sudden changes in pixel intensities are grasped by Frame Difference Distribution. Such changes are not registered by optical flow. Thus, Frame Difference Distribution is also computed along with flow magnitude distributions. We obtain the frame difference by averaging absolute frame difference in each of 3 color channels and the distribution is constructed with 32 bins in the range of [0, 255] . Edge Change Ratio Captures the motion of edges between consecutive frames and is defined as ratio of displaced edge pixels to the total number of edge pixels in a frame. We calculate the mean and variance of the ECR over the entire shot.   The Feature File is represented in Lib SVM data format and contains approximetly 63% commercial instances( Positives). Dimension index for different Features are as FollowsLabels : - +1/-1 ( Commercials/Non Commercials) FeatureDimension Index in feature FileShot Length1Motion Distribution( Mean and Variance)2 - 3Frame Difference Distribution ( Mean and Variance)4 - 5Short time energy ( Mean and Variance)6 â€“ 7 ZCR( Mean and Variance)8 - 9Spectral Centroid ( Mean and Variance)10 - 11Spectral Roll off ( Mean and Variance)12 - 13Spectral Flux ( Mean and Variance)14 - 15Fundamental Frequency ( Mean and Variance)16 - 17Motion Distribution ( 40 bins)18 -  58Frame Difference Distribution ( 32 bins)59 - 91Text area distribution (  15 bins Mean  and 15 bins for variance )92 - 122Bag of Audio Words ( 4000 bins)123 -  4123Edge change Ratio ( Mean and Variance)4124 - 4125  Key frames for shots can be made available on request.","Part of this dataset was used in A. Vyas, R. Kannao, V. Bhargava and P. Guha, â€œCommercial Block Detection in Broadcast News Videos,â€ in Proc. Ninth Indian Conference on Computer Vision, Graphics and Image Processing, Dec. 2014.","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/QSAR+aquatic+toxicity,339,QSAR aquatic toxicity Data Set,../machine-learning-databases/00505/,Multivariate,546,Physical,Real,9,9/23/2019,Regression,N/A,14204,"Davide Ballabio (davide.ballabio '@' unimib.it), Matteo Cassotti, Viviana Consonni, Roberto Todeschini, Milano Chemometrics and QSAR Research Group (http://www.michem.unimib.it/), UniversitÃ  degli Studi Milano - Bicocca, Milano (Italy)","This dataset was used to develop quantitative regression QSAR models to predict acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow) on a set of 908 chemicals. to predict acute aquatic toxicity towards Daphnia Magna. LC50 data, which is the concentration that causes death in 50% of test D. magna over a test duration of 48 hours, was used as model response. The model comprised 8 molecular descriptors: TPSA(Tot) (Molecular properties), SAacc (Molecular properties), H-050 (Atom-centred fragments), MLOGP (Molecular properties), RDCHI (Connectivity indices), GATS1p (2D autocorrelations), nN (Constitutional indices), C-040 (Atom-centred fragments). Details can be found in the quoted reference: M. Cassotti, D. Ballabio, V. Consonni, A. Mauri, I. V. Tetko, R. Todeschini (2014). Prediction of acute aquatic toxicity towards daphnia magna using GA-kNN method, Alternatives to Laboratory Animals (ATLA), 42,31:41; doi: 10.1177/026119291404200106","8 molecular descriptors and 1 quantitative experimental response:1) TPSA(Tot)2) SAacc3) H-0504) MLOGP5) RDCHI6) GATS1p7) nN8) C-0409) quantitative response, LC50 [-LOG(mol/L)]","M. Cassotti, D. Ballabio, V. Consonni, A. Mauri, I. V. Tetko, R. Todeschini (2014). Prediction of acute aquatic toxicity towards daphnia magna using GA-kNN method, Alternatives to Laboratory Animals (ATLA), 42,31:41; doi: 10.1177/026119291404200106","Please, cite the following paper if you publish results based on the QSAR aquatic toxicity dataset: M. Cassotti, D. Ballabio, V. Consonni, A. Mauri, I. V. Tetko, R. Todeschini (2014). Prediction of acute aquatic toxicity towards daphnia magna using GA-kNN method, Alternatives to Laboratory Animals (ATLA), 42,31:41; doi: 10.1177/026119291404200106",
http://archive.ics.uci.edu/ml/datasets/Abalone,340,Abalone Data Set,../machine-learning-databases/abalone/,Multivariate,4177,Life,"Categorical, Integer, Real",8,12/1/1995,Classification,No,956229,"Data comes from an original (non-machine-learning) study:Warwick J Nash, Tracy L Sellers, Simon R Talbot, Andrew J Cawthorn and Wes B Ford (1994) ""The Population Biology of Abalone (_Haliotis_ species) in Tasmania. I. Blacklip Abalone (_H. rubra_) from the North Coast and Islands of Bass Strait"", Sea Fisheries Division, Technical Report No. 48 (ISSN 1034-3288) Original Owners of Database: Marine Resources DivisionMarine Research Laboratories - TaroonaDepartment of Primary Industry and Fisheries, TasmaniaGPO Box 619F, Hobart, Tasmania 7001, Australia(contact: Warwick Nash +61 02 277277, wnash '@' dpi.tas.gov.au) Donor of Database: Sam Waugh (Sam.Waugh '@' cs.utas.edu.au)Department of Computer Science, University of TasmaniaGPO Box 252C, Hobart, Tasmania 7001, Australia","Predicting the age of abalone from physical measurements.  The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task.  Other measurements, which are easier to obtain, are used to predict the age.  Further information, such as weather patterns and location (hence food availability) may be required to solve the problem. From the original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been scaled for use with an ANN (by dividing by 200).","Given is the attribute name, attribute type, the measurement unit and a brief description.  The number of rings is the value to predict: either as a continuous value or as a classification problem. Name / Data Type / Measurement Unit / Description-----------------------------Sex / nominal / -- / M, F, and I (infant)Length / continuous / mm / Longest shell measurementDiameter	/ continuous / mm / perpendicular to lengthHeight / continuous / mm / with meat in shellWhole weight / continuous / grams / whole abaloneShucked weight / continuous	 / grams / weight of meatViscera weight / continuous / grams / gut weight (after bleeding)Shell weight / continuous / grams / after being driedRings / integer / -- / +1.5 gives the age in years The readme file contains attribute statistics.","Sam Waugh (1995) ""Extending and benchmarking Cascade-Correlation"", PhD thesis, Computer Science Department, University of Tasmania.[Web Link]David Clark, Zoltan Schreter, Anthony Adams ""A Quantitative Comparison of Dystal and Backpropagation"", submitted to the Australian Conference on Neural Networks (ACNN'96).","Please refer to the Machine Learning
Repository's citation policy","Ilhan Uysal and H. Altay Guvenir. Instance-Based Regression by Partitioning Feature Projections. Applied. 2004.  [View Context].Jianbin Tan and David L. Dowe. MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes. Australian Conference on Artificial Intelligence. 2003.  [View Context].Edward Snelson and Carl Edward Rasmussen and Zoubin Ghahramani. Warped Gaussian Processes. NIPS. 2003.  [View Context].Alexander G. Gray and Bernd Fischer and Johann Schumann and Wray L. Buntine. Automatic Derivation of Statistical Algorithms: The EM Family and Beyond. NIPS. 2002.  [View Context].Christopher K I Williams and Carl Edward Rasmussen and Anton Schwaighofer and Volker Tresp. Observations on the Nystrom Method for Gaussian Process Prediction. Division of Informatics Gatsby Computational Neuroscience Unit University of Edinburgh University College London. 2002.  [View Context].Marc Sebban and Richard Nock and Stéphane Lallich. Stopping Criterion for Boosting-Based Data Reduction Techniques: from Binary to Multiclass Problem. Journal of Machine Learning Research, 3. 2002.  [View Context].Anton Schwaighofer and Volker Tresp. Transductive and Inductive Methods for Approximate Gaussian Process Regression. NIPS. 2002.  [View Context].Shai Fine and Katya Scheinberg. Incremental Learning and Selective Sampling via Parametric Optimization Framework for SVM. NIPS. 2001.  [View Context].Matthew Mullin and Rahul Sukthankar. Complete Cross-Validation for Nearest Neighbor Classifiers. ICML. 2000.  [View Context].Nir Friedman and Iftach Nachman. Gaussian Process Networks. UAI. 2000.  [View Context].Bernhard Pfahringer and Hilan Bensusan and Christophe G. Giraud-Carrier. Meta-Learning by Landmarking Various Learning Algorithms. ICML. 2000.  [View Context].Iztok Savnik and Peter A. Flach. Discovery of multivalued dependencies from relations. Intell. Data Anal, 4. 2000.  [View Context].Tapio Elomaa and Juho Rousu. General and Efficient Multisplitting of Numerical Attributes. Machine Learning, 36. 1999.  [View Context].Christopher J. Merz. Using Correspondence Analysis to Combine Classifiers. Machine Learning, 36. 1999.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Khaled A. Alsabti and Sanjay Ranka and Vineet Singh. CLOUDS: A Decision Tree Classifier for Large Datasets. KDD. 1998.  [View Context].Marko Robnik-Sikonja and Igor Kononenko. Pruning Regression Trees with MDL. ECAI. 1998.  [View Context].Christopher J. Merz. Combining Classifiers Using Correspondence Analysis. NIPS. 1997.  [View Context].Christian Borgelt and Rudolf Kruse. Speeding Up Fuzzy Clustering with Neural Network Techniques. Research Group Neural Networks and Fuzzy Systems Dept. of Knowledge Processing and Language Engineering, School of Computer Science Otto-von-Guericke-University of Magdeburg.  [View Context].Miguel Moreira and Alain Hertz and Eddy Mayoraz. Data binarization by discriminant elimination. Proceedings of the ICML-99 Workshop: From Machine Learning to.  [View Context].Johannes Furnkranz. Pairwise Classification as an Ensemble Technique. Austrian Research Institute for Artificial Intelligence.  [View Context].Edward Snelson and Carl Edward Rasmussen and Zoubin Ghahramani. Draft version; accepted for NIPS*03 Warped Gaussian Processes. Gatsby Computational Neuroscience Unit University College London.  [View Context].Sally Jo Cunningham. Dataset cataloging metadata for machine learning applications and research. Department of Computer Science University of Waikato.  [View Context].Bernhard Pfahringer and Hilan Bensusan. Tell me who can learn you and I can tell you who you are: Landmarking Various Learning Algorithms. Austrian Research Institute for Artificial Intelligence.  [View Context].. Efficiently Updating and Tracking the Dominant Kernel Eigenspace. (a) Katholieke Universiteit Leuven Department of Electrical Engineering, ESAT-SCD-SISTA.  [View Context].Luc Hoegaerts and J. A. K Suykens and J. Vandewalle and Bart De Moor. Subset Based Least Squares Subspace Regression in RKHS. Katholieke Universiteit Leuven Department of Electrical Engineering, ESAT-SCD-SISTA.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context].Rong-En Fan and P. -H Chen and C. -J Lin. Working Set Selection Using the Second Order Information for Training SVM. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Johannes Furnkranz. Round Robin Rule Learning. Austrian Research Institute for Artificial Intelligence.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Logic+Theorist,341,Logic Theorist Data Set,../machine-learning-databases/logic-theorist/,Domain-Theory,N/A,Computer,N/A,N/A,N/A,N/A,N/A,34106,Donated by Paul O'Rorke's (described in Machine Learning) ,N/A,N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Shoulder+Implant+X-Ray+Manufacturer+Classification,342,Shoulder Implant X-Ray Manufacturer Classification Data Set,../machine-learning-databases/00517/,Multivariate,597,Life,Real,1,5/20/2020,Classification,N/A,1843,"Kazunori Okada, kazokada '@' sfsu.edu, BIDAL: Biomedical Image and Data Analyses Lab, Department of Computer Science, San Francisco State UniversityMaya Belen Stark, maya.b.stark '@' gmail.com, BIDAL: Biomedical Image and Data Analyses Lab, Department of Computer Science, San Francisco State UniversityBrian Feeley, brian.feeley '@' ucsf.edu, Department of Orthopedic Surgery, University of California, San Francisco","Images were collected by Maya Stark at BIDAL Lab at SFSU for her MS thesis project. They are from The UW Shoulder Site ([Web Link]), manufacturer websites, and Feeley Lab at UCSF. The original collection included 605 X-ray images. Eight images that appeared to have been taken from the same patients were removed, resulting in the final 597 images. The final set contains images from the following manufacturers: 83 from Cofield, 294 from Depuy, 71 from Tornier, and 149 from Zimmer, resulting in a 4-class classification problem. Class labels are provided as the manufacturer name in file names. ",Images are with 8-bit grayscale and various dimensions in jpeg format. ,"1) Maya Belen Stark, Automatic detection and segmentation of shoulder implants in X-ray images, MS thesis, San Francisco State University, 2018, [Web Link] 2) Gregor Urban, Saman Porhemmat, Maya Stark, Brian Feeley, Kazunori Okada, Pierre Baldi, Classifying Shoulder Implants in X-ray Images using Deep Learning, Computational and Structural Biotechnology Journal, 2020: e-pub: [Web Link] ","When using this data, please cite above two relevant publications of Stark et al. (2018) and Urban et al. (2020).",
http://archive.ics.uci.edu/ml/datasets/Steel+Plates+Faults,343,Steel Plates Faults Data Set,../machine-learning-databases/00198/,Multivariate,1941,Physical,"Integer, Real",27,10/26/2010,Classification,N/A,81708,"Semeion, Research Center of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy.www.semeion.it","Type of dependent variables (7 Types of Steel Plates Faults):1.Pastry2.Z_Scratch3.K_Scatch4.Stains5.Dirtiness6.Bumps7.Other_Faults","27 independent variables:X_MinimumX_MaximumY_MinimumY_MaximumPixels_AreasX_PerimeterY_PerimeterSum_of_LuminosityMinimum_of_LuminosityMaximum_of_LuminosityLength_of_ConveyerTypeOfSteel_A300TypeOfSteel_A400Steel_Plate_ThicknessEdges_IndexEmpty_IndexSquare_IndexOutside_X_IndexEdges_X_IndexEdges_Y_IndexOutside_Global_IndexLogOfAreasLog_X_IndexLog_Y_IndexOrientation_IndexLuminosity_IndexSigmoidOfAreas","1.M Buscema, S Terzi, W Tastle, A New Meta-Classifier,in NAFIPS 2010, Toronto (CANADA),26-28 July 2010, 978-1-4244-7858-6/10 Â©2010 IEEE2.M Buscema, MetaNet: The Theory of Independent Judges, in Substance Use & Misuse, 33(2), 439-461,1998","dataset provided by Semeion, Research Center of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy.www.semeion.it  ",
http://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly,344,Sales_Transactions_Dataset_Weekly Data Set,../machine-learning-databases/00396/,"Multivariate, Time-Series",811,N/A,"Integer, Real",53,7/16/2017,Clustering,N/A,69649,"James Tan, jamestansc '@' suss.edu.sg, Singapore University of Social Sciences",52 columns for 52 weeks; normalised values of provided too.,"Product_Code52 weeks: W0, W1, ..., W51.Normalised vlaues of weekly data: Normalised 0, Normalised 1, ..., Normalised 51 ","@inproceedings{tan2015finding,  title={Finding similar time series in sales transaction data},  author={Tan, Swee Chuan and San Lau, Pei and Yu, XiaoWei},  booktitle={International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},  pages={645--654},  year={2015},  organization={Springer, Cham}}","@inproceedings{tan2014time,  title={Time series clustering: A superior alternative for market basket analysis},  author={Tan, Swee Chuan and San Lau, Jess Pei},  booktitle={Proceedings of the First International Conference on Advanced Data and Information Engineering (DaEng-2013)},  pages={241--248},  year={2014},  organization={Springer, Singapore}}",
http://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions,345,Physical Unclonable Functions Data Set,../machine-learning-databases/00463/,Multivariate,6000000,Computer,Integer,129,10/8/2018,Classification,N/A,15457,"Ahmad O. Aseeri (a.aseeri '@' psau.edu.sa), Yu Zhuang (yu.zhuang '@' ttu.edu) - Department of Computer Science, Texas Tech University, United StatesMohammed Saeed Alkatheiri (msalkatheri '@' uj.edu.sa) - Faculty of Computing and Information Technology, University of Jeddah, Saudi Arabia", ,"There are two datasets generated from k-XOR Arbiter PUFs simulation:   (1) 5-XOR_128bit dataset:  This dataset is generated using 5-XOR arbiters of 128bit stages PUF. It consists of 6 million rows and 129 attributes where the last attribute is the class label (1 or -1). It is divided into two sets: training set (5 million) and testing set (1 million).   (1) 6-XOR_64bit dataset:  This dataset is generated using 6-XOR arbiters of 64bit stages PUF. It consists of 2.4 million rows and 65 attributes where the last attribute is the class label (1 or -1). It is divided into two sets: training set (2 million) and testing set (400K). ","[1] Aseeri, A. O., Zhuang, Y., & Alkatheiri, M. S. (2018, July). A Machine Learning-Based Security Vulnerability Study on XOR PUFs for Resource-Constraint Internet of Things. In 2018 IEEE International Congress on Internet of Things (ICIOT) (pp. 49-56). IEEE.",The use of this dataset in publications should be acknowledged by referencing publication [1] listed above.,
http://archive.ics.uci.edu/ml/datasets/Sponge,346,Sponge Data Set,../machine-learning-databases/sponge/,Multivariate,76,Life,"Categorical, Integer",45,N/A,Clustering,Yes,93881,"Creators:  Iosune Uriz and Marta DomingoCentre d'Estudis Aban\c{c}ats de Blanes (CSIC)Cami de Santa Barbara. Blanes (Girona). Spain Donor:  Javier B\'ejar and Ulises Cort\'es (bejar '@' lsi.upc.es)Dept. Llenguatges i Sistemes Inform\`atics;Universitat Politecnica de Catalunya. Barcelona; Spain",These are atlantic-mediterranean marine sponges that belong to O.Hadromerida (Demospongiae.Porifera).,"27 attributes are non-numeric and nominal.15 attributes are boolean and take the values (NO SI).3 attributes are numeric and take natural numbers.","Domingo, M. ""Aplicaci\'o de t\`ecniques de I.A. (LINNEO) a la classificaci\'o sistem\`atica: O.Hadromerida (Demospongiae.Porifera). Master Thesis. Departament d'ecologia. Universitat de Barcelona. Martin, M and Sanguesa, R. and Cor\'es ""Biasing induction with previous knowledge for knowledge acquisition in imprecise domains''.  Les syst\`emes experts et leus applications. Onzi\'emes Journ\'ees Internationales. Avignon'91. Vol 1. pp. 359-370. Avignon, France. 1991. Martin, M. and Sanguesa, R. and Cort\'es U. ""Knowledge acquisition combining analytical and empirical techniques''. Proceedings of the Eighth International Workshop of Machine Learning. ML 91. pp 657-661. Evanston, Illinois, USA 1991.[Web Link]  Bejar, J. and Cort\'es, U. ""LINNEO+: Herramienta para la adquisicion de conocimiento y generacion de reglas de clasificaci\'on en dominios poco estructurados''. Proceedings del III Congreso Iberoamericano de Inteligencia Artificial. IBERAMIA 92. pp 471-482. La Habana (Cuba).[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/EEG+Eye+State,347,EEG Eye State Data Set,../machine-learning-databases/00264/,"Multivariate, Sequential, Time-Series",14980,Life,"Integer, Real",15,6/10/2013,Classification,N/A,121008,"Oliver Roesler, it12148 '@' lehre.dhbw-stuttgart.de , Baden-Wuerttemberg Cooperative State University (DHBW), Stuttgart, Germany",All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data.,Provide information about each attribute in your data set.,Provide references to papers that have cited this data set in the past (if any).,"If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Hayes-Roth,348,Hayes-Roth Data Set,../machine-learning-databases/hayes-roth/,Multivariate,160,Social,Categorical,5,3/1/1989,Classification,No,101315,"Creators:  Barbara and Frederick Hayes-Roth Donor:  David W. Aha (aha '@' ics.uci.edu) (714) 856-8779   ","This database contains 5 numeric-valued attributes.  Only a subset of 3 are used during testing (the latter 3).  Furthermore, only 2 of the 3 concepts are ""used"" during testing (i.e., those with the prototypes 000 and 111).  I've mapped all values to their zero-indexing equivalents. Some instances could be placed in either category 0 or 1.  I've followed the authors' suggestion, placing them in each category with equal probability. I've replaced the actual values of the attributes (i.e., hobby has values chess, sports and stamps) with numeric values.  I think this is how the authors' did this when testing the categorization models described in the paper.  I find this unfair.  While the subjects were able to bring background knowledge to bear on the attribute values and their relationships, the algorithms were provided with no such knowledge.  I'm uncertain whether the 2 distractor attributes (name and hobby) are presented to the authors' algorithms during testing.  However, it is clear that only the age, educational status, and marital status attributes are given during the human subjects' transfer tests.  ","      -- 1. name: distinct for each instance and represented numerically      -- 2. hobby: nominal values ranging between 1 and 3      -- 3. age: nominal values ranging between 1 and 4      -- 4. educational level: nominal values ranging between 1 and 4      -- 5. marital status: nominal values ranging between 1 and 4      -- 6. class: nominal value between 1 and 3","Hayes-Roth, B., & Hayes-Roth, F. (1977).  Concept learning and the recognition and classification of exemplars.  Journal of Verbal Learning and Verbal Behavior, 16, 321-338.[Web Link]  Anderson, J.R., & Kline, P.J. (1979).  A learning system and its psychological implications.  In Proceedings of the Sixth International Joint Conference on Artificial Intelligence (pp. 16-21).  Tokyo, Japan: Morgan Kaufmann. Aha, D.W. (1989). Incremental learning of independent, overlapping, and graded concept descriptions with an instance-based process framework.Manuscript submitted for publication.","Please refer to the Machine Learning
Repository's citation policy","Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].Bob Ricks and Dan Ventura. Training a Quantum Neural Network. NIPS. 2003.  [View Context].Gabor Melli. A Lazy Model-Based Approach to On-Line Classification. University of British Columbia. 1989.  [View Context].Anthony D. Griffiths and Derek Bridge. A Yardstick for the Evaluation of Case-Based Classifiers. Department of Computer Science, University of York.  [View Context].Jerome H. Friedman and Ron Kohavi and Youngkeol Yun. To appear in AAAI-96 Lazy Decision Trees. Statistics Department and Stanford Linear Accelerator Center Stanford University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Daphnet+Freezing+of+Gait,349,Daphnet Freezing of Gait Data Set,../machine-learning-databases/00245/,"Multivariate, Time-Series",237,Life,Real,9,3/7/2013,Classification,N/A,70595," Daniel Roggen, University of Newcastle Upon Tyne, UK, daniel.roggen '@' ieee.org Meir Plotnik,  Sheba Medical Center, IL, meir.plotnikPeleg '@' sheba.health.gov.il Jeff Hausdorff, Tel Aviv Sourasky Medical Center, jhausdor '@' tlvmc.gov.il  This dataset was collected as part of the EU FP6 project Daphnet, grant number 018474-2.Additional effort to publish this dataset was supported in part by the EU FP7 project CuPiD, grant number 288516."," The Daphnet Freezing of Gait Dataset is a dataset devised to benchmark automatic methods to recognize gait freeze from wearable acceleration sensors placed on legs and hip. The dataset was recorded in the lab with emphasis on generating many freeze events. Users performed there kinds of tasks: straight line walking, walking with numerous turns, and finally a more realistic activity of daily living (ADL) task, where users went into different rooms while fetching coffee, opening doors, etc. This dataset is the result of a collaboration between the Laboratory for Gait and Neurodynamics, Tel Aviv Sourasky Medical Center, Israel and the Wearable Computing Laboratory, ETH Zurich, Switzerland. Recordings were run at the Tel Aviv Sourasky Medical Center in 2008. The study was approved by the local Human Subjects Review Committee, and was performed in accordance with the ethical standards of the Declaration of Helsinki."," Each file comprises the data in a matrix format, with one line per sample, and one column per channel. The channels are as follows:    Time of sample in millisecond    Ankle (shank) acceleration - horizontal forward acceleration [mg]    Ankle (shank) acceleration - vertical [mg]    Ankle (shank) acceleration - horizontal lateral [mg]    Upper leg (thigh) acceleration - horizontal forward acceleration [mg]    Upper leg (thigh) acceleration - vertical [mg]    Upper leg (thigh) acceleration - horizontal lateral [mg]    Trunk acceleration - horizontal forward acceleration [mg]    Trunk acceleration - vertical [mg]    Trunk acceleration - horizontal lateral [mg]    Annotation [0, 1, or 2] The meaning of the annotations are as follows:    0: not part of the experiment. For instance the sensors are installed on the user or the user is performing activities unrelated to the experimental protocol, such as debriefing    1: experiment, no freeze (can be any of stand, walk, turn)    2: freeze"," [1] Marc BÃ¤chlin, Meir Plotnik, Daniel Roggen, Nir Giladi, Jeffrey M Hausdorff and Gerhard TrÃ¶ster, A Wearable System to Assist Walking of Parkinson's Disease Patients.Methods of Information in Medicine, 49:1(88-95), 2010[2] Meir Plotnik, Marc BÃ¤chlin, Inbal Maidan, Daniel Roggen, Gerhard TrÃ¶ster, Nir Giladi and Jeffrey M Hausdorff, Automated biofeedback assistance for freezing of gait in patients with Parkinson's disease. Proceedings of the International Society for Posture and Gait Research (ISPGR), Bologna, Italy, 2009[3] Meir Plotnik, Marc BÃ¤chlin, Daniel Roggen, Noit Inbar, Inbal Maidan, Talia Herman, Marina Brozgol, Eliya Shaviv, Gerhard TrÃ¶ster and Jeffrey M Hausdorff, Automated treatment of freezing of gait in Parkinson's disease using a wearable device that automatically detects freezing. Annual meeting of the Israeli Neurological Society, Israel, pages 63, 2009[4] Marc BÃ¤chlin, Daniel Roggen, Meir Plotnik, Jeffrey M Hausdorff, Nir Giladi and Gerhard TrÃ¶ster, Online Detection of Freezing of Gait in Parkinson's Disease Patients: A Performance Characterization. Proceedings of the 4th International Conference on Body Area Networks, 2009[5] Marc BÃ¤chlin, Meir Plotnik, Daniel Roggen, Noit Inbar, Nir Giladi, Jeffrey M Hausdorff and Gerhard TrÃ¶ster. Parkinson patients' perspective on context aware wearable technology for auditive assistance. Proceedings of the 3rd International Conference on Pervasive Computing Technologies for Healthcare, 2009[6] Marc BÃ¤chlin, Daniel Roggen, Meir Plotnik, Noit Inbar, Inbal Maidan, Talia Herman, Marina Brozgol, Eliya Shaviv, Nir Giladi, Jeffrey M Hausdorff and Gerhard TrÃ¶ster,Potentials of enhanced context awareness in wearable assistants for Parkinsonâ€™s disease patients with freezing of gait syndrome. Proceedings of the 13th International Symposium on Wearable Computers (ISWC), pages 123-130, 2009[7] Sinziana Mazilu, Michael Hardegger, Zack Zhu, Daniel Roggen, Gerhard TrÃ¶ster, Meir Plotnik, Jeff Hausdorff. Online Detection of Freezing of Gait with Smartphones and Machine Learning Techniques. Proc 6th Int Conf on Pervasive Computing Technologies for Healthcare, 2012"," Use of this dataset in publications must be acknowledged by referencing the following publication: Marc BÃ¤chlin, Meir Plotnik, Daniel Roggen, Inbal Maidan, Jeffrey M. Hausdorff, Nir Giladi, and Gerhard TrÃ¶ster, Wearable Assistant for Parkinson's Disease Patients With the Freezing of Gait Symptom. IEEE Transactions on Information Technology in Biomedicine, 14(2), March 2010, pages 436-446 This paper describes the dataset in details. It explain the data acquisition protocol, the kind of sensor used and their placement, and the nature of the data acquired. It also provides baseline results for the automated detection of freezing of gait, against which newer methods can be benchmarked. In particular it describes detection sensitivity/specificity for 3 sensor placements and 4 kinds of derived sensor signals, it analyzes detection latency, and provides first insight into user specific v.s. user independent performance. We also appreciate if you inform us (daniel.roggen '@' ieee.org) of any publication using this dataset for cross-referencing purposes.",
http://archive.ics.uci.edu/ml/datasets/SML2010,350,SML2010 Data Set,../machine-learning-databases/00274/,"Multivariate, Sequential, Time-Series, Text",4137,Computer,Real,24,1/9/2014,Regression,Yes,127384,"Dr. Francisco Zamora-Martinez, Pablo Romeu-Guallart, Dr. Juan Pardo.francisco.zamora '@' uch.ceu.es Embedded Systems and Artificial Intelligence (ESAI) research groupDep. de Ciencias FÃ­sicas, MatemÃ¡ticas y de la ComputaciÃ³nUniversidad CEU Cardenal Herrera","The dataset could contain missing values. The data was sampled every minute, computing and uploading it smoothed with 15 minute means. The header of the data file is a commentary (begins with #) indicating which data is stored at which column (in Spanish). The data is time information is in UTC.","The attributes are: 1. Date: in UTC.2. Time: in UTC.3. Indoor temperature (dinning-room), in ÂºC.4. Indoor temperature (room), in ÂºC.5. Weather forecast temperature, in ÂºC.6. Carbon dioxide in ppm (dinning room).7. Carbon dioxide in ppm (room).8. Relative humidity (dinning room), in %.9. Relative humidity (room), in %.10. Lighting (dinning room), in Lux.11. Lighting (room), in Lux.12. Rain, the proportion of the last 15 minutes where rain was detected (a value in range [0,1]).13. Sun dusk.14. Wind, in m/s.15. Sun light in west facade, in Lux.16. Sun light in east facade, in Lux.17. Sun light in south facade, in Lux.18. Sun irradiance, in W/m2.19. Enthalpic motor 1, 0 or 1 (on-off).20. Enthalpic motor 2, 0 or 1 (on-off).21. Enthalpic motor turbo, 0 or 1 (on-off).22. Outdoor temperature, in ÂºC.23. Outdoor relative humidity, in %.24. Day of the week (computed from the date), 1=Monday, 7=Sunday.",N/A,"F. Zamora-Martínez, P. Romeu, P. Botella-Rocamora, J. Pardo, On-line learning of indoor temperature forecasting models towards energy efficiency, Energy and Buildings, Volume 83, November 2014, Pages 162-172, ISSN 0378-7788, [Web Link].",
http://archive.ics.uci.edu/ml/datasets/SECOM,351,SECOM Data Set,../machine-learning-databases/secom/,Multivariate,1567,Computer,Real,591,11/19/2008,"Classification, Causal-Discovery",Yes,121270,"Authors: Michael McCann, Adrian Johnston ","A complex modern semi-conductor manufacturing process is normally under consistent surveillance via the monitoring of signals/variables collected from sensors and or process measurement points. However, not all of these signals are equally valuable in a specific monitoring system. The measured signals contain a combination of useful information, irrelevant information as well as noise. It is often the case that useful information is buried in the latter two. Engineers typically have a much larger number of signals than are actually required. If we consider each type of signal as a feature, then feature selection may be applied to identify the most relevant signals. The Process Engineers may then use these signals to determine key factors contributing to yield excursions downstream in the process. This will enable an increase in process throughput, decreased time to learning and reduce the per unit production costs. To enhance current business improvement techniques the application of feature selection as an intelligent systems technique is being investigated. The dataset presented in this case represents a selection of such features where each example represents a single production entity with associated measured features and the labels represent a simple pass/fail yield for in house line testing, figure 2, and associated date time stamp. Where –1 corresponds to a pass and 1 corresponds to a fail and the data time stamp is for that specific test point.  Using feature selection techniques it is desired to rank features according to their impact on the overall yield for the product, causal relationships may also be considered with a view to identifying the key features. Results may be submitted in terms of feature relevance for predictability using error rates as our evaluation metrics. It is suggested that cross validation be applied to generate these results. Some baseline results are shown below for basic feature selection techniques using a simple kernel ridge classifier and 10 fold cross validation. Baseline Results: Pre-processing objects were applied to the dataset simply to standardize the data and remove the constant features and then a number of different feature selection objects selecting 40 highest ranked features were applied with a simple classifier to achieve some initial results. 10 fold cross validation was used and the balanced error rate (*BER) generated as our initial performance metric to help investigate this dataset.  SECOM Dataset: 1567 examples 591 features, 104 fails FSmethod (40 features) BER % True + % True - %S2N (signal to noise) 34.5 +-2.6 57.8 +-5.3 73.1 +2.1Ttest 33.7 +-2.1 59.6 +-4.7 73.0 +-1.8Relief 40.1 +-2.8 48.3 +-5.9 71.6 +-3.2Pearson 34.1 +-2.0 57.4 +-4.3 74.4 +-4.9Ftest 33.5 +-2.2 59.1 +-4.8 73.8 +-1.8Gram Schmidt 35.6 +-2.4 51.2 +-11.8 77.5 +-2.3","Key facts: Data Structure: The data consists of 2 files the dataset file SECOM consisting of 1567 examples each with 591 features a 1567 x 591 matrix and a labels file containing the classifications and date time stamp for each example.  As with any real life data situations this data contains null values varying in intensity depending on the individuals features. This needs to be taken into consideration when investigating the data either through pre-processing or within the technique applied.  The data is represented in a raw text file each line representing an individual example and the features seperated by spaces. The null values are represented by the 'NaN' value as per MatLab. ",N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Parkinson%27s+Disease+Classification,352,Parkinson's Disease Classification Data Set,../machine-learning-databases/00470/,Multivariate,756,Computer,"Integer, Real",754,11/5/2018,Classification,N/A,60392,"C. Okan Sakar a, Gorkem Serbes b, Aysegul Gunduz c, Hunkar C. Tunc a, Hatice Nizam d, Betul Erdogdu Sakar e, Melih Tutuncu c, Tarkan Aydin a, M. Erdem Isenkul d, Hulya Apaydin c a Department of Computer Engineering, Bahcesehir University, Istanbul, 34353, Turkeyb Department of Biomedical Engineering, Yildiz Technical University, Istanbul, 34220, Turkey c Department of Neurology, CerrahpaÅŸa Faculty of Medicine, Istanbul University, Istanbul 34098, Turkeyd Department of Computer Engineering, Istanbul University, Istanbul, 34320, Turkey e Department of Software Engineering, Bahcesehir University, Istanbul, 34353, Turkeye-mails: {okan.sakar '@' eng.bau.edu.tr; gserbes '@' yildiz.edu.tr;draysegulgunduz '@' yahoo.com; hunkarcan.tunc '@' stu.bahcesehir.edu.tr; haticenizam92 '@' gmail.com; betul.erdogdu '@' eng.bau.edu.tr; tutuncumelih '@' yahoo.com; tarkan.aydin '@' eng.bau.edu.tr; eisenkul '@' istanbul.edu.tr; hulyapay '@' istanbul.edu.tr}","The data used in this study were gathered from 188 patients with PD (107 men and 81 women) with ages ranging from 33 to 87 (65.1Â±10.9) at the Department of Neurology in CerrahpaÅŸa Faculty of Medicine, Istanbul University. The control group consists of 64 healthy individuals (23 men and 41 women) with ages varying between 41 and 82 (61.1Â±8.9). During the data collection process, the microphone is set to 44.1 KHz and following the physicianâ€™s examination, the sustained phonation of the vowel /a/ was collected from each subject with three repetitions.","Various speech signal processing algorithms including Time Frequency Features, Mel Frequency Cepstral Coefficients (MFCCs), Wavelet Transform based Features, Vocal Fold Features and TWQT features have been applied to the speech recordings of Parkinson's Disease (PD) patients to extract clinically useful information for PD assessment.",Provide references to papers that have cited this data set in the past (if any).,"If you use this dataset, please cite:Sakar, C.O., Serbes, G., Gunduz, A., Tunc, H.C., Nizam, H., Sakar, B.E., Tutuncu, M., Aydin, T., Isenkul, M.E. and Apaydin, H., 2018. A comparative analysis of speech signal processing algorithms for Parkinsonâ€™s disease classification and the use of the tunable Q-factor wavelet transform. Applied Soft Computing, DOI: [Web Link]",
http://archive.ics.uci.edu/ml/datasets/Thyroid+Disease,353,Thyroid Disease Data Set,../machine-learning-databases/thyroid-disease/,"Multivariate, Domain-Theory",7200,Life,"Categorical, Real",21,1/1/1987,Classification,N/A,237967,Ross Quinlan,"# From Garavan Institute# Documentation: as given by Ross Quinlan# 6 databases from the Garavan Institute in Sydney, Australia# Approximately the following for each database:     ** 2800 training (data) instances and 972 test instances    ** Plenty of missing data    ** 29 or so attributes, either Boolean or continuously-valued  # 2 additional databases, also from Ross Quinlan, are also here     ** Hypothyroid.data and sick-euthyroid.data    ** Quinlan believes that these databases have been corrupted    ** Their format is highly similar to the other databases  # 1 more database of 9172 instances that cover 20 classes, and a related domain theory# Another thyroid database from Stefan Aeberhard     ** 3 classes, 215 instances, 5 attributes    ** No missing values  # A Thyroid database suited for training ANNs     ** 3 classes    ** 3772 training instances, 3428 testing instances    ** Includes cost data (donated by Peter Turney)  ",N/A,"Quinlan,J.R., Compton,P.J., Horn,K.A., & Lazurus,L. (1986). Inductive knowledge acquisition: A case study. In Proceedings of the Second Australian Conference on Applications of Expert Systems.  Sydney, Australia.[Web Link]  Quinlan,J.R. (1986). Induction of decision trees. Machine Learning, 1, 81--106.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.  [View Context].Zhi-Hua Zhou and Yuan Jiang. NeC4.5: Neural Ensemble Based C4.5. IEEE Trans. Knowl. Data Eng, 16. 2004.  [View Context].Xiaoyong Chai and Li Deng and Qiang Yang and Charles X. Ling. Test-Cost Sensitive Naive Bayes Classification. ICDM. 2004.  [View Context].Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Michael L. Raymer and Travis E. Doom and Leslie A. Kuhn and William F. Punch. Knowledge discovery in medical and biological datasets using a hybrid Bayes classifier/evolutionary algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B, 33. 2003.  [View Context].Lukasz A. Kurgan and Waldemar Swiercz and Krzysztof J. Cios. Semantic Mapping of XML Tags Using Inductive Machine Learning. ICMLA. 2002.  [View Context].Qiang Yang and Jing Wu. Enhancing the Effectiveness of Interactive Case-Based Reasoning with Clustering and Decision Forests. Appl. Intell, 14. 2001.  [View Context].Erin L. Allwein and Robert E. Schapire and Yoram Singer. Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers. ICML. 2000.  [View Context].Petri Kontkanen and Jussi Lahtinen and Petri Myllymäki and Henry Tirri. Unsupervised Bayesian visualization of high-dimensional data. KDD. 2000.  [View Context].Andreas L. Prodromidis. On the Management of Distributed Learning Agents Ph.D. Thesis Proposal CUCS-032-97. Department of Computer Science Columbia University. 1998.  [View Context].Ethem Alpaydin. Voting over Multiple Condensed Nearest Neighbors. Artif. Intell. Rev, 11. 1997.  [View Context].Kai Ming Ting and Boon Toh Low. Model Combination in the Multiple-Data-Batches Scenario. ECML. 1997.  [View Context].Salvatore J. Stolfo and Andreas L. Prodromidis and Shelley Tselepis and Wenke Lee and David W. Fan and Philip K. Chan. JAM: Java Agents for Meta-Learning over Distributed Databases. KDD. 1997.  [View Context].Peter D. Turney. Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm. CoRR, csAI/9503102. 1995.  [View Context].George H. John and Ron Kohavi and Karl Pfleger. Irrelevant Features and the Subset Selection Problem. ICML. 1994.  [View Context].Wl/odzisl/aw Duch and Rafal Adamczak and Krzysztof Grabczewski. Extraction of crisp logical rules from medical datasets. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Sherrie L. W and Zijian Zheng. A BENCHMARK FOR CLASSIFIER LEARNING. Basser Department of Computer Science The University of Sydney.  [View Context].Pramod Viswanath and M. Narasimha Murty and Shalabh Bhatnagar. Partition Based Pattern Synthesis Technique with Efficient Algorithms for Nearest Neighbor Classification. Department of Computer Science and Automation, Indian Institute of Science.  [View Context].Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. Statistical methods for construction of neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].Je Scott and Mahesan Niranjan and Richard W. Prager. Realisable Classifiers: Improving Operating Performance on Variable Cost Problems. Cambridge University Department of Engineering.  [View Context].Pramod Viswanath and M. Narasimha Murty and Shalabh Bhatnagar. A pattern synthesis technique to reduce the curse of dimensionality effect. E-mail.  [View Context].H. Altay Guvenir. A Classification Learning Algorithm Robust to Irrelevant Features. Bilkent University, Department of Computer Engineering and Information Science.  [View Context].Kai Ming Ting and Boon Toh Low. Theory Combination: an alternative to Data Combination. University of Waikato.  [View Context].Michael L. Raymer and William F. Punch and Erik D. Goodman and Leslie A. Kuhn and Anil K. Jain. Brief Papers.  [View Context].Andrew I. Schein and Lyle H. Ungar. A-Optimality for Active Learning of Logistic Regression Classifiers. Department of Computer and Information Science Levine Hall.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Swarm+Behaviour,354,Swarm Behaviour Data Set,../machine-learning-databases/00524/,Multivariate,24017,Computer,Real,2400,6/16/2020,Classification,N/A,2088,"Dr Shadi Abpeikar- s.abpeikar '@' adfa.edu.au, University of New South Wales, Australia. A/Prof Kathryn Kasmarik- kathryn.kasmarik '@' adfa.edu.au, University of New South Wales, Australia. A/Prof Michael Barlow- m.barlow '@' adfa.edu.au, University of New South Wales, Australia.Md Mohiuddin Khan- mohiuddin.khan '@' student.unsw.edu.au, University of New South Wales, Australia.","To access the survey, please use the following link:[Web Link]","The attributes are xm, ym as the (X,Y) position of each boid, xVeln, yVeln as the velocity vector, xAm, yAm as the alignment vector, xSm, ySm as the separation vector, xCm, yCm as the cohesion vector, nACm as the number of boids in the radius of Alignment/Cohesion, and nSm as the number of boids in the radius of Separation. These attributes are repeated for all m boids, where m=1,...,200. Also, class labels are binary, which 1 refers to flocking, grouped, and aligned, and 0 refers to not flocking, not grouped, and not aligned. ",N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/DBWorld+e-mails,355,DBWorld e-mails Data Set,../machine-learning-databases/00219/,Text,64,Computer,N/A,4702,11/6/2011,Classification,N/A,58279,"Michele Filannino, PhDUniversity of ManchesterCentre for Doctoral TrainingEmail: filannim_AT_cs.man.ac.uk",I collected 64 e-mails from DBWorld newsletter and I used them to train different algorithms in order to classify between 'announces of conferences' and 'everything else'. I used a binary bag-of-words representation with a stopword removal pre-processing task before.,Each attribute corresponds to a precise word or stem in the entire data set vocabulary (I used bag-of-words representation).,"Michele Filannino, 'DBWorld e-mail classification using a very small corpus', Project of Machine Learning course, University of Manchester, 2011. [Web link]",Thanks to ACM-SIGMOD for its useful service! :),
http://archive.ics.uci.edu/ml/datasets/Speaker+Accent+Recognition,356,Speaker Accent Recognition Data Set,../machine-learning-databases/00518/,Multivariate,329,Social,Real,12,3/4/2020,Classification,N/A,2976,"Ernest FokoueSchool of Mathematical SciencesRochester Institute of TechnologyRochester, NY 14623, USAepfeqa '@' rit.edu",N/A,"Response variable: language = {ES, FR, GE, IT, UK, US} The six possible accents considered Explanatory variables:X1, X2, ..., X12 Obtained using MFCC on the original time domain soundtrack of the maximum 1s of reading of a word","@article{DBLP:journals/corr/MaF15,  author    = {Zichen Ma and               Ernest Fokou{'{e}}},  title     = {A Comparison of Classifiers in Performing Speaker Accent Recognition               Using MFCCs},  journal   = {CoRR},  volume    = {[Web Link]},  year      = {2015},  url       = {[Web Link]},  archivePrefix = {arXiv},  eprint    = {1501.07866},  timestamp = {Mon, 13 Aug 2018 16:47:23 +0200},  biburl    = {[Web Link]},  bibsource = {dblp computer science bibliography, [Web Link]}}","If you publish material based on databases obtained from this repository, then, in your acknowledgements, please note the assistance you received by using this repository. This will help others to obtain the same data sets and replicate your experiments. We suggest the following pseudo-APA reference format for referring to this repository: Fokoue, E. (2020). UCI Machine Learning Repository [[Web Link]]. Irvine, CA: University of California, School of Information and Computer Science. Here is a BiBTeX citation as well: @misc{Fokoue:Ernest:Data:2020:2,author = 'Fokoue, E.',year = '2020',title = '{UCI} Machine Learning Repository',url = '[Web Link]',institution = 'University of California, Irvine, School of Information and Computer Sciences' }",
http://archive.ics.uci.edu/ml/datasets/Concrete+Slump+Test,357,Concrete Slump Test Data Set,../machine-learning-databases/concrete/slump/,Multivariate,103,Computer,Real,10,4/30/2009,Regression,N/A,99926,"Donor: I-Cheng YehEmail: icyeh '@' chu.edu.tw Institution: Department of Information Management, Chung-Hua University (Republic of China)Other contact information: Department of Information Management, Chung-Hua University, Hsin Chu, Taiwan 30067, R.O.C.","The data set includes 103 data points. There are 7 input variables, and 3 output variables in the data set.The initial data set included 78 data. After several years, we got 25 new data points.","Input variables (7)(component kg in one M^3 concrete):Cement	Slag	Fly ash	Water	SP	Coarse Aggr.	Fine Aggr.	 Output variables (3):SLUMP (cm)	FLOW (cm)	28-day Compressive Strength (Mpa)","1. Yeh, I-Cheng, ""Modeling slump of concrete with fly ash and superplasticizer,"" Computers and Concrete, Vol.5, No.6, 559-572, 2008.  2. Yeh, I-Cheng, ""Simulation of concrete slump using neural networks,"" Construction Materials,Vol.162, No.1, 11-18, 2009. 3. Yeh, I-Cheng, ""Prediction of workability of concrete using design of experiments for mixtures,"" COMPUTERS AND CONCRETE, Vol.5, No.1, 1-20, 2008. 4. Yeh, I-Cheng, ""Modeling slump flow of concrete using second-order regressions and artificial neural networks,"" Cement and Concrete Composites, Vol.29, No. 6, 474-480, 2007. 5. Yeh, I-Cheng, ""Exploring concrete slump model using artificial neural networks,"" J. of Computing in Civil Engineering, ASCE, Vol.20, No.3, 217-221, 2006.","Yeh, I-Cheng, ""Modeling slump flow of concrete using second-order regressions and artificial neural networks,"" Cement and Concrete Composites, Vol.29, No. 6, 474-480, 2007.",
http://archive.ics.uci.edu/ml/datasets/Wholesale+customers,358,Wholesale customers Data Set,../machine-learning-databases/00292/,Multivariate,440,Business,Integer,8,3/31/2014,"Classification, Clustering",N/A,344519,"Margarida G. M. S. Cardoso, margarida.cardoso '@' iscte.pt, ISCTE-IUL, Lisbon, Portugal",Provide all relevant information about your data set.,"1)	FRESH: annual spending (m.u.) on fresh products (Continuous);2)	MILK: annual spending (m.u.) on milk products (Continuous);3)	GROCERY: annual spending (m.u.)on grocery products (Continuous);4)	FROZEN: annual spending (m.u.)on frozen products (Continuous)5)	DETERGENTS_PAPER: annual spending (m.u.) on detergents and paper products (Continuous) 6)	DELICATESSEN: annual spending (m.u.)on and delicatessen products (Continuous); 7)	CHANNEL: customersâ€™ Channel - Horeca (Hotel/Restaurant/CafÃ©) or Retail channel (Nominal)8)	REGION: customersâ€™ Region â€“ Lisnon, Oporto or Other (Nominal)Descriptive Statistics: 	(Minimum, Maximum, Mean, Std. Deviation)FRESH (	3, 112151, 12000.30, 12647.329)MILK	(55, 73498, 5796.27, 7380.377)GROCERY	(3, 92780, 7951.28, 9503.163)FROZEN	(25, 60869, 3071.93, 4854.673)DETERGENTS_PAPER (3, 40827, 2881.49, 4767.854)DELICATESSEN (3, 47943, 1524.87, 2820.106) REGION	FrequencyLisbon	77Oporto	47Other Region	316Total	440 CHANNEL	FrequencyHoreca	298Retail	142Total	440","Cardoso, Margarida G.M.S. (2013). Logical discriminant models â€“ Chapter 8 in Quantitative Modeling in Marketing and Management Edited by Luiz Moutinho and Kun-Huang Huarng. World Scientific. p. 223-253. ISBN 978-9814407717 Jean-Patrick Baudry, Margarida Cardoso, Gilles Celeux, Maria JosÃ© Amorim, Ana Sousa Ferreira (2012). Enhancing the selection of a model-based clustering with external qualitative variables. RESEARCH REPORT NÂ° 8124, October 2012, Project-Team SELECT. INRIA Saclay - ÃŽle-de-France, Projet select, UniversitÃ© Paris-Sud 11","The data set is originated from a larger database referred on: Abreu, N. (2011). Analise do perfil do cliente Recheio e desenvolvimento de um sistema promocional. Mestrado em Marketing, ISCTE-IUL, Lisbon",
http://archive.ics.uci.edu/ml/datasets/Meta-data,359,Meta-data Data Set,../machine-learning-databases/meta-data/,Multivariate,528,N/A,"Categorical, Integer, Real",22,3/1/1996,Classification,Yes,74679,"Creator:  LIACC - University of PortoR.Campo Alegre 8234150 PORTO Donor:  P.B.Brazdil or J.GamaLIACC, University of Porto		Rua Campo Alegre 823			4150 Porto, Portugal Tel.:  +351 600 1672Fax.:  +351 600 3654Email:  statlog-adm '@' ncc.up.pt","This DataSet is about the results of Statlog project. The project performed a comparative study between Statistical, Neural and Symbolic learning algorithms. Project StatLog (Esprit Project 5170) was concerned with comparative studies of different machine learning, neural and statistical classification algorithms. About 20 different algorithms were evaluated on more than 20 different datasets. The tests carried out under project produced many interesting results. The results of these tests are comprehensively described in a book  (D.Michie et.al, 1994). ","   1.	DS_Name		categorical	Name of DataSet    2.	T		continuous	Number of examples in test set   3.	N		continuous	Number of examples   4.	p		continuous	Number of attributes   5.	k		continuous	Number of classes    6.	Bin		continuous	Number of binary Attributes    7.	Cost		continuous	Cost (1=yes,0=no)    8.	SDratio		continuous	Standard deviation ratio    9.	correl		continuous	Mean correlation between attributes  10.	cancor1		continuous	First canonical correlation  11.	cancor2		continuous	Second canonical correlation  12.	fract1		continuous	First eigenvalue   13.	fract2		continuous	Second eigenvalue   14.	skewness	continuous	Mean of |E(X-Mean)|^3/STD^3  15.	kurtosis	continuous	Mean of |E(X-Mean)|^4/STD^4  16.	Hc		continuous	Mean entropy of attributes  17.	Hx		continuous	Entropy of classes  18.	MCx		continuous	Mean mutual entropy of class and attributes  19.	EnAtr		continuous	Equivalent number of attributes   20.	NSRatio		continuous	Noise-signal ratio   21.	Alg_Name	categorical	Name of Algorithm   22.	Norm_error	continuous	Normalized Error (continuous class) ","""Machine Learning, Neural and Statistical Learning"". Eds. D.Michie,D.J.Spiegelhalter and C.Taylor Ellis Horwood-1994 P. Brazdil, J.Gama and B.Henery. ""Characterizing the Applicability of Classification Algorithms Using Meta-Level Learning"",   in Proc. of Machine Learning - ECML-94,  ed. F.Bergadano and L.de Raedt,LNAI Vol.784 Springer-Verlag. [Web Link]  J.Gama, P.Brazdil. ""Characterization of Classification Algorithms"" in Proc. of EPIA 95, LNAI Vol.990 Springer-Verlag, 1995[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Dataset+for+Sensorless+Drive+Diagnosis,360,Dataset for Sensorless Drive Diagnosis Data Set,../machine-learning-databases/00325/,Multivariate,58509,Computer,Real,49,2/24/2015,Classification,N/A,72240,"Owner of database: Martyna Bator (University of Applied Sciences, Ostwestfalen-Lippe, martyna.bator '@' hs-owl.de)Donor of database: Martyna Bator (University of Applied Sciences, Ostwestfalen-Lippe, martyna.bator '@' hs-owl.de)","Features are extracted from electric current drive signals. The drive has intact and defective components. This results in 11 different classes with different conditions. Each condition has been measured several times by 12 different operating conditions, this means by different speeds, load moments and load forces. The current signals are measured with a current probe and an oscilloscope on two phases.","The Empirical Mode Decomposition (EMD) was used to generate a new database for the generation of features. The first three intrinsic mode functions (IMF) of the two phase currents and their residuals (RES) were used and broken down into sub-sequences. For each of this sub-sequences, the statistical features mean, standard deviation, skewness and kurtosis were calculated.","PASCHKE, Fabian ; BAYER, Christian ; BATOR, Martyna ; MÃ–NKS, Uwe ; DICKS, Alexander ; ENGE-ROSENBLATT, Olaf ; LOHWEG, Volker: Sensorlose ZustandsÃ¼berwachung an Synchronmotoren, Bd. 46. In: HOFFMANN, Frank; HÃœLLERMEIER, Eyke (Hrsg.): Proceedings 23. Workshop Computational Intelligence. Karlsruhe : KIT Scientific Publishing, 2013 (Schriftenreihe des Instituts fÃ¼r Angewandte Informatik - Automatisierungstechnik am Karlsruher Institut fÃ¼r Technologie, 46), S. 211-225","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Servo,361,Servo Data Set,../machine-learning-databases/servo/,Multivariate,167,Computer,"Categorical, Integer",4,5/1/1993,Regression,No,106815,"Creator: Karl Ulrich (MIT) Donor:  Ross Quinlan","Ross Quinlan: This data was given to me by Karl Ulrich at MIT in 1986.  I didn't record his description at the time, but here's his subsequent (1992) recollection: ""I seem to remember that the data was from a simulation of a servo system involving a servo amplifier, a motor, a lead screw/nut, and a sliding carriage of some sort.  It may have been on of the translational axes of a robot on the 9th floor of the AI lab.  In any case, the output value is almost certainly a rise time, or the time required for the system to respond to a step change in a position set point."" (Quinlan, ML'93) ""This is an interesting collection of data provided by Karl Ulrich.  It covers an extremely non-linear phenomenon - predicting the rise time of a servomechanism in terms of two (continuous) gain settings and two (discrete) choices of mechanical linkages.""","   1. motor: A,B,C,D,E   2. screw: A,B,C,D,E   3. pgain: 3,4,5,6   4. vgain: 1,2,3,4,5   5. class: 0.13 to 7.10","Quinlan, J.R., ""Learning with continuous classes"", Proc. 5th Australian Joint Conference on AI (eds A. Adams and L. Sterling), Singapore: World Scientific, 1992 [Web Link]  Quinlan, J.R., ""Combining instance-based and model-based learning"", Proc. ML'93 (ed P.E. Utgoff), San Mateo: Morgan Kaufmann 1993[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Art B. Owen. Tubular neighbors for regression and classification. Stanford University. 1999.  [View Context].Christopher J. Merz and Michael J. Pazzani. A Principal Components Approach to Combining Regression Estimates. Machine Learning, 36. 1999.  [View Context].H. Altay Guvenir and Ilhan Uysal. Regression on feature projections. a Department of Computer Engineering, Bilkent University. 1999.  [View Context].Mauro Birattari and Gianluca Bontempi and Hugues Bersini. Lazy Learning Meets the Recursive Least Squares Algorithm. NIPS. 1998.  [View Context].D. Greig and Hava T. Siegelmann and Michael Zibulevsky. A New Class of Sigmoid Activation Functions That Don't Saturate. 1997.  [View Context].Georg Thimm and E. Fiesler. Optimal Setting of Weights, Learning Rate, and Gain. E S E A R C H R E P R O R T I D I A P. 1997.  [View Context].Georg Thimm and Emile Fiesler. IDIAP Technical report High Order and Multilayer Perceptron Initialization. IEEE Transactions. 1994.  [View Context].Jianping Wu and Zhi-Hua Zhou and Cheng-The Chen. Ensemble of GA based Selective Neural Network Ensembles. National Laboratory for Novel Software Technology Nanjing University.  [View Context].Dorian Suc and Ivan Bratko. Combining Learning Constraints and Numerical Regression. National ICT Australia, Sydney Laboratory at UNSW.  [View Context].Georg Thimm and Emile Fiesler. High Order and Multilayer Perceptron Initialization.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/GNFUV+Unmanned+Surface+Vehicles+Sensor+Data,362,GNFUV Unmanned Surface Vehicles Sensor Data Data Set,../machine-learning-databases/00452/,"Multivariate, Time-Series",1672,Computer,Real,5,5/6/2018,Regression,N/A,21198,"Dr Christos Anagnostopoulos; School of Computing Science, University of Glasgow; email: christos.anagnostopoulos '@' glasgow.ac.uk; G12 8QQ Scotland, UK. (NETLAB Group: https://netlab.dcs.gla.ac.uk/)","The data-set comprises (4) sets of mobile sensor readings data (humidity, temperature) corresponding to a swarm of four (4) Unmanned Surface Vehicles (USVs). Each USV set contains records of the format: {'USV-ID'; 'humidity-value'; 'temperature-value'; 'experiment-id';'sensing-time'}The swarm of the USVs is moving according to a GPS pre-defined trajectory, whose relative way-points are specified in the README.pdf file. The USVs are floating over the sea surface in a coastal area of Athens (Greece). More information on the project: [Web Link] ","Attributes:'device' = USV ID (String)'humidity' = sensed humidity value from the USV sensor (real value)'temperature' = sensed temperature value from the USV sensor (real value)'experiment' = 1 (constant real value)'time' = the sensing and reporting time (real value)","Please cite one of the following papers:[1] Harth, N. and Anagnostopoulos, C. (2018) Edge-centric Efficient Regression Analytics. In: 2018 IEEE International Conference on Edge Computing (EDGE), San Francisco, CA, USA, 02-07 Jul 2018 [2] Harth, N.,  Anagnostopoulos, C., (2017) Quality-aware Aggregation & Predictive Analytics at the Edge. IEEE International Conference on Big Data (IEEE Big Data 2017), December 11-14, 2017, Boston, MA, USA.","Please cite one of the following papers:[1] Harth, N. Anagnostopoulos, C. (2018) Edge-centric Efficient Regression Analytics. In: 2018 IEEE International Conference on Edge Computing (EDGE), San Francisco, CA, USA, 02-07 Jul 2018 [2] Harth, N.,  Anagnostopoulos, C., (2017) Quality-aware Aggregation & Predictive Analytics at the Edge. IEEE International Conference on Big Data (IEEE Big Data 2017), December 11-14, 2017, Boston, MA, USA.",
http://archive.ics.uci.edu/ml/datasets/SUSY,363,SUSY Data Set,../machine-learning-databases/00279/,N/A,5000000,Physical,Real,18,2/12/2014,Classification,N/A,70007,"Daniel Whiteson daniel '@' uci.edu, Assistant Professor, Physics & Astronomy, Univ. of California Irvine","Provide all relevant informatioThe data has been produced using Monte Carlo simulations. The first 8 features are kinematic properties measured by the particle detectors in the accelerator. The last ten features are functions of the first 8 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks and the dropout algorithm are presented in the original paper. The last 500,000 examples are used as a test set.n about your data set.","The first column is the class label (1 for signal, 0 for background), followed by the 18 features (8 low-level features then 10 high-level features):: lepton  1 pT, lepton  1 eta, lepton  1 phi, lepton  2 pT, lepton  2 eta, lepton  2 phi, missing energy magnitude, missing energy phi, MET_rel, axial MET, M_R, M_TR_2, R, MT2, S_R, M_Delta_R, dPhi_r_b, cos(theta_r1). For detailed information about each feature see the original paper.","Baldi, P., P. Sadowski, and D. Whiteson. “Searching for Exotic Particles in High-energy Physics with Deep Learning.” Nature Communications 5 (July 2, 2014)","Baldi, P., P. Sadowski, and D. Whiteson. “Searching for Exotic Particles in High-energy Physics with Deep Learning.” Nature Communications 5 (July 2, 2014)",
http://archive.ics.uci.edu/ml/datasets/DSRC+Vehicle+Communications,364,DSRC Vehicle Communications Data Set,../machine-learning-databases/00415/,"Sequential, Text",10000,Computer,Real,5,12/13/2017,Clustering,N/A,30235,"Sharaf Malebary, malebary '@' email.sc.edu, University of South Carolina, Dept of computer Science and Engineering, USA.",Communications were setup based on IEEE 802.11p standards at 5.9Ghz. 10BSM (Basic Service messages) per second. Using Control Channel (Ch172) a 10 Mhz channel. Also Attached a clean version in spreadsheets for each dataset (jammed and normal),"Txnid Transmitted node ID numberRxnid- Received Node Id numberRSS- Received Signal Strength in dbmBER- Packet Error RateRSSI- Received Signal Strength IndicatorSNR- Signal to noise ratio","Malebary, W. Xu and C. T. Huang, 'Jamming mobility in 802.11p networks: Modeling, evaluation, and detection,' 2016 IEEE 35th International Performance Computing and Communications Conference (IPCCC), Las Vegas, NV, 2016, pp. 1-7, doi: 10.1109/PCCC.2016.7820665","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/BuddyMove+Data+Set,365,BuddyMove Data Set Data Set,../machine-learning-databases/00476/,"Multivariate, Text",249,N/A,Real,7,7/1/2018,"Classification, Clustering",N/A,27033,"Shini Renjith, shinirenjith '@' gmail.com",This dataset was populated from destination reviews published by 249 reviewers of holidayiq.com till October 2014. Reviews falling in 6 categories among destinations across South India were considered and the count of reviews in each category for every reviewer (traveler) is captured. ,"Attribute 1 : Unique user idAttribute 2 : Number of reviews on stadiums, sports complex, etc.Attribute 3 : Number of reviews on religious institutionsAttribute 4 : Number of reviews on beach, lake, river, etc.Attribute 5 : Number of reviews on theatres, exhibitions, etc.Attribute 6 : Number of reviews on malls, shopping places, etc.Attribute 7 : Number of reviews on parks, picnic spots, etc. ","S. Renjith and C. Anjali, 'A personalized mobile travel recommender system using hybrid algorithm,' 2014 First International Conference on Computational Systems and Communications (ICCSC), Trivandrum, 2014, pp. 12-17. doi: 10.1109/COMPSC.2014.7032612","Please cite the below paper while using this datasetS. Renjith and C. Anjali, 'A personalized mobile travel recommender system using hybrid algorithm,' 2014 First International Conference on Computational Systems and Communications (ICCSC), Trivandrum, 2014, pp. 12-17. doi: 10.1109/COMPSC.2014.7032612",
http://archive.ics.uci.edu/ml/datasets/Flags,366,Flags Data Set,../machine-learning-databases/flags/,Multivariate,194,N/A,"Categorical, Integer",30,5/15/1990,Classification,No,302025,"Creators:  Collected primarily from the ""Collins Gem Guide to Flags"": Collins Publishers (1986). Donor:  Richard S. Forsyth 8 Grosvenor AvenueMapperley ParkNottingham NG3 5DX0602-621676","This data file contains details of various nations and their flags. In this file the fields are separated by spaces (not commas).  With this data you can try things like predicting the religion of a country from its size and the colours in its flag.   10 attributes are numeric-valued.  The remainder are either Boolean- or nominal-valued.","   1. name:	Name of the country concerned   2. landmass:	1=N.America, 2=S.America, 3=Europe, 4=Africa, 4=Asia, 6=Oceania   3. zone:	Geographic quadrant, based on Greenwich and the Equator; 1=NE, 2=SE, 3=SW, 4=NW   4. area:	in thousands of square km   5. population:	in round millions   6. language: 1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic, 9=Japanese/Turkish/Finnish/Magyar, 10=Others   7. religion: 0=Catholic, 1=Other Christian, 2=Muslim, 3=Buddhist, 4=Hindu, 5=Ethnic, 6=Marxist, 7=Others   8. bars:     Number of vertical bars in the flag   9. stripes:  Number of horizontal stripes in the flag  10. colours:  Number of different colours in the flag  11. red:      0 if red absent, 1 if red present in the flag  12. green:    same for green  13. blue:     same for blue  14. gold:     same for gold (also yellow)  15. white:    same for white  16. black:    same for black  17. orange:   same for orange (also brown)  18. mainhue:  predominant colour in the flag (tie-breaks decided by taking the topmost hue, if that fails then the most central hue, and if that fails the leftmost hue)  19. circles:  Number of circles in the flag  20. crosses:  Number of (upright) crosses  21. saltires: Number of diagonal crosses  22. quarters: Number of quartered sections  23. sunstars: Number of sun or star symbols  24. crescent: 1 if a crescent moon symbol present, else 0  25. triangle: 1 if any triangles present, 0 otherwise  26. icon:     1 if an inanimate image present (e.g., a boat), otherwise 0  27. animate:  1 if an animate image (e.g., an eagle, a tree, a human hand) present, 0 otherwise  28. text:     1 if any letters or writing on the flag (e.g., a motto or slogan), 0 otherwise  29. topleft:  colour in the top-left corner (moving right to decide tie-breaks)  30. botright: Colour in the bottom-left corner (moving left to decide tie-breaks)",Forsyth's PC/BEAGLE User's Guide.,"Please refer to the Machine Learning
Repository's citation policy","George H. John and Ron Kohavi and Karl Pfleger. Irrelevant Features and the Subset Selection Problem. ICML. 1994.  [View Context].Ron Kohavi and George H. John and Richard Long and David Manley and Karl Pfleger. MLC++: A Machine Learning Library in C. ICTAI. 1994.  [View Context].Wl/odzisl/aw Duch and Karol Grudzi nski and Grzegorz Stawski. SYMBOLIC FEATURES IN NEURAL NETWORKS. Department of Computer Methods, Nicolaus Copernicus University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Crowdsourced+Mapping,367,Crowdsourced Mapping Data Set,../machine-learning-databases/00400/,Multivariate,10546,Physical,N/A,29,5/25/2016,Classification,N/A,22460,"Brian Johnson johnson '@' iges.or.jp Institute for Global Environmental Strategies, Japan","This dataset was derived from geospatial data from two sources: 1) Landsat time-series satellite imagery from the years 2014-2015, and 2) crowdsourced georeferenced polygons with land cover labels obtained from OpenStreetMap. The crowdsourced polygons cover only a small part of the image area, and are used used to extract training data from the image for classifying the rest of the image. The main challenge with the dataset is that both the imagery and the crowdsourced data contain noise (due to cloud cover in the images and innaccurate labeling/digitizing of polygons).  Files in zip folder-The 'training.csv' file contains the training data for classification. Do not use this file to evaluate classification accuracy because it contains noise (many class labeling errors).-The 'testing.csv' file contains testing data to evaluate the classification accuracy. This file does not contain any class labeling errors.","class: The land cover class (impervious, farm, forest, grass, orchard, water) [note: this is the target variable to classify].max_ndvi: the maximum NDVI (normalized difference vegetation index) value derived from the time-series of satellite images.20150720_N - 20140101_N : NDVI values extracted from satellite images acquired between January 2014 and July 2015, in reverse chronological order (dates given in the format yyyymmdd).","Johnson, B. A., & Iizuka, K. (2016). Integrating OpenStreetMap crowdsourced data and Landsat time-series imagery for rapid land use/land cover (LULC) mapping: Case study of the Laguna de Bay area of the Philippines. Applied Geography, 67, 140-149.","Please cite: Johnson, B. A., & Iizuka, K. (2016). Integrating OpenStreetMap crowdsourced data and Landsat time-series imagery for rapid land use/land cover (LULC) mapping: Case study of the Laguna de Bay area of the Philippines. Applied Geography, 67, 140-149.",
http://archive.ics.uci.edu/ml/datasets/Caesarian+Section+Classification+Dataset,368,Caesarian Section Classification Dataset Data Set,../machine-learning-databases/00472/,Univariate,80,Life,Integer,5,11/2/2018,Classification,N/A,37493,"Name: Muhammad Zain Amin Email: ZainAmin1 '@' outlook.com Institution: University of Engineering and Technology, Lahore, Pakistan Name: Amir AliEmail: amirali.ryk1 '@' gmail.com Institution: University of Engineering and Technology, Lahore, Pakistan",Provide all relevant information about your data set.,"We choose age, delivery number, delivery time, blood pressure and heart status.We classify delivery time to Premature, Timely and Latecomer. As like the delivery time we consider blood pressure in three statuses of Low, Normal and High moods. Heart Problem is classified as apt and inept. @attribute 'Age' { 22,26,28,27,32,36,33,23,20,29,25,37,24,18,30,40,31,19,21,35,17,38 } @attribute 'Delivery number' { 1,2,3,4 }@attribute 'Delivery time' { 0,1,2 } -> {0 = timely , 1 = premature , 2 = latecomer}@attribute 'Blood of Pressure' { 2,1,0 } -> {0 = low , 1 = normal , 2 = high }@attribute 'Heart Problem' { 1,0 } -> {0 = apt, 1 = inept } @attribute Caesarian { 0,1 } -> {0 = No, 1 = Yes } ","1. M.Zain Amin, Amir Ali.'Performance Evaluation of Supervised Machine Learning Classifiers for Predicting Healthcare Operational Decisions'.Machine Learning for Operational Decision Making, Wavy Artificial Intelligence Research Foundation, Pakistan, 2018","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Yeast,369,Yeast Data Set,../machine-learning-databases/yeast/,Multivariate,1484,Life,Real,8,9/1/1996,Classification,No,307503,"Creator and Maintainer: Kenta NakaiInstitue of Molecular and Cellular BiologyOsaka, University1-3 Yamada-oka, Suita 565 Japannakai '@' imcb.osaka-u.ac.jp http://www.imcb.osaka-u.ac.jp/nakai/psort.html  Donor:  Paul Horton (paulh '@' cs.berkeley.edu)","Predicted Attribute: Localization site of protein. ( non-numeric ). The references below describe a predecessor to this dataset and its development. They also give results (not cross-validated) for classification by a rule-based expert system with that version of the dataset. Reference: ""Expert Sytem for Predicting Protein Localization Sites in Gram-Negative Bacteria"", Kenta Nakai & Minoru Kanehisa,  PROTEINS: Structure, Function, and Genetics 11:95-110, 1991. Reference: ""A Knowledge Base for Predicting Protein Localization Sites in Eukaryotic Cells"", Kenta Nakai & Minoru Kanehisa, Genomics 14:897-911, 1992.","  1.  Sequence Name: Accession number for the SWISS-PROT database  2.  mcg: McGeoch's method for signal sequence recognition.  3.  gvh: von Heijne's method for signal sequence recognition.  4.  alm: Score of the ALOM membrane spanning region prediction program.  5.  mit: Score of discriminant analysis of the amino acid content of the N-terminal region (20 residues long) of mitochondrial and non-mitochondrial proteins.  6.  erl: Presence of ""HDEL"" substring (thought to act as a signal for retention in the endoplasmic reticulum lumen). Binary attribute.  7.  pox: Peroxisomal targeting signal in the C-terminus.  8.  vac: Score of discriminant analysis of the amino acid content of vacuolar and extracellular proteins.  9.  nuc: Score of discriminant analysis of nuclear localization signals of nuclear and non-nuclear proteins.","Paul Horton & Kenta Nakai, ""A Probablistic Classification System for Predicting the Cellular Localization Sites of Proteins"", Intelligent Systems in Molecular Biology, 109-115. St. Louis, USA 1996.[Web Link]  The references below describe a predecessor to this dataset and its  development. They also give results (not cross-validated) for classification by a rule-based expert system with that version of the dataset: Kenta Nakai & Minoru Kanehisa, ""Expert Sytem for Predicting Protein Localization Sites in Gram-Negative Bacteria"",  PROTEINS: Structure, Function, and Genetics 11:95-110, 1991. Kenta Nakai & Minoru Kanehisa, ""A Knowledge Base for Predicting Protein Localization Sites in Eukaryotic Cells"", Genomics 14:897-911, 1992.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Dmitry Pavlov and Alexandrin Popescul and David M. Pennock and Lyle H. Ungar. Mixtures of Conditional Maximum Entropy Models. ICML. 2003.  [View Context].Aik Choon Tan and David Gilbert. An Empirical Comparison of Supervised Machine Learning Techniques in Bioinformatics. APBC. 2003.  [View Context].Samuel Kaski and Jaakko Peltonen. Informative Discriminant Analysis. ICML. 2003.  [View Context].Nitesh V. Chawla and Kevin W. Bowyer and Lawrence O. Hall and W. Philip Kegelmeyer. SMOTE: Synthetic Minority Over-sampling Technique. J. Artif. Intell. Res. (JAIR, 16. 2002.  [View Context].Manoranjan Dash and Kiseok Choi and Peter Scheuermann and Huan Liu. Feature Selection for Clustering - A Filter Solution. ICDM. 2002.  [View Context].Erin L. Allwein and Robert E. Schapire and Yoram Singer. Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers. ICML. 2000.  [View Context].Paul Horton and Kenta Nakai. Better Prediction of Protein Cellular Localization Sites with the it k Nearest Neighbors Classifier. ISMB. 1997.  [View Context].Johannes Furnkranz. Round Robin Rule Learning. Austrian Research Institute for Artificial Intelligence.  [View Context].Gaurav Marwah and Lois C. Boggess. Artificial Immune Systems for Classification : Some Issues. Department of Computer Science Mississippi State University.  [View Context].Alain Rakotomamonjy. Analysis of SVM regression bounds for variable ranking. P.S.I CNRS FRE 2645, INSA de Rouen Avenue de l'Universite.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences,370,Sentiment Labelled Sentences Data Set,../machine-learning-databases/00331/,Text,3000,N/A,N/A,N/A,5/30/2015,Classification,N/A,174051,Dimitrios Kotzias dkotzias '@' ics.uci.edu,"This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015Please cite the paper if you want to use it :) It contains sentences labelled with positive or negative sentiment. =======Format:=======sentence 	 score    =======Details:=======Score is either 1 (for positive) or 0 (for negative)	The sentences come from three different websites/fields: imdb.comamazon.comyelp.com For each website, there exist 500 positive and 500 negative sentences. Those were selected randomly for larger datasets of reviews. We attempted to select sentences that have a clearly positive or negative connotaton, the goal was for no neutral sentences to be selected. ","The attributes are text sentences, extracted from reviews of products, movies, and restaurants","'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015","'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015",
http://archive.ics.uci.edu/ml/datasets/Bar+Crawl%3A+Detecting+Heavy+Drinking,371,Bar Crawl: Detecting Heavy Drinking Data Set,../machine-learning-databases/00515/,"Multivariate, Time-Series",14057567,Life,Real,3,2/24/2020,"Classification, Regression",N/A,48361,"   (a) Owner of database       Jackson A Killian (jkillian '@' g.harvard.edu, Harvard University); Danielle R Madden (University of Southern California); John Clapp (University of Southern California)   (b) Donor of database       Jackson A Killian (jkillian '@' g.harvard.edu, Harvard University); Danielle R Madden (University of Southern California); John Clapp (University of Southern California)   (c) Date collected       May 2017   (d) Date submitted       Jan 2020","Relevant Information:    All data is fully anonymized.     Data was originally collected from 19 participants, but the TAC readings of 6 participants were deemed unusable by SCRAM [1]. The data included is from the remaining 13 participants.     Accelerometer data was collected from smartphones at a sampling rate of 40Hz (file: all_accelerometer_data_pids_13.csv). The file contains 5 columns: a timestamp, a participant ID, and a sample from each axis of the accelerometer. Data was collected from a mix of 11 iPhones and 2 Android phones as noted in phone_types.csv. TAC data was collected using SCRAM [2] ankle bracelets and was collected at 30 minute intervals. The raw TAC readings are in the raw_tac directory. TAC readings which are more readily usable for processing are in clean_tac directory and have two columns: a timestamp and TAC reading. The cleaned TAC readings: (1) were processed with a zero-phase low-pass filter to smooth noise without shifting phase; (2) were shifted backwards by 45 minutes so the labels more closely match the true intoxication of the participant (since alcohol takes about 45 minutes to exit through the skin.) Please see the above referenced study for more details on how the data was processed ([Web Link]).     1 - [Web Link]     2 - J. Robert Zettl. The determination of blood alcohol concentration by transdermal measurement. [Web Link], 2002. Number of Instances:    Accelerometer readings: 14,057,567    TAC readings: 715    Participants: 13 Number of Attributes:    - Time series: 3 axes of accelerometer data (columns x, y, z in all_accelerometer_data_pids_13.csv)    - Static: 1 phone-type feature (in phone_types.csv)    - Target: 1 time series of TAC for each of the 13 participants (in clean_tac directory). For Each Attribute:    (Main)    all_accelerometer_data_pids_13.csv:        time: integer, unix timestamp, milliseconds        pid: symbolic, 13 categories listed in pids.txt         x: continuous, time-series        y: continuous, time-series        z: continuous, time-series    clean_tac/*.csv:        timestamp: integer, unix timestamp, seconds        TAC_Reading: continuous, time-series    phone_type.csv:        pid: symbolic, 13 categories listed in pids.txt         phonetype: symbolic, 2 categories (iPhone, Android)     (Other)    raw/*.xlsx:        TAC Level: continuous, time-series        IR Voltage: continuous, time-series        Temperature: continuous, time-series        Time: datetime        Date: datetime Missing Attribute Values:None Target Distribution:    TAC is measured in g/dl where 0.08 is the legal limit for intoxication while driving    Mean TAC: 0.065 +/- 0.182    Max TAC: 0.443    TAC Inner Quartiles: 0.002, 0.029, 0.092    Mean Time-to-last-drink: 16.1 +/- 6.9 hrs",Provide information about each attribute in your data set.,"Past Usage:   (a) Complete reference of article where it was described/used:        Killian, J.A., Passino, K.M., Nandi, A., Madden, D.R. and Clapp, J., Learning to Detect Heavy Drinking Episodes Using Smartphone Accelerometer Data. In Proceedings of the 4th International Workshop on Knowledge Discovery in Healthcare Data co-located with the 28th International Joint Conference on Artificial Intelligence (IJCAI 2019) (pp. 35-42). [Web Link]    (b) Indication of what attribute(s) were being predicted       Features: Three-axis time series accelerometer data       Target: Time series transdermal alcohol content (TAC) data (real-time measure of intoxication)   (c) Indication of study's results       The study decomposed each time series into 10 second windows and performed binary classification to predict if windows corresponded to an intoxicated participant (TAC >= 0.08) or sober participant (TAC < 0.08). The study tested several models and achieved a test accuracy of 77.5% with a random forest.","When using this dataset, please cite: Killian, J.A., Passino, K.M., Nandi, A., Madden, D.R. and Clapp, J., Learning to Detect Heavy Drinking Episodes Using Smartphone Accelerometer Data. In Proceedings of the 4th International Workshop on Knowledge Discovery in Healthcare Data co-located with the 28th International Joint Conference on Artificial Intelligence (IJCAI 2019) (pp. 35-42). [Web Link]",
http://archive.ics.uci.edu/ml/datasets/Moral+Reasoner,372,Moral Reasoner Data Set,../machine-learning-databases/moral-reasoner/,Domain-Theory,202,Computer,N/A,N/A,6/1/1994,N/A,N/A,39876,"Creators:  T.R. Shultz & J.M. Daley  Donor:  James L. Wogulis University of California, IrvineIrvine, CA USA","This is a rule-based model that qualitatively simulates moral reasoning. The model was intended to simulate how an ordinary person, down to about age five, reasons about harm-doing. The horn-clause theory and the 202 instances are the same as were used in (Wogulis, 1994).  The top-level predicate to predict is guilty/1. For more information, e.g. on the generation of instances, see (Wogulis, 1994).",N/A,"Darley, J.M. & Shultz, T.R. (1990). Moral rules: Their content and acquisition.  Annual Review of Psychology, 41, 525-556. Shultz, T.R. (1990). A rule base model of judging harm-doing. In Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, (pp. 229-236).,Cambridge, MA. Lawrence Erlbaum.[Web Link]  Wogulis, J.L. (1994). An Approach to Repairing and Evaluating First-Order Theories Containing Multiple Concepts and Negation. Doctoral Dissertation. University of California, Irvine.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame,373,Tic-Tac-Toe Endgame Data Set,../machine-learning-databases/tic-tac-toe/,Multivariate,958,Game,Categorical,9,8/19/1991,Classification,No,242052,"Creator:  David W. Aha (aha '@' cs.jhu.edu) Donor:  David W. Aha (aha '@' cs.jhu.edu)","This database encodes the complete set of possible board configurations at the end of tic-tac-toe games, where ""x"" is assumed to have played first.  The target concept is ""win for x"" (i.e., true when ""x"" has one of 8 possible ways to create a ""three-in-a-row"").   Interestingly, this raw database gives a stripped-down decision tree algorithm (e.g., ID3) fits.  However, the rule-based CN2 algorithm, the simple IB1 instance-based learning algorithm, and the CITRE feature-constructing decision tree algorithm perform well on it.","    1. top-left-square: {x,o,b}    2. top-middle-square: {x,o,b}    3. top-right-square: {x,o,b}    4. middle-left-square: {x,o,b}    5. middle-middle-square: {x,o,b}    6. middle-right-square: {x,o,b}    7. bottom-left-square: {x,o,b}    8. bottom-middle-square: {x,o,b}    9. bottom-right-square: {x,o,b}   10. Class: {positive,negative}","Matheus, C.J., & Rendell, L.A. (1989).  Constructive induction on decision trees.  In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence. (pp. 645--650).  Detroit, MI: Morgan Kaufmann.[Web Link]  Matheus, C.J. (1990). Adding domain knowledge to SBL through feature construction.  In Proceedings of the Eighth National Conference on Artificial Intelligence (pp. 803--808). Boston, MA: AAAI Press.[Web Link]  Aha, D. W. (1991). Incremental constructive induction: An instance-based approach.  In Proceedings of the Eighth International Workshop on Machine Learning (pp. 117--121).  Evanston, ILL: Morgan Kaufmann.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Saher Esmeir and Shaul Markovitch. Lookahead-based algorithms for anytime induction of decision trees. ICML. 2004.  [View Context].Bart Hamers and J. A. K Suykens. Coupled Transductive Ensemble Learning of Kernel Models. Bart De Moor. 2003.  [View Context].Michael Bain. Structured Features from Concept Lattices for Unsupervised Learning and Classification. Australian Joint Conference on Artificial Intelligence. 2002.  [View Context].Jinyan Li and Kotagiri Ramamohanarao and Guozhu Dong. Combining the Strength of Pattern Frequency and Distance for Classification. PAKDD. 2001.  [View Context].Jochen Garcke and Michael Griebel and Michael Thess. Data Mining with Sparse Grids. Computing, 67. 2001.  [View Context].Stephen D. Bay. Nearest neighbor classification from multiple feature subsets. Intell. Data Anal, 3. 1999.  [View Context].Alexey Tsymbal and Seppo Puuronen and Vagan Y. Terziyan. Arbiter Meta-Learning with Dynamic Selection of Classifiers and Its Experimental Investigation. ADBIS. 1999.  [View Context].Stephen D. Bay. Combining Nearest Neighbor Classifiers Through Multiple Feature Subsets. ICML. 1998.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context].Ron Kohavi and Brian Frasca. Useful Feature Subsets and Rough Set Reducts. the Third International Workshop on Rough Sets and Soft Computing.  [View Context].Shi Zhong and Weiyu Tang and Taghi M. Khoshgoftaar. Boosted Noise Filters for Identifying Mislabeled Data. Department of Computer Science and Engineering Florida Atlantic University.  [View Context].Jerome H. Friedman and Ron Kohavi and Youngkeol Yun. To appear in AAAI-96 Lazy Decision Trees. Statistics Department and Stanford Linear Accelerator Center Stanford University.  [View Context].Christophe G. Giraud-Carrier and Tony Martinez. AN INCREMENTAL LEARNING MODEL FOR COMMONSENSE REASONING. Department of Computer Science Brigham Young University.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery. CEFET-PR, Curitiba.  [View Context].Ron Kohavi and George H. John. Automatic Parameter Selection by Minimizing Estimated Error. Computer Science Dept. Stanford University.  [View Context].Jinyan Li and Kotagiri Ramamohanarao and Guozhu Dong. ICML2000 The Space of Jumping Emerging Patterns and Its Incremental Maintenance Algorithms. Department of Computer Science and Software Engineering, The University of Melbourne, Parkville.  [View Context].Masahiro Terabe and Takashi Washio and Hiroshi Motoda. The Effect of Subsampling Rate on S 3 Bagging Performance. Mitsubishi Research Institute.  [View Context].David R. Musicant. DATA MINING VIA MATHEMATICAL PROGRAMMING AND MACHINE LEARNING. Doctor of Philosophy (Computer Sciences) UNIVERSITY.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/SIFT10M,374,SIFT10M Data Set,../machine-learning-databases/00353/,Multivariate,11164866,Computer,Integer,128,2/23/2016,Causal-Discovery,N/A,32020,"Xiping Fu, Brendan McCane, Steven Mills, Michael Albert and Lech SzymanskiDepartment of Computer Science, University of Otago, Dunedin, New Zealand{xiping, mccane, steven, malbert, lechszym}@cs.otago.ac.nz","In SIFT10M, the titles of the png files indicate the columns position of the SIFT features. This data set has been used for evaluating the approximate nearest neighbour search methods. The patches can be used for visualisation purpose and helps for analysing the performance of the corresponding approximate nearest neighbour search methods.","Each SIFT feature is a 128D column, and the corresponding patch is saved in  41*41 png format. The png files are compressed into 307 tar files for downloading.","Xiping Fu, Brendan McCane, Steven Mills, and Michael Albert, 'NOKMeans: Non-orthogonal K-means hashing', in Asian Conference on Computer Vision (ACCV14). pp 162--177.Xiping Fu, Brendan McCane, Steven Mills, Michael Albert, and Lech Szymanski, 'Auto-JacoBin: Auto-encoder Jacobian Binary Hashing', submitted to PAMI.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/QSAR+androgen+receptor,375,QSAR androgen receptor Data Set,../machine-learning-databases/00509/,Multivariate,1687,Physical,N/A,1024,10/1/2019,Classification,N/A,3269,"Francesca Grisoni (francesca.grisoni '@' unimib.it), Davide Ballabio (davide.ballabio '@' unimib.it), Viviana Consonni, Milano Chemometrics and QSAR Research Group (http://www.michem.unimib.it/), UniversitÃ  degli Studi Milano - Bicocca, Milano (Italy)","This dataset was used to develop classification QSAR models for the discrimination of binder/positive (199) and non-binder/negative (1488) molecules by means of different machine learning methods. Details can be found in the quoted reference: F. Grisoni, V. Consonni, D. Ballabio, (2019) Machine Learning Consensus to Predict the Binding to the Androgen Receptor within the CoMPARA project, Journal of chemical information and modeling, 59, 1839-1848; doi: 10.1021/acs.jcim.8b00794. Attributes (molecular fingerprints) were calculated at the Milano Chemometrics and QSAR Research Group (UniversitÃ   degli Studi Milano - Bicocca, Milano, Italy) on a set of chemicals provided by the National Center of Computational Toxicology, at the U.S. Environmental Protection Agency in the framework of the  CoMPARA collaborative modelling project, which targeted the development of QSAR models to identify binders to the Androgen Receptor.","1024 binary molecular fingerprints and 1 experimental class:1-1024) binary molecular fingerprint1025) experimental class: positive (binder) and negative (non-binder)","F. Grisoni, V. Consonni, D. Ballabio, (2019) Machine Learning Consensus to Predict the Binding to the Androgen Receptor within the CoMPARA project, Journal of chemical information and modeling, 59, 1839-1848; doi: 10.1021/acs.jcim.8b00794","Please, cite the following paper if you publish results based on the QSAR androgen receptor dataset: F. Grisoni, V. Consonni, D. Ballabio, (2019) Machine Learning Consensus to Predict the Binding to the Androgen Receptor within the CoMPARA project, Journal of chemical information and modeling, 59, 1839-1848; doi: 10.1021/acs.jcim.8b00794",
http://archive.ics.uci.edu/ml/datasets/Parking+Birmingham,376,Parking Birmingham Data Set,../machine-learning-databases/00482/,"Multivariate, Univariate, Sequential, Time-Series",35717,Computer,Real,4,1/2/2019,"Classification, Regression, Clustering",Yes,49113,"Daniel H. Stolfi, dhstolfi '@' lcc.uma.es, University of Malaga - Spain.",Occupancy rates (8:00 to 16:30) from 2016/10/04 to 2016/12/19,"SystemCodeNumber: Car park IDCapacity: Car park capacityOccupancy: Car park occupancy rateLastUpdated: Date and Time of the measure","+ D. H. Stolfi, E. Alba, and X. Yao. Predicting Car Park Occupancy Rates in Smart Cities. In: Smart Cities: Second International Conference, Smart-CT 2017, MÃ¡laga, Spain, June 14-16, 2017, pp. 107â€“117. doi> 10.1007/978-3-319-59513-9_11+ A. Camero, J. Toutouh, D. H. Stolfi, and E. Alba, Evolutionary Deep Learning for Car Park Occupancy Prediction in Smart Cities. In International Conference on Learning and Intelligent Optimization, 2019, pp. 386â€“401. doi> 10.1007/978-3-030-05348-2_32","+ Daniel H. Stolfi, Enrique Alba, and Xin Yao. Predicting Car Park Occupancy Rates in Smart Cities. In: Smart Cities: Second International Conference, Smart-CT 2017, MÃ¡laga, Spain, June 14-16, 2017, pp. 107â€“117. doi> 10.1007/978-3-319-59513-9_11+ Birmingham City Council. [Web Link]",
http://archive.ics.uci.edu/ml/datasets/Othello+Domain+Theory,377,Othello Domain Theory Data Set,../machine-learning-databases/othello/,Domain-Theory,N/A,Game,N/A,N/A,2/1/1991,N/A,No,27891,"Tom Fawcett (fawcett '@' cs.umass.edu)COINS Deptartment, LGRCUniversity of MassachusettsAmherst, MA  10373","The Code (""othello.theory"") is well documented.",N/A,"T. Fawcett and P. Utgoff. ""A Hybrid Method for Feature Generation"".  Eighth International Workshop on Machine learning. Northwestern University, Evanston Illinois.  1991. pp. 137-141[Web Link]  T. Fawcett and P. Utgoff.  ""Automatic Feature Generation for Problem Solving Systems"". Ninth International Conference on Machine Learning. Aberdeen, Scotland. 1992.  pp 144-153.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Spambase,378,Spambase Data Set,../machine-learning-databases/spambase/,Multivariate,4601,Computer,"Integer, Real",57,7/1/1999,Classification,Yes,516387,"Creators:  Mark Hopkins, Erik Reeber, George Forman, Jaap SuermondtHewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304 Donor:  George Forman (gforman at nospam hpl.hp.com)  650-857-7835","The ""spam"" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography... Our collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter. For background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam! Communications of the ACM, 41(8):74-83, 1998.    (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.   (b) Determine whether a given email is spam or not.   (c) ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter.","The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes: 48 continuous real [0,100] attributes of type word_freq_WORD = percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A ""word"" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string. 6 continuous real [0,100] attributes of type char_freq_CHAR] = percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail 1 continuous real [1,...] attribute of type capital_run_length_average = average length of uninterrupted sequences of capital letters 1 continuous integer [1,...] attribute of type capital_run_length_longest = length of longest uninterrupted sequence of capital letters 1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail 1 nominal {0,1} class attribute of type spam= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  ",N/A,"Please refer to the Machine Learning
Repository's citation policy","Don R. Hush and Clint Scovel and Ingo Steinwart. Los Alamos National Laboratory Stability of Unstable Learning Algorithms. Modeling, Algorithms and Informatics Group, CCS-3. 2003.  [View Context].Yongmei Wang and Ian H. Witten. Modeling for Optimal Probability Prediction. ICML. 2002.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context].Christos Dimitrakakis and Samy Bengioy. Online Policy Adaptation for Ensemble Classifiers. IDIAP.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/MEx,379,MEx Data Set,../machine-learning-databases/00500/,Time-Series,6262,Computer,Real,710,9/20/2019,"Classification, Clustering",N/A,12006,"Anjana Wijekoon, Nirmalie Wiratunga, Kay CooperRobert Gordon UniversityAberdeen, UK","The MEx Multi-modal Exercise dataset contains data of 7 different physiotherapyexercises, performed by 30 subjects recorded four sensor modalities.**Application**The dataset can be used for exercise recognition, exercise quality assessment andexercise counting, by developing algorithms for pre-processing, feature extraction,multi-modal sensor fusion, segmentation and classification. ** Data collection method **Each subject was given a sheet of 7 exercises with instructions to perform theexercise at the beginning of the session. At the beginning of each exercise theresearcher demonstrated the exercise to the subject, then the subject performed theexercise for maximum 60 seconds while being recorded with four sensors. Duringthe recording, the researcher did not give any advice or kept count or time to enforcea rhythm.** Sensors**Obbrec Astra Depth Camera- sampling frequency - 15Hz - frame size - 240x320Sensing Tex Pressure Mat- sampling frequency - 15Hz- frame size - 32*16Axivity AX3 3-Axis Logging Accelerometer- sampling frequency - 100Hz- range - 8g ** Sensor Placement**All the exercises were performed lying down on the mat while the subject wearingtwo accelerometers on the wrist and the thigh. The depth camera was placed abovethe subject facing down-words recording an aerial view. Top of the depth cameraframe was aligned with the top of the pressure mat frame and the subjectâ€™sshoulders such that the face will not be included in the depth camera video.** Data folder **MEx folder has four folders, one for each sensor. Inside each sensor folder,30 folders can be found, one for each subject. In each subject folder, 8 files can befound for each exercise with 2 files for exercise 4 as it is performed on two sides.(The user 22 will only have 7 files as they performed the exercise 4 on only oneside.) One line in the data files correspond to one timestamped and sensory data.","The 4 columns in the act and acw files is organized as follows:1 - timestamp2 - x value3 - y value4 - z valueMin value = -8Max value = +8The 513 columns in the pm file is organized as follows:1 - timestamp2-513 pressure mat data frame (32x16)Min value - 0Max value - 1The 193 columns in the dc file is organized as follows:1 - timestamp2-193 depth camera data frame (12x16)dc data frame is scaled down from 240x320 to 12x16 using the OpenCV resizealgorithmMin value - 0Max value - 1","Wijekoon, Anjana, Nirmalie Wiratunga, and Kay Cooper. 'MEx: Multi-modal Exercises Dataset for Human Activity Recognition.' arXiv preprint [Web Link] (2019).","@article{wijekoon2019mex,  title={MEx: Multi-modal Exercises Dataset for Human Activity Recognition},  author={Wijekoon, Anjana and Wiratunga, Nirmalie and Cooper, Kay},  journal={arXiv preprint [Web Link]},  year={2019}}",
http://archive.ics.uci.edu/ml/datasets/Student+Performance,380,Student Performance Data Set,../machine-learning-databases/00320/,Multivariate,649,Social,Integer,33,11/27/2014,"Classification, Regression",N/A,731076,"Paulo Cortez, University of Minho, GuimarÃ£es, Portugal, http://www3.dsi.uminho.pt/pcortez ","This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).","# Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)2 sex - student's sex (binary: 'F' - female or 'M' - male)3 age - student's age (numeric: from 15 to 22)4 address - student's home address type (binary: 'U' - urban or 'R' - rural)5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)16 schoolsup - extra educational support (binary: yes or no)17 famsup - family educational support (binary: yes or no)18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)19 activities - extra-curricular activities (binary: yes or no)20 nursery - attended nursery school (binary: yes or no)21 higher - wants to take higher education (binary: yes or no)22 internet - Internet access at home (binary: yes or no)23 romantic - with a romantic relationship (binary: yes or no)24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)29 health - current health status (numeric: from 1 - very bad to 5 - very good)30 absences - number of school absences (numeric: from 0 to 93) # these grades are related with the course subject, Math or Portuguese:31 G1 - first period grade (numeric: from 0 to 20)31 G2 - second period grade (numeric: from 0 to 20)32 G3 - final grade (numeric: from 0 to 20, output target)","P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.Available at: [Web Link]","Please include this citation if you plan to use this database:  P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.[Web Link]",
http://archive.ics.uci.edu/ml/datasets/GPS+Trajectories,381,GPS Trajectories Data Set,../machine-learning-databases/00354/,Multivariate,163,Computer,Real,15,2/29/2016,"Classification, Regression",Yes,107769,"M. O. CruzH. T. MacedoR. BarretoA. P. GuimarÃ£es","The dataset is composed by two tables. The first table go_track_tracks presents general attributes and each instance has one trajectory that is represented by the tablego_track_trackspoints.","(1) go_track_tracks.csv: a list of trajectoriesid_android - it represents the device used to capture the instance;speed - it represents the average speed (Km/H)distance - it represent the total distance (Km)rating - it is an evaluation parameter. Evaluation the traffic is a way to verify the volunteers perception about the traffic during the travel, in other words,if volunteers move to  some place and face traffic jam, maybe they will evaluate 'bad'. (3- good, 2- normal, 1-bad).rating_bus - it is other evaluation parameter. (1 - The amount of people inside the bus is little, 2 - The bus is not crowded, 3- The bus is crowded.rating_weather - it is another evaluation parameter. ( 2- sunny, 1- raining).car_or_bus - (1 - car, 2-bus)linha - information about the bus that does the pathway   (2) go_track_trackspoints.csv: localization points of each trajectoryid: unique key to identify each pointlatitude: latitude from where the point islongitude: longitude from where the point istrack_id: identify the trajectory which the point belongtime: datetime when the point was collected (GMT-3)",Provide references to papers that have cited this data set in the past (if any).,"We have some papers that used this dataset. The first was presented in BRACIS (4th Brazilian Conference on Intelligent System).The paper was accepted but not published yet. The other paper was submitted to AT&T (IJCAI-16). The last paper is about the dataset. Publications:1 - CRUZ, M. O.; MACEDO, H.; GUIMARÃ£ES, A. P. Grouping similar trajectories forcarpooling purposes. In: Brazilian Conference on Intelligent Systems. [S.l.: s.n.], 2015. p.234â€“239. ISBN 9781509000166. ",
http://archive.ics.uci.edu/ml/datasets/Multiple+Features,382,Multiple Features Data Set,../machine-learning-databases/mfeat/,Multivariate,2000,Computer,"Integer, Real",649,N/A,Classification,No,111235,"Robert P.W. DuinDepartment of Applied Physics Delft University of Technology P.O. Box 5046, 2600 GA DelftThe Netherlands email: duin '@' ph.tn.tudelft.nl http : //www.ph.tn.tudelft.nl/~duintel +31 15 2786143","This dataset consists of features of handwritten numerals (`0'--`9') extracted from a collection of Dutch utility maps. 200 patterns per class (for a total of 2,000 patterns) have been digitized in  binary images. These digits are represented in terms of the following six feature sets (files):  1. mfeat-fou: 76 Fourier coefficients of the character shapes; 2. mfeat-fac: 216 profile correlations; 3. mfeat-kar: 64 Karhunen-Love coefficients; 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; 5. mfeat-zer: 47 Zernike moments; 6. mfeat-mor: 6 morphological features.  In each file the 2000 patterns are stored in ASCI on 2000 lines. The first 200 patterns are of class `0', followed by sets of 200 patterns for each of the classes `1' - `9'. Corresponding patterns in different feature sets (files) correspond to the same original character. The source image dataset is lost. Using the pixel-dataset (mfeat-pix) sampled versions of the original images may be obtained (15 x 16 pixels).","6 Files:1. mfeat-fou: 76 Fourier coefficients of the character shapes; 2. mfeat-fac: 216 profile correlations; 3. mfeat-kar: 64 Karhunen-Love coefficients; 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; 5. mfeat-zer: 47 Zernike moments; 6. mfeat-mor: 6 morphological features. ","M. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.[Web Link]  M. van Breukelen and R.P.W. Duin, Neural Network Initialization by Combined Classifiers, in: A.K. Jain, S. Venkatesh, B.C. Lovell (eds.), ICPR'98, Proc. 14th Int. Conference on Pattern Recognition (Brisbane, Aug. 16-20), A.K. Jain, R.P.W. Duin, J. Mao, Statisitcal Pattern Recognition: A Review, in preparation","Please refer to the Machine Learning
Repository's citation policy","Xiaoli Z. Fern and Carla Brodley. Cluster Ensembles for High Dimensional Clustering: An Empirical Study. Journal of Machine Learning Research n, a. 2004.  [View Context].Jaakko Peltonen and Samuel Kaski. Discriminative Components of Data. IEEE. 2004.  [View Context].Xiaofeng He and Partha Niyogi. Locality Preserving Projections. NIPS. 2003.  [View Context].Simon Perkins and James Theiler. Online Feature Selection using Grafting. ICML. 2003.  [View Context].Pavel Paclik and Robert P W Duin and Geert M. P. van Kempen and Reinhard Kohlus. On Feature Selection with Measurement Cost and Grouped Features. Pattern Recognition Group, Delft University of Technology.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data,383,Beijing Multi-Site Air-Quality Data Data Set,../machine-learning-databases/00501/,"Multivariate, Time-Series",420768,Physical,"Integer, Real",18,9/20/2019,Regression,Yes,42181,"Song Xi Chen, csx '@' gsm.pku.edu.cn, Guanghua School of Management, Center for Statistical Science, Peking University.","This data set includes hourly air pollutants data from 12 nationally-controlled air-quality monitoring sites. The air-quality data are from the Beijing Municipal Environmental Monitoring Center. The meteorological data in each air-quality site are matched with the nearest weather station from the China Meteorological Administration. The time period is from March 1st, 2013 to February 28th, 2017. Missing data are denoted as NA.","No: row number year: year of data in this row month: month of data in this row day: day of data in this row hour: hour of data in this row PM2.5: PM2.5 concentration (ug/m^3)PM10: PM10 concentration (ug/m^3)SO2: SO2 concentration (ug/m^3)NO2: NO2 concentration (ug/m^3)CO: CO concentration (ug/m^3)O3: O3 concentration (ug/m^3)TEMP: temperature (degree Celsius) PRES: pressure (hPa)DEWP: dew point temperature (degree Celsius)RAIN: precipitation (mm)wd: wind directionWSPM: wind speed (m/s)station: name of the air-quality monitoring site","Zhang, S., Guo, B., Dong, A., He, J., Xu, Z. and Chen, S.X. (2017) Cautionary Tales on Air-Quality Improvement in Beijing. Proceedings of the Royal Society A, Volume 473, No. 2205, Pages 20170457.","Zhang, S., Guo, B., Dong, A., He, J., Xu, Z. and Chen, S.X. (2017) Cautionary Tales on Air-Quality Improvement in Beijing. Proceedings of the Royal Society A, Volume 473, No. 2205, Pages 20170457.",
http://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data,384,Beijing PM2.5 Data Data Set,../machine-learning-databases/00381/,"Multivariate, Time-Series",43824,Physical,"Integer, Real",13,1/19/2017,Regression,Yes,174548,"Song Xi Chen, csx '@' gsm.pku.edu.cn, Guanghua School of Management, Center for Statistical Science, Peking University.","The dataâ€™s time period is between Jan 1st, 2010 to Dec 31st, 2014. Missing data are denoted as â€œNAâ€.","No: row numberyear: year of data in this rowmonth: month of data in this rowday: day of data in this rowhour: hour of data in this rowpm2.5: PM2.5 concentration (ug/m^3)DEWP: Dew Point (â„ƒ)TEMP: Temperature (â„ƒ)PRES: Pressure (hPa)cbwd: Combined wind directionIws: Cumulated wind speed (m/s)Is: Cumulated hours of snowIr: Cumulated hours of rain","Liang, X., Zou, T., Guo, B., Li, S., Zhang, H., Zhang, S., Huang, H.  and Chen, S. X. (2015). Assessing Beijing's PM2.5 pollution: severity, weather impact, APEC and winter heating. Proceedings of the Royal Society A, 471, 20150257.","Liang, X., Zou, T., Guo, B., Li, S., Zhang, H., Zhang, S., Huang, H.  and Chen, S. X. (2015). Assessing Beijing's PM2.5 pollution: severity, weather impact, APEC and winter heating. Proceedings of the Royal Society A, 471, 20150257.",
http://archive.ics.uci.edu/ml/datasets/Covertype,385,Covertype Data Set,../machine-learning-databases/covtype/,Multivariate,581012,Life,"Categorical, Integer",54,8/1/1998,Classification,No,284734,"Original Owners of Database: Remote Sensing and GIS ProgramDepartment of Forest SciencesCollege of Natural ResourcesColorado State UniversityFort Collins, CO  80523(contact Jock A. Blackard, jblackard '@' fs.fed.us or Dr. Denis J. Dean, denis.dean '@' utdallas.edu) Donors of database: 1. Jock A. Blackard (jblackard '@' fs.fed.us)GIS CoordinatorUSFS - Forest Inventory & AnalysisRocky Mountain Research Station507 25th StreetOgden, UT 84401  2. Dr. Denis J. Dean (denis.dean '@' utdallas.edu)ProfessorProgram in Geography and Geospatial SciencesSchool of Economic, Political and Policy Sciences800 West Campbell RdRichardson, TX  75080-3021  3. Dr. Charles W. Anderson (anderson '@' cs.colostate.edu)Associate ProfessorDepartment of Computer ScienceColorado State UniversityFort Collins, CO  80523  USA","Predicting forest cover type from cartographic variables only (no remotely sensed data).  The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data.  Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data.  Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types). This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado.  These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices. Some background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value.  As for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4).   The Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.)  Cache la Poudre would probably  be more unique than the others, due to its relatively low  elevation range and species composition. ","Given is the attribute name, attribute type, the measurement unit and a brief description.  The forest cover type is the classification  problem.  The order of this listing corresponds to the order of numerals along the rows of the database. Name / Data Type / Measurement / Description Elevation / quantitative /meters / Elevation in metersAspect / quantitative / azimuth / Aspect in degrees azimuthSlope / quantitative / degrees / Slope in degreesHorizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water featuresVertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water featuresHorizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadwayHillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solsticeHillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer solticeHillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solsticeHorizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition pointsWilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designationSoil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designationCover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation","Blackard, Jock A. and Denis J. Dean.  2000.  ""Comparative Accuracies of Artificial Neural Networks and Discriminant Analysis in Predicting Forest Cover Types from Cartographic Variables.""  Computers and Electronics in Agriculture  24(3):131-151.[Web Link]  Blackard, Jock A. and Denis J. Dean.  1998.  ""Comparative Accuracies of Neural Networks and Discriminant Analysis in Predicting Forest Cover Types from Cartographic Variables.""  Second Southern Forestry GIS Conference. University of Georgia.  Athens, GA.  Pages 189-199. Blackard, Jock A.  1998.  ""Comparison of Neural Networks and Discriminant Analysis in Predicting Forest Cover Types."" Ph.D. dissertation.  Department of Forest Sciences.  Colorado State University.  Fort Collins, Colorado.  165 pages.",Reuse of this database is unlimited with retention of copyright notice for Jock A. Blackard and Colorado State University.,"Joao Gama and Ricardo Rocha and Pedro Medas. Accurate decision trees for mining high-speed data streams. KDD. 2003.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Chris Giannella and Bassem Sayrafi. An Information Theoretic Histogram for Single Dimensional Selectivity Estimation. Department of Computer Science, Indiana University Bloomington.  [View Context].Johannes Furnkranz. Round Robin Rule Learning. Austrian Research Institute for Artificial Intelligence.  [View Context].Zoran Obradovic and Slobodan Vucetic. Challenges in Scientific Data Mining: Heterogeneous, Biased, and Large Samples. Center for Information Science and Technology Temple University.  [View Context].Arto Klami and Samuel Kaski and Ty n ohjaaja and Janne Sinkkonen. HELSINKI UNIVERSITY OF TECHNOLOGY Department of Engineering Physics and Mathematics Arto Klami Regularized Discriminative Clustering. Regularized Discriminative Clustering.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+%28Version+1%29,386,Waveform Database Generator (Version 1) Data Set,../machine-learning-databases/waveform/,"Multivariate, Data-Generator",5000,Physical,Real,21,11/10/1988,Classification,No,74614,"Original Owners: Breiman,L., Friedman,J.H., Olshen,R.A., & Stone,C.J. (1984). Classification and Regression Trees.  Wadsworth InternationalGroup: Belmont, California.  (see pages 43-49). Donor:  David Aha ","Notes:     -- 3 classes of waves     -- 21 attributes, all of which include noise     -- See the book for details (49-55, 169)     -- waveform.data.Z contains 5000 instances","    -- Each class is generated from a combination of 2 of 3 ""base"" waves    -- Each instance is generated f added noise (mean 0, variance 1) in each attribute     -- See the book for details (49-55, 169)","Leo Breiman, Jerome H. Friedman, Adam Olshen, Jonathan Stone. ""Classification and Regression Trees."" 1984.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Giorgio Valentini. Random Aggregated and Bagged Ensembles of SVMs: An Empirical Bias?Variance Analysis. Multiple Classifier Systems. 2004.  [View Context].Zhi-Hua Zhou and W-D Wei and Gang Li and Honghua Dai. On the Size of Training Set and the Benefit from Ensemble. PAKDD. 2004.  [View Context].Eibe Frank and Mark Hall and Bernhard Pfahringer. Locally Weighted Naive Bayes. UAI. 2003.  [View Context].Giorgio Valentini and Thomas G. Dietterich. Low Bias Bagged Support Vector Machines. ICML. 2003.  [View Context].Joao Gama and Ricardo Rocha and Pedro Medas. Accurate decision trees for mining high-speed data streams. KDD. 2003.  [View Context].Giorgio Valentini. Ensemble methods based on bias--variance analysis Theses Series DISI-TH-2003. Dipartimento di Informatica e Scienze dell'Informazione . 2003.  [View Context].S. Sathiya Keerthi and Kaibo Duan and Shirish Krishnaj Shevade and Aun Neow Poo. A Fast Dual Algorithm for Kernel Logistic Regression. ICML. 2002.  [View Context].James Bailey and Thomas Manoukian and Kotagiri Ramamohanarao. Fast Algorithms for Mining Emerging Patterns. PKDD. 2002.  [View Context].Bede Liu and Mingzeng Hu and Wynne Hsu. Multi-level organization and summarization of the discovered rules. KDD. 2000.  [View Context].Thomas G. Dietterich. An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization. Machine Learning, 40. 2000.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso. Applying Boosting to Similarity Literals for Time Series Classification. Department of Informatics University of Valladolid, Spain. 2000.  [View Context].Juan J Rodríguez Diez and Carlos Alonso González and Henrik Boström. Learning First Order Logic Time Series Classifiers: Rules and Boosting. PKDD. 2000.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso and Henrik Bostrom. Boosting Interval Based Literals. 2000.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Khaled A. Alsabti and Sanjay Ranka and Vineet Singh. CLOUDS: A Decision Tree Classifier for Large Datasets. KDD. 1998.  [View Context].Kai Ming Ting and Boon Toh Low. Model Combination in the Multiple-Data-Batches Scenario. ECML. 1997.  [View Context].Nir Friedman and Moisés Goldszmidt. Discretizing Continuous Attributes While Learning Bayesian Networks. ICML. 1996.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Tapio Elomaa and Juho Rousu. Finding Optimal Multi-Splits for Numerical Attributes in Decision Tree Learning. ESPRIT Working Group in Neural and Computational Learning. 1996.  [View Context].Dietrich Wettschereck and David W. Aha. Weighting Features. ICCBR. 1995.  [View Context].Vikas Sindhwani and P. Bhattacharya and Subrata Rakshit. Information Theoretic Feature Crediting in Multiclass Support Vector Machines.  [View Context].Mohammed Waleed Kadous. Expanding the Scope of Concept Learning Using Metafeatures. School of Computer Science and Engineering, University of New South Wales.  [View Context].Thomas T. Osugi and M. S. EXPLORATION-BASED ACTIVE MACHINE LEARNING. Faculty of The Graduate College at the University of Nebraska In Partial Fulfillment of Requirements.  [View Context].Pierre Geurts. Extremely randomized trees. Technical report June 2003 University of Li#ege Department of Electrical Engineering and Computer Science Institut Monte#ore.  [View Context].Iñaki Inza and Pedro Larraaga and Ramon Etxeberria and Basilio Sierra. Feature Subset Selection by Bayesian networks based optimization. Dept. of Computer Science and Artificial Intelligence. University of the Basque Country.  [View Context].Kai Ming Ting and Boon Toh Low. Theory Combination: an alternative to Data Combination. University of Waikato.  [View Context].Matthias Scherf and W. Brauer. Feature Selection by Means of a Feature Weighting Approach. GSF - National Research Center for Environment and Health.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context].Giorgio Valentini. An experimental bias--variance analysis of SVM ensembles based on resampling techniques.  [View Context].Juan J. Rodr and guez Diez and Carlos J. Alonso. Learning Classification RBF Networks by Boosting. Lenguajes y Sistemas Inform#aticos.  [View Context].Zoran Obradovic and Slobodan Vucetic. Challenges in Scientific Data Mining: Heterogeneous, Biased, and Large Samples. Center for Information Science and Technology Temple University.  [View Context].Carlos J. Alonso Gonzalez and Juan J. Rodr and iguez Diez. Time Series Classification by Boosting Interval Based Literals. Grupo de Sistemas Inteligentes Departamento de Informatica Universidad de Valladolid.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso and Henrik Bostrom. Learning First Order Logic Time Series Classifiers: Rules and Boosting. Grupo de Sistemas Inteligentes, Departamento de Inform#atica Universidad de Valladolid, Spain.  [View Context].Kai Ming Ting and Ian H. Witten. Stacked Generalization: when does it work. Department of Computer Science University of Waikato.  [View Context].Amund Tveit. Empirical Comparison of Accuracy and Performance for the MIPSVM classifier with Existing Classifiers. Division of Intelligent Systems Department of Computer and Information Science, Norwegian University of Science and Technology.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Lung+Cancer,388,Lung Cancer Data Set,../machine-learning-databases/lung-cancer/,Multivariate,32,Life,Integer,56,5/1/1992,Classification,Yes,302768,"Data was published in :  Hong, Z.Q. and Yang, J.Y. ""Optimal Discriminant Plane for a Small Number of Samples and Design Method of Classifier on the Plane"",Pattern Recognition, Vol. 24, No. 4, pp. 317-324, 1991. Donor:  Stefan Aeberhard, stefan '@' coral.cs.jcu.edu.au ","This data was used by Hong and Young to illustrate the power of the optimal discriminant plane even in ill-posed settings. Applying the KNN method in the resulting plane gave 77% accuracy. However, these results are strongly biased (See Aeberhard's second ref. above, or email to stefan '@' coral.cs.jcu.edu.au). Results obtained by Aeberhard et al. are : RDA : 62.5%, KNN 53.1%, Opt. Disc. Plane 59.4% The data described 3 types of pathological lung cancers. The Authors give no information on the individual variables nor on where the data was originally used. Notes:-  In the original data 4 values for the fifth attribute were -1. These values have been changed to ? (unknown). (*)-  In the original data 1 value for the 39 attribute was 4.  This value has been changed to ? (unknown). (*)","Attribute 1 is the class label. All predictive attributes are nominal, taking on integer values 0-3","Hong, Z.Q. and Yang, J.Y. ""Optimal Discriminant Plane for a Small Number of Samples and Design Method of Classifier on the Plane"", Pattern Recognition, Vol. 24, No. 4, pp. 317-324, 1991.[Web Link]  Aeberhard, S., Coomans, D, De Vel, O. ""Comparisons of Classification Methods in High Dimensional Settings"", submitted to Technometrics. Aeberhard, S., Coomans, D, De Vel, O. ""The Dangers of Bias in High Dimensional Settings"", submitted to pattern Recognition.","Please refer to the Machine Learning
Repository's citation policy","Jinyan Li and Limsoon Wong. Using Rules to Analyse Bio-medical Data: A Comparison between C4.5 and PCL. WAIM. 2003.  [View Context].Manoranjan Dash and Huan Liu. Hybrid Search of Feature Subsets. PRICAI. 1998.  [View Context].Glenn Fung and Sathyakama Sandilya and R. Bharat Rao. Rule extraction from Linear Support Vector Machines. Computer-Aided Diagnosis & Therapy, Siemens Medical Solutions, Inc.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Wave+Energy+Converters,389,Wave Energy Converters Data Set,../machine-learning-databases/00494/,Multivariate,288000,Computer,Real,49,6/30/2019,Regression,Yes,17675,"Creator/Donor:  Mehdi Neshat , Optimization and Logistic group, Computer science department, Adelaide University, neshat.mehdi '@' gmail.com, mehdi.neshat '@' adelaide.edu.au. Supervisors:Dr. Markus Wagnerhttps://cs.adelaide.edu.au/users/markus/ https://cs.adelaide.edu.au/~optlog/research/energy.php Dr. Bradley Alexanderhttps://researchers.adelaide.edu.au/profile/bradley.alexander ","This data set consists of positions and absorbed power outputs of wave energy converters (WECs) in four real wave scenarios from the southern coast of Australia (Sydney, Adelaide, Perth and Tasmania). The applied converter model is a fully submerged three-tether converter called CETO [1]. 16 WECs locations are placed and optimized in a size-constrained environment. In terms of optimization, the problem is categorised as an expensive optimization problem that each farm evaluation takes several minutes. The results are derived from several popular and successful Evolutionary optimization methods that are published in [2,3].  The source code of the applied hydrodynamic simulator [4] is available by the below link: [Web Link]  This work was supported with supercomputing resources provided by the Phoenix HPC service at the University of Adelaide.","Attribute: Attribute Range  1. WECs position {X1, X2, â€¦, X16; Y1, Y2,â€¦, Y16} continuous from 0 to 566 (m). 2. WECs absorbed power: {P1, P2, â€¦, P16} 3. Total power output of the farm: Powerall ","[1] L. D. Mann, A. R. Burns, , and M. E. Ottaviano. 2007. CETO, a carbon free wave power energy provider of the future. In the 7th European Wave and Tidal Energy Conference (EWTEC).  [2] Neshat, M., Alexander, B., Wagner, M., & Xia, Y. (2018, July). A detailed comparison of meta-heuristic methods for optimising wave energy converter placements. In Proceedings of the Genetic and Evolutionary Computation Conference (pp. 1318-1325). ACM.[3] Neshat, M., Alexander, B., Sergiienko, N., & Wagner, M. (2019). A new insight into the Position Optimization of Wave Energy Converters by a Hybrid Local Search. arXiv preprint [Web Link].","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/EMG+Physical+Action+Data+Set,390,EMG Physical Action Data Set Data Set,../machine-learning-databases/00213/,Time-Series,10000,Physical,Real,8,7/27/2011,Classification,N/A,86140,"Theo TheodoridisSchool of Computer Science and Electronic EngineeringUniversity of EssexWivenhoe Park, Colchester, CO4 3SQ, UKttheod '@' gmail.com http://sites.google.com/site/ttheod/","1. Protocol:   Three male and one female subjects (age 25 to 30), who have experienced aggression in scenarios   such as physical fighting, took part in the experiment. Throughout 20 individual experiments,   each subject had to perform ten normal and ten aggressive activities. Regarding the rights of the   subjects involved, ethical regulations and safety precaution have been followed based on the code   of ethics of the British psychological society. The regulations explain the ethical legislations   to be applied when experiments with human subjects are conducted. According to the experimental   setup and the precautions taken, the ultimate risk of injuries was minimal. The subjects were aware   that since their involvement in this series of experiments was voluntary, it was made clear that   they could withdraw at any time from the study. 2. Instrumentation:   The Essex robotic arena was the main experimental hall where the data collection took place.   With area 4x5.5m, the subjects expressed aggressive physical activities at random locations. A   professional kick-boxing standing bag has been used, 1.75m tall, with a human figure drawn on   its body. The subjectsâ€™ performance has been recorded by the Delsys EMG apparatus, interfacing   human activity with myoelectrical contractions. Based on this context, the data acquisition process   involved eight skin-surface electrodes placed on the upper arms (biceps and triceps), and upper legs   (thighs and hamstrings). 3. Data Setup:   The overall number of electrodes is 8, which corresponds to 8 input time series one for a muscle   channel (ch1-8). Each time series contains ~10000 samples (~15 actions per experimental session   for each subject).","Each file in the dataset contains in overall 8 columns, and is organised as follows: +---------+---------------+---------------+---------------+---------------+| Segment |     R-Arm     |     L-Arm     |     R-Leg     |     L-Leg     |+---------+-------+-------+-------+-------+-------+-------+-------+-------+| Channel | ch1   | ch2   | ch3   | ch4   | ch5   | ch6   | ch7   | ch8   || Muscle  | R-Bic | R-Tri | L-Bic | L-Tri | R-Thi | R-Ham | L-Thi | L-Ham || Column  | 0     | 1     | 2     | 3     | 4     | 5     | 6     | 7     |+---------+-------+-------+-------+-------+-------+-------+-------+-------+ Segment: A segment defines a body segment or limb.         - Right arm (R-Arm)	 - Left arm (L-Arm)	 - Right leg (R-Leg)	 - Left leg (L-Leg) Channel: A channel corresponds to an electrode attached on a muscle. Muscle:  A pair of muscles that corresponds to a segment.	 - R-Bic: right bicep (C1)	 - R-Tri: right tricep (C2)	 - L-Bic: left bicep (C3)	 - L-Tri: left tricep (C4)	 - R-Thi: right thigh (C5)	 - R-Ham: right hamstring (C6)	 - L-Thi: left thigh (C7)	 - L-Ham: left hamstring (C8)",N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/p53+Mutants,391,p53 Mutants Data Set,../machine-learning-databases/p53/,Multivariate,16772,Life,Real,5409,2/9/2010,Classification,Yes,79410,"Richard H. Lathrop, UC Irvine, http://www.ics.uci.edu/~rickl ","Biophysical models of mutant p53 proteins yield features which can be used to predict p53 transcriptional activity.  All class labels are determined via in vivo assays. K8.data - full dataset, 'K8' The following files are provided in order to reconstruct this historical subsets of this data set:K8.instance.tags - provides the precise p53 mutant tag for each instance in the K8.data, for use with the historical definition files:K1.def - defines instances in the 'K1' set.K2.def - defines instances in the 'K2' set.K3.def - defines instances in the 'K3' set.K4.def - defines instances in the 'K4' set.K5.def - defines instances in the 'K5' set.K6.def - defines instances in the 'K6' set.K7.def - defines instances in the 'K7' set.K8.def - defines instances in the 'K8' (full) set.","There are a total of 5409 attributes per instance.  Attributes 1-4826 represent 2D electrostatic and surface based features.Attributes 4827-5408 represent 3D distance based features.Attribute 5409 is the class attribute, which is either active or inactive. The class labels are to be interpreted as follows: 'active' represents transcriptonally competent, active p53 whereas the 'inactive' label represents cancerous, inactive p53.  Class labels are determined experimentally. More information is provided in the relevant papers cited.","Danziger, S.A., Baronio, R., Ho, L., Hall, L., Salmon, K., Hatfield, G.W., Kaiser, P., and Lathrop, R.H. (2009) Predicting Positive p53 Cancer Rescue Regions Using Most Informative Positive (MIP) Active Learning, PLOS Computational Biology, 5(9), e1000498 Danziger, S.A., Zeng, J., Wang, Y., Brachmann, R.K. and Lathrop, R.H. (2007) Choosing where to look next in a mutation sequence space: Active Learning of informative p53 cancer rescue mutants, Bioinformatics, 23(13), 104-114. Danziger, S.A., Swamidass, S.J., Zeng, J., Dearth, L.R., Lu, Q., Chen, J.H., Cheng, J., Hoang, V.P., Saigo, H., Luo, R., Baldi, P., Brachmann, R.K. and Lathrop, R.H. (2006) Functional census of mutation sequence spaces: the example of p53 cancer rescue mutants, IEEE/ACM transactions on computational biology and bioinformatics / IEEE, ACM, 3, 114-125.","If you use this dataset, please cite the relevant papers above.  Thank you.",
http://archive.ics.uci.edu/ml/datasets/Phishing+Websites,392,Phishing Websites Data Set,../machine-learning-databases/00327/,N/A,2456,Computer Security,Integer,30,3/26/2015,Classification,N/A,145660,"Rami Mustafa A Mohammad ( University of Huddersfield, rami.mohammad '@' hud.ac.uk, rami.mustafa.a '@' gmail.com)Lee McCluskey (University of Huddersfield,t.l.mccluskey '@' hud.ac.uk ) Fadi Thabtah (Canadian University of Dubai,fadi '@' cud.ac.ae)","One of the challenges faced by our research was the unavailability of reliable training datasets. In fact this challenge faces any researcher in the field. However, although plenty of articles about predicting phishing websites have been disseminated these days, no reliable training dataset has been published publically, may be because there is no agreement in literature on the definitive features that characterize phishing webpages, hence it is difficult to shape a dataset that covers all possible features. In this dataset, we shed light on the important features that have proved to be sound and effective in predicting phishing websites. In addition, we propose some new features.",For Further information about the features see the features file in the data folder.,"Mohammad, Rami, McCluskey, T.L. and Thabtah, Fadi (2012) An Assessment of Features Related to Phishing Websites using an Automated Technique. In: International Conferece For Internet Technology And Secured Transactions. ICITST 2012 . IEEE, London, UK, pp. 492-497. ISBN 978-1-4673-5325-0 Mohammad, Rami, Thabtah, Fadi Abdeljaber and McCluskey, T.L. (2014) Predicting phishing websites based on self-structuring neural network. Neural Computing and Applications, 25 (2). pp. 443-458. ISSN 0941-0643 Mohammad, Rami, McCluskey, T.L. and Thabtah, Fadi Abdeljaber (2014) Intelligent Rule based Phishing Websites Classification. IET Information Security, 8 (3). pp. 153-160. ISSN 1751-8709","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Incident+management+process+enriched+event+log,393,Incident management process enriched event log Data Set,../machine-learning-databases/00498/,"Multivariate, Sequential",141712,Business,Integer,36,7/14/2019,"Regression, Clustering",Yes,21060,"Claudio Aparecido Lira do Amaral, claudio.amaral '@' usp.br, University of SÃ£o Paulo, BrazilMarcelo Fantinato, m.fantinato '@' usp.br, University of SÃ£o Paulo, BrazilSarajane Marques Peres, sarajane '@' usp.br, University of SÃ£o Paulo, Brazil","This is an event log of an incident management process extracted from data gathered from the audit system of an instance of the ServiceNowTM platform used by an IT company. The event log is enriched with data loaded from a relational database underlying a corresponding process-aware information system. Information was anonymized for privacy. Number of instances: 141,712 events (24,918 incidents)Number of attributes: 36 attributes (1 case identifier, 1 state identifier, 32 descriptive attributes, 2 dependent variables) The attributed â€˜closed_atâ€™ is used to determine the dependent variable for the time completion prediction task. The attribute â€˜resolved_atâ€™ is highly correlated with â€˜closed_atâ€™. In this event log, some rows may have the same values (they are equal) since not all attributes involved in the real-world process are present in the log. Attributes used to record textual information are not placed in this log. The missing values should be considered â€˜unknown informationâ€™.","1. number: incident identifier (24,918 different values);2. incident state: eight levels controlling the incident management process transitions from opening until closing the case;3. active: boolean attribute that shows whether the record is active or closed/canceled;4. reassignment_count: number of times the incident has the group or the support analysts changed;5. reopen_count: number of times the incident resolution was rejected by the caller;6. sys_mod_count: number of incident updates until that moment;7. made_sla: boolean attribute that shows whether the incident exceeded the target SLA;8. caller_id: identifier of the user affected;9. opened_by: identifier of the user who reported the incident;10. opened_at: incident user opening date and time;11. sys_created_by: identifier of the user who registered the incident;12. sys_created_at: incident system creation date and time;13. sys_updated_by: identifier of the user who updated the incident and generated the current log record;14. sys_updated_at: incident system update date and time;15. contact_type: categorical attribute that shows by what means the incident was reported;16. location: identifier of the location of the place affected;17. category: first-level description of the affected service;18. subcategory: second-level description of the affected service (related to the first level description, i.e., to category);19. u_symptom: description of the user perception about service availability;20. cmdb_ci: (confirmation item) identifier used to report the affected item (not mandatory);21. impact: description of the impact caused by the incident (values: 1â€“High; 2â€“Medium; 3â€“Low);22. urgency: description of the urgency informed by the user for the incident resolution (values: 1â€“High; 2â€“Medium; 3â€“Low);23. priority: calculated by the system based on 'impact' and 'urgency';24. assignment_group: identifier of the support group in charge of the incident;25. assigned_to: identifier of the user in charge of the incident;26. knowledge: boolean attribute that shows whether a knowledge base document was used to resolve the incident;27. u_priority_confirmation: boolean attribute that shows whether the priority field has been double-checked;28. notify: categorical attribute that shows whether notifications were generated for the incident;29. problem_id: identifier of the problem associated with the incident;30. rfc: (request for change) identifier of the change request associated with the incident;31. vendor: identifier of the vendor in charge of the incident;32. caused_by: identifier of the RFC responsible by the incident;33. close_code: identifier of the resolution of the incident;34. resolved_by: identifier of the user who resolved the incident;35. resolved_at: incident user resolution date and time (dependent variable);36. closed_at: incident user close date and time (dependent variable).","Amaral, C. A. L., Fantinato, M., Reijers, H. A., Peres, S. M., Enhancing Completion Time Prediction Through Attribute Selection. Proceedings of the 15th International Conference on Advanced Information Technologies for Management (AITM 2018) and 13th International Conference on Information Systems Management (ISM 2018), Revised Selected Papers â€“ Lecture Notes in Business Information Processing, v. 346, pp. 3-23, 2019. [Web Link]  Amaral, C. A. L., Fantinato, M., Peres, S. M., Attribute Selection with Filter and Wrapper: An Application on Incident Management Process. Proceedings of the 14th Federated Conference on Computer Science and Information Systems (FedCSIS 2018), pp. 679-682, 2018. [Web Link]  Maita, A. R. C., Martins, L. C., Paz, C. R. L., Rafferty, L., Hung, P., Peres, S. M., Fantinato, M. A systematic mapping study of process mining. Enterprise Information Systems, v. 12, n. 5, pp. 505-549, 2018. [Web Link]","Please cite this paper if you use this dataset: Amaral, C. A. L., Fantinato, M., Reijers, H. A., Peres, S. M., Enhancing Completion Time Prediction Through Attribute Selection. Proceedings of the 15th International Conference on Advanced Information Technologies for Management (AITM 2018) and 13th International Conference on Information Systems Management (ISM 2018), Revised Selected Papers â€“ Lecture Notes in Business Information Processing, v. 346, pp. 3-23, 2019. [Web Link]  Moreover, refer to the Machine Learning Repository's citation policy.",
http://archive.ics.uci.edu/ml/datasets/Planning+Relax,394,Planning Relax Data Set,../machine-learning-databases/00230/,Univariate,182,Computer,Real,13,7/17/2012,Classification,N/A,59224,"Rajen Bhatt, rajen.bhatt '@' gmail.com, IIT Delhi","EEG record contains many regular oscillations, which are believed to reflect synchronized rhythmic activity in a group of neurons. Most activity related EEG patterns occur within the following frequency bands. Delta (0.5 â€“ 4 Hz.), Theta (4 â€“ 8 Hz), Alpha (8 â€“ 13 Hz), Beta (13 â€“ 22 Hz), and Gamma (30 â€“ 40 Hz). The waves with the frequency of  7 â€“ 13 Hz over motor processing areas are called mu rhythm and reflect idling activity in motor areas. It is more pronounced when the subjects are at rest and at least a second before subjects initiate voluntary movement, the mu  activity over the hemisphere contralateral to the region moved shows a decrease in amplitude and is called Event Related Desynchronization (ERD).For the current study, EEG data was collected for 5 times on various days from a healthy right-handed subject of 25 years of age. The data was recorded on a Medelec Profile Digital EEG machine. The settings of high frequency filter 50 Hz, low frequency filter 1.6 Hz, notch filter 50 Hz, sensitivity 70 micro volts/mm, and a sampling rate of 256 Hz were used for the basic signal processing. Eight EEG electrodes (C3, C4, P3, P4, F3, F4, T3, and T4) were placed according to the international standard 10-20 system of electrode placement. Bipolar and unipolar EEG was recorded from eight Ag/AgCI scalp electrodes, which were placed 2.5 cm anterior and posterior to the central electrodes C3 and C4 (left and right side of the hemisphere). A1 and A2 are reference electrodes. The reference electrodes are placed on the left and right ears and the ground electrode on the forehead. EOG (Electrooculogram) being a noise artifact, was derived from two electrodes, placed on the outer cantus of left and right eye in order to detect eye movement. These EOG signals are then used to eliminate eye movement artifacts. The subject was asked to lie down comfortably in a relaxed position with eyes closed and advised to minimize eye movements. The EEG was recorded for the relaxed state for 5 minutes. Following this, an audio beep of 60 db and 0.91 sec. duration was given at the start and end of a 5 second epoch where the subject was asked to mentally plan lifting of the right hand thumb. This activity is collected as a 5 second epoch data corresponding to â€˜movement imageryâ€™ state. After a gap of 5 minutes, the same cue is given to repeat the experiment. The whole experiment lasts for approximately 30 minutes, collecting data for 5 trials of 5 second epoch each for normal relaxed state and 5 trials of 5 second epoch each for movement imagery. No actual movement is performed during the session. All data sets were visually checked for artifacts before final selection.","Wavelet transform has been applied for feature extraction for EEG classification. However, wavelet transforms pyramidal algorithm work only on approximation coefficients. So it can not identify 7-13 Hz frequency band. We have extended the methodology by applying wavelet packet analysis, which also decompose detail coefficients. Wavelet packet analysis has been used for signal decomposition with equal frequency bandwidth at each level of decomposition, which leads to an equal number of the approximation and detail coefficients. By applying wavelet packet analysis on the original signal, we have obtained twelve wavelet coefficients in the 7-13 Hz frequency band at the 6th level node (6,2). The signal is reconstructed at node (6,2) and its FFT plot gave the frequency band 7-13 Hz as the most discriminating, in conjunction with the wavelet Daubechies#6 (db6).","1. Rajen B. Bhatt and M. Gopal, 2008, â€œFRCT: Fuzzy-Rough Classification Treesâ€, Pattern Analysis and Applications, 11(1), pp. 73-88.2. Shweta Sahu and Rajen B. Bhatt, â€œAutomatic classification of Electroencephalography Signals using Wavelet Packet Analysis and Fuzzy Decision Treesâ€, in Proc. of 28th National Systems Conference (NSC-2004), Dec. 16-18, Vellore, India.3. Rajen Bhatt, 'Fuzzy-Rough Approach to Pattern Classification:Hybrid Algorithms and Optimization', Ph.D. Thesis, IIT Delhi, 2006.","Rajen Bhatt, 'Planning-Relax Dataset for Automatic Classification of EEG Signals', UCI Machine Learning Repository",
http://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records,395,Heart failure clinical records Data Set,../machine-learning-databases/00519/,Multivariate,299,Life,"Integer, Real",13,2/5/2020,"Classification, Regression, Clustering",N/A,8666,"Provide the names, email addresses, institutions, and other contact information of the donors and creators of the data set.The original dataset version was collected by Tanvir Ahmad, Assia Munir, Sajjad Haider Bhatti, Muhammad Aftab, and Muhammad Ali Raza (Government College University, Faisalabad, Pakistan) and made available by them on FigShare under the Attribution 4.0 International (CC BY 4.0: freedom to share and adapt the material) copyright in July 2017.  The current version of the dataset was elaborated by Davide Chicco (Krembil Research Institute, Toronto, Canada) and donated to the University of California Irvine Machine Learning Repository under the same Attribution 4.0 International (CC BY 4.0) copyright in January 2020. Davide Chicco can be reached at <davidechicco '@' davidechicco.it> ","A detailed description of the dataset can be found in the Dataset section of the following paper:  Davide Chicco, Giuseppe Jurman: ""Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone"". BMC Medical Informatics and Decision Making 20, 16 (2020). [Web Link] ","Thirteen (13) clinical features: - age: age of the patient (years)- anaemia: decrease of red blood cells or hemoglobin (boolean)- high blood pressure: if the patient has hypertension (boolean)- creatinine phosphokinase  (CPK): level of the CPK enzyme in the blood (mcg/L)- diabetes: if the patient has diabetes (boolean)- ejection fraction: percentage of blood leaving the heart at each contraction  (percentage)- platelets: platelets in the blood (kiloplatelets/mL)- sex: woman or man (binary)- serum creatinine: level of serum creatinine in the blood (mg/dL)- serum sodium: level of serum sodium in the blood (mEq/L)- smoking: if the patient smokes or not (boolean)- time: follow-up period (days)- [target] death event: if the patient deceased during the follow-up period (boolean) For more information, please check Table 1, Table 2, and Table 3 of the following paper:  Davide Chicco, Giuseppe Jurman: ""Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone"". BMC Medical Informatics and Decision Making 20, 16 (2020). [Web Link] ","Original dataset version: Tanvir Ahmad, Assia Munir, Sajjad Haider Bhatti, Muhammad Aftab, and Muhammad Ali Raza: ""Survival analysis of heart failure patients: a case study"". PLoS ONE 12(7), 0181001 (2017). [Web Link]  Current dataset version on the UCI ML Repository: Davide Chicco, Giuseppe Jurman: ""Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone"". BMC Medical Informatics and Decision Making 20, 16 (2020). [Web Link] ","Davide Chicco, Giuseppe Jurman: ""Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone"". BMC Medical Informatics and Decision Making 20, 16 (2020). [Web Link] ",
http://archive.ics.uci.edu/ml/datasets/South+German+Credit,396,South German Credit Data Set,../machine-learning-databases/00522/,Multivariate,1000,Business,"Integer, Real",21,11/29/2019,"Classification, Regression, Clustering",N/A,2345,"Ulrike GrömpingBeuth University of Applied Sciences BerlinWebsite with contact information: https://prof.beuth-hochschule.de/groemping/","The widely used Statlog German credit data ([Web Link]), as of November 2019, suffers from severe errors in the coding information and does not come with any background information. The 'South German Credit' data provide a correction and some background information, based on the Open Data LMU (2010) representation of the same data and several other German language resources.","## This section contains a brief description for each attribute.## Details on attribute coding can be obtained from the accompanying R code for reading the data## or the accompanying code table,## as well as from Groemping (2019) (listed under 'Relevant Papers'). Column name: laufkontVariable name: statusContent: status of the debtor's checking account with the bank (categorical) Column name: laufzeitVariable name: durationContent: credit duration in months (quantitative) Column name: moralVariable name: credit_historyContent: history of compliance with previous or concurrent credit contracts (categorical) Column name: verwVariable name: purposeContent: purpose for which the credit is needed (categorical) Column name: hoeheVariable name: amountContent: credit amount in DM (quantitative; result of monotonic transformation; actual data and type oftransformation unknown) Column name: sparkontVariable name: savingsContent: debtor's savings (categorical) Column name: beszeitVariable name: employment_durationContent: duration of debtor's employment with current employer (ordinal; discretized quantitative) Column name: rateVariable name: installment_rateContent: credit installments as a percentage of debtor's disposable income (ordinal; discretized quantitative) Column name: famgesVariable name: personal_status_sexContent: combined information on sex and marital status; categorical; sex cannot be recovered from thevariable, because male singles and female non-singles are coded with the same code (2); female widows cannotbe easily classified, because the code table does not list them in any of the female categories Column name: buergeVariable name: other_debtorsContent: Is there another debtor or a guarantor for the credit? (categorical) Column name: wohnzeitVariable name: present_residenceContent: length of time (in years) the debtor lives in the present residence (ordinal; discretized quantitative) Column name: vermVariable name: propertyContent: the debtor's most valuable property, i.e. the highest possible code is used. Code 2 is used, if codes 3or 4 are not applicable and there is a car or any other relevant property that does not fall under variablesparkont. (ordinal) Column name: alterVariable name: ageContent: age in years (quantitative) Column name: weitkredVariable name: other_installment_plansContent: installment plans from providers other than the credit-giving bank (categorical) Column name: wohnVariable name: housingContent: type of housing the debtor lives in (categorical) Column name: bishkredVariable name: number_creditsContent: number of credits including the current one the debtor has (or had) at this bank (ordinal, discretizedquantitative); contrary to Fahrmeir and HamerleÃ¢â‚¬â„¢s (1984) statement, the original data values are not available. Column name: berufVariable name: jobContent: quality of debtor's job (ordinal) Column name: persVariable name: people_liableContent: number of persons who financially depend on the debtor (i.e., are entitled to maintenance) (binary,discretized quantitative) Column name: telefVariable name: telephoneContent: Is there a telephone landline registered on the debtor's name? (binary; remember that the data arefrom the 1970s) Column name: gastarbVariable name: foreign_workerContent: Is the debtor a foreign worker? (binary) Column name: kreditVariable name: credit_riskContent: Has the credit contract been complied with (good) or not (bad) ? (binary)","Fahrmeir, L. and Hamerle, A. (1981, in German). Kategoriale Regression in der betrieblichen Planung. *Zeitschrift för Operations Research* **25**, B63-B78. Fahrmeir, L. and Hamerle, A. (1984, in German). *Multivariate Statistische Verfahren* (1st ed., Ch.8 and Appendix C). De Gruyter, Berlin. Grömping, U. (2019). South German Credit Data: Correcting a Widely Used Data Set. Report 4/2019, Reports in Mathematics, Physics and Chemistry, Department II, Beuth University of Applied Sciences Berlin. URL: [[Web Link]]. Häußler, W.M. (1979, in German). Empirische Ergebnisse zu Diskriminationsverfahren bei Kreditscoringsystemen. *Zeitschrift för Operations Research* **23**, B191-B210. Hofmann, H.J. (1990, in German). Die Anwendung des CART-Verfahrens zur statistischen Bonitätsanalyse von Konsumentenkrediten. *Zeitschrift för Betriebswirtschaft* **60**, 941-962. Open data LMU (2010; accessed Nov 27 2019; in German). Kreditscoring zur Klassifikation von Kreditnehmern. URL: [[Web Link]].","Grömping, U. (2019). South German Credit Data: Correcting a Widely Used Data Set. Report 4/2019, Reports in Mathematics, Physics and Chemistry, Department II, Beuth University of Applied Sciences Berlin.",
http://archive.ics.uci.edu/ml/datasets/Soybean+%28Small%29,397,Soybean (Small) Data Set,../machine-learning-databases/soybean/,Multivariate,47,Life,Categorical,35,1/1/1987,Classification,No,101965,"Origin: Michalski,R.S. Learning by being told and learning from examples: an experimental comparison of the two methodes of knowledge acquisition in the context of developing an expert system for soybean desease diagnoiss"", International Journal of Policy Analysis and Information Systems, 1980, 4(2), 125-161. Donor:  Doug Fisher (dfisher%vuse '@' uunet.uucp)","A small subset of the original soybean database.  See the reference for Fisher and Schlimmer in soybean-large.names for more information. Steven Souders wrote:     > Figure 15 in the Michalski and Stepp paper (PAMI-82) says that the    > discriminant values for the attribute CONDITION OF FRUIT PODS for the    > classes Rhizoctonia Root Rot and Phytophthora Rot are ""few or none""    > and ""irrelevant"" respectively.  However, in the SOYBEAN-SMALL dataset    > I got from UCI, the value for this attribute is ""dna"" (does not apply)    > for both classes.  I show the actual data below for cases D3    > (Rhizoctonia Root Rot) and D4 (Phytophthora Rot).  According to the    > attribute names given in soybean-large.names, FRUIT-PODS is attribute    > #28.  If you look at column 28 in the data below (marked with arrows)    > you'll notice that all cases of D3 and D4 have the same value.  Thus,    > the SOYBEAN-SMALL dataset from UCI could NOT have produced the results    > in the Michalski and Stepp paper. I do not have that paper, but have found what is probably a later variation of that figure in Stepp's dissertation, which lists the value ""normal"" for the first 2 classes and ""irrelevant"" for the latter 2 classes.  I believe that ""irrelevant"" is used here as a synonym for ""not-applicable"", ""dna"", and ""does-not-apply"".  I believe that there is a mis-print in the figure he read in their PAMI-83 article. I have checked over each attribute value in this database.  It corresponds exactly with the copies listed in both Stepp's and Fisher's dissertations.","    1. date:		april,may,june,july,august,september,october,?.    2. plant-stand:	normal,lt-normal,?.    3. precip:		lt-norm,norm,gt-norm,?.    4. temp:		lt-norm,norm,gt-norm,?.    5. hail:		yes,no,?.    6. crop-hist:	diff-lst-year,same-lst-yr,same-lst-two-yrs,                        same-lst-sev-yrs,?.    7. area-damaged:	scattered,low-areas,upper-areas,whole-field,?.    8. severity:	minor,pot-severe,severe,?.    9. seed-tmt:	none,fungicide,other,?.   10. germination:	90-100%,80-89%,lt-80%,?.   11. plant-growth:	norm,abnorm,?.   12. leaves:		norm,abnorm.   13. leafspots-halo:	absent,yellow-halos,no-yellow-halos,?.   14. leafspots-marg:	w-s-marg,no-w-s-marg,dna,?.   15. leafspot-size:	lt-1/8,gt-1/8,dna,?.   16. leaf-shread:	absent,present,?.   17. leaf-malf:	absent,present,?.   18. leaf-mild:	absent,upper-surf,lower-surf,?.   19. stem:		norm,abnorm,?.   20. lodging:    	yes,no,?.   21. stem-cankers:	absent,below-soil,above-soil,above-sec-nde,?.   22. canker-lesion:	dna,brown,dk-brown-blk,tan,?.   23. fruiting-bodies:	absent,present,?.   24. external decay:	absent,firm-and-dry,watery,?.   25. mycelium:	absent,present,?.   26. int-discolor:	none,brown,black,?.   27. sclerotia:	absent,present,?.   28. fruit-pods:	norm,diseased,few-present,dna,?.   29. fruit spots:	absent,colored,brown-w/blk-specks,distort,dna,?.   30. seed:		norm,abnorm,?.   31. mold-growth:	absent,present,?.   32. seed-discolor:	absent,present,?.   33. seed-size:	norm,lt-norm,?.   34. shriveling:	absent,present,?.   35. roots:		norm,rotted,galls-cysts,?.","Tan, M., & Eshelman, L. (1988). Using weighted networks to represent classification knowledge in noisy domains.  Proceedings of the Fifth International Conference on Machine Learning (pp. 121-134). Ann Arbor, Michigan: Morgan Kaufmann.[Web Link]  Fisher,D.H. & Schlimmer,J.C. (1988). Concept Simplification and Predictive Accuracy. Proceedings of the Fifth International Conference on Machine Learning (pp. 22-28). Ann Arbor, Michigan: Morgan Kaufmann.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Rich Caruana and Alexandru Niculescu-Mizil and Geoff Crew and Alex Ksikes. Ensemble selection from libraries of models. ICML. 2004.  [View Context].Rich Caruana and Alexandru Niculescu-Mizil. Data Mining in Metric Space: An Empirical Analysis of Supervised Learning Performance Criteria. ROCAI. 2004.  [View Context].Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].Rich Caruana and Alexandru Niculescu-Mizil. An Empirical Evaluation of Supervised Learning for ROC Area. ROCAI. 2004.  [View Context].Prem Melville and Raymond J. Mooney. Diverse ensembles for active learning. ICML. 2004.  [View Context].Geoffrey Holmes and Bernhard Pfahringer and Richard Kirkby and Eibe Frank and Mark A. Hall. Multiclass Alternating Decision Trees. ECML. 2002.  [View Context].Subramani Mani and Marco Porta and Suzanne McDermott. Building Bayesian Network Models in Medicine: the MENTOR Experience. Center for Biomedical Informatics University of Pittsburgh. 2002.  [View Context].Marco Porta and Subramani Mani and Suzanne McDermott. MENTOR: Building Bayesian Network Models in Medicine CSCE Technical Report TR-2002-016. Department of Computer Science and Engineering University of South Carolina. 2002.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Bianca Zadrozny. Reducing multiclass to binary by coupling probability estimates. NIPS. 2001.  [View Context].Rudy Setiono. Feedforward Neural Network Construction Using Cross Validation. Neural Computation, 13. 2001.  [View Context].Kiri Wagstaff and Claire Cardie. Clustering with Instance-level Constraints. ICML. 2000.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Manoranjan Dash and Huan Liu. Hybrid Search of Feature Subsets. PRICAI. 1998.  [View Context].Huan Liu and Rudy Setiono. Incremental Feature Selection. Appl. Intell, 9. 1998.  [View Context].Hendrik Blockeel and Luc De Raedt and Jan Ramon. Top-Down Induction of Clustering Trees. ICML. 1998.  [View Context].Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF. Appl. Intell, 7. 1997.  [View Context].Nir Friedman and Dan Geiger and Moisés Goldszmidt. Bayesian Network Classifiers. Machine Learning, 29. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Guszti Bartfai. VICTORIA UNIVERSITY OF WELLINGTON Te Whare Wananga o te Upoko o te Ika a Maui. Department of Computer Science PO Box 600. 1996.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Ron Kohavi. A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection. IJCAI. 1995.  [View Context].Thomas G. Dietterich and Ghulum Bakiri. Solving Multiclass Learning Problems via Error-Correcting Output Codes. CoRR, csAI/9501101. 1995.  [View Context].Christophe Giraud and Tony Martinez and Christophe G. Giraud-Carrier. University of Bristol Department of Computer Science ILA: Combining Inductive Learning with Prior Knowledge and Reasoning. 1995.  [View Context].Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. Exploiting Upper Approximation in the Rough Set Methodology. KDD. 1995.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Geoffrey I. Webb. OPUS: A systematic search algorithm and its application to categorical attribute-value datadriven machine learning. School of Computing and Mathematics, Deakin University. 1993.  [View Context].Perry Moerland. A Comparison of Mixture Models for Density Estimation. IDIAP.  [View Context].Zhi-Hua Zhou and Yang Yu. Ensembling Local Learners Through Multimodal Perturbation.  [View Context].Geoffrey I Webb. Generality is more significant than complexity: Toward an alternative to Occam's Razor. School of Computing and Mathematics Deakin University.  [View Context].Sherrie L. W and Zijian Zheng. A BENCHMARK FOR CLASSIFIER LEARNING. Basser Department of Computer Science The University of Sydney.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context].Prem Melville and Raymond J. Mooney. Proceedings of the 21st International Conference on Machine Learning. Department of Computer Sciences.  [View Context].Jarinee Chattratichart and John Darlington and Moustafa Ghanem and Yang Guo and Harold Huning and Martin Kohler and Janjao Sutiwaraphun and Hing Wing and Dan Yang. Large Scale Data Mining: The Challenges and The Solutions. Department of Computing.  [View Context].Daichi Mochihashi and Gen-ichiro Kikui and Kenji Kita. Learning Nonstructural Distance Metric by Minimum Cluster Distortions. ATR Spoken Language Translation research laboratories.  [View Context].Miguel Moreira and Alain Hertz and Eddy Mayoraz. Data binarization by discriminant elimination. Proceedings of the ICML-99 Workshop: From Machine Learning to.  [View Context].Igor Kononenko and Edvard Simec. Induction of decision trees using RELIEFF. University of Ljubljana, Faculty of electrical engineering & computer science.  [View Context].BayesianClassifi552 Pat Langley and Wayne Iba. In Proceedings of the Tenth National ConferenceonArtifi256 Intelligence( 42840. Lambda Kevin Thompson.  [View Context].YongSeog Kim and W. Nick Street and Filippo Menczer. Optimal Ensemble Construction via Meta-Evolutionary Ensembles. Business Information Systems, Utah State University.  [View Context].Iñaki Inza and Pedro Larraaga and Basilio Sierra. Bayesian networks for feature subset selection. Department of Computer Sciences and Artificial Intelligence.  [View Context].Perry Moerland. Mixtures of latent variable models for density estimation and classification. E S E A R C H R E P R O R T I D I A P D a l l e M o l l e I n s t i t u t e f o r Pe r cep t ua l A r t i f i c i a l Intelligence .  [View Context].Suresh K. Choubey and Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. A comparison of feature selection algorithms in the context of rough classifiers.  [View Context].Takao Mohri and Hidehiko Tanaka. An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes. Information Engineering Course, Faculty of Engineering The University of Tokyo.  [View Context].Nikunj C. Oza and Stuart J. Russell. Online Bagging and Boosting. Computer Science Division University of California.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29,398,Statlog (German Credit Data) Data Set,../machine-learning-databases/statlog/german/,Multivariate,1000,Financial,"Categorical, Integer",20,11/17/1994,Classification,N/A,625844,"Professor Dr. Hans Hofmann  Institut f""ur Statistik und ""Okonometrie  Universit""at Hamburg  FB Wirtschaftswissenschaften  Von-Melle-Park 5    2000 Hamburg 13 ","Two datasets are provided.  the original dataset, in the form provided by Prof. Hofmann, contains categorical/symbolic attributes and is in the file ""german.data"".    For algorithms that need numerical attributes, Strathclyde University produced the file ""german.data-numeric"".  This file has been edited and several indicator variables added to make it suitable for algorithms which cannot cope with categorical variables.   Several attributes that are ordered categorical (such as attribute 17) have been coded as integer.    This was the form used by StatLog. This dataset requires use of a cost matrix (see below)  ..... 1        2----------------------------  1   0        1-----------------------  2   5        0 (1 = Good,  2 = Bad) The rows represent the actual classification and the columns the predicted classification. It is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).","Attribute 1:  (qualitative)       Status of existing checking account             A11 :      ... <    0 DM	       A12 : 0 <= ... <  200 DM	       A13 :      ... >= 200 DM / salary assignments for at least 1 year               A14 : no checking account Attribute 2:  (numerical)	      Duration in month Attribute 3:  (qualitative)	      Credit history	      A30 : no credits taken/ all credits paid back duly              A31 : all credits at this bank paid back duly	      A32 : existing credits paid back duly till now              A33 : delay in paying off in the past	      A34 : critical account/  other credits existing (not at this bank) Attribute 4:  (qualitative)	      Purpose	      A40 : car (new)	      A41 : car (used)	      A42 : furniture/equipment	      A43 : radio/television	      A44 : domestic appliances	      A45 : repairs	      A46 : education	      A47 : (vacation - does not exist?)	      A48 : retraining	      A49 : business	      A410 : others Attribute 5:  (numerical)	      Credit amount Attibute 6:  (qualitative)	      Savings account/bonds	      A61 :          ... <  100 DM	      A62 :   100 <= ... <  500 DM	      A63 :   500 <= ... < 1000 DM	      A64 :          .. >= 1000 DM              A65 :   unknown/ no savings account Attribute 7:  (qualitative)	      Present employment since	      A71 : unemployed	      A72 :       ... < 1 year	      A73 : 1  <= ... < 4 years  	      A74 : 4  <= ... < 7 years	      A75 :       .. >= 7 years Attribute 8:  (numerical)	      Installment rate in percentage of disposable income Attribute 9:  (qualitative)	      Personal status and sex	      A91 : male   : divorced/separated	      A92 : female : divorced/separated/married              A93 : male   : single	      A94 : male   : married/widowed	      A95 : female : single Attribute 10: (qualitative)	      Other debtors / guarantors	      A101 : none	      A102 : co-applicant	      A103 : guarantor Attribute 11: (numerical)	      Present residence since Attribute 12: (qualitative)	      Property	      A121 : real estate	      A122 : if not A121 : building society savings agreement/ life insurance              A123 : if not A121/A122 : car or other, not in attribute 6	      A124 : unknown / no property Attribute 13: (numerical)	      Age in years Attribute 14: (qualitative)	      Other installment plans 	      A141 : bank	      A142 : stores	      A143 : none Attribute 15: (qualitative)	      Housing	      A151 : rent	      A152 : own	      A153 : for free Attribute 16: (numerical)              Number of existing credits at this bank Attribute 17: (qualitative)	      Job	      A171 : unemployed/ unskilled  - non-resident	      A172 : unskilled - resident	      A173 : skilled employee / official	      A174 : management/ self-employed/		     highly qualified employee/ officer Attribute 18: (numerical)	      Number of people being liable to provide maintenance for Attribute 19: (qualitative)	      Telephone	      A191 : none	      A192 : yes, registered under the customers name Attribute 20: (qualitative)	      foreign worker	      A201 : yes	      A202 : no",N/A,"Please refer to the Machine Learning
Repository's citation policy","Jeroen Eggermont and Joost N. Kok and Walter A. Kosters. Genetic Programming for data classification: partitioning the search space. SAC. 2004.  [View Context].Ke Wang and Shiyu Zhou and Ada Wai-Chee Fu and Jeffrey Xu Yu. Mining Changes of Classification by Correspondence Tracing. SDM. 2003.  [View Context].Avelino J. Gonzalez and Lawrence B. Holder and Diane J. Cook. Graph-Based Concept Learning. FLAIRS Conference. 2001.  [View Context].Oya Ekin and Peter L. Hammer and Alexander Kogan and Pawel Winter. Distance-Based Classification Methods. e p o r t RUTCOR ffl Rutgers Center for Operations Research ffl Rutgers University. 1996.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Paul O' Dea and David Griffith and Colm O' Riordan. DEPARTMENT OF INFORMATION TECHNOLOGY. P. O'Dea (NUI.  [View Context].Paul O' Dea and Josephine Griffith and Colm O' Riordan. Combining Feature Selection and Neural Networks for Solving Classification Problems. Information Technology Department, National University of Ireland.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Northix,399,Northix Data Set,../machine-learning-databases/00237/,"Multivariate, Univariate, Text",115,Computer,"Integer, Real",200,8/15/2012,Classification,N/A,38211,"Farid Bourennani, University of Ontario Institute of Technology, farid.bourennani '@' uoit.ca","Northix is designed to be a schema matching benchmark problem for data integration of two entity relationship databases. Northix is the resulting schema matching of two demonstration databases namely Northwind and Sakila. Some unnecessary database entities (columns) such as multimedia were deleted. It was desired to have at least around 200 tuples per database entity; therefore, tuples were randomly injected, respecting the existing pattern, if the number of tuples was low. The schema matching was done manually. The ideal entities matching are grouped into classes. In total, there are 115 input database entities stored respectively as '.dat' from the first database and as '.txt' if from the second database. The file naming pattern is attributeName@ColumnName@Database. After schema matching, the files are grouped into 34 classes (folders). 33 classes are ideal matchings whereas the class 'UNCLASSED' groups all the attributes that are unique and donâ€™t have another similar attribute. The attributes are of different data types such as texts, integers, real numbers, dates, and alphanumeric data types. In total, there are 21805 tokens. A token is separated by spaces and other non alphanumeric characters such as â€œ/-,â€. [1]	Microsoft. Northwind. [Online] 2005. [Cited: 06 28, 2009.] [Web Link].[2]	MySQL. Sakila. [Online] 2005. [Cited: 06 28, 2009.] [Web Link].","In total, there are 115 input database entities stored respectively as '.dat' from the first database and as '.txt' if from the second database. The file naming pattern is attributeName@ColumnName@Database. After schema matching, the files are grouped into 34 classes (folders). 33 classes are ideal matchings whereas the class 'UNCLASSED' groups all the attributes that are unique and donâ€™t have another similar attribute.",Provide references to papers that have cited this data set in the past (if any).,"If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/UbiqLog+%28smartphone+lifelogging%29,400,UbiqLog (smartphone lifelogging) Data Set,../machine-learning-databases/00369/,Multivariate,9782222,Computer,N/A,N/A,6/16/2016,Causal-Discovery,N/A,30464,Reza Rawassizadeh rrawassizadeh '@' acm.org. University of California Riverside.,"This is the first smartphone based lifelogging dataset that is going to be available for public use. Please consider that the user of this dataset are obliged NOT to perform any sort of analysis that can harm the privacy of participants. This dataset is not for any privacy related analysis that can re-identify users.The UbiqLog tool is open source and accessible here:  [Web Link]","With respect to users privacy UbiqLog collects their Calls, SMS headers (no content), App use, WiFi & Bluetooth devices in user's  proximity, geographical location (if available and GPS works), physical activities form Google play API.Data format is in JSON, because there are different sensors and they have different variables. Nevertheless, we have the code for cleaning and converting the data into CSV + smoothing the time. Moreover, we can share our visualization code. Interested individuals could contact the given email address.",To appear: Scalable Daily Human Behavioral Pattern Mining from Multivariate Temporal Data. ,"Please cite both of the following paper and NOT only one of them: Rawassizadeh, R., Tomitsch, M., Wac, K., & Tjoa, A. M. (2013). UbiqLog: a generic mobile phone-based life-log framework. Personal and ubiquitous computing, 17(4), 621-637. Rawassizadeh, R., Momeni, E., Dobbins, C., Mirza-Babaei, P., & Rahnamoun, R. (2015). Lesson Learned from Collecting Quantified Self Information via Mobile and Wearable Devices. Journal of Sensor and Actuator Networks, 4(4), 315-335.",
http://archive.ics.uci.edu/ml/datasets/Echocardiogram,401,Echocardiogram Data Set,../machine-learning-databases/echocardiogram/,Multivariate,132,Life,"Categorical, Integer, Real",12,2/28/1989,Classification,Yes,185027,"Donor:  Steven Salzberg (salzberg '@' cs.jhu.edu) Collector: Dr. Evlin KinneyThe Reed InstituteP.O. Box 402603Maimi, FL 33140-0603","All the patients suffered heart attacks at some point in the past. Some are still alive and some are not.  The survival and still-alive variables, when taken together, indicate whether a patient survived for at least one year following the heart attack.   The problem addressed by past researchers was to predict from the other variables whether or not the patient will survive at least one year.  The most difficult part of this problem is correctly predicting that the patient will NOT survive.  (Part of the difficulty seems to be the size of the data set.)","   1. survival -- the number of months patient survived (has survived, if patient is still alive).  Because all the patients had their heart attacks at different times, it is possible that some patients have survived less than one year but they are still alive.  Check the second variable to confirm this.  Such patients cannot be used for the prediction task mentioned above.   2. still-alive -- a binary variable.  0=dead at end of survival period, 1 means still alive    3. age-at-heart-attack -- age in years when heart attack occurred   4. pericardial-effusion -- binary. Pericardial effusion is fluid around the heart.  0=no fluid, 1=fluid   5. fractional-shortening -- a measure of contracility around the heart lower numbers are increasingly abnormal   6. epss -- E-point septal separation, another measure of contractility.  Larger numbers are increasingly abnormal.   7. lvdd -- left ventricular end-diastolic dimension.  This is a measure of the size of the heart at end-diastole. Large hearts tend to be sick hearts.   8. wall-motion-score -- a measure of how the segments of the left ventricle are moving   9. wall-motion-index -- equals wall-motion-score divided by number of segments seen.  Usually 12-13 segments are seen in an echocardiogram.  Use this variable INSTEAD of the wall motion score.   10. mult -- a derivate var which can be ignored   11. name -- the name of the patient (I have replaced them with ""name"")   12. group -- meaningless, ignore it   13. alive-at-1 -- Boolean-valued. Derived from the first two attributes. 0 means patient was either dead after 1 year or had been followed for less than 1 year.  1 means patient was alive at 1 year.","Salzberg, S. (1988).  Exemplar-based learning: Theory and implementation (Technical Report TR-10-88).  Harvard University, Center for Research in Computing Technology, Aiken Computation Laboratory (33 Oxford Street; Cambridge, MA 02138).[Web Link]  Kan, G., Visser, C., Kooler, J., & Dunning, A. (1986).  Short and long term predictive value of wall motion score in acute myocardial infarction.  British Heart Journal, 56, 422-427.","Please refer to the Machine Learning
Repository's citation policy","Marc Sebban and Richard Nock and Stéphane Lallich. Stopping Criterion for Boosting-Based Data Reduction Techniques: from Binary to Multiclass Problem. Journal of Machine Learning Research, 3. 2002.  [View Context].Gabor Melli. A Lazy Model-Based Approach to On-Line Classification. University of British Columbia. 1989.  [View Context].D. Randall Wilson and Roel Martinez. Improved Center Point Selection for Probabilistic Neural Networks. Proceedings of the International Conference on Artificial Neural Networks and Genetic Algorithms.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context].Federico Divina and Elena Marchiori. Handling Continuous Attributes in an Evolutionary Inductive Learner. Department of Computer Science Vrije Universiteit.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Internet+Advertisements,402,Internet Advertisements Data Set,../machine-learning-databases/internet_ads/,Multivariate,3279,Computer,"Categorical, Integer, Real",1558,7/1/1998,Classification,Yes,355927,"Creator & donor:  Nicholas Kushmerick <nick '@' ucd.ie>","This dataset represents a set of possible advertisements on Internet pages.  The features encode the geometry of the image (if available) as well as phrases occuring in the URL, the image's URL and alt text, the anchor text, and words occuring near the anchor text. The task is to predict whether an image is an advertisement (""ad"") or not (""nonad"").","(3 continous; others binary; this is the ""STANDARD encoding"" mentioned in the [Kushmerick, 99].) One or more of the three continous features are missing in 28% of the instances; missing values should be interpreted as ""unknown"".","N. Kushmerick (1999). ""Learning to remove Internet advertisements"", 3rd Int Conf Autonomous Agents.  Available at www.cs.ucd.ie/staff/nick/research/[Web Link].[Web Link] ","Please refer to the Machine Learning
Repository's citation policy",Dmitriy Fradkin and David Madigan. Experiments with random projections for machine learning. KDD. 2003.  [View Context].Sergio A. Alvarez and Takeshi Kawato and Carolina Ruiz. Mining over loosely coupled data sources using neural experts. Computer Science Dept. Boston College.  [View Context].Shay Cohen and Eytan Ruppin and Gideon Dror. Feature Selection Based on the Shapley Value. School of Computer Sciences Tel-Aviv University.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Libras+Movement,403,Libras Movement Data Set,../machine-learning-databases/libras/,"Multivariate, Sequential",360,N/A,Real,91,8/17/2009,"Classification, Clustering",N/A,84958,"Creators:    Daniel Baptista Dias (Dias, D.B.)   Sarajane Marques Peres (Peres, S. M.)   Helton Hideraldo Bíscaro (Bíscaro. H. H.)   {danielbdias,heltonhb, sarajane} at usp.br Donor:   University of São Paulo - Brazil","The dataset (movement_libras) contains 15 classes of 24 instances each, where each class references to a hand movement type in LIBRAS. In the video pre-processing, a time normalization is carried out selecting 45 frames from each video, in according to an uniform distribution. In each frame, the centroid pixels of the segmented objects (the hand) are found, which compose the discrete version of the curve F with 45 points. All curves are normalized in the unitary space. In order to prepare these movements to be analysed by algorithms, we have carried out a mapping operation, that is, eachcurve F is mapped in a representation with 90 features, with representing the coordinates of movement.  Some sub-datasets are offered in order to support comparisons of results.",90 numeric (double) and 1 for the class (integer),"DIAS, D. B.; MADEO, R. C. B.; ROCHA, T.; BÍSCARO, H. H.; PERES, S. M.. Hand Movement Recognition for Brazilian Sign Language: A Study Using Distance-Based Neural Networks. In: 2009 International Joint Conference on Neural Networks, 2009, Atlanta, GA. Proceedings of 2009 International Joint Conference on Neural Networks. Eau Claire, WI, USA : Documation LLC, 2009. p. 697-704.Digital Object Identifier 10.1109/IJCNN.2009.5178917 ",Please refer to the Machine Learning Repository's citation policy.,
http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Prognostic%29,404,Breast Cancer Wisconsin (Prognostic) Data Set,../machine-learning-databases/breast-cancer-wisconsin/,Multivariate,198,Life,Real,34,12/1/1995,"Classification, Regression",Yes,215797,"Creators:  1. Dr. William H. Wolberg, General Surgery Dept. University of Wisconsin,  Clinical Sciences CenterMadison, WI 53792wolberg '@' eagle.surgery.wisc.edu  2. W. Nick Street, Computer Sciences Dept. University of Wisconsin1210 West Dayton St., Madison, WI 53706street '@' cs.wisc.edu  608-262-6619 3. Olvi L. Mangasarian, Computer Sciences Dept., University of Wisconsin1210 West Dayton St., Madison, WI 53706olvi '@' cs.wisc.edu  Donor:  Nick Street","Each record represents follow-up data for one breast cancer case.  These are consecutive patients seen by Dr. Wolberg since 1984, and include only those cases exhibiting invasive breast cancer and no evidence of distant metastases at the time of diagnosis.  The first 30 features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]  The separation described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree Construction Via Linear Programming."" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34]. The Recurrence Surface Approximation (RSA) method is a linear programming model which predicts Time To Recur using both recurrent and nonrecurrent cases.  See references (i) and (ii) above for details of the RSA method.  This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.educd math-prog/cpo-dataset/machine-learn/WPBC/","1) ID number2) Outcome (R = recur, N = nonrecur)3) Time (recurrence time if field 2 = R, disease-free time if field 2 = N)4-33) Ten real-valued features are computed for each cell nucleus: 	a) radius (mean of distances from center to points on the perimeter)	b) texture (standard deviation of gray-scale values)	c) perimeter	d) area	e) smoothness (local variation in radius lengths)	f) compactness (perimeter^2 / area - 1.0)	g) concavity (severity of concave portions of the contour)	h) concave points (number of concave portions of the contour)	i) symmetry 	j) fractal dimension (""coastline approximation"" - 1)","W. N. Street, O. L. Mangasarian, and W.H. Wolberg.  An inductive learning approach to prognostic prediction. In A. Prieditis and S. Russell, editors, Proceedings of the Twelfth International Conference on Machine Learning, pages 522--530, San Francisco, 1995. Morgan Kaufmann.[Web Link]  O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995. [Web Link]  W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. Computerized breast cancer diagnosis and prognosis from fine needle aspirates.  Archives of Surgery 1995;130:511-516. [Web Link]  W.H. Wolberg, W.N. Street, and O.L. Mangasarian.  Image analysis and machine learning applied to breast cancer diagnosis and prognosis. Analytical and Quantitative Cytology and Histology, Vol. 17 No. 2, pages 77-87, April 1995. W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. Computer-derived nuclear ``grade'' and breast cancer prognosis. Analytical and Quantitative Cytology and Histology, Vol. 17, pages 257-264, 1995. [Web Link]  See also:[Web Link] [Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Gavin Brown. Diversity in Neural Network Ensembles. The University of Birmingham. 2004.  [View Context].Baback Moghaddam and Gregory Shakhnarovich. Boosted Dyadic Kernel Discriminants. NIPS. 2002.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. Heterogeneous Forests of Decision Trees. ICANN. 2002.  [View Context].András Antos and Balázs Kégl and Tamás Linder and Gábor Lugosi. Data-dependent margin-based generalization bounds for classification. Journal of Machine Learning Research, 3. 2002.  [View Context].Kristin P. Bennett and Ayhan Demiriz and Richard Maclin. Exploiting unlabeled data in ensemble methods. KDD. 2002.  [View Context].Hussein A. Abbass. An evolutionary artificial neural networks approach for breast cancer diagnosis. Artificial Intelligence in Medicine, 25. 2002.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Robert Burbidge and Matthew Trotter and Bernard F. Buxton and Sean B. Holden. STAR - Sparsity through Automated Rejection. IWANN (1). 2001.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Improved Generalization Through Explicit Optimization of Margins. Machine Learning, 38. 2000.  [View Context].P. S and Bradley K. P and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. An Implementation of Logical Analysis of Data. IEEE Trans. Knowl. Data Eng, 12. 2000.  [View Context].Yuh-Jeng Lee. Smooth Support Vector Machines. Preliminary Thesis Proposal Computer Sciences Department University of Wisconsin. 2000.  [View Context].Justin Bradley and Kristin P. Bennett and Bennett A. Demiriz. Constrained K-Means Clustering. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000.  [View Context].Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining. Institute of Information Science. 1999.  [View Context].W. Nick Street. A Neural Network Model for Prognostic Prediction. ICML. 1998.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].Huan Liu and Hiroshi Motoda and Manoranjan Dash. A Monotonic Measure for Optimal Feature Selection. ECML. 1998.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Direct Optimization of Margins Improves Generalization in Combined Classifiers. NIPS. 1998.  [View Context].Rudy Setiono and Huan Liu. NeuroLinear: From neural networks to oblique decision rules. Neurocomputing, 17. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. A Parametric Optimization Method for Machine Learning. INFORMS Journal on Computing, 9. 1997.  [View Context].Jennifer A. Blue and Kristin P. Bennett. Hybrid Extreme Point Tabu Search. Department of Mathematical Sciences Rensselaer Polytechnic Institute. 1996.  [View Context].Erin J. Bredensteiner and Kristin P. Bennett. Feature Minimization within Decision Trees. National Science Foundation. 1996.  [View Context].Ismail Taha and Joydeep Ghosh. Characterization of the Wisconsin Breast cancer Database Using a Hybrid Symbolic-Connectionist System. Proceedings of ANNIE. 1996.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Jarkko Salojarvi and Samuel Kaski and Janne Sinkkonen. Discriminative clustering in Fisher metrics. Neural Networks Research Centre Helsinki University of Technology.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. A hybrid method for extraction of logical rules from data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. An Ant Colony Based System for Data Mining: Applications to Medical Data. CEFET-PR, CPGEI Av. Sete de Setembro, 3165.  [View Context].Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. Statistical methods for construction of neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery. CEFET-PR, Curitiba.  [View Context].Adam H. Cannon and Lenore J. Cowen and Carey E. Priebe. Approximate Distance Classification. Department of Mathematical Sciences The Johns Hopkins University.  [View Context].Andrew I. Schein and Lyle H. Ungar. A-Optimality for Active Learning of Logistic Regression Classifiers. Department of Computer and Information Science Levine Hall.  [View Context].Bart Baesens and Stijn Viaene and Tony Van Gestel and J. A. K Suykens and Guido Dedene and Bart De Moor and Jan Vanthienen and Katholieke Universiteit Leuven. An Empirical Assessment of Kernel Type Performance for Least Squares Support Vector Machine Classifiers. Dept. Applied Economic Sciences.  [View Context].Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. Unsupervised and supervised data classification via nonsmooth and global optimization. School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Rudy Setiono and Huan Liu. Neural-Network Feature Selector. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Huan Liu. A Family of Efficient Rule Generators. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Rudy Setiono. Extracting M-of-N Rules from Trained Neural Networks. School of Computing National University of Singapore.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Hybrid+Indoor+Positioning+Dataset+from+WiFi+RSSI%2C+Bluetooth+and+magnetometer,405,"Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer Data Set",../machine-learning-databases/00402/,"Multivariate, Sequential, Time-Series",1540,Computer,Real,65,12/18/2016,Classification,Yes,14791,"Zsolt Tóth University of Miskolc <tothzs '@' iit.uni-miskolc.hu>Judit Tamás University of Miskolc <tamas13 '@' iit.uni-miskolc.hu>","The measurements were created to ease the development, comparison and evaluation of fingerprinting based hybrid indoor positioning methods. The measurements were recorded by the same kind of Android devices in order to reduce the effect of the variety of the hardware. The recording was preformed at weekend to reduce the noise of the environment. The measurements were performed in a three-story building and cover about 50% of it. ","#Measurement Info1) 	Measurement Id - Java UUID2) 	Timestamp - YYYY-MM-dd hh:mm:ss  #Position Info3-5) 	Coordinates of the absolute position (x,y,z)6-7) 	Symbolic position - UUID and name of the position #Measruement Values8-10) 	Magnetometer values x,y,z, real11-42) 	WiFi RSSI values, negative integeres [-255,0]43-65) 	Bluetooth devices {0,1} - 1 if the given devices was sensed in during the measurement.","@InProceedings{toth2016miskolcIIS,  Title                    = {Miskolc IIS Hybrid IPS: Dataset for Hybrid Indoor Positioning},  Author                   = {Zsolt Tóth, Judit Tamás},  Booktitle                = {26st International Conference on Radioelektronika},  Year                     = {2016},  Organization             = {IEEE},  Pages                    = {408--412},} @inproceedings{tamas2016classification,  title={Classification based Symbolic Indoor Positioning over the Miskolc IIS Dataset},  author={Tamás, Judit and Tóth, Zsolt},  booktitle={THE 10TH JUBILEE CONFERENCE OF PHD STUDENTS IN COMPUTER SCIENCE},  pages={60},  year={2016}} @article{toth7data,  title={Data model for hybrid indoor positioning systems},  author={Tóth, Zsolt and Magnucz, Péter and Németh, Richárd and Tamás, Judit},  journal={Production Systems and Information Engineering},  volume={7},  number={1},  pages={67--80}}","@InProceedings{toth2016miskolcIIS,  Title                    = {Miskolc IIS Hybrid IPS: Dataset for Hybrid Indoor Positioning},  Author                   = {{Zs}olt Tóth, Judit Tamás},  Booktitle                = {26st International Conference on Radioelektronika},  Year                     = {2016},  Organization             = {IEEE},  Pages                    = {408--412},}",
http://archive.ics.uci.edu/ml/datasets/Climate+Model+Simulation+Crashes,406,Climate Model Simulation Crashes Data Set,../machine-learning-databases/00252/,Multivariate,540,Physical,Real,18,6/18/2013,Classification,N/A,85121,"D. Lucas (ddlucas .at. alum.mit.edu), Lawrence Livermore National LaboratoryR. Klein (rklein .at. astron.berkeley.edu), Lawrence Livermore National Laboratory & U.C. BerkeleyJ. Tannahill (tannahill1 .at. llnl.gov), Lawrence Livermore National LaboratoryD. Ivanova (ivanova2 .at. llnl.gov), Lawrence Livermore National LaboratoryS. Brandon (brandon1 .at. llnl.gov), Lawrence Livermore National LaboratoryD. Domyancic (domyancic1 .at. llnl.gov), Lawrence Livermore National LaboratoryY. Zhang (zhang24 .at. llnl.gov), Lawrence Livermore National Laboratory This data was constructed using LLNL's UQ Pipeline, was created under the auspices of the US Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344, was funded by LLNL's Uncertainty Quantification Strategic Initiative Laboratory Directed Research and Development Project under tracking code 10-SI-013, and is released under UCRL number LLNL-MISC-633994.","This dataset contains records of simulation crashes encountered during climate model uncertainty quantification (UQ) ensembles.  Ensemble members were constructed using a Latin hypercube method in LLNL's UQ Pipeline software system to sample the uncertainties of 18 model parameters within the Parallel Ocean Program (POP2) component of the Community Climate System Model (CCSM4).  Three separate Latin hypercube ensembles were conducted, each containing 180 ensemble members. 46 out of the 540 simulations failed for numerical reasons at combinations of parameter values.  The goal is to use classification to predict simulation outcomes (fail or succeed) from input parameter values, and to use sensitivity analysis and feature selection to determine the causes of simulation crashes.  Further details about the data and methods are given in the publication 'Failure Analysis of Parameter-Induced Simulation Crashes in Climate Models,' Geoscientific Model Development ([Web Link]).","The goal is to predict climate model simulation outcomes (column 21, fail or succeed) given scaled values of climate model input parameters (columns 3-20). Column 1: Latin hypercube study ID (study 1 to study 3) Column 2: simulation ID (run 1 to run 180) Columns 3-20: values of 18 climate model parameters scaled in the interval [0, 1] Column 21: simulation outcome (0 = failure, 1 = success)","Lucas, D. D., Klein, R., Tannahill, J., Ivanova, D., Brandon, S., Domyancic, D., and Zhang, Y.: Failure analysis of parameter-induced simulation crashes in climate models, Geosci. Model Dev. Discuss., 6, 585-623, [Web Link], 2013.[[Web Link]]",Please cite our final revised paper in Geoscientific Model Development.,
http://archive.ics.uci.edu/ml/datasets/Challenger+USA+Space+Shuttle+O-Ring,407,Challenger USA Space Shuttle O-Ring Data Set,../machine-learning-databases/space-shuttle/,Multivariate,23,Physical,Integer,4,8/5/1993,Regression,No,140058,"Original Owner: David Draper (draper '@' math.ucla.edu)University of California, Los Angeles Donor:  David Draper (draper '@' math.ucla.edu)","There are two databases: (both use the same set of 5 attributes):1. Primary o-ring erosion and/or blowby2. Primary o-ring erosion only The two databases are identical except for the 2nd attribute of the 21st instance (confirmed by David Draper on 8/5/93). Edited from (Draper, 1993): The motivation for collecting this database was the explosion of the USA Space Shuttle Challenger on 28 January, 1986.  An investigation ensued into the reliability of the shuttle's propulsion system.  The explosion was eventually traced to the failure of one of the three field joints on one of the two solid booster rockets.  Each of these six field joints includes two O-rings, designated as primary and secondary, which fail when phenomena called erosion and blowby both occur.  The night before the launch a decision had to be made regarding launch safety.  The discussion among engineers and managers leading to this decision included concern that the probability of failure of the O-rings depended on the temperature t at launch, which was forecase to be 31 degrees F. There are strong engineering reasons based on the composition of O-rings to support the judgment that failure probability may rise monotonically as temperature drops.  One other variable, the pressure s at which safety testing for field join leaks was performed, was available, but its relevance to the failure process was unclear. Draper's paper includes a menacing figure graphing the number of field joints experiencing stress vs. liftoff temperature for the 23 shuttle flights previous to the Challenger disaster.  No previous liftoff temperature was under 53 degrees F.  Although tremendous extrapolation must be done from the given data to assess risk at 31 degrees F, it is obvious even to the layman ""to foresee the unacceptably high risk created by launching at 31 degrees F.""  For more information, see Draper (1993) or the other previous analyses. The task is to predict the number of O-rings that will experience thermal distress for a given flight when the launch temperature is below freezing.","     1. Number of O-rings at risk on a given flight     2. Number experiencing thermal distress     3. Launch temperature (degrees F)     4. Leak-check pressure (psi)     5. Temporal order of flight","Draper,D. (1993).  Assessment and propagation of model uncertainty.  In Proceedings of the Fourth International Workshop on Artificial Intelligence and Statistics (pp. 497--509).  Ft. Lauderdale, FL:  Unpublished.[Web Link]  Dalal,S.R., Fowlkes,E.B., & Hoadley,B. (1989). Risk analysis of the space shuttle: pre-Challenger prediction of failure.  Journal of the American Statisticians Association,  84, 945--957.[Web Link]  Lavine,M. (1991). Problems in extrapolation illustrated with space shuttle O-ring data.  Journal of the American Statisticians Association, 86, 919--922. Martz H.F., & Zimmer, W.J. (1992). The risk of catastrophic failure of the solid rocket boosters on the space shuttle.  American Statistics, 46, 42--47. [Web Link]","Please refer to the Machine Learning
Repository's citation policy","Stephen D. Bay. Multivariate Discretization for Set Mining. Knowl. Inf. Syst, 3. 2001.  [View Context].Pedro Domingos. Linear-Time Rule Induction. KDD. 1996.  [View Context].Mohammed Waleed Kadous and Claude Sammut. The University of New South Wales School of Computer Science and Engineering Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients,408,default of credit card clients Data Set,../machine-learning-databases/00350/,Multivariate,30000,Business,"Integer, Real",24,1/26/2016,Classification,N/A,487247,"Name: I-Cheng Yehemail addresses: (1) icyeh '@' chu.edu.tw (2) 140910 '@' mail.tku.edu.tw institutions: (1) Department of Information Management, Chung Hua University, Taiwan. (2) Department of Civil Engineering, Tamkang University, Taiwan.other contact information: 886-2-26215656 ext. 3181","This research aimed at the case of customersâ€™ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel â€œSorting Smoothing Methodâ€ to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.","This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.X2: Gender (1 = male; 2 = female).X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).X4: Marital status (1 = married; 2 = single; 3 = others).X5: Age (year).X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.","Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480.","Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480.",
http://archive.ics.uci.edu/ml/datasets/Pittsburgh+Bridges,409,Pittsburgh Bridges Data Set,../machine-learning-databases/bridges/,Multivariate,108,N/A,"Categorical, Integer",13,8/1/1990,Classification,Yes,102453,"Creators: Yoram Reich & Steven J. FenvesDepartment of Civil Engineering      andEngineering Design Research CenterCarnegie Mellon UniversityPittsburgh, PA 15213 Compiled from various sources. Donor:  Yoram Reich (yoram.reich '@' cs.cmu.edu)","There are two versions to the database:     -  V1 contains the original examples and      - V2 contains descriptions after discretizing numeric properties. There are no ``classes'' in the domain. Rather this is a DESIGN domain where 5 properties (design description) need to be predicted based on 7 specification properties.","The type field state whether a property is continuous/integer (c) or nominal (n). For properties with c,n type, the range of continuous numbers is given first and the possible values of the nominal follow the semi-colon. Name / Type / Possible values / Comments    1.  IDENTIF / -- /	-- / identifier of the examples   2.  RIVER / n / A, M, O / --   3.  LOCATION / n / 1 to 52 / --   4.  ERECTED / c,n / 1818-1986 ; CRAFTS, EMERGING, MATURE, MODERN / --   5.  PURPOSE / n / WALK, AQUEDUCT, RR, HIGHWAY / --   6.  LENGTH / c,n / 804-4558 ; SHORT, MEDIUM, LONG / --   7.  LANES / c,n / 1, 2, 4, 6 ; 1, 2, 4, 6 / --   8.  CLEAR-G / n / N, G / --   9.  T-OR-D / n / THROUGH, DECK / --   10. MATERIAL / n / WOOD, IRON, STEEL / --   11. SPAN / n / SHORT, MEDUIM, LONG / --   12. REL-L / n / S, S-F, F / --   13. TYPE / n / WOOD, SUSPEN, SIMPLE-T, ARCH, CANTILEV, CONT-T / --","Reich & Fenves (1989). Incremental Learning for Capturing Design Expertise. Technical Report: EDRC 12-34-89, Engineering Design Research Center, Carnegie Mellon University, Pittsburgh, PA. Reich (1989). Converging to ``Ideal'' Design Knowledge by Learning, Proceedings of the First International Workshop on Formal Methods in Engineering Design, pp: 330-349, Colorado Springs, CO, January 1990.[Web Link]  Reich (1989) Combining Nominal and Continuous Properties in an Incremental Learning System for Design. Technical Report: EDRC 12-33-89. Reich (1989) Incremental Concept Formation with Mixed Property Types. Unpublished Manuscript. ","Please refer to the Machine Learning
Repository's citation policy",Ljupco Todorovski and Saso Dzeroski. Experiments in Meta-level Learning with ILP. PKDD. 1999.  [View Context].Paul D. Wilson and Tony R. Martinez. Combining Cross-Validation and Confidence to Measure Fitness. fonix corporation Brigham Young University.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Facebook+Live+Sellers+in+Thailand,410,Facebook Live Sellers in Thailand Data Set,../machine-learning-databases/00488/,Multivariate,7051,Business,Integer,12,4/22/2019,Clustering,N/A,35267,"Nassim Dehouche, Mahidol University International College, nassim.deh '@' mahidol.edu","The variability of consumer engagement is analysed through a Principal Component Analysis, highlighting the changes induced by the use of Facebook Live. The seasonal component is analysed through a study of the averages of the different engagement metrics for different time-frames (hourly, daily and monthly). Finally, we identify statistical outlier posts, that are qualitatively analyzed further, in terms of their selling approach and activities.  ","status_id	status_type	status_published	num_reactions	num_comments	num_shares	num_likes	num_loves	num_wows	num_hahas	num_sads	num_angrys","Nassim Dehouche and Apiradee Wongkitrungrueng. Facebook Live as a Direct Selling Channel, 2018, Proceedings of ANZMAC 2018: The 20th Conference of the Australian and New Zealand Marketing Academy. Adelaide (Australia), 3-5 December 2018.","Nassim Dehouche and Apiradee Wongkitrungrueng. Facebook Live as a Direct Selling Channel, 2018, Proceedings of ANZMAC 2018: The 20th Conference of the Australian and New Zealand Marketing Academy. Adelaide (Australia), 3-5 December 2018.",
http://archive.ics.uci.edu/ml/datasets/Credit+Approval,411,Credit Approval Data Set,../machine-learning-databases/credit-screening/,Multivariate,690,Financial,"Categorical, Integer, Real",15,N/A,Classification,Yes,423051,"(confidential source)  Submitted by quinlan '@' cs.su.oz.au","This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.","A1:	b, a.A2:	continuous.A3:	continuous.A4:	u, y, l, t.A5:	g, p, gg.A6:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.A7:	v, h, bb, j, n, z, dd, ff, o.A8:	continuous.A9:	t, f.A10:	t, f.A11:	continuous.A12:	t, f.A13:	g, p, s.A14:	continuous.A15:	continuous.A16: +,-         (class attribute)","Quinlan. ""Simplifying decision trees"", Int J Man-Machine Studies 27, Dec 1987, pp. 221-234.[Web Link]  Quinlan. ""C4.5: Programs for Machine Learning"", Morgan Kaufmann, Oct 1992[Web Link] ","Please refer to the Machine Learning
Repository's citation policy","Xiaoming Huo. FBP: A Frontier-Based Tree-Pruning Algorithm. Seoung Bum Kim. 2002.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Improved Generalization Through Explicit Optimization of Margins. Machine Learning, 38. 2000.  [View Context].Kagan Tumer and Joydeep Ghosh. Robust Combining of Disparate Classifiers through Order Statistics. CoRR, csLG/9905013. 1999.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Direct Optimization of Margins Improves Generalization in Combined Classifiers. NIPS. 1998.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Gas+Sensor+Array+Drift+Dataset+at+Different+Concentrations,412,Gas Sensor Array Drift Dataset at Different Concentrations Data Set,../machine-learning-databases/00270/,"Multivariate, Time-Series",13910,Computer,Real,129,10/23/2013,"Classification, Regression, Clustering, Causa",N/A,69948,"Creators: Alexander Vergara (vergara '@' ucsd.edu) BioCircutis Institute University of California San Diego San Diego, California, USA Donors of the Dataset:	Alexander Vergara (vergara '@' ucsd.edu) Jordi Fonollosa (fonollosa '@'ucsd.edu)Irene Rodriguez-Lujan (irrodriguezlujan '@' ucsd.edu)Ramon Huerta (rhuerta '@' ucsd.edu) ","This data set contains 13,910 measurements from 16 chemical sensors exposed to 6 gases at different concentration levels. This dataset is an extension of the Gas Sensor Array Drift Dataset ([Web Link]), providing now the information about the concentration level at which the sensors were exposed for each measurement. The primary purpose of making this dataset freely accessible on-line is to provide an extensive dataset to the sensor and artificial intelligence research communities to develop and test strategies to solve a wide variety of tasks, including sensor drift, classification, regression, among others.  The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded. Citation of both Vergara et al. 'Chemical gas sensor drift compensation using classifier ensembles' and Rodriguez-Lujan et al. â€œOn the calibration of sensor arrays for pattern recognition using the minimal number of experimentsâ€ is required (see below). The dataset was gathered during the period of January 2008 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors. See reference 1 for more details on the experimental setup.  The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, dosed at a wide variety of concentration levels in the intervals (50,1000), (5,500), (12,1000), (10,300), (10,600), and (10,100) ppmv, respectively.","The responses of the said sensors are read in the form of the resistance across the active layer of each sensor; hence, each measurement produced a 16-channel time series, each  represented by an aggregate of features reflecting the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. In particular, two distinct types of features were considered in the creation of this dataset: (i) the so-called steady-state feature (DR), defined as the maximal resistance change with respect to the baseline and its DR normalized version (DR divided by the acquired value when the chemical vapor is present in the test chamber). And (ii), an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement. This aggregate of features is a transformation, borrowed from the field of econometrics and originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the transient portion of the sensor response into a real scalar by estimating the maximum/minimum value y[k] for the rising/decaying portion of the exponential moving average of the sensor response: y[k] = (1-Alfa) y[k-1]+Alfa(R[k]-R[k-1]) where R[k] is the sensor resistance measured at time k and Alfa is a scalar smoothing parameter between 0 and 1. In particular, three different values for Alfa=0.1, 0.01, 0.001 were set to obtain three different feature values from the rising portion of the sensor response and three additional features with the same Alfa values for the decaying portion of the sensor response, covering thus the entire sensor response dynamics.  Thus, each feature vector contains the 8 features extracted from each particular sensor, resulting in a 128-dimensional feature vector (8 features x 16 sensors) containing all the features and organized as follows:DR_1, |DR|_1, EMAi0.001_1, EMAi0.01_1, EMAi0.1_1, EMAd0.001_1, EMAd0.01_1, EMAd0.1_1, DR_2, |DR|_2, EMAi0.001_2, EMAi0.01_2, EMAi0.1_2, EMAd0.001_2, EMAd0.01_2, EMAd0.1_2,..., DR_16, |DR|_16, EMAi0.001_16, EMAi0.01_16, EMAi0.1_16, EMAd0.001_16, EMAd0.01_16, EMAd0.1_16where: DR_j and |DR|_j are the R and the normalized R features, respectively. EMAi0.001_j, EMAi0.01_j, and EMAi0.1_j, are the emaR of the rising transient portion of the sensor response for Alfa 0.001, 0.01, and 0.1, respectively. EMAd0.001_j, EMAd0.01_j, and EMAd0.1_j, are emaR of the decaying transient portion of the sensor response for Alfa 0.001, 0.01, and 0.1, respectively. The index j=1â€¦16 represents the number of the sensor, forming thus the 128-dimensional feature vector.  For processing purposes, the dataset is organized into ten batches, each containing the number of measurements per class and month indicated in the tables below. This reorganization of data was done to ensure having a sufficient and as uniformly distributed as possible number of experiments in each batch.  Batch ID	Month IDs Batch 1	 Months 1 and 2 Batch 2	 Months 3, 4, 8, 9 and 10 Batch 3	 Months 11, 12, and 13 Batch 4	 Months 14 and 15 Batch 5	 Month 16 Batch 6	 Months 17, 18, 19, and 20 Batch 7	 Month 21 Batch 8	 Months 22 and 23 Batch 9	 Months 24 and 30 Batch 10 Month 36  Batch ID: Ethanol, Ethylene, Ammonia, Acetaldehyde, Acetone, TolueneBatch 1: 83, 30, 70, 98, 90, 74Batch 2: 100, 109, 532, 334, 164, 5Batch 3: 216, 240, 275, 490, 365, 0Batch 4: 12, 30, 12, 43, 64, 0Batch 5: 20, 46, 63, 40, 28, 0Batch 6: 110, 29, 606, 574, 514, 467Batch 7: 360, 744, 630, 662, 649, 568Batch 8: 40, 33, 143, 30, 30, 18Batch 9: 100, 75, 78, 55, 61, 101Batch 10: 600, 600, 600, 600, 600, 600   The dataset is organized in files, each representing a different batch. Within the files, each line represents a measurement. The first character (1-6) codes the analyte, followed by the concentration level: 1: Ethanol; 2: Ethylene; 3: Ammonia; 4: Acetaldehyde; 5: Acetone; 6: Toluene The data format follows the same coding style as in libsvm format x:v, where x stands for the feature number and v for the actual value of the feature. For example, in 1;10.000000 1:15596.162100 2:1.868245 3:2.371604 4:2.803678 5:7.512213 â€¦ 128:-2.654529  The number 1 stands for the class number (in this case Ethanol), the gas concentration level was 10ppmv, and the remaining 128 columns list the actual feature values for each measurement recording organized as described above. ",N/A,"Citation of both papers is required:A Vergara, S Vembu, T Ayhan, M Ryan, M Homer, R Huerta. ""Chemical gas sensor drift compensation using classifier ensembles."" Sensors and Actuators B: Chemical 166 (2012): 320-329.I Rodriguez-Lujan, J Fonollosa, A Vergara, M Homer, R Huerta. ""On the calibration of sensor arrays for pattern recognition using the minimal number of experiments."" Chemometrics and Intelligent Laboratory Systems 130 (2014): 123-134.",
http://archive.ics.uci.edu/ml/datasets/Fertility,413,Fertility Data Set,../machine-learning-databases/00244/,Multivariate,100,Life,Real,10,1/17/2013,"Classification, Regression",N/A,201449,"David Gil,dgil '@' dtic.ua.es, Lucentia Research Group, Department of Computer Technology, University of Alicante Jose Luis Girela,girela '@' ua.es,Department of Biotechnology, University of Alicante",Provide all relevant information about your data set.,"Season in which the analysis was performed. 	1) winter, 2) spring, 3) Summer, 4) fall. 	(-1, -0.33, 0.33, 1)  Age at the time of analysis. 	18-36 	(0, 1)  Childish diseases (ie , chicken pox, measles, mumps, polio)	1) yes, 2) no. 	(0, 1)  Accident or serious trauma 	1) yes, 2) no. 	(0, 1)  Surgical intervention 	1) yes, 2) no. 	(0, 1)  High fevers in the last year 	1) less than three months ago, 2) more than three months ago, 3) no. 	(-1, 0, 1)  Frequency of alcohol consumption 	1) several times a day, 2) every day, 3) several times a week, 4) once a week, 5) hardly ever or never 	(0, 1)  Smoking habit 	1) never, 2) occasional 3) daily. 	(-1, 0, 1)  Number of hours spent sitting per day 	ene-16	(0, 1)  Output: Diagnosis	normal (N), altered (O)	","David Gil, Jose Luis Girela, Joaquin De Juan, M. Jose Gomez-Torres, andMagnus Johnsson. Predicting seminal quality with artificial intelligencemethods. Expert Systems with Applications, 39(16):12564 â€“ 12573, 2012","David Gil, Jose Luis Girela, Joaquin De Juan, M. Jose Gomez-Torres, andMagnus Johnsson. Predicting seminal quality with artificial intelligencemethods. Expert Systems with Applications, 39(16):12564 â€“ 12573, 2012",
http://archive.ics.uci.edu/ml/datasets/ILPD+%28Indian+Liver+Patient+Dataset%29,414,ILPD (Indian Liver Patient Dataset) Data Set,../machine-learning-databases/00225/,Multivariate,583,Life,"Integer, Real",10,5/21/2012,Classification,N/A,133380,"1. Bendi Venkata Ramana ramana.bendi '@' gmail.com    Associate Professor,   Department of Information Technology,   Aditya Instutute of Technology and Management,   Tekkali - 532201, Andhra Pradesh, India. 2. Prof. M. Surendra Prasad Babu drmsprasadbabu '@' yahoo.co.in    Deptartment of Computer Science & Systems Engineering,   Andhra University College of Engineering,   Visakhapatnam-530 003 Andhra Pradesh,  India. 3.Prof. N. B. Venkateswarlu venkat_ritch '@' yahoo.com   Department of Computer Science and Engineering,  Aditya Instutute of Technology and Management,  Tekkali - 532201, Andhra Pradesh, India.","This data set contains 416 liver patient records and 167 non liver patient records.The data set was collected from north east of Andhra Pradesh, India. Selector is a class label used to divide into groups(liver patient or not). This data set contains 441 male patient records and 142 female patient records.  Any patient whose age exceeded 89 is listed as being of age ""90"".","1.   Age		Age of the patient2.   Gender		Gender of the patient3.   TB			Total Bilirubin4.   DB		 	Direct Bilirubin5.   Alkphos 		Alkaline Phosphotase6.   Sgpt 		Alamine Aminotransferase7.   Sgot 		Aspartate Aminotransferase8.   TP			Total Protiens9.   ALB		Albumin10. A/G Ratio		Albumin and Globulin Ratio11. Selector field used to split the data into two sets (labeled by the experts)","1. Bendi Venkata Ramana,   Prof. M. S. Prasad Babu and Prof. N. B. Venkateswarlu,    â€œA Critical Comparative Study of Liver Patients from USA and INDIA: An Exploratory Analysisâ€, International Journal of Computer Science Issues, ISSN :1694-0784, May 2012. 2. Bendi Venkata Ramana,  Prof. M. S. Prasad  Babu  and  Prof. N. B. Venkateswarlu,   â€œA Critical Study of Selected Classification Algorithms for Liver Disease Diagnosisâ€, International Journal of Database Management Systems (IJDMS), Vol.3, No.2, ISSN : 0975-5705, PP 101-114, May 2011.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/QSAR+fish+bioconcentration+factor+%28BCF%29,415,QSAR fish bioconcentration factor (BCF) Data Set,../machine-learning-databases/00511/,Multivariate,1056,Life,"Integer, Real",7,11/27/2019,Regression,N/A,5907,"Francesca Grisoni, University of Milano-Bicocca, Dept. of Earth and Environmental Sciences, Milano Chemometrics & QSAR Research Group, francesca.grisoni '@' unimib.it Viviana Consonni,  University of Milano-Bicocca, Dept. of Earth and Environmental Sciences, Milano Chemometrics & QSAR Research Group,  viviana.consonni '@' unimib.it Marco Vighi, University of Milano-Bicocca, Dept. of Earth and Environmental SciencesSara Villa, University of Milano-Bicocca, Dept. of Earth and Environmental SciencesRobertoTodeschini,  University of Milano-Bicocca, Dept. of Earth and Environmental Sciences, Milano Chemometrics & QSAR Research Group, roberto.todeschini '@' unimib.it","This dataset contains manually-curated experimental bioconcentration factor (BCF) for 1058 molecules (continuous values). Each row contains a molecule, identified by a CAS number, a name (if available), and a SMILES string. Additionally, the KOW (experimental or predicted) is reported. In this database, you will also find Extended Connectivity Fingerprints (binary vectors of 1024 bits), to be used as independent variables to predict the BCF. You can find additional information in the referenced papers.In case you had questions, please do not hesitate to contact us!","The provided zip file contains two files. (I) The file 'QSAR BCF KOW' contains the following attributes:1. CAS number (molecule identifier)2. Molecule Name (if not available, marked as 'n.a.')3. SMILES string to identify the 2D molecular structure4. LogKOW: octanol water partitioning coefficient (experimental or predicted, as indicated by the column 'KOW Type'5. KOW Type: indicates whether the logKOW value is experimental or predicted 6. Experimental logBCF (quantitative response): experimental fish bioconcentration factor (logarithm form) (II) The file 'ECFP_1024_m0-2_b2_c.txt' contains the following molecular descriptors (to be used to predict the BCF):- Extended Connectivity Fingerprints (ECFPs): binary descriptors useful to predict the experimental logBCF (computed with Dragon7, default settings --> details specified in the file)Each row corresponds to one molecule, as identified by the SMILES field. The molecules are in the same order as in the previous file. ","1. Grisoni, F., Consonni, V., Villa, S., Vighi, M. and Todeschini, R., 2015. QSAR models for bioconcentration: Is the increase in the complexity justified by more accurate predictions?. Chemosphere, 127, pp.171-179. --> Procedure for data curation.2. Grisoni, F., Consonni, V., Vighi, M., Villa, S. and Todeschini, R., 2016. Expert QSAR system for predicting the bioconcentration factor under the REACH regulation. Environmental research, 148, pp.507-512.  -->  Benchmark on the performance for this dataset3. Grisoni, F., Consonni, V., Vighi, M., Villa, S. and Todeschini, R., 2016. Investigating the mechanisms of bioconcentration through QSAR classification trees. Environment international, 88, pp.198-205. --> Relationship between KOW and BCF","If you publish results based on this dataset or parts of it, please cite the following paper:@article{grisoni2015,  title={QSAR models for bioconcentration: Is the increase in the complexity justified by more accurate predictions?},  author={Grisoni, Francesca and Consonni, Viviana and Villa, Sara and Vighi, Marco and Todeschini, Roberto},  journal={Chemosphere},  volume={127},  pages={171--179},  year={2015},  publisher={Elsevier}} If you use the ECFP values, additionally please cite the following software: Dragon (Software for Molecular Descriptor Calculation) Version 6.0 â€” 2012[Web Link] (2012) And paper: @article{rogers2010,  title={Extended-connectivity fingerprints},  author={Rogers, David and Hahn, Mathew},  journal={Journal of chemical information and modeling},  volume={50},  number={5},  pages={742--754},  year={2010},  publisher={ACS Publications}} --> Thanks and happy predicting!",
http://archive.ics.uci.edu/ml/datasets/Protein+Data,416,Protein Data Data Set,../machine-learning-databases/undocumented/sigillito/,N/A,N/A,Life,N/A,N/A,N/A,N/A,N/A,71476,N/A,N/A,N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy","Qingping Tao Ph. D. MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004.  [View Context].Michihiro Kuramochi and George Karypis. Finding Frequent Patterns in a Large Sparse Graph. SDM. 2004.  [View Context].Mikhail Bilenko and Sugato Basu and Raymond J. Mooney. Integrating constraints and metric learning in semi-supervised clustering. ICML. 2004.  [View Context].Qingping Tao and Stephen Scott and N. V. Vinodchandran and Thomas T. Osugi. SVM-based generalized multiple-instance learning via approximate box counting. ICML. 2004.  [View Context].Jianbin Tan and David L. Dowe. MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes. Australian Conference on Artificial Intelligence. 2003.  [View Context].Aik Choon Tan and David Gilbert. An Empirical Comparison of Supervised Machine Learning Techniques in Bioinformatics. APBC. 2003.  [View Context].Michael L. Raymer and Travis E. Doom and Leslie A. Kuhn and William F. Punch. Knowledge discovery in medical and biological datasets using a hybrid Bayes classifier/evolutionary algorithm. IEEE Transactions on Systems, Man, and Cybernetics, Part B, 33. 2003.  [View Context].Steven Eschrich and Nitesh V. Chawla and Lawrence O. Hall. Generalization Methods in Bioinformatics. BIOKDD. 2002.  [View Context].Mukund Deshpande and George Karypis. Evaluation of Techniques for Classifying Biological Sequences. PAKDD. 2002.  [View Context].Andreas L. Prodromidis. On the Management of Distributed Learning Agents Ph.D. Thesis Proposal CUCS-032-97. Department of Computer Science Columbia University. 1998.  [View Context].Kai Ming Ting and Boon Toh Low. Model Combination in the Multiple-Data-Batches Scenario. ECML. 1997.  [View Context].Kuan-ming Lin and Chih-Jen Lin. A Study on Reduced Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Kai Ming Ting and Boon Toh Low. Theory Combination: an alternative to Data Combination. University of Waikato.  [View Context].Zoran Obradovic and Slobodan Vucetic. Challenges in Scientific Data Mining: Heterogeneous, Biased, and Large Samples. Center for Information Science and Technology Temple University.  [View Context].Daichi Mochihashi and Gen-ichiro Kikui and Kenji Kita. Learning Nonstructural Distance Metric by Minimum Cluster Distortions. ATR Spoken Language Translation research laboratories.  [View Context].Mehmet Dalkilic and Arijit Sengupta. A Logic-theoretic classifier called Circle. School of Informatics Center for Genomics and BioInformatics Indiana University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Dishonest+Internet+users+Dataset,417,Dishonest Internet users Dataset Data Set,../machine-learning-databases/00453/,Multivariate,322,Computer,N/A,5,3/20/2018,"Classification, Clustering",N/A,45114,"Gianni D'Angelo, Ph.D.Department of Law, Economics, Management and Quantitative Methods (DEMM)University of SannioBenevento, Italy. Email: dangelo '@' unisannio.it","In pervasive computing the interacting users are not able to obtain information about the trustworthiness of each other. Thus, unfair users can act maliciously towards others. The proposed solution enables to evaluate the trustworthiness of each user by monitoring the behavior of each other during their interaction on the network. These behaviors are represented by tuples including significant parameters. Based on these tuples, the architecture combines some artificial intelligence-based technologies to implement a decision making system.The tuples are as follows:eij =  where: eij - i-th entity interacting with j-th entity. EIDj - j-th entity Identification CT - Counting Trust. It is used to count how many trustworthy transactions (belonging to a specific context) occur after the last untrustworthy transaction.CU - Counting Un-trust. It is used to count how many untrustworthy transactions (belonging to a specific context) occur after the last trustworthy transaction.LT - Last Time. It is used to take into account of the date at which the last experience in a specific context took place.TC - Transactions Context. It is used to identify the type of transaction, such as game, e-commerce, social network and others.TS - Trust Score. It  is the score that an entity gives to another entity at the end of each direct interaction.  The data set was obtained by a Java simulator which implemented the proposed architecture.It includes data for the three most popular types of attack, namely:- Counting-based attack. The user tries to gain a good reputation by alternating the honest and dishonest behavior.- Time-based attack. User again tries to gain a good reputation by alternating the honest and dishonest behavior, but acts in different time.- Context-based attack. R tries to gain a good reputation by acting honestly for a type of transaction and dishonestly for another one. Because EIDj parameters are not relevant for the decision-making process, only the following parameters were reported in the dataset:- CT- CU- LT- TC- TS Because, there could be situation in which users have not historical data (tuples) for interacting with another one, it may get data (tuples) from third-parties who previously have had interaction with the inquired user.Nevertheless, the trustworthiness of such third party entities (recommenders) needs to be evaluated also. Indeed, they may act through attacks, such as: Ballot Stuffing (BS), Bad mouthing , and Random opinion (RO).Changing of the TS parameter for a number of rows in the dataset, and in according to a specific attack, allows to obtain different datasets useful for the recommenders trustworthiness evaluation.According to this, the following datasets are also provided:- BM_x%.txt  x is the percentage of unfair recommendations obtained by a BM attack. It ranges from 10 to 50.- BS_x%.txt  x is the percentage of unfair recommendations obtained by a BS attack. It ranges from 10 to 50.- RO_x%.txt  x is the percentage of unfair recommendations obtained by a BM attack. It ranges from 10 to 50. ","1) CT {CT_range_1, CT_range_2, CT_range_3, CT_range_4}2) CU {CU_range_1, CU_range_2, CU_range_3, CU_range_4}3) LT {LT_range_1, LT_range_2, LT_range_3, LT_range_4}4) TC {sport, game, ECommerce, holiday}5) TS {trustworthy, untrustworthy} The numerical attributes (CT, CU, LT) was discretized.Several of the papers listed below contain detailed descriptions of how these attributes were discretized.","G. Dâ€™Angelo, S. Rampone, F. Palmieri, â€œDeveloping a Trust Model for Pervasive Computing Based on Apriori Association Rules Learning and Bayesian Classificationâ€, SOCO â€“ Soft Computing Journal, Vol.21, n.21, pp. 6297-6315, 2017.  DOI: 10.1007/s00500-016-2183-1","If you intend to use this dataset on your research, please cite the following works:1. G. Dâ€™Angelo, S. Rampone, F. Palmieri, â€œDeveloping a Trust Model for Pervasive Computing Based on Apriori Association Rules Learning and Bayesian Classificationâ€, SOCO â€“ Soft Computing Journal, Vol.21, n.21, pp. 6297-6315, 2017.  DOI: 10.1007/s00500-016-2183-12. G. D'Angelo, S. Rampone and F. Palmieri, 'An Artificial Intelligence-Based Trust Model for Pervasive Computing,' 2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC), Krakow, 2015, pp. 701-706. DOI: 10.1109/3PGCIC.2015.94",
http://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29,418,Anuran Calls (MFCCs) Data Set,../machine-learning-databases/00406/,Multivariate,7195,Life,Real,22,2/24/2017,"Classification, Clustering",N/A,47396,"Eng. Juan Gabriel Colonna <juancolonna '@' icomp.ufam.edu.br>, Prof. Eduardo Freire Nakamura <nakamura '@' icomp.ufam.edu.br>, Prof. Marco A. P. Cristo <marco.cristo '@' gmail.com>, Biologist and collaborator Prof. Marcelo Gordo <mgordo '@' ufam.edu.br>Universidade Federal do Amazonas, Av. General Rodrigo Octavio JordÃ£o Ramos, 1200 - Coroado I, Manaus - AM, 69067-005, Brasil.","This dataset was used in several classifications tasks related to the challenge of anuran species recognition through their calls. It is a multilabel dataset with three columns of labels. This dataset was created segmenting 60 audio records belonging to 4 different families, 8 genus, and 10 species. Each audio corresponds to one specimen (an individual frog), the record ID is also included as an extra column. We used the spectral entropy and a binary cluster method to detect audio frames belonging to each syllable. The segmentation and feature extraction were carried out in Matlab. After the segmentation we got 7195 syllables, which became instances for train and test the classifier. These records were collected in situ under real noise conditions (the background sound). Some species are from the campus of Federal University of Amazonas, Manaus, others from Mata AtlÃ¢ntica, Brazil, and one of them from CÃ³rdoba, Argentina. The recordings were stored in wav format with 44.1kHz of sampling frequency and 32bit of resolution, which allows us to analyze signals up to 22kHz. From every extracted syllable 22 MFCCs were calculated by using 44 triangular filters. These coefficients were normalized between -1 â‰¤ mfcc â‰¤ 1. The amount of instances per class are: Families:	 Bufonidae              68      Dendrobatidae         542      Hylidae              2165      Leptodactylidae      4420  Genus:     Adenomera          4150      Ameerega            542      Dendropsophus       310      Hypsiboas          1593      Leptodactylus       270      Osteocephalus       114      Rhinella             68      Scinax              148  Species:     AdenomeraAndre             672      AdenomeraHylaedactâ€¦       3478      Ameeregatrivittata         542      HylaMinuta                 310      HypsiboasCinerascens       472      HypsiboasCordobae         1121      LeptodactylusFuscus        270      OsteocephalusOophaâ€¦        114      Rhinellagranulosa           68      ScinaxRuber                148 ","Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an mel-frequency cepstrum (MFC). Due to each syllable has different length, every row (i) was normalized acording to MFCCs_i/(max(abs(MFCCs_i))).","1) COLONNA, J. G.; CRISTO, M.; SALVATIERRA, M.; NAKAMURA, E. F. An Incremental Technique for Real-Time Bioacoustic Signal Segmentation. Expert Systems with Applications, v. 42, p. 7367-7374, 2015. 2) COLONNA, J. G.; GAMA, J.; NAKAMURA, E. F.How to Correctly Evaluate an Automatic Bioacoustics Classification Method. In: 17th Conference of the Spanish Association for Artificial Intelligence (CAEPIA). Lecture Notes in Computer Science. 986ed.: Springer International Publishing, 2016, v. , p. 37-47. 3) COLONNA, J. G.; GAMA, J.; NAKAMURA, E. F. Recognizing Family, Genus, and Species of Anuran Using a Hierarchical Classification Approach.Lecture Notes in Computer Science. 995ed.: Springer International Publishing, 2016, v. 9956, p. 198-212. 4) COLONNA, J. G.; RIBAS, A. D.; SANTOS, E. M.; NAKAMURA, E. F.Feature Subset Selection for Automatically Classifying Anuran Calls Using Sensor Networks. In: International Joint Conference on Neural Networks, 2012, Brisbane. Proceedings of the International Joint Conference on Neural Networks (IJCNN 2012), 2012. p. 1-8. IEEE 5) COLONNA, J. G.; PEET, T.; FERREIRA, C. A.; JORGE, A. M.; GOMES, E. F.; GAMA, J. (2016, July). Automatic Classification of Anuran Sounds Using Convolutional Neural Networks. In Proceedings of the Ninth International C* Conference on Computer Science & Software Engineering (No. C3S2E '16, pp. 73-78). ACM. 6) COLONNA, J. G.; CRISTO, M.; NAKAMURA, E. F. (2014, August). A Distributed Approach for Classifying Anuran Species Based on Their Calls. In Pattern Recognition (ICPR), 2014 22nd International Conference on (pp. 1242-1247). IEEE. 7) RIBAS, A. D.; COLONNA, J. G.; FIGUEIREDO, C. M. S.; NAKAMURA, E. F.Similarity clustering for data fusion in wireless sensor networks using k-meansThe 2012 International Joint Conference on Neural Networks (IJCNN 2012), p. 1-7. IEEE 8) DIAZ, J. M.; COLONNA, J. G.; SOARES, R. B.; FIGUEREIDO, C. M. S.; NAKAMURA, E. F.Compressive sensing for efficiently collecting wildlife sounds with wireless sensor networks21st International Conference on Computer Communications and Networks (ICCCN 2012), p. 1-7. IEEE","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work,419,Absenteeism at work Data Set,../machine-learning-databases/00445/,"Multivariate, Time-Series",740,Business,"Integer, Real",21,4/5/2018,"Classification, Clustering",N/A,174579,"Creators original owner and donors: Andrea Martiniano (1), Ricardo Pinto Ferreira (2), and Renato Jose Sassi (3). E-mail address: andrea.martiniano'@'gmail.com (1) - PhD student;log.kasparov'@'gmail.com (2) - PhD student;sassi'@'uni9.pro.br (3) - Prof. Doctor. Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management. Address: Rua Vergueiro, 235/249 Liberdade, Sao Paulo, SP, Brazil. Zip code: 01504-001. Website: http://www.uninove.br/curso/informatica-e-gestao-do-conhecimento/","The data set allows for several new combinations of attributes and attribute exclusions, or the modification of the attribute type (categorical, integer, or real) depending on the purpose of the research.The data set (Absenteeism at work - Part I) was used in academic research at the Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management.","1. Individual identification (ID)2. Reason for absence (ICD).Absences attested by the International Code of Diseases (ICD) stratified into 21 categories (I to XXI) as follows: I Certain infectious and parasitic diseases  II Neoplasms  III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism  IV Endocrine, nutritional and metabolic diseases  V Mental and behavioural disorders  VI Diseases of the nervous system  VII Diseases of the eye and adnexa  VIII Diseases of the ear and mastoid process  IX Diseases of the circulatory system  X Diseases of the respiratory system  XI Diseases of the digestive system  XII Diseases of the skin and subcutaneous tissue  XIII Diseases of the musculoskeletal system and connective tissue  XIV Diseases of the genitourinary system  XV Pregnancy, childbirth and the puerperium  XVI Certain conditions originating in the perinatal period  XVII Congenital malformations, deformations and chromosomal abnormalities  XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified  XIX Injury, poisoning and certain other consequences of external causes  XX External causes of morbidity and mortality  XXI Factors influencing health status and contact with health services. And 7 categories without (CID) patient follow-up (22), medical consultation (23), blood donation (24), laboratory examination (25), unjustified absence (26), physiotherapy (27), dental consultation (28).3. Month of absence4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))5. Seasons (summer (1), autumn (2), winter (3), spring (4))6. Transportation expense7. Distance from Residence to Work (kilometers)8. Service time9. Age10. Work load Average/day 11. Hit target12. Disciplinary failure (yes=1; no=0)13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))14. Son (number of children)15. Social drinker (yes=1; no=0)16. Social smoker (yes=1; no=0)17. Pet (number of pet)18. Weight19. Height20. Body mass index21. Absenteeism time in hours (target) .arff header for Weka:  @relation Absenteeism_at_work @attribute ID {31.0, 27.0, 19.0, 30.0, 7.0, 20.0, 24.0, 32.0, 3.0, 33.0, 26.0, 29.0, 18.0, 25.0, 17.0, 14.0, 16.0, 23.0, 2.0, 21.0, 36.0, 15.0, 22.0, 5.0, 12.0, 9.0, 6.0, 34.0, 10.0, 28.0, 13.0, 11.0, 1.0, 4.0, 8.0, 35.0}@attribute Reason_for_absence {17.0, 3.0, 15.0, 4.0, 21.0, 2.0, 9.0, 24.0, 18.0, 1.0, 12.0, 5.0, 16.0, 7.0, 27.0, 25.0, 8.0, 10.0, 26.0, 19.0, 28.0, 6.0, 23.0, 22.0, 13.0, 14.0, 11.0, 0.0}@attribute Month_of_absence REAL@attribute Day_of_the_week {5.0, 2.0, 3.0, 4.0, 6.0}@attribute Seasons {4.0, 1.0, 2.0, 3.0}@attribute Transportation_expense REAL@attribute Distance_from_Residence_to_Work REAL@attribute Service_time INTEGER@attribute Age INTEGER@attribute Work_load_Average/day_ REAL@attribute Hit_target REAL@attribute Disciplinary_failure {1.0, 0.0}@attribute Education REAL@attribute Son REAL@attribute Social_drinker {1.0, 0.0}@attribute Social_smoker {1.0, 0.0}@attribute Pet REAL@attribute Weight REAL@attribute Height REAL@attribute Body_mass_index REAL@attribute Absenteeism_time_in_hours REAL","Martiniano, A., Ferreira, R. P., Sassi, R. J., & Affonso, C. (2012). Application of a neuro fuzzy network in prediction of absenteeism at work. In Information Systems and Technologies (CISTI), 7th Iberian Conference on (pp. 1-4). IEEE.","Martiniano, A., Ferreira, R. P., Sassi, R. J., & Affonso, C. (2012). Application of a neuro fuzzy network in prediction of absenteeism at work. In Information Systems and Technologies (CISTI), 7th Iberian Conference on (pp. 1-4). IEEE. Acknowledgements:Professor Gary Johns for contributing to the selection of relevant research attributes.Professor Emeritus of ManagementHonorary Concordia University Research Chair in ManagementJohn Molson School of BusinessConcordia UniversityMontreal, Quebec, CanadaAdjunct Professor, OB/HR DivisionSauder School of Business,University of British ColumbiaVancouver, British Columbia, Canada",
http://archive.ics.uci.edu/ml/datasets/Function+Finding,420,Function Finding Data Set,../machine-learning-databases/function-finding/,N/A,352,Physical,Real,N/A,9/1/1990,Function-Learning,No,54018,"Donor:  Cullen SchafferDepartment of Computer ScienceRutgers UniversityNew Brunswick, NJ  08903schaffer '@' paul.rutgers.edu  Source:  Cullen Schaffer, Domain-Independent Scientific Function Finding.  PhD Thesis, Department of Computer Science, Rutgers University, 1990 (Technical Report LCSR-TR-149).","[Please note the use of Latex format here for algebraic expressions. See Leslie Lamport, Latex: A Document Preparation System, Addison-Wesley, 1986 for details.] This database contains 352 bivariate numeric data sets collected from diverse sources and resulting, with a few exceptions, from investigations in physical science. For each data set, the collection includes: 1. Source: Bibliographic information for the source of the data.2. Description: Identification of the variables $x$ and $y$.  Except in a few clearly identified instances, the abbreviated format $y$ vs. $x$ is employed.  An entry of the form Description: Force vs. separation. indicates that $x$ is a separation and $y$ is a force.  In some cases--when the information was readily available--the description also includes the units in which the data was originally reported. 3. Reference relation: The functional relationship proposed by the reporting scientist in the original source. 4. Comments (optional): Additional information pertaining to the case. In recording reference relations, the database often omits details of parameter values.  If a scientist proposes $y=23.1x-.0014$, the reference relation may be given as just $y=k_{1}x+k_{2}$.  Also, since algebraic transformations have been employed freely, the same relation might be given as $y/x=k_{2}/x+k_{1}$. In general, data collected here is given in full as it appeared in the original source.  Fractions have been converted to decimals, numbers have been freely translated to and from scientific notation and zeros have sometimes been added to decimal numbers to facilitate tabulation. Any additional deviations from verbatim transcription are noted in the Comments entry of the associated case.  Note in particular that, in a few clearly identified cases, apparent typographical errors have been corrected and that, in others, data points identified by the reporting scientist as *not* conforming to the proposed relationship have been omitted.",N/A,"Cullen Schaffer, ""A Proven Domain-Independent Scientific Function-Finding Algorithm,"" in AAAI-90.[Web Link] ","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Mechanical+Analysis,421,Mechanical Analysis Data Set,../machine-learning-databases/mechanical-analysis/,Multivariate,209,Computer,"Categorical, Integer, Real",8,6/1/1990,Classification,No,99144,"Original Owners of Database: 1. F. Bergadano, A. Giordana, L. SaittaUniversity of Torino, ItalyCorso Svizzera 185, Torino - tel. (39) 11 7712002e-mail: bergadan '@' itoinfo.bitnet  2. F. Bracadori, D. De MarchiSogesta, Localita' Crocicchio, Urbino, Italy Donor:  Enichem (Eni), Ravenna through Sogesta (Eni), Urbino.","F. Bergadano supplied this database.  Each instance contains many components, each of which has 8 attributes.  Different instances in this database have different numbers of components.   It was impossible to put one instance on one line.  He originally had one instance per file, but this makes it difficult to ftp them (imagine ftp'ing 222 or so files!).  I bundled the set of 209 instances into a single data file, prefixing each with the line:               ===== Instance number 1: ===== where ""n"" is a number in [1,221].  However, they are NOT, repeat NOT in sequential order.  Twelve (12) of the instances are missing.  Bergadano supplied these additional 12 instances (numbers 8,12,32,33,66,69,73,152,167,194,203,208) in a ""notused"" sub-directory.  I bundled these up with the same format in the ""notused-instances"" file. A quick scan of their file didn't reveal what the purpose is for these twelve instances.","   0 - dummy (always 1) - used for numbering - ignore   1 - class - classification (1..6, the same for components of one example)   2 - # - component number (integer)   3 - sup - support in the machine where measure was taken (1..4)   4 - cpm - frequency of the measure (integer)   5 - mis - measure  (real)   6 - misr - earlier measure (real)   7 - dir - filter, type of the measure and direction:		       {vo=,			va=,			vv=,			ao=,			aa=,			av=,			io=,			ia=,			iv=}   8 - omega - rpm of the machine (integer, the same for components of one example)","F. Bergadano, A. Giordana, L. Saitta, F. Brancadori, D. De Marchi: ""Integrated Learning in a real Domain"" Proc. VII ML Conference, Austin TX, 1990 (pages 322-329)[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Discrete+Tone+Image+Dataset,422,Discrete Tone Image Dataset Data Set,../machine-learning-databases/00431/,Multivariate,71,Computer,N/A,11,1/20/2018,Classification,N/A,19755,"Creator: J.UthayakumarResearch Scholar,Department of Computer Science,Pondicherry University,India.Contact: +91 9677583754Email Id: uthayresearchscholar '@' gmail.com  Guided By, Dr.T.VengattaramanAssistant Professor,Department of Computer Science,Pondicherry University,India.Email Id: vengattaramant '@' gmail.com  Dr.P.DhavachelvanProfessor,Department of Computer Science,Pondicherry University,India.Email Id: dhavachelvan '@' gmail.com",This dataset contains a total of 71 images including 11 types of images with its distorted versions. Each and every image has its own uniqueness of discrete tone image properties. ,"Types of Images1.System Generated DTI by setting distinct pixel values 2.Discrete Pixel Logo 3.Business Charts4.Bi-Level 5.Part of Discrete Information from an Continuous Image Colorspace models1.RGB 2.Grayscale 3.Binary  Distortion Types1.JPEG2.Gaussian White Noise (GWN)3.Salt and Pepper noise (SP)4.Multiplicative Speckle Noise (MSN)5.Poisson Noise (PN)","The parameters which we used to create this dataset is referred in the paper 'Compression Techniques are Lovable or Hateful: For Discrete Tone Images'. International conference on Electronics, Communication and Aerospace Technology (ICECA), IEEE.","It has been decided to make the dataset available to the research community free of charge. If you use these images in your research, kindly cite this dataset link.",
http://archive.ics.uci.edu/ml/datasets/ICMLA+2014+Accepted+Papers+Data+Set,423,ICMLA 2014 Accepted Papers Data Set Data Set,../machine-learning-databases/00434/,Multivariate,105,N/A,N/A,5,2/19/2018,"Classification, Clustering",N/A,15332,"Diego Vallejo-Huanga, dvallejoh '@' asig.com.ec, Professor of the Department of Mathematics, Universidad San Francisco de Quito.",CSV format where each row is a paper and each column an attribute.,"Paper_Id: Number; identifier of the paperPaper_Title: Free text; title of the paper Author_Keywords: Free text; author-generated keywords Abstract: Free text; paper abstractsSession: Categorical; conference organizer's-selected, conference session in which the paper was presented","[1] Vallejo-Huanga, Diego, Paulina Morillo, and Cesar Ferri. 2017. â€œSemi-Supervised Clustering Algorithms for Grouping Scientific Articles.â€ In Procedia Computer Science, 108:325â€“34. Elsevier B.V. [Web Link].[2] Vallejo, Diego, Paulina Morillo, and Cesar Ferri. 2017. â€œADoCS: Automatic Designer of Conference Schedules.â€ In Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics (pp. 41-44).","[1] Vallejo-Huanga, Diego, Paulina Morillo, and Cesar Ferri. 2017. â€œSemi-Supervised Clustering Algorithms for Grouping Scientific Articles.â€ In Procedia Computer Science, 108:325â€“34. Elsevier B.V. [Web Link].[2] Vallejo, Diego, Paulina Morillo, and Cesar Ferri. 2017. â€œADoCS: Automatic Designer of Conference Schedules.â€ In Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics (pp. 41-44).",
http://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+,424,Electrical Grid Stability Simulated Data  Data Set,../machine-learning-databases/00471/,Multivariate,10000,Physical,Real,14,11/16/2018,"Classification, Regression",N/A,44209,"   -- Creator and donor: Vadim  Arzamasov (vadim.arzamasov '@' kit.edu),   Department of computer science,   Karlsruhe Institute of Technology;    Karlsruhe, 76131; Germany     -- Date: November, 2018","The analysis is performed for different sets of input values using the methodology similar to that described in [SchÃ¤fer, Benjamin, et al. 'Taming instabilities in power grid networks by decentralized control.' The European Physical Journal Special Topics 225.3 (2016): 569-582.]. Several input values are kept the same: averaging time: 2 s; coupling strength: 8 s^-2; damping: 0.1 s^-1","11 predictive attributes, 1 non-predictive(p1), 2 goal fields:1. tau[x]: reaction time of participant (real from the range [0.5,10]s). Tau1 - the value for electricity producer.   2. p[x]: nominal power consumed(negative)/produced(positive)(real). For consumers from the range [-0.5,-2]s^-2; p1 = abs(p2 + p3 + p4)   3. g[x]: coefficient (gamma) proportional to price elasticity (real from the range [0.05,1]s^-1). g1 - the value for electricity producer.   4. stab: the maximal real part of the characteristic equation root (if positive - the system is linearly unstable)(real)   5. stabf: the stability label of the system (categorical: stable/unstable)","Arzamasov, Vadim, Klemens BÃ¶hm, and Patrick Jochem. 'Towards Concise Models of Grid Stability.' Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm), 2018 IEEE International Conference on. IEEE, 2018  (Section V-A)",We thank Dr. Benjamin SchÃ¤fer for helping us with the initial version of the code used for simulations.,
http://archive.ics.uci.edu/ml/datasets/SCADI,425,SCADI Data Set,../machine-learning-databases/00446/,Multivariate,70,Life,N/A,206,4/14/2018,"Classification, Clustering",N/A,29373,"--Creators: S.M.M. Fatemi Bushehri, Moslem Dehghanizadeh, Shokoofeh Kalantar, Mohsen Sardari Zarchi  * S.M.M. Fatemi Bushehri: Department of Software Engineering, Yazd Branch, Islamic Azad University, Yazd, Iran * Moslem Dehghanizadeh: Department of Occupational Therapy, School of Rehabilitation, Iran University of Medical Sciences, Tehran, Iran * Shokoofeh Kalantar: Student Senior Counseling & Guidance, Islamic Azad University, Department of Human Science, Yazd, Iran * Mohsen Sardari Zarchi: Department of Computer Engineering, Meybod University, Meybod, Iran  -- Donator: S.M.M. Fatemi Bushehri ","This dataset contains 206 attributes of 70 children with physical and motor disability based on ICF-CY. In particular, the SCADI dataset is the only one that has been used by ML researchers for self-care problems classification based on ICF-CY to this date. The 'Class' field refers to the presence of the self-care problems of the children with physical and motor disabilities.The classes are determined by occupational therapists.The names and social security numbers of the children were recently removed from the dataset.  Two files have been 'processed', SCADI.arff for using in WEKA and SCADI.CSV for using in MATLAB and similar tools. ","1:     gender: gender (1 = male; 0 = female)2:     age: age in years 3-205: self-care activities based on ICF-CY (1 = The case has this feature; 0 = otherwise) 206:   Classes ( class1 = Caring for body parts problem; class2 = Toileting problem; class3 = Dressing problem; class4 = Washing oneself and Caring for body parts and Dressing problem; class5 = Washing oneself, Caring for body parts, Toileting, and Dressing problem; class6 = Eating, Drinking, Washing oneself, Caring for body parts, toileting,Dressing, Looking after oneâ€™s health and Looking  after oneâ€™s safety problem; class7 = No Problem; ) ","Zarchi, M. S., SMM Fatemi Bushehri, and M. Dehghanizadeh. 'SCADI: A standard dataset for self-care problems classification of children with physical and motor disability.' International Journal of Medical Informatics (2018). Bushehri, SMM Fatemi, and Mohsen Sardari Zarchi. ""An expert model for self-care problems classification using probabilistic neural network and feature selection approach."" Applied Soft Computing 82 (2019): 105545.","Please include this citation if you plan to use this database (BibTeX format): @article{zarchi2018scadi,  title={SCADI: A standard dataset for self-care problems classification of children with physical and motor disability},  author={Zarchi, MS and Bushehri, SMM Fatemi and Dehghanizadeh, M},  journal={International Journal of Medical Informatics},  year={2018},  publisher={Elsevier}}  @article{bushehri2019expert,  title={An expert model for self-care problems classification using   probabilistic neural network and feature selection approach},  author={Bushehri, SMM Fatemi and Zarchi, Mohsen Sardari},  journal={Applied Soft Computing},  volume={82},  pages={105545},  year={2019},  publisher={Elsevier}}",
http://archive.ics.uci.edu/ml/datasets/Facebook+metrics,426,Facebook metrics Data Set,../machine-learning-databases/00368/,Multivariate,500,Business,Integer,19,8/5/2016,Regression,N/A,164993,"Created by: SÃ©rgio Moro, Paulo Rita and Bernardo Vala (ISCTE-IUL) @ 2016","The data is related to posts' published during the year of 2014 on the Facebook's page of a renowned cosmetics brand.This dataset contains 500 of the 790 rows and part of the features analyzed by Moro et al. (2016). The remaining were omitted due to confidentiality issues.","It includes 7 features known prior to post publication and 12 features for evaluating post impact (see Tables 2 and 3 from Moro et al., 2016 - complete reference in the 'Citation Request')","(Moro et al., 2016) Moro, S., Rita, P., & Vala, B. (2016). Predicting social media performance metrics and evaluation of the impact on brand building: A data mining approach. Journal of Business Research, 69(9), 3341-3351.","This dataset is public available for research. The details are described in (Moro et al., 2016).Please include this citation if you plan to use this database:  (Moro et al., 2016) Moro, S., Rita, P., & Vala, B. (2016). Predicting social media performance metrics and evaluation of the impact on brand building: A data mining approach. Journal of Business Research, 69(9), 3341-3351. Available at: [Web Link]",
http://archive.ics.uci.edu/ml/datasets/Folio,427,Folio Data Set,../machine-learning-databases/00338/,Multivariate,637,N/A,N/A,20,7/5/2015,"Classification, Clustering",Yes,58783,"The leaves were taken from plants in the farm of the University of Mauritius and nearby locations. Donors: Trishen Munisamitrishen.munisami '@' gmail.com  Mahess Ramsurnramsurn.mahess '@' umail.uom.ac.mu  Somveer Kishnahs.kishnah '@' uom.ac.mu  Sameerchand Pudaruthsameerchand.pudaruth '@' gmail.com","- The leaves were placed on a white background and then photographed. - The pictures were taken in broad daylight to ensure optimum light intensity.",List of plant species:1. Beaumier du perou2. Eggplant3. Fruitcitere4. Guava5. Hibiscus6. Betel7. Rose8. Chrysanthemum9. Ficus10. Duranta gold11. Ashanti blood12. Bitter Orange13. Coeur Demoiselle14. Jackfruit15. Mulberry Leaf16. Pimento17. Pomme Jacquot18. Star Apple19. Barbados Cherry20. Sweet Olive21. Croton22. Thevetia23. Vieux Garcon24. Chocolate tree25. Carricature plant26. Coffee27. Ketembilla28. Chinese guava29. Lychee30. Geranium31. Sweet potato32. Papaya,"Munisami, T., Ramsurn, M., Kishnah, S. and Pudaruth, S., 2015. Plant leaf recognition using shape features and colour histogram with k-nearest neighbour classifiers. Procedia Computer Science (Elsevier) Journal. 58, pp. 740-747.","Munisami, T., Ramsurn, M., Kishnah, S. and Pudaruth, S., 2015. Plant leaf recognition using shape features and colour histogram with k-nearest neighbour classifiers. Procedia Computer Science (Elsevier) Journal. 58, pp. 740-747.",
http://archive.ics.uci.edu/ml/datasets/CNAE-9,428,CNAE-9 Data Set,../machine-learning-databases/00233/,"Multivariate, Text",1080,Business,Integer,857,8/3/2012,Classification,N/A,65396,"Patrick Marques Ciarelli, pciarelli '@' lcad.inf.ufes.br, Department of Electrical Engineering, Federal University of Espirito Santo Elias Oliveira, elias '@' lcad.inf.ufes.br, Department of Information Science, Federal University of Espirito Santo","This is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into asubset of 9 categories cataloged in a table called National Classification of Economic Activities (ClassificaÃ§Ã£o Nacional deAtividade EconÃ´micas - CNAE). The original texts were pre-processed to obtain the current data set: initially, it was kept onlyletters and then it was removed prepositions of the texts. Next, the words were transformed to their canonical form. Finally,each document was represented as a vector, where the weight of each word is its frequency in the document. This data set ishighly sparse (99.22% of the matrix is filled with zeros).","In the data set there are 857 attributes, 1 attributes with the class of instance and 856 with word frequency: 1. category: range 1 - 9 (integer)2 - 857. word frequency: (integer)","Patrick Marques Ciarelli, Elias Oliveira, 'Agglomeration and Elimination of Terms for Dimensionality Reduction',Ninth International Conference on Intelligent Systems Design and Applications, pp.547-552, 2009 Patrick Marques Ciarelli, Elias Oliveira, Evandro O. T. Salles, 'An Evolving System Based on Probabilistic Neural Network',Brazilian Symposium on Artificial Neural Network, 2010","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Miskolc+IIS+Hybrid+IPS,429,Miskolc IIS Hybrid IPS Data Set,../machine-learning-databases/00375/,Text,1540,Computer,Integer,67,7/4/2016,"Classification, Clustering, Causal-Discovery",Yes,13341,"Zsolt TÃ³th University of Miskolc <tothzs '@' iit.uni-miskolc.hu>Judit TamÃ¡s University of Miskolc <tamas13 '@' iit.uni-miskolc.hu>","The measurements were created to ease the development, comparison and evaluation of fingerprinting based hybrid indoor positioning methods. The measurements were recorded by the same kind of Android devices in order to reduce the effect of the variety of the hardware. The recording was preformed at weekend to reduce the noise of the environment. The measurements were performed in a three-story building and cover about 50% of it. ","#Measurement Info1) 	Measurement Id - Java UUID2) 	Timestamp - YYYY-MM-dd hh:mm:ss  #Position Info3-5) 	Coordinates of the absolute position (x,y,z)6-7) 	Symbolic position - UUID and name of the position #Measruement Values8-10) 	Magnetometer values x,y,z, real11-42) 	WiFi RSSI values, negative integeres [-255,0]43-65) 	Bluetooth devices {0,1} - 1 if the given devices was sensed in during the measurement.",Provide references to papers that have cited this data set in the past (if any).,"@InProceedings{toth2016miskolcIIS,  Title                    = {Miskolc IIS Hybrid IPS: Dataset for Hybrid Indoor Positioning},  Author                   = {{Zs}olt TÃ³th, Judit TamÃ¡s},  Booktitle                = {26st International Conference on Radioelektronika},  Year                     = {2016},  Organization             = {IEEE},  Pages                    = {408--412},}",
http://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks,430,APS Failure at Scania Trucks Data Set,../machine-learning-databases/00421/,Multivariate,60000,Computer,"Integer, Real",171,12/8/2017,Classification,Yes,55762,"-- Creator: Scania CV AB               VagnmakarvÃ¤gen 1                151 32 SÃ¶dertÃ¤lje                Stockholm               Sweden    -- Donor:   Tony Lindgren (tony '@' dsv.su.se) and Jonas Biteus (jonas.biteus '@' scania.com)   -- Date:    September, 2016","This file is part of APS Failure and Operational Data for Scania Trucks. Copyright (c) <2016>   This program (APS Failure and Operational Data for Scania Trucks) is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version. This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details. You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <[Web Link]>. ------------------------------------------------------------------------ 1. Title: APS Failure at Scania Trucks 2. Source Information   -- Creator: Scania CV AB               VagnmakarvÃ¤gen 1                151 32 SÃ¶dertÃ¤lje                Stockholm               Sweden    -- Donor:   Tony Lindgren (tony '@' dsv.su.se) and Jonas Biteus (jonas.biteus '@' scania.com)   -- Date:    September, 2016 3. Past Usage:   Industrial Challenge 2016 at The 15th International Symposium on Intelligent Data Analysis (IDA)    -- Results:              The top three contestants                                                | Score | Number of Type 1 faults | Number of Type 2 faults     ------------------------------------------------------------------------------------------------------------------------------------     Camila F. Costa and Mario A. Nascimento                                  | 9920  | 542                     | 9     Christopher Gondek, Daniel Hafner and Oliver R. Sampson                  | 10900 | 490                     | 12     Sumeet Garnaik, Sushovan Das, Rama Syamala Sreepada and Bidyut Kr. Patra | 11480 | 398                     | 15 4. Relevant Information:   -- Introduction     The dataset consists of data collected from heavy Scania      trucks in everyday usage. The system in focus is the      Air Pressure system (APS) which generates pressurised      air that are utilized in various functions in a truck,      such as braking and gear changes. The datasets'      positive class consists of component failures      for a specific component of the APS system.      The negative class consists of trucks with failures      for components not related to the APS. The data consists      of a subset of all available data, selected by experts.     -- Challenge metric        Cost-metric of miss-classification:      Predicted class |      True class       |                     |    pos    |    neg    |     -----------------------------------------      pos            |     -     |  Cost_1   |     -----------------------------------------      neg            |  Cost_2   |     -     |     -----------------------------------------     Cost_1 = 10 and cost_2 = 500      The total cost of a prediction model the sum of 'Cost_1'      multiplied by the number of Instances with type 1 failure      and 'Cost_2' with the number of instances with type 2 failure,      resulting in a 'Total_cost'.      In this case Cost_1 refers to the cost that an unnessecary      check needs to be done by an mechanic at an workshop, while      Cost_2 refer to the cost of missing a faulty truck,      which may cause a breakdown.      Total_cost = Cost_1*No_Instances + Cost_2*No_Instances. 5. Number of Instances:      The training set contains 60000 examples in total in which      59000 belong to the negative class and 1000 positive class.      The test set contains 16000 examples.  6. Number of Attributes: 171  7. Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:     bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20     |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20   The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'.","Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:     bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20     |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20   The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'.","Costa C.F., Nascimento M.A. (2016) IDA 2016 Industrial Challenge: Using Machine Learning for Predicting Failures. In: BostrÃ¶m H., Knobbe A., Soares C., Papapetrou P. (eds) Advances in Intelligent Data Analysis XV. IDA 2016. Lecture Notes in Computer Science, vol 9897. Springer, Cham Gondek C., Hafner D., Sampson O.R. (2016) Prediction of Failures in the Air Pressure System of Scania Trucks Using a Random Forest and Feature Engineering. In: BostrÃ¶m H., Knobbe A., Soares C., Papapetrou P. (eds) Advances in Intelligent Data Analysis XV. IDA 2016. Lecture Notes in Computer Science, vol 9897. Springer, Cham Cerqueira V., Pinto F., SÃ¡ C., Soares C. (2016) Combining Boosted Trees with Metafeature Engineering for Predictive Maintenance. In: BostrÃ¶m H., Knobbe A., Soares C., Papapetrou P. (eds) Advances in Intelligent Data Analysis XV. IDA 2016. Lecture Notes in Computer Science, vol 9897. Springer, Cham Ozan E.C., Riabchenko E., Kiranyaz S., Gabbouj M. (2016) An Optimized k-NN Approach for Classification on Imbalanced Datasets with Missing Data. In: BostrÃ¶m H., Knobbe A., Soares C., Papapetrou P. (eds) Advances in Intelligent Data Analysis XV. IDA 2016. Lecture Notes in Computer Science, vol 9897. Springer, Cham","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume,431,Metro Interstate Traffic Volume Data Set,../machine-learning-databases/00492/,"Multivariate, Sequential, Time-Series",48204,N/A,"Integer, Real",9,5/7/2019,Regression,N/A,43754,"John Hogue, john.d.hogue '@' live.com, Social Data Science & General Mills","Hourly Interstate 94 Westbound traffic volume for MN DoT ATR station 301, roughly midway between Minneapolis and St Paul, MN. Hourly weather features and holidays included for impacts on traffic volume.","holiday                Categorical    US National holidays plus regional holiday, Minnesota State Fairtemp                   Numeric        Average temp in kelvinrain_1h                Numeric        Amount in mm of rain that occurred in the hoursnow_1h                Numeric        Amount in mm of snow that occurred in the hourclouds_all             Numeric        Percentage of cloud coverweather_main           Categorical    Short textual description of the current weatherweather_description    Categorical    Longer textual description of the current weatherdate_time              DateTime       Hour of the data collected in local CST timetraffic_volume         Numeric        Hourly I-94 ATR 301 reported westbound traffic volume","Talk on anomaly detection.[Web Link]","Traffic data from MN Department of TransportationWeather data from OpenWeatherMap",
http://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports,432,Legal Case Reports Data Set,../machine-learning-databases/00239/,Text,N/A,N/A,N/A,N/A,10/19/2012,Classification,N/A,88204,"Filippo Galganigalganif '@' cse.unsw.edu.au School of Computer Science and EngineeringThe Univeristy of New South Wales, Australia","This dataset contains Australian legal cases from the Federal Court of Australia (FCA). The cases were downloaded from AustLII ([Web Link]). We included all cases from the year 2006,2007,2008 and 2009. We built it to experiment with automatic summarization and citation analysis. For each document we collected catchphrases, citations sentences, citation catchphrases, and citation classes. Catchphrases are found in the document, we used the catchphrases are gold standard for our summarization experiments. Citation sentences are found in later cases that cite the present case, we use citation sentences for summarization. Citation catchphrases are the catchphrases (where available) of both later cases that cite the present case, and older cases cited by the present case. Citation classes are indicated in the document, and indicate the type of treatment given to the cases cited by the present case.",Provide information about each attribute in your data set.,"[1] F. Galgani, P. Compton, and A. Hoffmann. Citation based summarisation of legal texts. In PRICAI 2012, volume LNCS 7458, pages 40â€“52. Springer, Heidelberg, 2012.[2] F. Galgani, P. Compton, and A. Hoffmann. Combining different summarization techniques for legal text. In Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data, pages 115â€“123, Avignon, France, April 2012. Association for Computational Linguistics.[3] F. Galgani, P. Compton, and A. Hoffmann. Knowledge acquisition for categorization of legal case re- ports. In D. Richards and B. Kang, editors, PKAW 2012, volume LNAI 7457, pages 118â€“132. Springer, Heidelberg, 2012.[4] F. Galgani, P. Compton, and A. Hoffmann. Towards automatic generation of catchphrases for legal case reports. In the 13th International Conference on Intelligent Text Processing and Computational Linguistics, volume 7182 of Lecture Notes in Computer Science, pages 415â€“426, New Delhi, India, 2012. Springer Berlin Heidelberg.[5] F. Galgani and A. Hoffmann. Lexa: Towards automatic legal citation classification. In J. Li, editor, AI 2010: Advances in Artificial Intelligence, volume 6464 of Lecture Notes in Computer Science, pages 445 â€“454. Springer Berlin Heidelberg, 2010.","[1] F. Galgani, P. Compton, and A. Hoffmann. Citation based summarisation of legal texts. In PRICAI 2012, volume LNCS 7458, pages 40â€“52. Springer, Heidelberg, 2012.[2] F. Galgani, P. Compton, and A. Hoffmann. Combining different summarization techniques for legal text. In Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data, pages 115â€“123, Avignon, France, April 2012. Association for Computational Linguistics.[3] F. Galgani, P. Compton, and A. Hoffmann. Knowledge acquisition for categorization of legal case re- ports. In D. Richards and B. Kang, editors, PKAW 2012, volume LNAI 7457, pages 118â€“132. Springer, Heidelberg, 2012.[4] F. Galgani, P. Compton, and A. Hoffmann. Towards automatic generation of catchphrases for legal case reports. In the 13th International Conference on Intelligent Text Processing and Computational Linguistics, volume 7182 of Lecture Notes in Computer Science, pages 415â€“426, New Delhi, India, 2012. Springer Berlin Heidelberg.[5] F. Galgani and A. Hoffmann. Lexa: Towards automatic legal citation classification. In J. Li, editor, AI 2010: Advances in Artificial Intelligence, volume 6464 of Lecture Notes in Computer Science, pages 445 â€“454. Springer Berlin Heidelberg, 2010.",
http://archive.ics.uci.edu/ml/datasets/Wall-Following+Robot+Navigation+Data,433,Wall-Following Robot Navigation Data Data Set,../machine-learning-databases/00194/,"Multivariate, Sequential",5456,Computer,Real,24,8/4/2010,Classification,N/A,62588,"(a) Creators: 	Ananda Freire, Marcus Veloso and Guilherme Barreto 		Department of Teleinformatics Engineering 		Federal University of CearÃ¡			Fortaleza, CearÃ¡, Brazil   (b) Donors of database: Ananda Freire (anandalf '@' gmail.com)			Guilherme Barreto (guilherme '@' deti.ufc.br)","The provided files comprise three different data sets. The first one contains the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label (see Section 7). Sensor readings are sampled at a rate of 9 samples per second. The second one contains four sensor readings named 'simplified distances' and the corresponding class label (see Section 7). These simplified distances are referred to as the 'front distance', 'left distance', 'right distance' and 'back distance'. They consist, respectively, of the minimum sensor readings among those within 60 degree arcs located at the front, left, right and back parts of the robot. The third one contains only the front and left simplified distances and the corresponding class label. It is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step). The wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions.  If some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot succesfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network. Files with different number of sensor readings were built in order to evaluate the performance of the classifiers with respect to the number of inputs.","Number of Attributes    -- sensor_readings_24.data: 24 numeric attributes and the class.   -- sensor_readings_4.data:   4 numeric attributes and the class.   -- sensor_readings_2.data:   2 numeric attributes and the class.   For Each Attribute:    -- File sensor_readings_24.data:	1. US1: ultrasound sensor at the front of the robot (reference angle: 180Â°) - (numeric: real)	2. US2: ultrasound reading (reference angle: -165Â°) - (numeric: real)	3. US3: ultrasound reading (reference angle: -150Â°) - (numeric: real)	4. US4: ultrasound reading (reference angle: -135Â°) - (numeric: real)	5. US5: ultrasound reading (reference angle: -120Â°) - (numeric: real)	6. US6: ultrasound reading (reference angle: -105Â°) - (numeric: real)	7. US7: ultrasound reading (reference angle: -90Â°) - (numeric: real)	8. US8: ultrasound reading (reference angle: -75Â°) - (numeric: real)	9. US9: ultrasound reading (reference angle: -60Â°) - (numeric: real)	10. US10: ultrasound reading (reference angle: -45Â°) - (numeric: real)	11. US11: ultrasound reading (reference angle: -30Â°) - (numeric: real)	12. US12: ultrasound reading (reference angle: -15Â°) - (numeric: real)	13. US13: reading of ultrasound sensor situated at the back of the robot (reference angle: 0Â°) - (numeric: real)	14. US14: ultrasound reading (reference angle: 15Â°) - (numeric: real)	15. US15: ultrasound reading (reference angle: 30Â°) - (numeric: real)	16. US16: ultrasound reading (reference angle: 45Â°) - (numeric: real)	17. US17: ultrasound reading (reference angle: 60Â°) - (numeric: real)	18. US18: ultrasound reading (reference angle: 75Â°) - (numeric: real)	19. US19: ultrasound reading (reference angle: 90Â°) - (numeric: real)	20. US20: ultrasound reading (reference angle: 105Â°) - (numeric: real)	21. US21: ultrasound reading (reference angle: 120Â°) - (numeric: real)	22. US22: ultrasound reading (reference angle: 135Â°) - (numeric: real)	23. US23: ultrasound reading (reference angle: 150Â°) - (numeric: real)	24. US24: ultrasound reading (reference angle: 165Â°) - (numeric: real)   	25. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn    -- File sensor_readings_4.data:	1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)	2. SD_left:  minimum sensor reading within a 60 degree arc located at the left of the robot  - (numeric: real)	3. SD_right: minimum sensor reading within a 60 degree arc located at the right of the robot - (numeric: real)	4. SD_back:  minimum sensor reading within a 60 degree arc located at the back of the robot - (numeric: real)   	5. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn    -- File sensor_readings_2.data:	1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)	2. SD_left:  minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real)   	3. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn","Ananda L. Freire, Guilherme A. Barreto, Marcus Veloso and Antonio T. Varela (2009),'Short-Term Memory Mechanisms in Neural Network Learning of Robot Navigation Tasks: A Case Study'. Proceedings of the 6th Latin American Robotics Symposium (LARS'2009),ValparaÃ­so-Chile, pages 1-6, DOI: 10.1109/LARS.2009.5418323 ","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+%28Version+2%29,434,Waveform Database Generator (Version 2) Data Set,../machine-learning-databases/waveform/,"Multivariate, Data-Generator",5000,Physical,Real,40,11/10/1988,Classification,No,60447,"Original Owners: Breiman,L., Friedman,J.H., Olshen,R.A., & Stone,C.J. (1984). Classification and Regression Trees.  Wadsworth InternationalGroup: Belmont, California.  (see pages 43-49). Donor:  David Aha ","Notes:     -- 3 classes of waves     -- 40 attributes, all of which include noise        -- The latter 19 attributes are all noise attributes with mean 0 and variance 1     -- See the book for details (49-55, 169)     -- waveform-+noise.data.Z contains 5000 instances","    -- Each class is generated from a combination of 2 of 3 ""base"" waves    -- Each instance is generated f added noise (mean 0, variance 1) in each attribute     -- See the book for details (49-55, 169)","Leo Breiman, Jerome H. Friedman, Adam Olshen, Jonathan Stone. ""Classification and Regression Trees."" 1984.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Giorgio Valentini. Random Aggregated and Bagged Ensembles of SVMs: An Empirical Bias?Variance Analysis. Multiple Classifier Systems. 2004.  [View Context].Zhi-Hua Zhou and W-D Wei and Gang Li and Honghua Dai. On the Size of Training Set and the Benefit from Ensemble. PAKDD. 2004.  [View Context].Eibe Frank and Mark Hall and Bernhard Pfahringer. Locally Weighted Naive Bayes. UAI. 2003.  [View Context].Giorgio Valentini and Thomas G. Dietterich. Low Bias Bagged Support Vector Machines. ICML. 2003.  [View Context].Joao Gama and Ricardo Rocha and Pedro Medas. Accurate decision trees for mining high-speed data streams. KDD. 2003.  [View Context].Giorgio Valentini. Ensemble methods based on bias--variance analysis Theses Series DISI-TH-2003. Dipartimento di Informatica e Scienze dell'Informazione . 2003.  [View Context].S. Sathiya Keerthi and Kaibo Duan and Shirish Krishnaj Shevade and Aun Neow Poo. A Fast Dual Algorithm for Kernel Logistic Regression. ICML. 2002.  [View Context].James Bailey and Thomas Manoukian and Kotagiri Ramamohanarao. Fast Algorithms for Mining Emerging Patterns. PKDD. 2002.  [View Context].Bede Liu and Mingzeng Hu and Wynne Hsu. Multi-level organization and summarization of the discovered rules. KDD. 2000.  [View Context].Thomas G. Dietterich. An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization. Machine Learning, 40. 2000.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso. Applying Boosting to Similarity Literals for Time Series Classification. Department of Informatics University of Valladolid, Spain. 2000.  [View Context].Juan J Rodríguez Diez and Carlos Alonso González and Henrik Boström. Learning First Order Logic Time Series Classifiers: Rules and Boosting. PKDD. 2000.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso and Henrik Bostrom. Boosting Interval Based Literals. 2000.  [View Context].Kai Ming Ting and Ian H. Witten. Issues in Stacked Generalization. J. Artif. Intell. Res. (JAIR, 10. 1999.  [View Context].Khaled A. Alsabti and Sanjay Ranka and Vineet Singh. CLOUDS: A Decision Tree Classifier for Large Datasets. KDD. 1998.  [View Context].Kai Ming Ting and Boon Toh Low. Model Combination in the Multiple-Data-Batches Scenario. ECML. 1997.  [View Context].Nir Friedman and Moisés Goldszmidt. Discretizing Continuous Attributes While Learning Bayesian Networks. ICML. 1996.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Tapio Elomaa and Juho Rousu. Finding Optimal Multi-Splits for Numerical Attributes in Decision Tree Learning. ESPRIT Working Group in Neural and Computational Learning. 1996.  [View Context].Dietrich Wettschereck and David W. Aha. Weighting Features. ICCBR. 1995.  [View Context].Vikas Sindhwani and P. Bhattacharya and Subrata Rakshit. Information Theoretic Feature Crediting in Multiclass Support Vector Machines.  [View Context].Mohammed Waleed Kadous. Expanding the Scope of Concept Learning Using Metafeatures. School of Computer Science and Engineering, University of New South Wales.  [View Context].Thomas T. Osugi and M. S. EXPLORATION-BASED ACTIVE MACHINE LEARNING. Faculty of The Graduate College at the University of Nebraska In Partial Fulfillment of Requirements.  [View Context].Pierre Geurts. Extremely randomized trees. Technical report June 2003 University of Li#ege Department of Electrical Engineering and Computer Science Institut Monte#ore.  [View Context].Iñaki Inza and Pedro Larraaga and Ramon Etxeberria and Basilio Sierra. Feature Subset Selection by Bayesian networks based optimization. Dept. of Computer Science and Artificial Intelligence. University of the Basque Country.  [View Context].Kai Ming Ting and Boon Toh Low. Theory Combination: an alternative to Data Combination. University of Waikato.  [View Context].Matthias Scherf and W. Brauer. Feature Selection by Means of a Feature Weighting Approach. GSF - National Research Center for Environment and Health.  [View Context].Zhi-Hua Zhou and Xu-Ying Liu. Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem.  [View Context].Giorgio Valentini. An experimental bias--variance analysis of SVM ensembles based on resampling techniques.  [View Context].Juan J. Rodr and guez Diez and Carlos J. Alonso. Learning Classification RBF Networks by Boosting. Lenguajes y Sistemas Inform#aticos.  [View Context].Zoran Obradovic and Slobodan Vucetic. Challenges in Scientific Data Mining: Heterogeneous, Biased, and Large Samples. Center for Information Science and Technology Temple University.  [View Context].Carlos J. Alonso Gonzalez and Juan J. Rodr and iguez Diez. Time Series Classification by Boosting Interval Based Literals. Grupo de Sistemas Inteligentes Departamento de Informatica Universidad de Valladolid.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso and Henrik Bostrom. Learning First Order Logic Time Series Classifiers: Rules and Boosting. Grupo de Sistemas Inteligentes, Departamento de Inform#atica Universidad de Valladolid, Spain.  [View Context].Kai Ming Ting and Ian H. Witten. Stacked Generalization: when does it work. Department of Computer Science University of Waikato.  [View Context].Amund Tveit. Empirical Comparison of Accuracy and Performance for the MIPSVM classifier with Existing Classifiers. Division of Intelligent Systems Department of Computer and Information Science, Norwegian University of Science and Technology.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Mushroom,435,Mushroom Data Set,../machine-learning-databases/mushroom/,Multivariate,8124,Life,Categorical,22,4/27/1987,Classification,Yes,546738,"Origin: Mushroom records drawn from The Audubon Society Field Guide to North American Mushrooms (1981). G. H. Lincoff (Pres.), New York: Alfred A. Knopf Donor:  Jeff Schlimmer (Jeffrey.Schlimmer '@' a.gp.cs.cmu.edu)","This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525).  Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended.  This latter class was combined with the poisonous one.  The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.","     1. cap-shape:                bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s     2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s     3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y     4. bruises?:                 bruises=t,no=f     5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s     6. gill-attachment:          attached=a,descending=d,free=f,notched=n     7. gill-spacing:             close=c,crowded=w,distant=d     8. gill-size:                broad=b,narrow=n     9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y    10. stalk-shape:              enlarging=e,tapering=t    11. stalk-root:               bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?    12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s    13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s    14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y    15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y    16. veil-type:                partial=p,universal=u    17. veil-color:               brown=n,orange=o,white=w,yellow=y    18. ring-number:              none=n,one=o,two=t    19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z    20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y    21. population:               abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y    22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d","Schlimmer,J.S. (1987). Concept Acquisition Through Representational Adjustment (Technical Report 87-19).  Doctoral disseration, Department of Information and Computer Science, University of California, Irvine.[Web Link]  Iba,W., Wogulis,J., & Langley,P. (1988).  Trading off Simplicity and Coverage in Incremental Concept Learning. In Proceedings of the 5th International Conference on Machine Learning, 73-79. Ann Arbor, Michigan: Morgan Kaufmann.  [Web Link]  Duch W, Adamczak R, Grabczewski K (1996) Extraction of logical rules from training data using backpropagation networks, in: Proc. of the The 1st Online Workshop on Soft Computing, 19-30.Aug.1996, pp. 25-30, [Web Link] [Web Link]  Duch W, Adamczak R, Grabczewski K, Ishikawa M, Ueda H, Extraction of crisp logical rules using constrained backpropagation networks - comparison of two new approaches, in: Proc. of the European Symposium on Artificial Neural Networks (ESANN'97), Bruge, Belgium 16-18.4.1997.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Manuel Oliveira. Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted. University of Alberta Library. 2005.  [View Context].Xiaoyong Chai and Li Deng and Qiang Yang and Charles X. Ling. Test-Cost Sensitive Naive Bayes Classification. ICDM. 2004.  [View Context].Hyunsoo Kim and Se Hyun Park. Data Reduction in Support Vector Machines by a Kernelized Ionic Interaction Model. SDM. 2004.  [View Context].Daniel J. Lizotte and Omid Madani and Russell Greiner. Budgeted Learning of Naive-Bayes Classifiers. UAI. 2003.  [View Context].Daniel Barbar and Yi Li and Julia Couto. COOLCAT: an entropy-based algorithm for categorical clustering. CIKM. 2002.  [View Context].Stephen D. Bay and Michael J. Pazzani. Detecting Group Differences: Mining Contrast Sets. Data Min. Knowl. Discov, 5. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. DeEPs: A New Instance-based Discovery and Classification System. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001.  [View Context].Huan Liu and Hongjun Lu and Jie Yao. Toward Multidatabase Mining: Identifying Relevant Databases. IEEE Trans. Knowl. Data Eng, 13. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao. Instance-Based Classification by Emerging Patterns. PKDD. 2000.  [View Context].Farhad Hussain and Huan Liu and Einoshin Suzuki and Hongjun Lu. Exception Rule Mining with a Relative Interestingness Measure. PAKDD. 2000.  [View Context].Kiri Wagstaff and Claire Cardie. Clustering with Instance-level Constraints. ICML. 2000.  [View Context].Venkatesh Ganti and Johannes Gehrke and Raghu Ramakrishnan. CACTUS - Clustering Categorical Data Using Summaries. KDD. 1999.  [View Context].Ismail Taha and Joydeep Ghosh. Symbolic Interpretation of Artificial Neural Networks. IEEE Trans. Knowl. Data Eng, 11. 1999.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Huan Liu and Hongjun Lu and Ling Feng and Farhad Hussain. Efficient Search of Reliable Exceptions. PAKDD. 1999.  [View Context].Mark A. Hall and Lloyd A. Smith. Feature Selection for Machine Learning: Comparing a Correlation-Based Filter Approach to the Wrapper. FLAIRS Conference. 1999.  [View Context].Jinyan Li and Xiuzhen Zhang and Guozhu Dong and Kotagiri Ramamohanarao and Qun Sun. Efficient Mining of High Confidience Association Rules without Support Thresholds. PKDD. 1999.  [View Context].Seth Bullock and Peter M. Todd. Made to Measure: Ecological Rationality in Structured Environments. Center for Adaptive Behavior and Cognition Max Planck Institute for Human Development. 1999.  [View Context].Huan Liu and Rudy Setiono. Incremental Feature Selection. Appl. Intell, 9. 1998.  [View Context].Nicholas Howe and Claire Cardie. Examining Locally Varying Weights for Nearest Neighbor Algorithms. ICCBR. 1997.  [View Context].Robert M French. Pseudo-recurrent connectionist networks: An approach to the ""sensitivity-stability"" dilemma.. Connection Science. 1997.  [View Context].Guszti Bartfai. VICTORIA UNIVERSITY OF WELLINGTON Te Whare Wananga o te Upoko o te Ika a Maui. Department of Computer Science PO Box 600. 1996.  [View Context].Huan Liu and Rudy Setiono. A Probabilistic Approach to Feature Selection - A Filter Solution. ICML. 1996.  [View Context].Kamal Ali and Michael J. Pazzani. Error Reduction through Learning Multiple Descriptions. Machine Learning, 24. 1996.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Daniel J. Lizotte. Library Release Form Name of Author. Budgeted Learning of Naive Bayes Classifiers.  [View Context].David R. Musicant. DATA MINING VIA MATHEMATICAL PROGRAMMING AND MACHINE LEARNING. Doctor of Philosophy (Computer Sciences) UNIVERSITY.  [View Context].Sherrie L. W and Zijian Zheng. A BENCHMARK FOR CLASSIFIER LEARNING. Basser Department of Computer Science The University of Sydney.  [View Context].Anthony Robins and Marcus Frean. Learning and generalisation in a stable network. Computer Science, The University of Otago.  [View Context].Rudy Setiono. Extracting M-of-N Rules from Trained Neural Networks. School of Computing National University of Singapore.  [View Context].Jos'e L. Balc'azar. Rules with Bounded Negations and the Coverage Inference Scheme. Dept. LSI, UPC.  [View Context].Mehmet Dalkilic and Arijit Sengupta. A Logic-theoretic classifier called Circle. School of Informatics Center for Genomics and BioInformatics Indiana University.  [View Context].Daniel J. Lizotte and Omid Madani and Russell Greiner. Budgeted Learning, Part II: The Na#ve-Bayes Case. Department of Computing Science University of Alberta.  [View Context].Ron Kohavi and Barry G. Becker and Dan Sommerfield. Improving Simple Bayes. Data Mining and Visualization Group Silicon Graphics, Inc.  [View Context].Wl odzisl/aw Duch and Rafal Adamczak and Krzysztof Grabczewski and Norbert Jankowski. Control and Cybernetics. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Huan Liu. A Family of Efficient Rule Generators. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Shi Zhong and Weiyu Tang and Taghi M. Khoshgoftaar. Boosted Noise Filters for Identifying Mislabeled Data. Department of Computer Science and Engineering Florida Atlantic University.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Eric P. Kasten and Philip K. McKinley. MESO: Perceptual Memory to Support Online Learning in Adaptive Software. Proceedings of the Third International Conference on Development and Learning (ICDL.  [View Context].Stefan R uping. A Simple Method For Estimating Conditional Probabilities For SVMs. CS Department, AI Unit Dortmund University.  [View Context].Josep Roure Alcobe. Incremental Hill-Climbing Search Applied to Bayesian Network Structure Learning. Escola Universitria Politcnica de Mataro.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. A hybrid method for extraction of logical rules from data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Jinyan Li and Kotagiri Ramamohanarao and Guozhu Dong. ICML2000 The Space of Jumping Emerging Patterns and Its Incremental Maintenance Algorithms. Department of Computer Science and Software Engineering, The University of Melbourne, Parkville.  [View Context].Wl/odzisl/aw Duch and Rafal Adamczak and Krzysztof Grabczewski. Extraction of crisp logical rules using constrained backpropagation networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Cardiotocography,436,Cardiotocography Data Set,../machine-learning-databases/00193/,Multivariate,2126,Life,Real,23,9/7/2010,Classification,N/A,168353,"Marques de SÃ¡, J.P., jpmdesa '@' gmail.com, Biomedical Engineering Institute, Porto, Portugal.Bernardes, J., joaobern '@' med.up.pt, Faculty of Medicine, University of Porto, Portugal.Ayres de Campos, D., sisporto '@' med.up.pt, Faculty of Medicine, University of Porto, Portugal.","2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.","LB - FHR baseline (beats per minute)AC - # of accelerations per secondFM - # of fetal movements per secondUC - # of uterine contractions per secondDL - # of light decelerations per secondDS - # of severe decelerations per secondDP - # of prolongued decelerations per secondASTV - percentage of time with abnormal short term variabilityMSTV - mean value of short term variabilityALTV - percentage of time with abnormal long term variabilityMLTV - mean value of long term variabilityWidth - width of FHR histogramMin - minimum of FHR histogramMax - Maximum of FHR histogramNmax - # of histogram peaksNzeros - # of histogram zerosMode - histogram modeMean - histogram meanMedian - histogram medianVariance - histogram varianceTendency - histogram tendencyCLASS - FHR pattern class code (1 to 10) NSP - fetal state class code (N=normal; S=suspect; P=pathologic)","Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/SGEMM+GPU+kernel+performance,437,SGEMM GPU kernel performance Data Set,../machine-learning-databases/00440/,Multivariate,241600,Computer,Integer,18,2/27/2018,Regression,N/A,26042,"Enrique G. Paredes (egparedes '@' ifi.uzh.ch). Visualization and MultiMedia Lab, Department of Informatics, University of Zurich. Zurich, 8050. SwitzerlandRafael Ballester-Ripoll (rballester '@' ifi.uzh.ch). Visualization and MultiMedia Lab, Department of Informatics, University of Zurich. Zurich, 8050. Switzerland","This data set measures the running time of a matrix-matrix product A*B = C, where all matrices have size 2048 x 2048, using a parameterizable SGEMM GPU kernel with 241600 possible parameter combinations. For each tested combination, 4 runs were performed and their results are reported as the 4 last columns. All times are measured in milliseconds*. There are 14 parameter, the first 10 are ordinal and can only take up to 4 different powers of two values, and the 4 last variables are binary. Out of 1327104 total parameter combinations, only 241600 are feasible (due to various kernel constraints). This data set contains the results for all these feasible combinations. The experiment was run on a desktop workstation running Ubuntu 16.04 Linux with an Intel Core i5 (3.5GHz), 16GB RAM, and a NVidia Geforce GTX 680 4GB GF580 GTX-1.5GB GPU. We use the 'gemm_fast' kernel from the automatic OpenCL kernel tuning library 'CLTune' ([Web Link]). * Note: for this kind of data sets it is usually better to work with the logarithm of the running times (see e.g. Falch and Elster, 'Machine learning-based auto-tuning for enhanced performance portability of OpenCL applications', 2015).","- Independent variables:    1-2. MWG, NWG: per-matrix 2D tiling at workgroup level: {16, 32, 64, 128} (integer)    3. KWG: inner dimension of 2D tiling at workgroup level: {16, 32} (integer)    4-5. MDIMC, NDIMC: local workgroup size: {8, 16, 32} (integer)    6-7. MDIMA, NDIMB: local memory shape: {8, 16, 32} (integer)    8. KWI: kernel loop unrolling factor: {2, 8} (integer)    9-10. VWM, VWN: per-matrix vector widths for loading and storing: {1, 2, 4, 8} (integer)    11-12. STRM, STRN: enable stride for accessing off-chip memory within a single thread: {0, 1} (categorical)    13-14. SA, SB: per-matrix manual caching of the 2D workgroup tile: {0, 1} (categorical) - Output:    15-18. Run1, Run2, Run3, Run4: performance times in milliseconds for 4 independent runs using the same parameters. They range between 13.25 and 3397.08.","A fraction of this data set was used in the following paper to compute a tensor train based predictive model and estimate the Sobol sensitivity indices of all the parameters: Rafael Ballester-Ripoll, Enrique G. Paredes, Renato Pajarola.Sobol Tensor Trains for Global Sensitivity Analysis.In arXiv Computer Science / Numerical Analysis e-prints, 2017 ([Web Link]).","If you use this data set, please cite one or both of these: - Rafael Ballester-Ripoll, Enrique G. Paredes, Renato Pajarola.Sobol Tensor Trains for Global Sensitivity Analysis.In arXiv Computer Science / Numerical Analysis e-prints, 2017 ([Web Link]). - Cedric Nugteren and Valeriu Codreanu.CLTune: A Generic Auto-Tuner for OpenCL Kernels.In: MCSoC: 9th International Symposium on Embedded Multicore/Many-core Systems-on-Chip. IEEE, 2015 ([Web Link])",
http://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival,438,Haberman's Survival Data Set,../machine-learning-databases/haberman/,Multivariate,306,Life,Integer,3,3/4/1999,Classification,No,211780,"Donor:    Tjen-Sien Lim (limt '@' stat.wisc.edu)",The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.,"   1. Age of patient at time of operation (numerical)   2. Patient's year of operation (year - 1900, numerical)   3. Number of positive axillary nodes detected (numerical)   4. Survival status (class attribute)        -- 1 = the patient survived 5 years or longer        -- 2 = the patient died within 5 year","Haberman, S. J. (1976). Generalized Residuals for Log-Linear Models, Proceedings of the 9th International Biometrics Conference, Boston, pp. 104-122. Landwehr, J. M., Pregibon, D., and Shoemaker, A. C. (1984), Graphical Models for Assessing Logistic Regression Models (with discussion), Journal of the American Statistical Association 79: 61-83.[Web Link]  Lo, W.-D. (1993). Logistic Regression Trees, PhD thesis, Department of Statistics, University of Wisconsin, Madison, WI.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",Dennis DeCoste. Anytime Query-Tuned Kernel Machines via Cholesky Factorization. SDM. 2003.  [View Context].Dennis DeCoste. Anytime Interval-Valued Outputs for Kernel Machines: Fast Support Vector Machine Classification via Distance Geometry. ICML. 2002.  [View Context].Yin Zhang and W. Nick Street. Bagging with Adaptive Costs. Management Sciences Department University of Iowa Iowa City.  [View Context].Denver Dash and Gregory F. Cooper. Model Averaging with Discrete Bayesian Network Classifiers. Decision Systems Laboratory Intelligent Systems Program University of Pittsburgh.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Badges,439,Badges Data Set,../machine-learning-databases/badges/,"Univariate, Text",294,N/A,N/A,1,9/1/1994,Classification,No,116715,"Creator:  Haym Hirsh, after an idea by Rob Schapire Donor:  Haym Hirsh (hirsh '@' cs.rutgers.edu)","Part of the problem in using an automated program to discover the unknown target function is to decide how to encode names such that the program can be used.  The data below are presented in the form of a +/- label followed by the person's name.  It is up to the learning-system user to decide how to convert this data into something usable by the system (e.g., what attributes to use if your favorite learner requires feature-vector data).",N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/News+Popularity+in+Multiple+Social+Media+Platforms,440,News Popularity in Multiple Social Media Platforms Data Set,../machine-learning-databases/00432/,"Multivariate, Time-Series, Text",93239,Computer,"Integer, Real",11,2/20/2018,Regression,N/A,56516,"Nuno MonizLIAAD - INESC Tec; Sciences College, University of PortoEmail: nmmoniz '@' inesctec.pt LuÃ­s TorgoLIAAD - INESC Tec; Sciences College, University of PortoEmail: ltorgo '@' dcc.fc.up.pt","This is a large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn. The collected data relates to a period of 8 months, between November 2015 and July 2016, accounting for about 100,000 news items on four different topics: economy, microsoft, obama and palestine. This data set is tailored for evaluative comparisons in predictive analytics tasks, although allowing for tasks in other research areas such as topic detection and tracking, sentiment analysis in short text, first story detection or news recommendation. Further details on the process of building the data set are provided in the article mentioned in the 'Relevant Papers' section. An .R file is provided to provide a simple introduction to handling the data set.","######################## VARIABLES OF NEWS DATA ######################## IDLink (numeric): Unique identifier of news itemsTitle (string): Title of the news item according to the official media sourcesHeadline (string): Headline of the news item according to the official media sourcesSource (string): Original news outlet that published the news itemTopic (string): Query topic used to obtain the items in the official media sourcesPublishDate (timestamp): Date and time of the news items' publicationSentimentTitle (numeric): Sentiment score of the text in the news items' titleSentimentHeadline (numeric): Sentiment score of the text in the news items' headlineFacebook (numeric): Final value of the news items' popularity according to the social media source FacebookGooglePlus (numeric): Final value of the news items' popularity according to the social media source Google+LinkedIn (numeric): Final value of the news items' popularity according to the social media source LinkedIn ################################## VARIABLES OF SOCIAL FEEDBACK DATA ################################## IDLink (numeric): Unique identifier of news itemsTS1 (numeric): Level of popularity in time slice 1 (0-20 minutes upon publication)TS2 (numeric): Level of popularity in time slice 2 (20-40 minutes upon publication)TS... (numeric): Level of popularity in time slice ...TS144 (numeric): Final level of popularity after 2 days upon publication","Nuno Moniz and LuÃ­s Torgo (2018), â€œMulti-Source Social Feedback of Online News Feedsâ€, CoRR, [Web Link]","When using this data set, please cite the following article. Nuno Moniz and LuÃ­s Torgo (2018), â€œMulti-Source Social Feedback of Online News Feedsâ€, CoRR, [Web Link]  @Article{Moniz2018,   title = {Multi-Source Social Feedback of Online News Feeds},   author = {Nuno Moniz and Luâ€™is Torgo},   year = {2018},   ee = {[Web Link]},   volume = {[Web Link]},   journal = {CoRR},}",
http://archive.ics.uci.edu/ml/datasets/FMA%3A+A+Dataset+For+Music+Analysis,441,FMA: A Dataset For Music Analysis Data Set,../machine-learning-databases/00386/,"Multivariate, Time-Series",106574,Computer,Real,518,5/24/2017,"Classification, Clustering",N/A,84832,"Michaël Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.","* Audio track (encoded as mp3) of each of the 106,574 tracks. It is on average 10 millions samples per track.* Nine audio features (consisting of 518 attributes) for each of the 106,574 tracks.* Given the metadata, multiple problems can be explored: recommendation, genre recognition, artist identification, year prediction, music annotation, unsupervized categorization.* The dataset is split into four sizes: small, medium, large, full.* Please see the paper and the GitHub repository for more information ([Web Link])","Nine audio features computed across time and summarized with seven statistics (mean, standard deviation, skew, kurtosis, median, minimum, maximum):1. Chroma, 84 attributes2. Tonnetz, 42 attributes3. Mel Frequency Cepstral Coefficient (MFCC), 140 attributes4. Spectral centroid, 7 attributes5. Spectral bandwidth, 7 attributes6. Spectral contrast, 49 attributes7. Spectral rolloff, 7 attributes8. Root Mean Square energy, 7 attributes9. Zero-crossing rate, 7 attributes",N/A,"Michaël Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson. FMA: A Dataset For Music Analysis. [Web Link], 2017.",
http://archive.ics.uci.edu/ml/datasets/BlogFeedback,442,BlogFeedback Data Set,../machine-learning-databases/00304/,Multivariate,60021,Social,"Integer, Real",281,5/29/2014,Regression,N/A,96744,"Krisztian BuzaBudapest University of Technology and Economicsbuza '@' cs.bme.hu http://www.cs.bme.hu/~buza","This data originates from blog posts. The raw HTML-documents of the blog posts were crawled and processed. The prediction task associated with the data is the prediction of the number of comments in the upcoming 24 hours. In order to simulate this situation, we choose a basetime (in the past) and select the blog posts that were published at most72 hours before the selected base date/time. Then, we calculateall the features of the selected blog posts from the information that was available at the basetime, therefore each instance corresponds to a blog post. The target is the number of comments that the blog post received in the next 24 hours relative to the basetime.  In the train data, the basetimes were in the years 2010 and 2011. In the test data the basetimes were in February and March 2012. This simulates the real-world situtation in which training data from the past is available to predict events in the future. The train data was generated from different basetimes that may temporally overlap. Therefore, if you simply split the train into disjoint partitions, the underlying time intervals may overlap. Therefore, the you should use the provided, temporally disjoint train and test splits in order to ensure that theevaluation is fair. ","1...50:       Average, standard deviation, min, max and median of the       Attributes 51...60 for the source of the current blog post      With source we mean the blog on which the post appeared.       For example, myblog.blog.org would be the source of       the post myblog.blog.org/post_2010_09_10 51:   Total number of comments before basetime52:   Number of comments in the last 24 hours before the       basetime53:   Let T1 denote the datetime 48 hours before basetime,      Let T2 denote the datetime 24 hours before basetime.      This attribute is the number of comments in the time period       between T1 and T254:   Number of comments in the first 24 hours after the       publication of the blog post, but before basetime55:   The difference of Attribute 52 and Attribute 5356...60:       The same features as the attributes 51...55, but        features 56...60 refer to the number of links (trackbacks),       while features 51...55 refer to the number of comments.61:   The length of time between the publication of the blog post       and basetime62:   The length of the blog post63...262:       The 200 bag of words features for 200 frequent words of the       text of the blog post263...269: binary indicator features (0 or 1) for the weekday      (Monday...Sunday) of the basetime270...276: binary indicator features (0 or 1) for the weekday      (Monday...Sunday) of the date of publication of the blog      post277:  Number of parent pages: we consider a blog post P as a      parent of blog post B, if B is a reply (trackback) to       blog post P.278...280:        Minimum, maximum, average number of comments that the       parents received281:  The target: the number of comments in the next 24 hours      (relative to basetime)","Buza, K. (2014). Feedback Prediction for Blogs. In Data Analysis, Machine Learning and Knowledge Discovery (pp. 145-152). Springer International Publishing.","Buza, K. (2014). Feedback Prediction for Blogs. In Data Analysis, Machine Learning and Knowledge Discovery (pp. 145-152). Springer International Publishing.",
http://archive.ics.uci.edu/ml/datasets/AAAI+2013+Accepted+Papers,443,AAAI 2013 Accepted Papers Data Set,../machine-learning-databases/00314/,Multivariate,150,Computer,N/A,5,7/30/2014,Clustering,N/A,56703,"Carla Brodleyc.brodley '@' neu.edu Dean of the College of Computer and Information ScienceNortheastern University",CSV format where each row is a paper and each column is an attribute.,"Title: Free text; title of the paperKeywords: Free text; author-generated keywordsTopics: Categorical; author-selected, low-level keywords from conference-provided listHigh-level keywords: Categorical; author-selected, high-level keywords from conference-provided list","Discovering Better AAAI Keywords via Clustering with Community-sourced ConstraintsKelly H. Moran, Byron C. Wallace and Carla E. BrodleyAAAI Conference on Artificial Intelligence (AAAI), 2014","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Online+News+Popularity,444,Online News Popularity Data Set,../machine-learning-databases/00332/,Multivariate,39797,Business,"Integer, Real",61,5/31/2015,"Classification, Regression",N/A,294019,"Kelwin Fernandes (kafc â€˜@â€™ inesctec.pt, kelwinfc â€™@â€™ gmail.com) - INESC TEC, Porto, Portugal/Universidade do Porto, Portugal.Pedro Vinagre (pedro.vinagre.sousa â€™@â€™ gmail.com) - ALGORITMI Research Centre, Universidade do Minho, PortugalPaulo Cortez - ALGORITMI Research Centre, Universidade do Minho, PortugalPedro Sernadela - Universidade de Aveiro","* The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.* Acquisition date: January 8, 2015* The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method.  See their article for more details on how the relative performance values were set.","Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field) Attribute Information:     0. url:                           URL of the article (non-predictive)     1. timedelta:                     Days between the article publication and the dataset acquisition (non-predictive)     2. n_tokens_title:                Number of words in the title     3. n_tokens_content:              Number of words in the content     4. n_unique_tokens:               Rate of unique words in the content     5. n_non_stop_words:              Rate of non-stop words in the content     6. n_non_stop_unique_tokens:      Rate of unique non-stop words in the content     7. num_hrefs:                     Number of links     8. num_self_hrefs:                Number of links to other articles published by Mashable     9. num_imgs:                      Number of images    10. num_videos:                    Number of videos    11. average_token_length:          Average length of the words in the content    12. num_keywords:                  Number of keywords in the metadata    13. data_channel_is_lifestyle:     Is data channel 'Lifestyle'?    14. data_channel_is_entertainment: Is data channel 'Entertainment'?    15. data_channel_is_bus:           Is data channel 'Business'?    16. data_channel_is_socmed:        Is data channel 'Social Media'?    17. data_channel_is_tech:          Is data channel 'Tech'?    18. data_channel_is_world:         Is data channel 'World'?    19. kw_min_min:                    Worst keyword (min. shares)    20. kw_max_min:                    Worst keyword (max. shares)    21. kw_avg_min:                    Worst keyword (avg. shares)    22. kw_min_max:                    Best keyword (min. shares)    23. kw_max_max:                    Best keyword (max. shares)    24. kw_avg_max:                    Best keyword (avg. shares)    25. kw_min_avg:                    Avg. keyword (min. shares)    26. kw_max_avg:                    Avg. keyword (max. shares)    27. kw_avg_avg:                    Avg. keyword (avg. shares)    28. self_reference_min_shares:     Min. shares of referenced articles in Mashable    29. self_reference_max_shares:     Max. shares of referenced articles in Mashable    30. self_reference_avg_sharess:    Avg. shares of referenced articles in Mashable    31. weekday_is_monday:             Was the article published on a Monday?    32. weekday_is_tuesday:            Was the article published on a Tuesday?    33. weekday_is_wednesday:          Was the article published on a Wednesday?    34. weekday_is_thursday:           Was the article published on a Thursday?    35. weekday_is_friday:             Was the article published on a Friday?    36. weekday_is_saturday:           Was the article published on a Saturday?    37. weekday_is_sunday:             Was the article published on a Sunday?    38. is_weekend:                    Was the article published on the weekend?    39. LDA_00:                        Closeness to LDA topic 0    40. LDA_01:                        Closeness to LDA topic 1    41. LDA_02:                        Closeness to LDA topic 2    42. LDA_03:                        Closeness to LDA topic 3    43. LDA_04:                        Closeness to LDA topic 4    44. global_subjectivity:           Text subjectivity    45. global_sentiment_polarity:     Text sentiment polarity    46. global_rate_positive_words:    Rate of positive words in the content    47. global_rate_negative_words:    Rate of negative words in the content    48. rate_positive_words:           Rate of positive words among non-neutral tokens    49. rate_negative_words:           Rate of negative words among non-neutral tokens    50. avg_positive_polarity:         Avg. polarity of positive words    51. min_positive_polarity:         Min. polarity of positive words    52. max_positive_polarity:         Max. polarity of positive words    53. avg_negative_polarity:         Avg. polarity of negative  words    54. min_negative_polarity:         Min. polarity of negative  words    55. max_negative_polarity:         Max. polarity of negative  words    56. title_subjectivity:            Title subjectivity    57. title_sentiment_polarity:      Title polarity    58. abs_title_subjectivity:        Absolute subjectivity level    59. abs_title_sentiment_polarity:  Absolute polarity level    60. shares:                        Number of shares (target)","K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence, September, Coimbra, Portugal.","K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence, September, Coimbra, Portugal.",
http://archive.ics.uci.edu/ml/datasets/Cloud,445,Cloud Data Set,../machine-learning-databases/undocumented/taylor/,Multivariate,1024,Physical,Real,10,8/3/1989,N/A,N/A,131424,"Philippe CollardCalifornia Space Institute A-021, UCSDLa Jolla, CA 92093(619)534-6369","The data sets we propose to analyse are constituted of 1024 vectors, each vector includes 10 parameters. You can think of it as a 1024*10 matrix. To produce these vectors, we proceed as follows: 1. we start with two 512*512 AVHRR images  (1 in the visible, 1 in the IR)2. each images is divided in super-pixels 16*16 and in each  super-pixel we compute a set of parameters:(a) visible: mean, max, min, mean distribution, contrast, entropy, second angular momentum(b) IR: mean, max, min The set of 10 parameters we picked to form the vectors is a compromised between various constraints. Actually we are still working on the choice of parameters for the data vectors. The data set I send you has not been normalized. The normalization of the data set is required by our classification scheme but that may not be true for yours. To normalize the data we compute the mean and standard deviation for each parameter on the entire data set then for each parameter of each vector we compute:  Norm. value = (un-norm value - mean)/SD	 where mean = mean value for this particular parameter over the data setSD   = standard deviation .....",N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy","Kristiaan Pelckmans and Jos De Brabanter and J. A. K Suykens and Bart De Moor and K. U. Leuven - ESAT. The Differogram: Non-parametric Noise Variance Estimation and its Use for Model Selection. SCDSISTA. 2004.  [View Context].Stephen D. Bay. Nearest neighbor classification from multiple feature subsets. Intell. Data Anal, 3. 1999.  [View Context].Cesar Guerra-Salcedo and Stephen Chen and Darrell Whitley and Sarah Smith. Fast and Accurate Feature Selection Using Hybrid Genetic Strategies. Department of Computer Science Colorado State University.  [View Context].C. esar and Cesar Guerra-Salcedo and Darrell Whitley. Feature Selection Mechanisms for Ensemble Creation : A Genetic Search Perspective. Department of Computer Science Colorado State University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Vowel+Recognition+-+Deterding+Data%29,446,Connectionist Bench (Vowel Recognition - Deterding Data) Data Set,../machine-learning-databases/undocumented/connectionist-bench/vowel/,N/A,528,N/A,Real,10,N/A,Classification,N/A,74183,"David Deterding  (data and non-connectionist analysis)Mahesan Niranjan (first connectionist analysis)Tony Robinson    (description, program, data, and results) - ""ajr '@' dsl.eng.cam.ac.uk""","The problem is specified by the accompanying data file, ""vowel.data"".  This consists of a three dimensional array: voweldata [speaker, vowel, input]. The speakers are indexed by integers 0-89.  (Actually, there are fifteen individual speakers, each saying each vowel six times.)  The vowels are indexed by integers 0-10.  For each utterance, there are ten floating-point input values, with array indices 0-9. The problem is to train the network as well as possible using only on data from ""speakers"" 0-47, and then to test the network on speakers 48-89, reporting the number of correct classifications in the test set. For a more detailed explanation of the problem, see the excerpt from Tony Robinson's Ph.D. thesis in the COMMENTS section.  In Robinson's opinion, connectionist problems fall into two classes, the possible and the impossible.  He is interested in the latter, by which he means problems that have no exact solution.  Thus the problem here is not to see how fast a network can be trained (although this is important), but to maximise a less than perfect performance.",N/A,"[Deterding89] D. H. Deterding, 1989, University of Cambridge, ""Speaker Normalisation for Automatic Speech Recognition"", submitted for PhD.[Web Link]  [NiranjanFallside88] M. Niranjan and F. Fallside, 1988, Cambridge University Engineering Department, ""Neural Networks and Radial Basis Functions in Classifying Static Speech Patterns"", CUED/F-[Web Link].[Web Link]  [RenalsRohwer89-ijcnn] Steve Renals and Richard Rohwer, ""Phoneme Classification Experiments Using Radial Basis Functions"", International Joint Conference on Neural Networks, Washington, 1989.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",M. Layton and M. J. F Gales. CAMBRIDGE UNIVERSITY ENGINEERING DEPARTMENT Maximum Margin Training of Generative Kernels. CUED. 2004.  [View Context].Matthew Brand. Pattern discovery via entropy minimization. MERL -- A MITSUBISHI ELECTRIC RESEARCH LABORATORY. 1998.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Corel+Image+Features,447,Corel Image Features Data Set,../machine-learning-databases/CorelFeatures-mld/,Multivariate,68040,N/A,Real,89,7/1/1999,N/A,N/A,86755,"Original Owner: Michael Ortega-BinderbergerInformation and Computer ScienceUniversity of California at IrvineIrvine, CA 92697-3425USAmiki '@' ics.uci.edu  Donor: Kriengkrai Porkaew and Sharad MehrotraInformation and Computer ScienceUniversity of California at IrvineIrvine, CA 92697-3425USA nid '@' ics.uci.edu,sharad '@' ics.uci.edu  ","The original image collection was obtained from Corel at [Web Link]. There are 68,040 photo images from various categories. Each set of features is stored in a separate file. For each file, a line corresponds to a single image. The first value in a line is is the image ID and the subsequent values are the feature vector (e.g. color histogram, etc.) of the image. The same image has the same ID in all files but the image ID is not the same as the image filename. ","From each image four sets of features were extracted:  - Color Histogram - Color Histogram Layout - Color Moments - Co-occurrence Texture  Color Histogram: 32 dimensions (8 x 4 = H x S)- HSV color space is divided into 32 subspaces (32 colors : 8 ranges of H and 4 ranges of S). - the value in each dimension in a ColorHistogram of an image is the density of each color in the entire image. - Histogram intersection (overlap area between ColorHistograms of two images) can be used to measure the similarity between two images.  Color Histogram Layout: 32 dimensions (4 x 2 x 4 = H x S x sub-images)- each image is divided into 4 sub-images (one horizontal split and one vertical split). - 4x2 Color Histogram for each sub-image is computed. - Histogram Intersection can be used to measure the similarity between two images.  Color Moments: 9 dimensions (3 x 3)- the 9 values are: (one for each of H,S, and V in HSV color space)   -- mean,   -- standard deviation, and   -- skewness. - Euclidean distance between Color Moments of two images can be used to represent the dis-similarity (distance) between two images.  Co-occurrence Texture: 16 dimensions (4 x 4)- images are converted to 16 gray-scale images. - co-ocurrence in 4 directions is computed (horizontal, vertical, and two diagonal directions). the 16 values are: (one for each direction).   -- Second Angular Moment,   -- Contrast, I  -- nverse Difference Moment, and   -- Entropy. -Euclidean distance between ColorMoments of two images can be used to measure the dis-similarity (distance) between two images. ","Michael Ortega, Yong Rui, Kaushik Chakrabarti, Kriengkrai Porkaew, Sharad Mehrotra, and Thomas S. Huang, Supporting Ranked Boolean Similarity Queries in MARS, IEEE Transaction on Knowledge and Data Engineering, Vol. 10, No. 6, Pages 905-925, December 1998. [Web Link]  Kaushik Chakrabarti, and Sharad Mehrotra, The Hybrid Tree: An Index Structure for High Dimensional Feature Spaces, 1999 IEEE International Conference on Data Engineering (ICDE), Pages 440-447, February, 1999. [Web Link]  Kriengkrai Porkaew, Kaushik Chakrabarti, and Sharad Mehrotra, Query Refinement for Multimedia Retrieval and its Evaluation Techniques in MARS, 1999 ACM International Multimedia Conference, Orlando, Florida, Oct 30 - Nov 4, 1999. [Web Link]  Kaushik Chakrabarti, Kriengkrai Porkaew, and Sharad Mehrotra, Efficient Query Refinement in Multimedia Databases, ICDE, 2000[Web Link]",This data may be used for non-commercial purposes only. ,Thomas T. Osugi and M. S. EXPLORATION-BASED ACTIVE MACHINE LEARNING. Faculty of The Graduate College at the University of Nebraska In Partial Fulfillment of Requirements.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Anonymous+Microsoft+Web+Data,448,Anonymous Microsoft Web Data Data Set,../machine-learning-databases/anonymous/,N/A,37711,Computer,Categorical,294,11/1/1998,Recommender-Systems,N/A,180504,"Creators:  Jack S. Breese, David Heckerman, Carl M. KadieMicrosoft Research, Redmond WA, 98052-6399, USAbreese '@' microsoft.com, heckerma '@' microsoft.com, carlk '@' microsoft.com  Donors: Breese:, Heckerman, & Kadie","We created the data by sampling and processing the www.microsoft.com logs. The data records the use of www.microsoft.com by 38000 anonymous, randomly-selected users. For each user, the data lists all the areas of the web site (Vroots) that user visited in a one week timeframe. Users are identified only by a sequential number, for example, User #14988, User #14989, etc. The file contains no personally identifiable information. The 294 Vroots are identified by their title (e.g. ""NetShow for PowerPoint"") and URL (e.g. ""/stream""). The data comes from one week in February, 1998.","Each attribute is an area (""vroot"") of the www.microsoft.com web site. The datasets record which Vroots each user visited in a one-week timeframe in Feburary 1998.","J. Breese, D. Heckerman., C. Kadie _Empirical Analysis of Predictive Algorithms for Collaborative Filtering_ Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Madison, WI, July, 1998. [Web Link]  Also, expanded as Microsoft Research Technical Report MSR-TR-98-12,  The papers are available on-line at: [Web Link] ","Please refer to the Machine Learning
Repository's citation policy",W. Nick Street and Yoo-Hyon Kim. A streaming ensemble algorithm (SEA) for large-scale classification. KDD. 2001.  [View Context].Dmitry Pavlov and Jianchang Mao and Byron Dom. Scaling-Up Support Vector Machines Using Boosting Algorithm. ICPR. 2000.  [View Context].Dmitry Pavlov and Darya Chudova and Padhraic Smyth. Towards scalable support vector machines using squashing. KDD. 2000.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. Geometry in Learning. Department of Mathematical Sciences Rensselaer Polytechnic Institute.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Geo-Magnetic+field+and+WLAN+dataset+for+indoor+localisation+from+wristband+and+smartphone,449,Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone Data Set,../machine-learning-databases/00377/,"Multivariate, Sequential, Time-Series",153540,Computer,"Integer, Real",25,1/10/2017,"Classification, Regression, Clustering",N/A,31865,"Paolo Barsocchi, Antonino Crivello, Davide La Rosa, Filippo Palumbo Italian National Council of Research, ISTI-CNR, Pisa, Italy {name.surname}@isti.cnr.it ","Indoor localisation is a key topic for the Ambient Intelligence (AmI) research community.  In this scenarios, recent advancements in wearable technologies, particularly smartwatches with built-in sensors, and personal devices, such as smartphones, are being seen as the breakthrough for making concrete the envisioned Smart Environment (SE) paradigm.  In particular, scenarios devoted to indoor localization represent a key challenge to be addressed. Many works try to solve the indoor localization issue, but the lack of a common dataset or frameworks to compare and evaluate solutions represent a big barrier to be overcome in the ï¬eld. The unavailability and uncertainty of public datasets hinders the  possibility to compare different indoor localization algorithms. This constitutes the main motivation of the proposed dataset described herein.  We collected Wi-Fi and geo-magnetic ï¬eld ï¬ngerprints, together with inertial sensor data during two campaigns performed in the same environment. Retrieving syncronized data from a smartwatch and a smartphone worn by users at the purpose of create and present a public available dataset is the goal of this work. ","Pointsmapping.ods: 	A three column spreadsheet (ID,X,Y) which points mapping in local coordinates. 	Each ID represents an unique place on the map. The X-Y coordinates represents the local coordinates. For each measure: measure1(2)_timestamp_id.csv: 	Timestamp (Unixtime) of arrival on placeID, timestamp (Unixtime) of departure by placeID, Place ID identifier (0-324) measure1(2)_smartphone_sens.csv:	 	According to measure1(2)_timestamp_id.csv, this csv contains the data sensors retrieved by the smartphone. 	Timestamp, AccelerationX, AccelerationY, AccelerationZ, MagneticFieldX, MagneticFieldY, MagneticFieldZ, Z-AxisAgle(Azimuth), X-AxisAngle(Pitch), Y-AxisAngle(Roll), GyroX, GyroY, GyroZ measure1(2)_smartwatch_sens.csv: 	According to measure1(2)_timestamp_id.csv, this csv contains the data sensors retrieved by the smartwatch. 	Timestamp, AccelerationX, AccelerationY, AccelerationZ, MagneticFieldX, MagneticFieldY, MagneticFieldZ, Z-AxisAgle(Azimuth), X-AxisAngle(Pitch), Y-AxisAngle(Roll), GyroX, GyroY, GyroZ measure1(2)_smartphone_wifi.csv: 	Each rows contains PlaceId (ascending order) and 127 column, with RSSI level for each different	WAPs retrieved during the campaign. Not all the WAPs are detected in each scan.	For these WAPs, the articial RSSI value is -100 (dbm).","Barsocchi, P., Crivello, A., La Rosa, D., & Palumbo, F. (2016, October). A multisource and multivariate dataset for indoor localization methods based on WLAN and geo-magnetic field fingerprinting. In Indoor Positioning and Indoor Navigation (IPIN), 2016 International Conference on (pp. 1-8). IEEE.","Barsocchi, P., Crivello, A., La Rosa, D., & Palumbo, F. (2016, October). A multisource and multivariate dataset for indoor localization methods based on WLAN and geo-magnetic field fingerprinting. In Indoor Positioning and Indoor Navigation (IPIN), 2016 International Conference on (pp. 1-8). IEEE.",
http://archive.ics.uci.edu/ml/datasets/Labor+Relations,450,Labor Relations Data Set,../machine-learning-databases/labor-negotiations/,Multivariate,57,Social,"Categorical, Integer, Real",16,11/1/1988,N/A,No,78116,"Creators:  Collective Barganing Review, montly publication,Labour Canada, Industrial Relations Information Service,Ottawa, Ontario, K1A 0J2, Canada, (819) 997-3117 The data includes all collective agreements reached in the business and personal services sector for locals with at least 500 members (teachers, nurses, university staff, police, etc) in Canada in 87 and first quarter of 88.    Donor:  Stan Matwin, Computer Science DeptUniversity of Ottawa,34 Somerset East, K1N 9B4, (stan '@' uotcsi2.bitnet)",Data was used to test 2 tier approach with learning from positive and negative examples,"   1.  dur: duration of agreement        [1..7]   2   wage1.wage : wage increase in first year of contract        [2.0 .. 7.0]   3   wage2.wage : wage increase in second year of contract       [2.0 .. 7.0]   4   wage3.wage : wage increase in third year of contract       [2.0 .. 7.0]   5   cola : cost of living allowance        [none, tcf, tc]   6   hours.hrs : number of working hours during week       [35 .. 40]   7   pension : employer contributions to pension plan       [none, ret_allw, empl_contr]   8   stby_pay : standby pay       [2 .. 25]   9   shift_diff : shift differencial : supplement for work on II and III shift       [1 .. 25]  10   educ_allw.boolean : education allowance        [true false]  11   holidays : number of statutory holidays        [9 .. 15]  12   vacation : number of paid vacation days       [ba, avg, gnr]  13   lngtrm_disabil.boolean : employer's help during employee longterm disability         [true , false]  14   dntl_ins : employers contribution towards the dental plan       [none, half, full]  15   bereavement.boolean : employer's financial contribution towards the covering the costs of bereavement       [true , false]  16   empl_hplan : employer's contribution towards the health plan       [none, half, full]","Bergadano, F., Matwin, S., Michalski, R., Zhang, J., Measuring Quality of Concept Descriptions, Procs. of the 3rd European Working Sessions on Learning, Glasgow, October 1988.[Web Link]  Bergadano, F., Matwin, S., Michalski, R., Zhang, J.,Representing and Acquiring Imprecise and Context-dependent Concepts in Knowledge-based Systems, Procs. of ISMIS'88, North Holland, 1988.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Rudy Setiono. Feedforward Neural Network Construction Using Cross Validation. Neural Computation, 13. 2001.  [View Context].Gary M. Weiss and Haym Hirsh. A Quantitative Study of Small Disjuncts: Experiments and Results. Department of Computer Science Rutgers University. 2000.  [View Context].Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. An Implementation of Logical Analysis of Data. IEEE Trans. Knowl. Data Eng, 12. 2000.  [View Context].Lorne Mason and Jonathan Baxter and Peter L. Bartlett and Marcus Frean. Boosting Algorithms as Gradient Descent. NIPS. 1999.  [View Context].Richard Maclin. Boosting Classifiers Regionally. AAAI/IAAI. 1998.  [View Context].Huan Liu and Rudy Setiono. A Probabilistic Approach to Feature Selection - A Filter Solution. ICML. 1996.  [View Context].Oya Ekin and Peter L. Hammer and Alexander Kogan and Pawel Winter. Distance-Based Classification Methods. e p o r t RUTCOR ffl Rutgers Center for Operations Research ffl Rutgers University. 1996.  [View Context].George H. John and Ron Kohavi and Karl Pfleger. Irrelevant Features and the Subset Selection Problem. ICML. 1994.  [View Context].Ron Kohavi and George H. John. Automatic Parameter Selection by Minimizing Estimated Error. Computer Science Dept. Stanford University.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].YongSeog Kim and W. Nick Street and Filippo Menczer. Optimal Ensemble Construction via Meta-Evolutionary Ensembles. Business Information Systems, Utah State University.  [View Context].Ida G. Sprinkhuizen-Kuyper and Elena Smirnova and I. Nalbantis. Reliability yields Information Gain. IKAT, Universiteit Maastricht.  [View Context].Chris Drummond and Robert C. Holte. C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling. Institute for Information Technology, National Research Council Canada.  [View Context].Huan Liu and Rudy Setiono. To appear in Proceedings of IEA-AIE96 FEATURE SELECTION AND CLASSIFICATION -- A PROBABILISTIC WRAPPER APPROACH. Department of Information Systems and Computer Science National University of Singapore.  [View Context].John G. Cleary and Leonard E. Trigg. Experiences with OB1, An Optimal Bayes Decision Tree Learner. Department of Computer Science University of Waikato.  [View Context].Alexander K. Seewald. Meta-Learning for Stacked Classification. Austrian Research Institute for Artificial Intelligence.  [View Context].Karthik Ramakrishnan. UNIVERSITY OF MINNESOTA.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Druglib.com%29,451,Drug Review Dataset (Druglib.com) Data Set,../machine-learning-databases/00461/,"Multivariate, Text",4143,N/A,Integer,8,10/2/2018,"Classification, Regression, Clustering",N/A,49706,"Surya KallumadiKansas State UniversityManhattan, Kansas, USAsurya '@' ksu.edu  Felix GräßerInstitut für Biomedizinische TechnikTechnische Universität DresdenDresden, Germanyfelix.graesser '@' tu-dresden.de","The dataset provides patient reviews on specific drugs along with related conditions. Furthermore, reviews are grouped into reports on the three aspects benefits, side effects and overall comment. Additionally, ratings are available concerning overall satisfaction as well as a 5 step side effect rating and a 5 step effectiveness rating. The data was obtained by crawling online pharmaceutical review sites. The intention was to study  (1) sentiment analysis of drug experience over multiple facets, i.e. sentiments learned on specific aspects such as effectiveness and side effects,(2) the transferability of models among domains, i.e. conditions, and (3) the transferability of models among different data sources (see 'Drug Review Dataset (Drugs.com)'). The data is split into a train (75%) a test (25%) partition (see publication) and stored in two .tsv (tab-separated-values) files, respectively. Important notes: When using this dataset, you agree that you1) only use the data for research purposes2) don't use the data for any commerical purposes3) don't distribute the data to anyone else4) cite us","1. urlDrugName (categorical): name of drug2. condition (categorical): name of condition3. benefitsReview (text): patient on benefits4. sideEffectsReview (text): patient on side effects5. commentsReview (text): overall patient comment6. rating (numerical): 10 star patient rating7. sideEffects (categorical): 5 step side effect rating8. effectiveness (categorical): 5 step effectiveness rating","Felix Gräßer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018. Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-Domain and Cross-Data Learning. In Proceedings of the 2018 International Conference on Digital Health (DH '18). ACM, New York, NY, USA, 121-125. DOI: [Web Link] ","Felix Gräßer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018. Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-Domain and Cross-Data Learning. In Proceedings of the 2018 International Conference on Digital Health (DH '18). ACM, New York, NY, USA, 121-125. DOI: [Web Link] ",
http://archive.ics.uci.edu/ml/datasets/Student+Loan+Relational,452,Student Loan Relational Data Set,../machine-learning-databases/student-loan/,Domain-Theory,1000,Social,N/A,N/A,1/1/1993,N/A,N/A,67873,"Donor:  Michael J. Pazzani University of California, IrvineIrvine, CA USA",The predicate no_payment_due/1 is true for those people who are not required to repay a student loan.  Auxiliary relations can be used to fully discriminate positive from negative instances of no_payment_due/1.  Closed world assumption applies to all auxiliary relations.,N/A,"Pazzani, M., & Brunk, C. (1991). Detecting and correcting errors in rule-based expert systems: an integration of empirical and explanation-based learning. Knowledge Acquisition, 3, 157-173.[Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+%28AReM%29,453,Activity Recognition system based on Multisensor data fusion (AReM) Data Set,../machine-learning-databases/00366/,"Multivariate, Sequential, Time-Series",42240,Computer,Real,6,5/18/2016,Classification,N/A,62222,"Filippo Palumbo (a,b), Claudio Gallicchio (b), Rita Pucci (b) and Alessio Micheli (b) (a) Institute of Information Science and Technologies â€œAlessandro Faedoâ€, National Research Council, Pisa, Italy(b) Department of Computer Science, University of Pisa, Pisa, Italy","This dataset represents a real-life benchmark in the area of Activity Recognition applications, as described in [1].  The classification tasks consist in predicting the activity performed by the user from time-series generated by a Wireless Sensor Network (WSN), according to the EvAAL competition technical annex ([Web Link]).  In our activity recognition system we use information coming the implicit alteration of the wireless channel due to the movements of the user. The devices measure the RSS of the beacon packets they exchange among themselves in the WSN [2]. We collect RSS data using IRIS nodes embedding a Chipcon AT86RF230 radio subsystem that implements the IEEE 802.15.4 standard and programmed with a TinyOS firmware. They are placed on the userâ€™s chest and ankles. For the purpose of communications, the beacon packets are exchanged by using a simple virtual token protocol that completes its execution in a time slot of 50 milliseconds. A modified version of the Spin ([Web Link]) token-passing protocol is used to schedule node transmission, in order to prevent packet collisions and maintain high data collection rate. When an anchor is transmitting, all other anchors receive the packet and perform the RSS measurements. The payload of the transmitting packet is the set of RSS values between the transmitting node and the other sensors sampled during the previous cycle. From the raw data we extract time-domain features to compress the time series and slightly remove noise and correlations. We choose an epoch time of 250 milliseconds according to the EVAAL technical annex. In such a time slot we elaborate 5 samples of RSS (sampled at 20 Hz) for each of the three couples of WSN nodes (i.e. Chest-Right Ankle, Chest-Left Ankle, Right Ankle-Left Ankle). The features include the mean value and standard deviation for each reciprocal RSS reading from worn WSN sensors. For each activity 15 temporal sequences of input RSS data are present. The dataset contains 480 sequences, for a total number of 42240 instances. We also consider two kind of bending activity, illustrated in the figure provided (bendingTupe.pdf). The positions of sensor nodes with the related identifiers are shown in figure sensorsPlacement.pdf.","For each sequence, data is provided in comma separated value (csv) format.  - Input data:Input RSS streams are provided in files named datasetID.csv, where ID is the progressive numeric sequence ID for each repetition of the activity performed. In each file, each row corresponds to a time step measurement (in temporal order) and contains the following information:    avg_rss12, var_rss12, avg_rss13, var_rss13, avg_rss23, var_rss23where avg and var are the mean and variance values over 250 ms of data, respectively. - Target data:Target data is provided as the containing folder name. For each activity, we have the following parameters:# Frequency (Hz): 20# Clock (millisecond): 250# Total duration (seconds): 120","[1] F. Palumbo, C. Gallicchio, R. Pucci and A. Micheli, Human activity recognition using multisensor data fusion based on Reservoir Computing, Journal of Ambient Intelligence and Smart Environments, 2016, 8 (2), pp. 87-107.[2] F. Palumbo, P. Barsocchi, C. Gallicchio, S. Chessa and A. Micheli, Multisensor data fusion for activity recognition based on reservoir computing, in: Evaluating AAL Systems Through Competitive Benchmarking, Communications in Computer and Information Science, Vol. 386, Springer, Berlin, Heidelberg, 2013, pp. 24â€“35.","F. Palumbo, C. Gallicchio, R. Pucci and A. Micheli, Human activity recognition using multisensor data fusion based on Reservoir Computing, Journal of Ambient Intelligence and Smart Environments, 2016, 8 (2), pp. 87-107.",
http://archive.ics.uci.edu/ml/datasets/Online+Video+Characteristics+and+Transcoding+Time+Dataset,454,Online Video Characteristics and Transcoding Time Dataset Data Set,../machine-learning-databases/00335/,Multivariate,168286,Computer,"Integer, Real",11,5/19/2015,Regression,N/A,43002,"Tewodros Deneke, tdeneke '@' abo.fi ","The presented dataset is composed of two tsv files named 'youtube_videos.tsv' and 'transcoding_mesurment.tsv'. The first contains 10 columns of fundamental video characteristics for 1.6 million youtube videos; It contains YouTube video id, duration, bitrate(total in Kbits), bitrate(video bitrate in Kbits), height(in pixle), width(in pixles), framrate, estimated framerate, codec, category, and direct video link. This dataset can be used to gain insightin characteristics of consumer videos found on UGC(Youtube). The second file of our dataset contains 20 columns(see column names for names) which include input and output video characteristics along with their transcoding time and memory resource requirements while transcoding videos to diffrent but valid formats. The second dataset was collected based on experiments on an Intel i7-3720QM CPU through randomly picking two rows from the first dataset and using these as input and output parameters of a video transcoding application, ffmpeg 4 . In section 6 we will use the second dataset to build a transcoding time predictionmodel and show the significance of our datasets.","id  = Youtube videp id     duration = duration of video        bitrate bitrate(video) = video bitrate  height = height of video in pixles  width  = width of video in pixlesframe rate = actual video frame rate      frame rate(est.) =  estimated video frame rate       codec = coding standard used for the video   category = YouTube video category        url = direct link to video (has expiration date)i = number of i frames in the video    p = number of p frames in the video    b = number of b frames in the videoframes = number of frames in videoi_size = total size in byte of i videos         p_size = total size in byte of p videos        b_size = total size in byte of b videos        size = total size of video  o_codec = output codec used for transcodingo_bitrate = output bitrate used for transcoding      o_framerate = output framerate used for transcodingo_width = output width in pixel used for transcodingo_height = output height used in pixel for transcodingumem = total codec allocated memory for transcoding   utime = total transcoding time for transcoding","@INPROCEEDINGS{6890256, author={Deneke, T. and Haile, H. and Lafond, S. and Lilius, J.}, booktitle={Multimedia and Expo (ICME), 2014 IEEE International Conference on}, title={Video transcoding time prediction for proactive load balancing}, year={2014}, month={July}, pages={1-6}, keywords={prediction theory;resource allocation;transcoding;video coding;video streaming;input video stream;proactive load balancing;video transcoding time prediction;Bit rate;Codecs;Load management;Load modeling;Predictive models;Transcoding;YouTube;Load Balancing;Machine Learning;Prediction;Transcoding}, doi={10.1109/ICME.2014.6890256},}","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones,455,Human Activity Recognition Using Smartphones Data Set,../machine-learning-databases/00240/,"Multivariate, Time-Series",10299,Computer,N/A,561,12/10/2012,"Classification, Clustering",N/A,1010043,"Jorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2)1 - Smartlab - Non-Linear Complex Systems LaboratoryDITEN - Università  degli Studi di Genova, Genoa (I-16145), Italy. 2 - CETpD - Technical Research Centre for Dependency Care and Autonomous LivingUniversitat Politècnica de Catalunya (BarcelonaTech). Vilanova i la Geltrú (08800), Spainactivityrecognition '@' smartlab.ws ","The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.Check the README.txt file for further details about this dataset. A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: [Web Link]An updated version of this dataset can be found at [Web Link]. It includes labels of postural transitions between activities and also the full raw inertial signals instead of the ones pre-processed into windows. ","For each record in the dataset it is provided:- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.- Triaxial Angular velocity from the gyroscope. - A 561-feature vector with time and frequency domain variables. - Its activity label. - An identifier of the subject who carried out the experiment. ","Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012  Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge L. Reyes-Ortiz.  Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic. Journal of Universal Computer Science. Special Issue in Ambient Assisted Living: Home Care.   Volume 19, Issue 9. May 2013Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 4th International Workshop of Ambient Assited Living, IWAAL 2012, Vitoria-Gasteiz, Spain, December 3-5, 2012. Proceedings. Lecture Notes in Computer Science 2012, pp 216-223. Jorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra-Llanas, Davide Anguita, Joan Cabestany, Andreu Català. Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.  ","Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013. ",
http://archive.ics.uci.edu/ml/datasets/Autistic+Spectrum+Disorder+Screening+Data+for+Children++,456,Autistic Spectrum Disorder Screening Data for Children   Data Set,../machine-learning-databases/00419/,Multivariate,292,Life,Integer,21,12/24/2017,Classification,Yes,43408,"Fadi Fayez ThabtahDepartment of Digital TechnologyManukau Institute of Technology,Auckland, New Zealandfadi.fayez '@' manukau.ac.nz ",see attached file for variables' description ,see attached file for variables' description ,"1) Tabtah, F. (2017). Autism Spectrum Disorder Screening: Machine Learning Adaptation and DSM-5 Fulfillment. Proceedings of the 1st International Conference on Medical and Health Informatics 2017, pp.1-6. Taichung City, Taiwan, ACM.2) Thabtah, F. (2017). ASDTests. A mobile app for ASD screening. www.asdtests.com [accessed December  20th, 2017].3) Thabtah, F. (2017). Machine Learning in Autistic Spectrum Disorder Behavioural Research: A Review. To Appear in Informatics for Health and Social Care Journal. December, 2017 (in press)","If you have no special citation requests, please leave this field blank.",
http://archive.ics.uci.edu/ml/datasets/IPUMS+Census+Database,457,IPUMS Census Database Data Set,../machine-learning-databases/ipums-mld/,Multivariate,256932,Social,"Categorical, Integer",61,11/9/1999,N/A,N/A,41282,"Original Owner: IPUMSHistorical Census ProjectsUniversity of Minnesota614 Social Sciences267 19th Avenue SouthMinneapolis, MN 55455ipums '@' hist.umn.edu http://www.ipums.umn.edu/  Donor: Stephen BayDepartment of Information and Computer Science,University of California, IrvineIrvine, CA 92697sbay '@' ics.uci.edu ","The original source for this data set is the IPUMS project (RugglesSobek, 1997). The IPUMS project is a large collection of federal census data which has standardized coding schemes to make comparisons across time easy. The data is an unweighted 1 in 100 sample of responses from the Los Angeles -- Long Beach area for the years 1970, 1980, and 1990. The household and individual records were flattened into a single table and we used all variables that were available for all three years. When there was more than one version of a variable, such as for race, we used the most general. For occupation and industry we used the 1950 basis. Note that PUMS data is based on cluster samples, i.e. samples are made of households or dwellings from which there may be multiple individuals. Individuals from the same household are no longer independent. Ruggles (1995) considers this issue further and discusses its effect (along with the effects of stratification) on standard errors. The variable schltype appears to have different coding values across the years 1970, 1980, and 1990. There are two versions of this data set: 1. The Small Data Set The small data set contains a 1 in 1000 sample of the Los Angeles and Long Beach area. It was formed by sampling from the large data set. 2. The Large Data Set The large data set contains a 1 in 100 sample of the Los Angeles and Long Beach area.",Please see ipums.la.names,"S. Ruggles. (1995). ""Sample Designs and Sampling Errors"". Historical Methods. Volume 28. Number 1. Pages 40 - 46.[Web Link]","Reproduced here is the original IPUMS citation and use documentation: All persons are granted a limited license to use and distribute this documentation and the accompanying data, subject to the following conditions:      * No fee may be charged for use or distribution.    * Publications and research reports based on the database must cite it appropriately. The citation should include the following:       Steven Ruggles and Matthew Sobek et. al.       Integrated Public Use Microdata Series: Version 2.0      Minneapolis: Historical Census Projects,       University of Minnesota, 1997       If possible, citations should also include the URL for the IPUMS site: [Web Link]. In addition, we request that users send us a copy of any publications, research reports, or educational material making use of the data or documentation. Printed matter should be sent to:  IPUMS Historical Census Projects University of Minnesota 614 Social Sciences 267 19th Avenue South Minneapolis, MN 55455Send all electronic material to ipums '@' hist.umn.edu","Ke Wang and Shiyu Zhou and Ada Wai-Chee Fu and Jeffrey Xu Yu. Mining Changes of Classification by Correspondence Tracing. SDM. 2003.  [View Context].Stephen D. Bay and Michael J. Pazzani. Detecting Group Differences: Mining Contrast Sets. Data Min. Knowl. Discov, 5. 2001.  [View Context].Chris Giannella and Bassem Sayrafi. An Information Theoretic Histogram for Single Dimensional Selectivity Estimation. Department of Computer Science, Indiana University Bloomington.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Gisette,458,Gisette Data Set,../machine-learning-databases/gisette/,Multivariate,13500,Computer,Integer,5000,2/29/2008,Classification,N/A,117652,"a. Original ownersThe data set was constructed from the MNIST data that is made available by Yann LeCun and Corinna Cortes at http://yann.lecun.com/exdb/mnist/. b. Donor of databaseThis version of the database was prepared for the NIPS 2003 variable and feature selection benchmark by Isabelle Guyon, 955 Creston Road, Berkeley, CA 94708, USA (isabelle '@' clopinet.com).","The digits have been size-normalized and centered in a fixed-size image of dimension 28x28. The original data were modified for the purpose of the feature selection challenge. In particular, pixels were samples at random in the middle top part of the feature containing the information necessary to disambiguate 4 from 9 and higher order features were created as products of these pixels to plunge the problem in a higher dimensional feature space. We also added a number of distractor features called 'probes' having no predictive power. The order of the features and patterns were randomized.  GISETTE -- Positive ex. -- Negative ex. -- TotalTraining set -- 3000 -- 3000 -- 6000Validation set -- 500 -- 500 -- 1000Test set -- 3250 -- 3250 -- 6500All -- 6750 -- 6750 -- 13500 Number of variables/features/attributes:Real: 2500Probes: 2500Total: 5000 This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link]. All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge. The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link]. The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a coma delimited regular matrix, patterns in lines, features in columns).dataname_valid.data: Validation set.dataname_test.data: Test set.dataname_train.labels: Labels (truth values of the classes) for training examples.dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels (withheld, so the data can still be use as a benchmark). ",We do not provide attribute information to avoid biasing the feature selection process. ,"The best challenge entrants wrote papers collected in the book:Isabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer. [Web Link]  See also:Isabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 14381444.and the associated technical report:Isabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report. [Web Link].","Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge. In: NIPS. [Web Link].",
http://archive.ics.uci.edu/ml/datasets/Iris,459,Iris Data Set,../machine-learning-databases/iris/,Multivariate,150,Life,Real,4,7/1/1988,Classification,No,3438990,"Creator:  R.A. Fisher Donor:  Michael Marshall (MARSHALL%PLU '@' io.arc.nasa.gov)","This is perhaps the best known database to be found in the pattern recognition literature.  Fisher's paper is a classic in the field and is referenced frequently to this day.  (See Duda & Hart, for example.)  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. Predicted attribute: class of iris plant. This is an exceedingly simple domain. This data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick '@' espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,""Iris-setosa"" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,""Iris-setosa"" where the errors are in the second and third features.  ","   1. sepal length in cm   2. sepal width in cm   3. petal length in cm   4. petal width in cm   5. class:       -- Iris Setosa      -- Iris Versicolour      -- Iris Virginica","Fisher,R.A. ""The use of multiple measurements in taxonomic problems"" Annual Eugenics, 7, Part II, 179-188 (1936); also in ""Contributions to Mathematical Statistics"" (John Wiley, NY, 1950).[Web Link]  Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis. (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.[Web Link]  Dasarathy, B.V. (1980) ""Nosing Around the Neighborhood: A New System Structure and Classification Rule for Recognition in Partially Exposed Environments"".  IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. PAMI-2, No. 1, 67-71.[Web Link]  Gates, G.W. (1972) ""The Reduced Nearest Neighbor Rule"".  IEEE Transactions on Information Theory, May 1972, 431-433.[Web Link]  See also: 1988 MLC Proceedings, 54-64.","Please refer to the Machine Learning
Repository's citation policy","Ping Zhong and Masao Fukushima. A Regularized Nonsmooth Newton Method for Multi-class Support Vector Machines. 2005.  [View Context].Anthony K H Tung and Xin Xu and Beng Chin Ooi. CURLER: Finding and Visualizing Nonlinear Correlated Clusters. SIGMOD Conference. 2005.  [View Context].Igor Fischer and Jan Poland. Amplifying the Block Matrix Structure for Spectral Clustering. Telecommunications Lab. 2005.  [View Context].Sotiris B. Kotsiantis and Panayiotis E. Pintelas. Logitboost of Simple Bayesian Classifier. Informatica. 2005.  [View Context].Manuel Oliveira. Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted. University of Alberta Library. 2005.  [View Context].Judith E. Devaney and Steven G. Satterfield and John G. Hagedorn and John T. Kelso and Adele P. Peskin and William George and Terence J. Griffin and Howard K. Hung and Ronald D. Kriz. Science at the Speed of Thought. Ambient Intelligence for Scientific Discovery. 2004.  [View Context].Jennifer G. Dy and Carla Brodley. Feature Selection for Unsupervised Learning. Journal of Machine Learning Research, 5. 2004.  [View Context].Jeroen Eggermont and Joost N. Kok and Walter A. Kosters. Genetic Programming for data classification: partitioning the search space. SAC. 2004.  [View Context].Remco R. Bouckaert and Eibe Frank. Evaluating the Replicability of Significance Tests for Comparing Learning Algorithms. PAKDD. 2004.  [View Context].Mikhail Bilenko and Sugato Basu and Raymond J. Mooney. Integrating constraints and metric learning in semi-supervised clustering. ICML. 2004.  [View Context].Qingping Tao Ph. D. MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004.  [View Context].Yuan Jiang and Zhi-Hua Zhou. Editing Training Data for kNN Classifiers with Neural Network Ensemble. ISNN (1). 2004.  [View Context].Sugato Basu. Semi-Supervised Clustering with Limited Background Knowledge. AAAI. 2004.  [View Context].Bob Ricks and Dan Ventura. Training a Quantum Neural Network. NIPS. 2003.  [View Context].Eibe Frank and Mark Hall. Visualizing Class Probability Estimators. PKDD. 2003.  [View Context].Ross J. Micheals and Patrick Grother and P. Jonathon Phillips. The NIST HumanID Evaluation Framework. AVBPA. 2003.  [View Context].Sugato Basu. Also Appears as Technical Report, UT-AI. PhD Proposal. 2003.  [View Context].Dick de Ridder and Olga Kouropteva and Oleg Okun and Matti Pietikäinen and Robert P W Duin. Supervised Locally Linear Embedding. ICANN. 2003.  [View Context].Aristidis Likas and Nikos A. Vlassis and Jakob J. Verbeek. The global k-means clustering algorithm. Pattern Recognition, 36. 2003.  [View Context].Zhi-Hua Zhou and Yuan Jiang and Shifu Chen. Extracting symbolic rules from trained neural network ensembles. AI Commun, 16. 2003.  [View Context].Jeremy Kubica and Andrew Moore. Probabilistic Noise Identification and Data Cleaning. ICDM. 2003.  [View Context].Julie Greensmith. New Frontiers For An Artificial Immune System. Digital Media Systems Laboratory HP Laboratories Bristol. 2003.  [View Context].Manoranjan Dash and Huan Liu and Peter Scheuermann and Kian-Lee Tan. Fast hierarchical clustering and its validation. Data Knowl. Eng, 44. 2003.  [View Context].Jun Wang and Bin Yu and Les Gasser. Concept Tree Based Clustering Visualization with Shaded Similarity Matrices. ICDM. 2002.  [View Context].Michail Vlachos and Carlotta Domeniconi and Dimitrios Gunopulos and George Kollios and Nick Koudas. Non-linear dimensionality reduction techniques for classification and visualization. KDD. 2002.  [View Context].Geoffrey Holmes and Bernhard Pfahringer and Richard Kirkby and Eibe Frank and Mark A. Hall. Multiclass Alternating Decision Trees. ECML. 2002.  [View Context].Inderjit S. Dhillon and Dharmendra S. Modha and W. Scott Spangler. Class visualization of high-dimensional data with applications. Department of Computer Sciences, University of Texas. 2002.  [View Context].Manoranjan Dash and Kiseok Choi and Peter Scheuermann and Huan Liu. Feature Selection for Clustering - A Filter Solution. ICDM. 2002.  [View Context].Ayhan Demiriz and Kristin P. Bennett and Mark J. Embrechts. A Genetic Algorithm Approach for Semi-Supervised Clustering. E-Business Department, Verizon Inc.. 2002.  [View Context].David Hershberger and Hillol Kargupta. Distributed Multivariate Regression Using Wavelet-Based Collective Data Mining. J. Parallel Distrib. Comput, 61. 2001.  [View Context].David Horn and A. Gottlieb. The Method of Quantum Clustering. NIPS. 2001.  [View Context].Wai Lam and Kin Keung and Charles X. Ling. PR 1527. Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. DeEPs: A New Instance-based Discovery and Classification System. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001.  [View Context].Carlotta Domeniconi and Jing Peng and Dimitrios Gunopulos. An Adaptive Metric Machine for Pattern Classification. NIPS. 2000.  [View Context].Asa Ben-Hur and David Horn and Hava T. Siegelmann and Vladimir Vapnik. A Support Vector Method for Clustering. NIPS. 2000.  [View Context].Neil Davey and Rod Adams and Mary J. George. The Architecture and Performance of a Stochastic Competitive Evolutionary Neural Tree Network. Appl. Intell, 12. 2000.  [View Context].Edgar Acuna and Alex Rojas. Ensembles of classifiers based on Kernel density estimators. Department of Mathematics University of Puerto Rico. 2000.  [View Context].Manoranjan Dash and Huan Liu. Feature Selection for Clustering. PAKDD. 2000.  [View Context].David M J Tax and Robert P W Duin. Support vector domain description. Pattern Recognition Letters, 20. 1999.  [View Context].Ismail Taha and Joydeep Ghosh. Symbolic Interpretation of Artificial Neural Networks. IEEE Trans. Knowl. Data Eng, 11. 1999.  [View Context].Foster J. Provost and Tom Fawcett and Ron Kohavi. The Case against Accuracy Estimation for Comparing Induction Algorithms. ICML. 1998.  [View Context].Stephen D. Bay. Combining Nearest Neighbor Classifiers Through Multiple Feature Subsets. ICML. 1998.  [View Context].Wojciech Kwedlo and Marek Kretowski. Discovery of Decision Rules from Databases: An Evolutionary Approach. PKDD. 1998.  [View Context].Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF. Appl. Intell, 7. 1997.  [View Context].. Prototype Selection for Composite Nearest Neighbor Classifiers. Department of Computer Science University of Massachusetts. 1997.  [View Context].Ke Wang and Han Chong Goh. Minimum Splits Based Discretization for Continuous Features. IJCAI (2). 1997.  [View Context].Ethem Alpaydin. Voting over Multiple Condensed Nearest Neighbors. Artif. Intell. Rev, 11. 1997.  [View Context].Daniel C. St and Ralph W. Wilkerson and Cihan H. Dagli. RULE SET QUALITY MEASURES FOR INDUCTIVE LEARNING ALGORITHMS. proceedings of the Artificial Neural Networks In Engineering Conference 1996 (ANNIE. 1996.  [View Context].Tapio Elomaa and Juho Rousu. Finding Optimal Multi-Splits for Numerical Attributes in Decision Tree Learning. ESPRIT Working Group in Neural and Computational Learning. 1996.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Ron Kohavi. A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection. IJCAI. 1995.  [View Context].Zoubin Ghahramani and Michael I. Jordan. Learning from incomplete data. MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNING DEPARTMENT OF BRAIN AND COGNITIVE SCIENCES. 1994.  [View Context].George H. John and Ron Kohavi and Karl Pfleger. Irrelevant Features and the Subset Selection Problem. ICML. 1994.  [View Context].Gabor Melli. A Lazy Model-Based Approach to On-Line Classification. University of British Columbia. 1989.  [View Context].Stefan Aeberhard and Danny Coomans and De Vel. THE PERFORMANCE OF STATISTICAL PATTERN RECOGNITION METHODS IN HIGH DIMENSIONAL SETTINGS. James Cook University.  [View Context].Michael P. Cummings and Daniel S. Myers and Marci Mangelson. Applying Permuation Tests to Tree-Based Statistical Models: Extending the R Package rpart. Center for Bioinformatics and Computational Biology, Institute for Advanced Computer Studies, University of Maryland.  [View Context].Ping Zhong and Masao Fukushima. Second Order Cone Programming Formulations for Robust Multi-class Classification.  [View Context].Wl odzisl/aw Duch and Rafal Adamczak and Norbert Jankowski. Initialization of adaptive parameters in density networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Aynur Akku and H. Altay Guvenir. Weighting Features in k Nearest Neighbor Classification on Feature Projections. Department of Computer Engineering and Information Science Bilkent University.  [View Context].Jun Wang. Classification Visualization with Shaded Similarity Matrix. Bei Yu Les Gasser Graduate School of Library and Information Science University of Illinois at Urbana-Champaign.  [View Context].Andrew Watkins and Jon Timmis and Lois C. Boggess. Artificial Immune Recognition System (AIRS): An ImmuneInspired Supervised Learning Algorithm. (abw5,jt6@kent.ac.uk) Computing Laboratory, University of Kent.  [View Context].Gaurav Marwah and Lois C. Boggess. Artificial Immune Systems for Classification : Some Issues. Department of Computer Science Mississippi State University.  [View Context].Igor Kononenko and Edvard Simec. Induction of decision trees using RELIEFF. University of Ljubljana, Faculty of electrical engineering & computer science.  [View Context].Daichi Mochihashi and Gen-ichiro Kikui and Kenji Kita. Learning Nonstructural Distance Metric by Minimum Cluster Distortions. ATR Spoken Language Translation research laboratories.  [View Context].Wl odzisl/aw Duch and Karol Grudzinski. Prototype based rules - a new way to understand the data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].H. Altay Guvenir. A Classification Learning Algorithm Robust to Irrelevant Features. Bilkent University, Department of Computer Engineering and Information Science.  [View Context].Enes Makalic and Lloyd Allison and David L. Dowe. MML INFERENCE OF SINGLE-LAYER NEURAL NETWORKS. School of Computer Science and Software Engineering Monash University.  [View Context].Ron Kohavi and Brian Frasca. Useful Feature Subsets and Rough Set Reducts. the Third International Workshop on Rough Sets and Soft Computing.  [View Context].G. Ratsch and B. Scholkopf and Alex Smola and Sebastian Mika and T. Onoda and K. -R Muller. Robust Ensemble Learning for Data Mining. GMD FIRST, Kekul#estr.  [View Context].YongSeog Kim and W. Nick Street and Filippo Menczer. Optimal Ensemble Construction via Meta-Evolutionary Ensembles. Business Information Systems, Utah State University.  [View Context].Maria Salamo and Elisabet Golobardes. Analysing Rough Sets weighting methods for Case-Based Reasoning Systems. Enginyeria i Arquitectura La Salle.  [View Context].Lawrence O. Hall and Nitesh V. Chawla and Kevin W. Bowyer. Combining Decision Trees Learned in Parallel. Department of Computer Science and Engineering, ENB 118 University of South Florida.  [View Context].Anthony Robins and Marcus Frean. Learning and generalisation in a stable network. Computer Science, The University of Otago.  [View Context].Geoffrey Holmes and Leonard E. Trigg. A Diagnostic Tool for Tree Based Supervised Classification Learning Algorithms. Department of Computer Science University of Waikato Hamilton New Zealand.  [View Context].Shlomo Dubnov and Ran El and Yaniv Technion and Yoram Gdalyahu and Elad Schneidman and Naftali Tishby and Golan Yona. Clustering By Friends : A New Nonparametric Pairwise Distance Based Clustering Algorithm. Ben Gurion University.  [View Context].Michael R. Berthold and Klaus--Peter Huber. From Radial to Rectangular Basis Functions: A new Approach for Rule Learning from Large Datasets. Institut fur Rechnerentwurf und Fehlertoleranz (Prof. D. Schmid) Universitat Karlsruhe.  [View Context].Norbert Jankowski. Survey of Neural Transfer Functions. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Karthik Ramakrishnan. UNIVERSITY OF MINNESOTA.  [View Context].Wl/odzisl/aw Duch and Rafal Adamczak and Geerd H. F Diercksen. Neural Networks from Similarity Based Perspective. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Fernando Fern#andez and Pedro Isasi. Designing Nearest Neighbour Classifiers by the Evolution of a Population of Prototypes. Universidad Carlos III de Madrid.  [View Context].Asa Ben-Hur and David Horn and Hava T. Siegelmann and Vladimir Vapnik. A Support Vector Method for Hierarchical Clustering. Faculty of IE and Management Technion.  [View Context].Lawrence O. Hall and Nitesh V. Chawla and Kevin W. Bowyer. Decision Tree Learning on Very Large Data Sets. Department of Computer Science and Engineering, ENB 118 University of South Florida.  [View Context].G. Ratsch and B. Scholkopf and Alex Smola and K. -R Muller and T. Onoda and Sebastian Mika. Arc: Ensemble Learning in the Presence of Outliers. GMD FIRST.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].H. Altay G uvenir and Aynur Akkus. WEIGHTED K NEAREST NEIGHBOR CLASSIFICATION ON FEATURE PROJECTIONS. Department of Computer Engineering and Information Science Bilkent University.  [View Context].Huan Liu. A Family of Efficient Rule Generators. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Rudy Setiono and Huan Liu. Fragmentation Problem and Automated Feature Construction. School of Computing National University of Singapore.  [View Context].Fran ois Poulet. Cooperation between automatic algorithms, interactive algorithms and visualization tools for Visual Data Mining. ESIEA Recherche.  [View Context].Takao Mohri and Hidehiko Tanaka. An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes. Information Engineering Course, Faculty of Engineering The University of Tokyo.  [View Context].Huan Li and Wenbin Chen. Supervised Local Tangent Space Alignment for Classification.  I-Fan Shen.  [View Context].Adam H. Cannon and Lenore J. Cowen and Carey E. Priebe. Approximate Distance Classification. Department of Mathematical Sciences The Johns Hopkins University.  [View Context].A. da Valls and Vicen Torra. Explaining the consensus of opinions with the vocabulary of the experts. Dept. d'Enginyeria Informtica i Matemtiques Universitat Rovira i Virgili.  [View Context].Wl/odzisl/aw Duch and Rafal Adamczak and Krzysztof Grabczewski. Extraction of crisp logical rules using constrained backpropagation networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Eric P. Kasten and Philip K. McKinley. MESO: Perceptual Memory to Support Online Learning in Adaptive Software. Proceedings of the Third International Conference on Development and Learning (ICDL.  [View Context].Karol Grudzi nski and Wl/odzisl/aw Duch. SBL-PM: A Simple Algorithm for Selection of Reference Instances in Similarity Based Methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Chih-Wei Hsu and Cheng-Ru Lin. A Comparison of Methods for Multi-class Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. A hybrid method for extraction of logical rules from data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl/odzisl/aw Duch and Rafal Adamczak and Geerd H. F Diercksen. Classification, Association and Pattern Completion using Neural Similarity Based Methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Computer+Hardware,460,Computer Hardware Data Set,../machine-learning-databases/cpu-performance/,Multivariate,209,Computer,Integer,9,10/1/1987,Regression,No,308218,"Creator:  Phillip Ein-Dor and Jacob FeldmesserEin-Dor: Faculty of Management Tel Aviv University; Ramat-Aviv; Tel Aviv, 69978; Israel Donor:  David W. Aha (aha '@' ics.uci.edu) (714) 856-8779   ",The estimated relative performance values were estimated by the authors using a linear regression method.  See their article (pp 308-313) for more details on how the relative performance values were set.,"   1. vendor name: 30       (adviser, amdahl,apollo, basf, bti, burroughs, c.r.d, cambex, cdc, dec,        dg, formation, four-phase, gould, honeywell, hp, ibm, ipl, magnuson,        microdata, nas, ncr, nixdorf, perkin-elmer, prime, siemens, sperry,        sratus, wang)   2. Model Name: many unique symbols   3. MYCT: machine cycle time in nanoseconds (integer)   4. MMIN: minimum main memory in kilobytes (integer)   5. MMAX: maximum main memory in kilobytes (integer)   6. CACH: cache memory in kilobytes (integer)   7. CHMIN: minimum channels in units (integer)   8. CHMAX: maximum channels in units (integer)   9. PRP: published relative performance (integer)  10. ERP: estimated relative performance from the original article (integer)","Ein-Dor and Feldmesser (CACM 4/87, pp 308-317) Kibler,D. & Aha,D. (1988).  Instance-Based Prediction of Real-Valued Attributes.  In Proceedings of the CSCSI (Canadian AI) Conference.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Dan Pelleg. Scalable and Practical Probability Density Estimators for Scientific Anomaly Detection. School of Computer Science Carnegie Mellon University. 2004.  [View Context].Yongge Wang. A New Approach to Fitting Linear Models in High Dimensional Spaces. Alastair Scott (Department of Statistics, University of Auckland).  [View Context]."
http://archive.ics.uci.edu/ml/datasets/PubChem+Bioassay+Data,461,PubChem Bioassay Data Data Set,../machine-learning-databases/00209/,Multivariate,N/A,Life,"Integer, Real",N/A,3/29/2011,Classification,N/A,38752,"Virtual Screening of Bioassay DataAmanda C Schierz,Smart Technology Research Centre, Bournemouth University, Talbot Campus, Poole, Dorset, BH12 5BB, UKJournal of Cheminformatics 2009, 1:21 doi:10.1186/1758-2946-1-21  ","21 bioassay datasets generated from Pubchem. Both Primary and confirmatory bioassays (12 bioassays, 21 mixes)The data is provided in the same train/test split as the original paper. The compound IDs have been provided in separate files in case people wish to generate their own molecular representation. The order of the compound Ids is the same as the data files. â€¢ AID362 details the results of a primary screening bioassay for Formylpeptide Receptor Ligand Binding University from the New Mexico Center for Molecular Discovery. It is a relatively small dataset with 4279 compounds and with a ratio of 1 active to 70 inactive compounds (1.4% minority class). The compounds were selected on the basis of preliminary virtual screening of approximately 480,000 drug-like small molecules from Chemical Diversity Laboratories. â€¢ AID456 is a primary screen assay from the Burnham Center for Chemical Genomics for inhibition of TNFa induced VCAM-1 cell surface expression and consists of 9,982 compounds with a ratio of 1 active compound to 368 inactive compounds (0.27% minority). The compounds have been selected for their known drug-like properties and 9,431 meet the Rule of 5 [19]. â€¢ AID688 is the result of a primary screen for Yeast eIF2B from the Penn Center for Molecular Discovery and contains activity information of 27,198 compounds with a ratio of 1 active compound to 108 inactive compounds (0.91% minority). The screen is a reporter-gene assay and 25,656 of the compounds have known drug-like properties. â€¢ AID604 is a primary screening bioassay for Rho kinase 2 inhibitors from the Scripps Research Institute Molecular Screening Center. The bioassay contains activity information of 59,788 compounds with a ratio of 1 active compound to 281 inactive compounds (1.4%). 57,546 of the compounds have known drug-like properties. â€¢ AID373 is a primary screen from the Scripps Research Institute Molecular Screening Center for endothelial differentiation, sphingolipid G-protein-coupled receptor, 3. 59,788 compounds were screened with a ratio of 1 active compound to 963 inactive compounds (0.1%). 57,546 of the compounds screened had known drug-like properties. â€¢ AID746 is a primary screen from the Scripps Research Institute Molecular Screening Center for Mitogen-activated protein kinase. 59,788 compounds were screened with a ratio of 1 active compound to 162 inactive compounds (0.61%). 57,546 of the compounds screened had known drug-like properties. â€¢ AID687 is the result of a primary screen for coagulation factor XI from the Penn Center for Molecular Discovery and contains activity information of 33,067 compounds with a ratio of 1 active compound to 350 inactive compounds (0.28% minority). 30,353 of the compounds screened had known drug-like properties. â€¢ AID1608 is a different type of screening assay that was used to identify compounds that prevent HttQ103-induced cell death. National Institute of Neurological Disorders and Stroke Approved Drug Program. The compounds that prevent a release of a certain chemical into the growth medium are labelled as active and the remaining compounds are labelled as having inconclusive activity. AID1608 is a small dataset with 1,033 compounds and a ratio of 1 active to 14 inconclusive compounds (6.58% minority class). â€¢ AID644 confirmatory screen of AID604 â€¢ AID1284 confirmatory screen of AID746 â€¢ AID439 confirmatory screen of AID373 â€¢ AID721 confirmatory screen of AID746 ","Each attribute has been fully described in the Open Access publication. The data is a mixture of boolean, integer and real values. Only 2 class - Active and Inactive. Highly Imbalanced.","Citations for paper: The use of classification trees for bioinformaticsXiang Chen, Minghui Wang, Heping Zhang: 6 JAN 2011DOI: 10.1002/widm.14 Consensus model for identification of novel PI3K inhibitors in large chemical library Chin Yee Liew, Xiao Hua Ma and Chun Wei YapJournal of Computer-Aided Molecular Design Volume 24, Number 2, 131-141, DOI: 10.1007/s10822-010-9321-0  Genetic Algorithm-Neural Network (GANN): a study of neural network activation functions and depth of genetic algorithm search applied to feature selection Dong Ling Tong and Robert MintramInternational Journal of Machine Learning and Cybernetics Volume 1, Numbers 1-4, 75-87, DOI: 10.1007/s13042-010-0004-x    ","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/AAAI+2014+Accepted+Papers,462,AAAI 2014 Accepted Papers Data Set,../machine-learning-databases/00307/,Multivariate,399,Computer,N/A,6,7/30/2014,Clustering,N/A,53924,"Carla Brodleyc.brodley '@' neu.edu Dean of the College of Computer and Information ScienceNortheastern University",CSV format where each row is a paper and each column an attribute.,"Title: Free text; title of the paperAuthors: Free text; author(s) of the paperGroups: Categorical; author-selected, high-level keyword(s)Keywords: Free text; author-generated keywordsTopics: Free text; author-selected, low-level keywordsAbstracts: Free text; paper abstracts","Discovering Better AAAI Keywords via Clustering with Community-sourced ConstraintsKelly H. Moran, Byron C. Wallace and Carla E. BrodleyAAAI Conference on Artificial Intelligence (AAAI), 2014","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Coil+1999+Competition+Data,463,Coil 1999 Competition Data Data Set,../machine-learning-databases/coil-mld/,Multivariate,340,Physical,"Categorical, Real",17,9/9/1999,N/A,No,50547,"Original Owner: ERUDITEuropean Network for Fuzzy Logic and Uncertainty Modelling in Information Technologyhttp://www.erudit.de/  Donor: Jens StrackeljanTechnical University ClausthalInstitute of Applied MechanicsGraupenstr. 3, 38678 Clausthal-Zellerfeld, Germanytmjs '@' itm.tu-clausthal.de  ","This data comes from a water quality study where samples were taken from sites on different European rivers of a period of approximately one year. These samples were analyzed for various chemical substances including: nitrogen in the form of nitrates, nitrites and ammonia, phosphate, pH, oxygen, chloride. In parallel, algae samples were collected to determine the algae population distributions.  The competition involved the prediction of algal frequency distributions on the basis of the measured concentrations of the chemical substances and the global information concerning the season when the sample was taken, the river size and its flow velocity. The competition instructions contain additional information on the prediction task: [Web Link]  ","There are a total of 340 examples each containing 17 values. The first 11 values of each data set are the season, the river size, the fluid velocity and 8 chemical concentrations which should be relevant for the algae population distribution. The last 8 values of each example are the distribution of different kinds of algae. These 8 kinds are only a very small part of the whole community, but for the competition we limited the number to 7. The value 0.0 means that the frequency is very low. The data set also contains some empty fields which are labeled with the string XXXXX.  The training data are saved in the file: analysis.data (ASCII format). Table 1: Structure of the file analysis.data A ... K  a ... gCC1,1  ... CC1,11  AG1,1 ... AG1,7 ... CC200,1 ... CC200,11  AG200,1 ... AG200,7   Explanation:CCi,j: Chemical concentration or river characteristicAGi,j: Algal frequency The chemical parameters are labeled as A, ..., K. The columns of the algaes are labeled as a, ..,g. ",N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Statlog+%28Landsat+Satellite%29,464,Statlog (Landsat Satellite) Data Set,../machine-learning-databases/statlog/satimage/,Multivariate,6435,Physical,Integer,36,2/13/1993,Classification,N/A,133621,"    Ashwin Srinivasan     Department of Statistics and Data Modeling     University of Strathclyde     Glasgow     Scotland     UK ross '@' uk.ac.turing  	The original Landsat data for this database was generated	from data purchased from NASA by the Australian Centre	for Remote Sensing, and used for research at:		The Centre for Remote Sensing		University of New South Wales		Kensington, PO Box 1		NSW 2033		Australia.      The sample database was generated taking a small section (82     rows and 100 columns) from the original data. The binary values     were converted to their present ASCII form by Ashwin Srinivasan.     The classification for each pixel was performed on the basis of     an actual site visit by Ms. Karen Hall, when working for Professor     John A. Richards, at the Centre for Remote Sensing at the University     of New South Wales, Australia. Conversion to 3x3 neighbourhoods and     splitting into test and training sets was done by Alistair Sutherland.","The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number. The Landsat satellite data is one of the many sources of information available for a scene. The interpretation of a scene by integrating spatial data of diverse types and resolutions including multispectral and radar data, maps indicating topography, land use etc. is expected to assume significant importance with the onset of an era characterised by integrative approaches to remote sensing (for example, NASA's Earth Observing System commencing this decade). Existing statistical methods are ill-equipped for handling such diverse data types. Note that this is not true for Landsat MSS data considered in isolation (as in this sample database). This data satisfies the important requirements of being numerical and at a single resolution, and standard maximum-likelihood classification performs very well. Consequently, for this data, it should be interesting to compare the performance of other methods against the statistical approach. One frame of Landsat MSS imagery consists of four digital images of the same scene in different spectral bands. Two of these are in the visible region (corresponding approximately to green and red regions of the visible spectrum) and two are in the (near) infra-red. Each pixel is a 8-bit binary word, with 0 corresponding to black and 255 to white. The spatial resolution of a pixel is about 80m x 80m. Each image contains 2340 x 3380 such pixels. The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel. The number is a code for the following classes: Number			Class1			red soil2			cotton crop3			grey soil4			damp grey soil5			soil with vegetation stubble6			mixture class (all types present)7			very damp grey soil NB. There are no examples with class 6 in this dataset. The data is given in random order and certain lines of data have been removed so you cannot reconstruct the original image from this dataset. In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. If you like you can use only these four attributes, while ignoring the others. This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary.","The attributes are numerical, in the range 0 to 255.",N/A,"Please refer to the Machine Learning
Repository's citation policy","Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. Linear dimensionalityreduction using relevance weighted LDA. School of Electrical and Electronic Engineering Nanyang Technological University. 2005.  [View Context].Jaakko Peltonen and Arto Klami and Samuel Kaski. Improved Learning of Riemannian Metrics for Exploratory Analysis. Improved Learning of Riemannian Metrics for Exploratory Analysis. Neural Networks. 2004.  [View Context].Fabian Hoti and Lasse Holmström. A semiparametric density estimation approach to pattern classification. Pattern Recognition, 37. 2004.  [View Context].Giorgio Valentini. Random Aggregated and Bagged Ensembles of SVMs: An Empirical Bias?Variance Analysis. Multiple Classifier Systems. 2004.  [View Context].Xiaoli Z. Fern and Carla Brodley. Cluster Ensembles for High Dimensional Clustering: An Empirical Study. Journal of Machine Learning Research n, a. 2004.  [View Context].Jaakko Peltonen and Samuel Kaski. Discriminative Components of Data. IEEE. 2004.  [View Context].S. Augustine Su and Jennifer G. Dy. Automated hierarchical mixtures of probabilistic principal component analyzers. ICML. 2004.  [View Context].Giorgio Valentini and Thomas G. Dietterich. Low Bias Bagged Support Vector Machines. ICML. 2003.  [View Context].Zoubin Ghahramani and Hyun-Chul Kim. Bayesian Classifier Combination. Gatsby Computational Neuroscience Unit University College London. 2003.  [View Context].Giorgio Valentini. Ensemble methods based on bias--variance analysis Theses Series DISI-TH-2003. Dipartimento di Informatica e Scienze dell'Informazione . 2003.  [View Context].Peter Sykacek and Stephen J. Roberts. Adaptive Classification by Variational Kalman Filtering. NIPS. 2002.  [View Context].Igor V. Tetko. Associative Neural Network. Neural Processing Letters, 16. 2002.  [View Context].Jaakko Peltonen and Arto Klami and Samuel Kaski. Learning More Accurate Metrics for Self-Organizing Maps. ICANN. 2002.  [View Context].Stephen D. Bay. Multivariate Discretization for Set Mining. Knowl. Inf. Syst, 3. 2001.  [View Context].Kagan Tumer and Joydeep Ghosh. Robust Combining of Disparate Classifiers through Order Statistics. CoRR, csLG/9905013. 1999.  [View Context].Kagan Tumer and Nikunj C. Oza. Decimated Input Ensembles for Improved Generalization. NASA Ames Research Center. 1999.  [View Context].Xavier Giannakopoulos and Juha Karhunen and Erkki Oja. An Experimental Comparison of Neural Algorithms for Independent Component Analysis and Blind Separation. Int. J. Neural Syst, 9. 1999.  [View Context].Cesar Guerra-Salcedo and L. Darrell Whitley. Genetic Approach to Feature Selection for Ensemble Creation. GECCO. 1999.  [View Context].Robert E. Schapire and Yoav Freund and Peter Bartlett and Wee Sun Lee. The Annals of Statistics, to appear. Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods. AT&T Labs. 1998.  [View Context].Je Scott and Mahesan Niranjan and Richard W. Prager. Realisable Classifiers: Improving Operating Performance on Variable Cost Problems. Cambridge University Department of Engineering.  [View Context].Vikas Sindhwani and P. Bhattacharya and Subrata Rakshit. Information Theoretic Feature Crediting in Multiclass Support Vector Machines.  [View Context].Jaakko Peltonen and Arto Klami and Samuel Kaski. Learning Metrics for Information Visualization. Neural Networks Research Centre Helsinki University of Technology.  [View Context].C. esar and Cesar Guerra-Salcedo and Darrell Whitley. Feature Selection Mechanisms for Ensemble Creation : A Genetic Search Perspective. Department of Computer Science Colorado State University.  [View Context].Grigorios Tsoumakas and Ioannis P. Vlahavas. Fuzzy Meta-Learning: Preliminary Results. Greek Secretariat for Research and Technology.  [View Context].Xavier Giannakopoulos and Juha Karhunen and Erkki Oja. A COMPARISON OF NEURAL ICA ALGORITHMS USING REAL-WORLD DATA. IDSIA.  [View Context].Adil M. Bagirov and Julien Ugon. An algorithm for computation of piecewise linear function separating two sets. CIAO, School of Information Technology and Mathematical Sciences, The University of Ballarat.  [View Context].Giorgio Valentini. An experimental bias--variance analysis of SVM ensembles based on resampling techniques.  [View Context].Cesar Guerra-Salcedo and Stephen Chen and Darrell Whitley and Sarah Smith. Fast and Accurate Feature Selection Using Hybrid Genetic Strategies. Department of Computer Science Colorado State University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/News+Aggregator,465,News Aggregator Data Set,../machine-learning-databases/00359/,Multivariate,422937,N/A,N/A,5,2/28/2016,"Classification, Clustering",N/A,87843,"Provided by Artificial Intelligence Lab @ Faculty of Engineering, Roma Tre University - Italy Contact: Fabio Gasparetti, Faculty of Engineering, Roma Tre University - Italy (gaspare '@' dia.uniroma3.it)","News are grouped into clusters that represent pages discussing the same news story. The dataset includes also references to web pages that, at the access time, pointed (has a link to) one of the news page in the collection. 422937 news pages and divided up into: 152746 	news of business category108465 	news of science and technology category115920 	news of business category 45615 	news of health category 2076 clusters of similar news for entertainment category1789 clusters of similar news for science and technology category2019 clusters of similar news for business category1347 clusters of similar news for health category References to web pages containing a link to one news included in the collection are also included. They are represented as pairs of urls corresponding to 2-page browsing sessions. The collection includes 15516 2-page browsing sessions covering 946 distinct clusters divided up into: 6091 2-page sessions for business category9425 2-page sessions for entertainment category","FILENAME #1: newsCorpora.csv (102.297.000 bytes)DESCRIPTION: News pagesFORMAT: ID 	 TITLE 	 URL 	 PUBLISHER 	 CATEGORY 	 STORY 	 HOSTNAME 	 TIMESTAMP where:ID		Numeric IDTITLE		News title URL		UrlPUBLISHER	Publisher nameCATEGORY	News category (b = business, t = science and technology, e = entertainment, m = health)STORY		Alphanumeric ID of the cluster that includes news about the same storyHOSTNAME	Url hostnameTIMESTAMP 	Approximate time the news was published, as the number of milliseconds since the epoch 00:00:00 GMT, January 1, 1970  FILENAME #2: 2pageSessions.csv (3.049.986 bytes)DESCRIPTION: 2-page sessionsFORMAT: STORY 	 HOSTNAME 	 CATEGORY 	 URL where:STORY		Alphanumeric ID of the cluster that includes news about the same storyHOSTNAME	Url hostnameCATEGORY	News category (b = business, t = science and technology, e = entertainment, m = health)URL		Two space-delimited urls representing a browsing session","Fabio Gasparetti. 2017. Modeling user interests from web browsing activities. Data Min. Knowl. Discov. 31, 2 (March 2017), 502-547. DOI: [Web Link]","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Statlog+Project,466,Statlog Project Data Set,../machine-learning-databases/statlog/,N/A,N/A,N/A,N/A,N/A,10/1/1992,N/A,N/A,47497,"Origin: The Stalog databases are a subset of the datasets used in the European Statlog project. Donor:  Ross D. KingDepartment of Statistics and Modelling ScienceUniversity of StrathclydeGlasgow G1 1XHScotlandU.K.+44 41 552-4400 x 3033Fax +44 41 552-4711ross '@' turing.uk.ac","The databases available here were in used in the European StatLog project, which involves comparing the performances of machine learning, statistical, and neural network algorithms on data sets from real-world industrial areas including medicine, finance, image analysis, and engineering design.  Not all of the databases used in the project are available in this repository. Databases: (a) Vehicle Silhouettes: The original purpose was to find a method of distinguishing 3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects. (b) Landsat Satellite: The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number. (c) Shuttle: The shuttle dataset contains 9 attributes all of which are numerical. Approximately 80% of the data belongs to class 1. (d) Australian Credit Approval: This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.  This database exists elsewhere in the repository (Credit Screening Database) in a slightly different form. (e) Heart Disease: This dataset is a heart disease database similar to a database already present in the repository (Heart Disease databases) but in a slightly different form.  This database contains 13  attributes (which have been extracted from a larger set of 75). (f) Image Segmentation: This dataset is an image segmentation database similar to a database already present in the repository (Image segmentation database) but in a slightly different form.  The instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.  Each instance is a 3x3 region. (g) German Credit: This dataset classifies people described by a set of attributes as good or bad credit risks.  Comes in two formats (one all numeric). Also comes with a cost matrix.",N/A,"Feng,C., Sutherland,A., King,S., Muggleton,S. & Henery,R. (1993). Comparison of Machine Learning Classifiers to  Statistics and Neural Networks. AI & Stats Conf. 93.[Web Link]",Any publications based on these datasets should include an acknowledgment of the original sources of the datasets.,"Gavin Brown. Diversity in Neural Network Ensembles. The University of Birmingham. 2004.  [View Context].Jeroen Eggermont and Joost N. Kok and Walter A. Kosters. Genetic Programming for data classification: partitioning the search space. SAC. 2004.  [View Context].Wei-Chun Kao and Kai-Min Chung and Lucas Assun and Chih-Jen Lin. Decomposition Methods for Linear Support Vector Machines. Neural Computation, 16. 2004.  [View Context].Xiaoli Z. Fern and Carla Brodley. Cluster Ensembles for High Dimensional Clustering: An Empirical Study. Journal of Machine Learning Research n, a. 2004.  [View Context].Zoubin Ghahramani and Hyun-Chul Kim. Bayesian Classifier Combination. Gatsby Computational Neuroscience Unit University College London. 2003.  [View Context].Bart Hamers and J. A. K Suykens. Coupled Transductive Ensemble Learning of Kernel Models. Bart De Moor. 2003.  [View Context].Ramesh Natarajan and Edwin P D Pednault. Segmented Regression Estimators for Massive Data Sets. SDM. 2002.  [View Context].Jun Wang and Bin Yu and Les Gasser. Concept Tree Based Clustering Visualization with Shaded Similarity Matrices. ICDM. 2002.  [View Context].Avelino J. Gonzalez and Lawrence B. Holder and Diane J. Cook. Graph-Based Concept Learning. FLAIRS Conference. 2001.  [View Context].Jochen Garcke and Michael Griebel and Michael Thess. Data Mining with Sparse Grids. Computing, 67. 2001.  [View Context].Haixun Wang and Carlo Zaniolo. CMP: A Fast Decision Tree Classifier Using Multivariate Predictions. ICDE. 2000.  [View Context].Edgar Acuna and Alex Rojas. Ensembles of classifiers based on Kernel density estimators. Department of Mathematics University of Puerto Rico. 2000.  [View Context].Cesar Guerra-Salcedo and L. Darrell Whitley. Genetic Approach to Feature Selection for Ensemble Creation. GECCO. 1999.  [View Context].Guido Lindner and Rudi Studer. AST: Support for Algorithm Selection with a CBR Approach. PKDD. 1999.  [View Context].Ljupco Todorovski and Saso Dzeroski. Experiments in Meta-level Learning with ILP. PKDD. 1999.  [View Context].Art B. Owen. Tubular neighbors for regression and classification. Stanford University. 1999.  [View Context].Khaled A. Alsabti and Sanjay Ranka and Vineet Singh. CLOUDS: A Decision Tree Classifier for Large Datasets. KDD. 1998.  [View Context].Robert E. Schapire and Yoav Freund and Peter Bartlett and Wee Sun Lee. The Annals of Statistics, to appear. Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods. AT&T Labs. 1998.  [View Context].Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF. Appl. Intell, 7. 1997.  [View Context].Oya Ekin and Peter L. Hammer and Alexander Kogan and Pawel Winter. Distance-Based Classification Methods. e p o r t RUTCOR ffl Rutgers Center for Operations Research ffl Rutgers University. 1996.  [View Context].Georgios Paliouras and David S. Brée. The Effect of Numeric Features on the Scalability of Inductive Learning Programs. ECML. 1995.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Ron Kohavi and George H. John and Richard Long and David Manley and Karl Pfleger. MLC++: A Machine Learning Library in C. ICTAI. 1994.  [View Context].Ron Kohavi and Barry G. Becker and Dan Sommerfield. Improving Simple Bayes. Data Mining and Visualization Group Silicon Graphics, Inc.  [View Context].Wl odzisl and aw Duch. Control and Cybernetics. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. Computational intelligence methods for rule-based data understanding.  [View Context].Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. Statistical methods for construction of neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Chih-Wei Hsu and Cheng-Ru Lin. A Comparison of Methods for Multi-class Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].Wl/odzisl/aw Duch. Support Vector Neural Training. Index Terms--.  [View Context].Alexander K. Seewald. Meta-Learning for Stacked Classification. Austrian Research Institute for Artificial Intelligence.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski. Meta-learning: searching in the model space. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Kuan-ming Lin and Chih-Jen Lin. A Study on Reduced Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Je Scott and Mahesan Niranjan and Richard W. Prager. Realisable Classifiers: Improving Operating Performance on Variable Cost Problems. Cambridge University Department of Engineering.  [View Context].Yishay Mansour. Pessimistic decision tree pruning based on tree size. Computer Science Dept. Tel-Aviv University.  [View Context].Guido Lindner and Rudi Studer. Algorithm Selection Support for Classification. DaimlerChrysler AG, Research & Technology FT3/KL.  [View Context].Ron Kohavi and George H. John. Automatic Parameter Selection by Minimizing Estimated Error. Computer Science Dept. Stanford University.  [View Context].Iñaki Inza and Pedro Larraaga and Ramon Etxeberria and Basilio Sierra. Feature Subset Selection by Bayesian networks based optimization. Dept. of Computer Science and Artificial Intelligence. University of the Basque Country.  [View Context].Ron Kohavi and George John and Richard Long and David Manley and Karl Pfleger. Appears in Tools with AI '94. Computer Science Department Stanford University.  [View Context].H. -T Lin and C. -J Lin. A Study on Sigmoid Kernels for SVM and the Training of non-PSD Kernels by SMO-type Methods. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Jun Wang. Classification Visualization with Shaded Similarity Matrix. Bei Yu Les Gasser Graduate School of Library and Information Science University of Illinois at Urbana-Champaign.  [View Context].Rong-En Fan and P. -H Chen and C. -J Lin. Working Set Selection Using the Second Order Information for Training SVM. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Wl odzisl/aw Duch and Karol Grudzinski. Search and global minimization in similarity-based methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Wl odzisl and aw Duch. Committees of Undemocratic Competent Models. School of Computer Engineering Nanyang Technological University.  [View Context].Krzysztof Grabczewski and Wl/odzisl/aw Duch. THE SEPARABILITY OF SPLIT VALUE CRITERION. Department of Computer Methods, Nicolaus Copernicus University.  [View Context].C. esar and Cesar Guerra-Salcedo and Darrell Whitley. Feature Selection Mechanisms for Ensemble Creation : A Genetic Search Perspective. Department of Computer Science Colorado State University.  [View Context].Elena Smirnova and Ida G. Sprinkhuizen-Kuyper and I. Nalbantis and b. ERIM and Universiteit Rotterdam. Unanimous Voting using Support Vector Machines. IKAT, Universiteit Maastricht.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/PEMS-SF,467,PEMS-SF Data Set,../machine-learning-databases/00204/,"Multivariate, Time-Series",440,Computer,Real,138672,5/22/2011,Classification,N/A,69620,"Source: California Department of Transportation, www.pems.dot.ca.govCreator: Marco Cuturi, Kyoto University, mcuturi '@' i.kyoto-u.ac.jp","We have downloaded 15 months worth of daily data from the California Department of Transportation PEMS website, [Web Link], The data describes the occupancyrate, between 0 and 1, of different car lanes of San Francisco bay area freeways. The measurements cover the period from Jan. 1st 2008 to Mar. 30th 2009 and are sampled every 10 minutes. We consider each day in this database as a single time series of dimension 963 (the number of sensors which functioned consistently throughout the studied period) and length 6 x 24=144. We remove public holidays from the dataset, as wellas two days with anomalies (March 8th 2009 and March 9th 2008) where all sensors were muted between 2:00 and 3:00 AM. This results in a database of 440 time series. The task we propose on this dataset is to classify each observed day as the correct day of the week, from Monday to Sunday, e.g. label it with an integer in {1,2,3,4,5,6,7}.  I will keep separate copies of this database on my website in a Matlab format. If you use Matlab, it might be more convenient to consider these .mat files directly. Data-Format------------- There are two files for each fold, the data file and the labels file. We have split the 440 time series between train and test folds, but you are of course free to merge them to consider a different cross validation setting.- The PEMS_train textfile has 263 lines. Each line describes a time-series provided as a matrix. The matrix syntax is that of Matlab, e.g. [ a b ; c d] is the matrix with row vectors [a b] and [c d] in that order. Each matrix describes the different occupancies rates (963 lines, one for each station/detector) sampled every 10 minutes during the day (144 columns).- The PEMS_trainlabel text describes, for each day of measurements described above, the day of the week on which the data was sampled, namely an integer between 1 (Mon.) and 7 (Sun.). - PEMS_test and PEMS_testlabels are formatted in the same way, except that there are 173 test instances. - The permutation that I used to shuffle the dataset is given in the randperm file. If you need to rearrange the data so that it follows the calendar order, you should merge train and test samples and reorder them using the inverse permutation of randperm.","Each attribute describes the measurement of the occupancy rate (between 0 and 1) of a captor location as recorded by a measuring station, at a given timestamp in time during the day.  The ID of each station is given in the stations_list text file. For more information on the location (GPS, Highway, Direction) of each station please refer to the PEMS website. There are 963 (stations) x 144 (timestamps) =  138.672 attributes for each record.","M. Cuturi, Fast Global Alignment Kernels, Proceedings of the Intern. Conference on Machine Learning 2011.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/KEGG+Metabolic+Reaction+Network+%28Undirected%29,468,KEGG Metabolic Reaction Network (Undirected) Data Set,../machine-learning-databases/00221/,"Multivariate, Univariate, Text",65554,Life,"Integer, Real",29,11/28/2011,"Classification, Regression, Clustering",Yes,53800,"1. Muhammad Naeem, Centre of Research in Data Engineering(CORDE) & Department of Computer Science, MAJU Islamabad Pakistan(naeems.naeem '@' gmail.com).2. Sohail Asghar, Director/Associate Professor University Institute of IT PMAS-Arid Agriculture University,Rawalpindi Pakistan, Centre of Research in Data Engineering (CORDE),(sohail.asghar '@' gmail.com)","KEGG Metabolic pathways can be realized into network. Two kinds of network / graph can be formed. These include Reaction Network and Relation Network. In Reaction network, Substrate or Product compound are considered as Node and genes are treated as edge. Whereas in the relation network, Substrate and Product componds are considered as Edges while enzyme and genes are placed as nodes. We tool large number of metabolic pathways from KEGG XML. They were modeled into the graph as described above. With the help of Cytoscape tool, variety of network features were compunted. "," a)	Pathway	text b)	Connected Components	Integer (min:1, max:39 )c)	Diameter	Integer (min:1, max:46 )d)	Radius	Integer (min:1, max:13 )e)	Centralization	Integer (min:0, max:1 )f)	Shortest Path	Integer (min:2, max:23420 )g)	Characteristic Path Length	Integer (min:1, [Web Link] )h)	Avg.num.Neighbours	real ([Web Link], [Web Link])i)	Density	real ([Web Link], max:1)j)	Heterogeneity	real (min:0, [Web Link])k)	Isolated Nodes	Integer (min:0, max:3)l)	Number of Self Loops	Integer (min:0, max:4)m)	Multi-edge Node Pair	Integer (min:0, max:220)n)	NeighborhoodConnectivity	real ([Web Link], [Web Link])o)	NumberOfDirectedEdges		real ([Web Link], [Web Link])p)	Stress		real (min:0, [Web Link])q)	SelfLoops		real (min:0, [Web Link])r)	Partner Of MultiEdged NodePairs		Integer (min:0, max:3)s)	Degree		real (min:1, [Web Link])t)	TopologicalCoefficient	real (min:0, max:1)u)	BetweennessCentrality		real (min:0, [Web Link])v)	Radiality		real ([Web Link], max:30744573457 )w)	Eccentricity	real ([Web Link], [Web Link])x)	NumberOfUndirectedEdges	real (min:0, [Web Link])y)	ClosenessCentrality	real ([Web Link], max:1)z)	AverageShortestPathLength	real ([Web Link], [Web Link] )aa)	ClusteringCoefficient		real (min:0, max:1)bb)	nodeCount		Integer (min:2, max:232)cc)	edgeCount	Integer (min:1, max:444)","Shannon,P., Markiel,A., Ozier,O., Baliga,N.S.,	Wang,J.T.,Ramage,D., Amin,N., Schwikowski,B. and Ideker,T. (2003) Cytoscape: a software environment for integrated models of biomolecular interaction networks. Genome Res., 13, 2498â€“2504.","Naeem M,Asghar S, Centre of Research in Data Engineering Islamabad Pakistan, naeems.naeem '@' gmail.com, sohail.asg '@' gmail.com",
http://archive.ics.uci.edu/ml/datasets/Auto+MPG,469,Auto MPG Data Set,../machine-learning-databases/auto-mpg/,Multivariate,398,N/A,"Categorical, Real",8,7/7/1993,Regression,Yes,562317,This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The dataset was used in the 1983 American Statistical Association Exposition.,"This dataset is a slightly modified version of the dataset provided in the StatLib library.  In line with the use by Ross Quinlan (1993) in predicting the attribute ""mpg"", 8 of the original instances were removed because they had unknown values for the ""mpg"" attribute.  The original dataset is available in the file ""auto-mpg.data-original"". ""The data concerns city-cycle fuel consumption in miles per gallon, to be predicted in terms of 3 multivalued discrete and 5 continuous attributes."" (Quinlan, 1993)","    1. mpg:           continuous    2. cylinders:     multi-valued discrete    3. displacement:  continuous    4. horsepower:    continuous    5. weight:        continuous    6. acceleration:  continuous    7. model year:    multi-valued discrete    8. origin:        multi-valued discrete    9. car name:      string (unique for each instance)","Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Qingping Tao Ph. D. MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004.  [View Context].Dan Pelleg. Scalable and Practical Probability Density Estimators for Scientific Anomaly Detection. School of Computer Science Carnegie Mellon University. 2004.  [View Context].Christopher R. Palmer and Christos Faloutsos. Electricity Based External Similarity of Categorical Attributes. PAKDD. 2003.  [View Context].Thomas Melluish and Craig Saunders and Ilia Nouretdinov and Volodya Vovk and Carol S. Saunders and I. Nouretdinov V.. The typicalness framework: a comparison with the Bayesian approach. Department of Computer Science. 2001.  [View Context].Wai Lam and Kin Keung and Charles X. Ling. PR 1527. Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong. 2001.  [View Context].Dan Pelleg and Andrew W. Moore. Mixtures of Rectangles: Interpretable Soft Clustering. ICML. 2001.  [View Context].Jinyan Li and Kotagiri Ramamohanarao and Guozhu Dong. Combining the Strength of Pattern Frequency and Distance for Classification. PAKDD. 2001.  [View Context].Zhi-Hua Zhou and Shifu Chen and Zhaoqian Chen. A Statistics Based Approach for Extracting Priority Rules from Trained Neural Networks. IJCNN (3). 2000.  [View Context].Mauro Birattari and Gianluca Bontempi and Hugues Bersini. Lazy Learning Meets the Recursive Least Squares Algorithm. NIPS. 1998.  [View Context].D. Greig and Hava T. Siegelmann and Michael Zibulevsky. A New Class of Sigmoid Activation Functions That Don't Saturate. 1997.  [View Context].Johannes Furnkranz. Pairwise Classification as an Ensemble Technique. Austrian Research Institute for Artificial Intelligence.  [View Context].C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Indoor+User+Movement+Prediction+from+RSS+data,470,Indoor User Movement Prediction from RSS data Data Set,../machine-learning-databases/00348/,"Multivariate, Sequential, Time-Series",13197,Computer,Real,4,2/4/2016,Classification,N/A,62798,"Davide Bacciu (a), Paolo Barsocchi (b), Stefano Chessa (a), Claudio Gallicchio (a), Alessio Micheli (a) (a) Department of Computer Science, University of Pisa.Largo Bruno Pontecorvo 3, 56127 Pisa, Italy(b) Institute of Information Science and Technologies,  Italian National Research Council.Via G. Moruzzi 1, 56124 Pisa, Italy For info about this dataset contactPaolo Barsocchi: paolo.barsocchi '@' isti.cnr.itClaudio Gallicchio: gallicch '@' di.unipi.it","This dataset represents a real-life benchmark in the area of Ambient Assisted Living applications, as described in [1].The binary classification task consists in predicting  the pattern of user movements in real-world office environments from time-series generated by a Wireless Sensor Network (WSN). Input data contains temporal streams of radio signal strength (RSS) measured between the nodes of a WSN, comprising 5 sensors: 4 anchors deployed in the environment and 1 mote worn by the user. Data has been collected during user movements at the frequency of 8 Hz (8 samples per second). In the provided dataset, the RSS signals have been rescaled to the interval [-1,1], singly on the set of traces collected from each anchor (as in [1]).Target data consists in a class label indicating whether the user's trajectory will lead to a change in the spatial context (i.e. a room change) or not. In particular, the target class +1 is associated to the location changing movements, while the target class -1 is associated to the location preserving movements.The measurement campaign involved a number of 3 different environmental settings, each of which comprises 2 rooms (containing typical office furniture) separated by a corridor. A sketch of the common setup considered is provided in the attached Figure. In each environmental setting, the anchors are deployed in fixed positions near the rooms corners (at the height of 1.5 m from the ground), while the mobile is worn on the chest of the user. The Figure also shows a simplified illustration of the types of user trajectories considered, with straight paths yielding to a spatial context change and curved ones leading to spatial context preservation. Each path produces a trace of RSS measurements from the beginning of the trajectory until a marker point, which is denoted as M in the Figure. The marker M is the same for all the movements, therefore different paths cannot be distinguished based only on the RSS values collected at M. Each input file in the provided dataset contains data pertaining to one temporal sequence of input RSS data (1 user trajectory for each file). The dataset contains 314 sequences, for a total number of 13197 steps. Further information can be found at the webpage: [Web Link].A complete description of this dataset can be found in [1], which also provides details on the performance achieved by Echo State Networks on the corresponding classification task.","Data is provided in comma separated value (csv) format.  - Input dataInput RSS streams are provided in files named MovementAAL_RSS_SEQID.csv, where IDSEQ is the progressive numeric sequence ID.In each file, each row corresponds to a time step measurement (in temporal order) and contains the following information:RSS_anchor1, RSS_anchor2, RSS_anchor3, RSS_anchor4  - Target dataTarget data is provided in the file MovementAAL_target.csvEach row in this file contains:sequence_ID, class_label  - Dataset groupingData is grouped in 3 sets, as described in [1].File MovementAAL_DatasetGroup.csv, provides information about such data grouping.Each row in this file contains:sequence_ID, dataset_ID - Path groupingUsers' movements are divided in 6 prototypical paths, as described in [1].File MovementAAL_Paths.csv provides information about data grouping based on path type.Each row in this file contains:sequence_ID, path_ID","[1] D. Bacciu, P. Barsocchi, S. Chessa, C. Gallicchio, and A. Micheli, 'An experimental characterization of reservoir computing in ambient assisted living applications', Neural Computing and Applications, Springer-Verlag, vol. 24 (6), pp. 1451-1464, [Web Link], ISSN 0941-0643, 2014. [2] D. Bacciu, S. Chessa, C. Gallicchio, A. Micheli, P. Barsocchi, 'An Experimental Evaluation of Reservoir Computation for Ambient Assisted Living', 22nd Italian Workshop on Neural Networks, Vietri sul Mare, Salerno, Italy, 17-19 May 2012, Neural Networks and Surroundings, Springer Smart Innovation, Systems and Technologies series, Volume 19, pag. 41-50, ISBN: 978-3-642-35466-3, 2013. [3] C. Gallicchio, A. Micheli, P. Barsocchi, S. Chessa, 'User Movements Forecasting by Reservoir Computing Using Signal Streams Produced by Mote-Class Sensors', Mobile Lightweight Wireless Systems (MOBILIGHT), Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, Volume 81, Part 3, pag. 151-168, ISBN 978-3-642-29478-5, 2012. [4] D. Bacciu, C. Gallicchio, A. Micheli, S. Chessa, P. Barsocchi, 'Predicting user movements in heterogeneous indoor environments by reservoir computing', M. Bhatt, H. W. Guesgen, and J. C. Augusto, editors, Proceedings of the IJCAI Workshop on Space, Time and Ambient Intelligence (STAMI), pag. 1-6, 2011.","D. Bacciu, P. Barsocchi, S. Chessa, C. Gallicchio, and A. Micheli, 'An experimental characterization of reservoir computing in ambient assisted living applications', Neural Computing and Applications, Springer-Verlag, vol. 24 (6), pp. 1451-1464, [Web Link], ISSN 0941-0643, 2014.",
http://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+temperature+modulation,471,Gas sensor array temperature modulation Data Set,../machine-learning-databases/00487/,"Multivariate, Time-Series",4095000,Computer,Real,20,4/15/2019,"Classification, Regression",N/A,20825,"Javier BurguÃ©s (jburgues8 '@'ibecbarcelona.eu, jburgues8 '@'gmail.com) Institute of Bioengineering of Catalonia (IBEC)Baldiri Reixac 10-12Barcelona, Spain"," A chemical detection platform composed of 14 temperature-modulated metal oxide semiconductor (MOX) gas sensors was exposed to dynamic mixtures of carbon monoxide (CO) and humid synthetic air in a gas chamber.  The acquired time series of the sensors and the measured values of CO concentration, humidity and temperature inside the gas chamber are provided.  a) Chemical detection platform: The chemical detection platform was composed of 14 MOX gas sensors that generate a time-dependent multivariate response to the different gas stimuli. The utilized sensors were made commercially available by Figaro Engineering (7 units of TGS 3870-A04) and FIS (7 units of SB-500-12).The operating temperature of the sensors was controlled by the built-in heater, which voltage was modulated in the range 0.2-0.9 V in cycles of 20 and 25 s, following the manufacturer recommendations (0.9 V for 5s, 0.2 V for 20s, 0.9 V for 5 s, 0.2 V for 25 s, ...). The sensors were pre-heated for one week before starting the experiments.The MOX read-out circuits consisted of voltage dividers with 1 MOhm load resistors and powered at 5V.The output voltage of the sensors was sampled at 3.5 Hz using an Agilent HP34970A/34901A DAQ configured at 15 bits of precision and input impedance greater than 10 GOhm. b) Generator of dynamic gas mixturesDynamic mixtures of CO and humid synthetic air were delivered from high purity gases in cylinders to a small-sized polytetrafluoroethylene (PTFE) test chamber (250 cm3 internal volume), by means of a piping system and mass flow controllers (MFCs).Gas mixing was performed using mass flow controllers (MFC),which controlled three different gas streams (CO, wet air and dry air). These streams were delivered from high quality pressurizedgases in cylinders. The selected MFCs (EL-FLOW Select, Bronkhorst) had full scale flow rates of 1000 mln/min for the dry and wet air streams and 3 mln/min for the CO channel. The CO bottle contained 1600 ppm of CO diluted in synthetic air with 21 Â± 1% O2. The relative uncertainty in the generated CO concentration was below 5.5%.The wet and dry air streams were both delivered from a synthetic air bottle with 99.995% purity and 21 Â± 1% O2. Humidification of the wet stream was based on the saturation method using a glass bubbler (Drechsler bottles).  c)  Temperature/humidity valuesA temperature/humidity sensor (SHT75, from Sensirion) provided reference humidity and temperature values inside the test chamber with tolerance below 1.8% r.h. and 0.5 ÂºC, respectively, every 5 s.The temperature variations inside the gas chamber, for each experiment, were below 3 ÂºC.  d) Experimental protocol: Each experiment consisted on 100 measurements: 10 experimental concentrations uniformly distributed in the range 0-20 ppm and 10 replicates per concentration. Each replicate had a relative humidity randomly chosen from a uniform distribution between 15% and 75% r.h. At the beginning of each experiment, the gas chamber was cleaned for 15 min using a stream of synthetic air at a flow rate of 240 mln/min. After that, the gas mixtures were released in random order at a constant flow rate of 240 mln/min for 15 min each. A single experiment lasted 25 hours (100 samples x 15 minutes/sample) and was replicated on 13 working days spanning a natural period of 17 days.","The dataset is presented in 13 text files, where each file corresponds to a different measurement day. The filenames indicate the timestamp (yyyymmdd_HHMMSS) of the start of the measurements.Each file includes the acquired time series, presented in 20 columns: Time (s), CO concentration (ppm), Humidity (%r.h.), Temperature (ÂºC), Flow rate (mL/min), Heater voltage (V), and the resistance of the 14 gas sensors: R1 (MOhm),R2 (MOhm),R3 (MOhm),R4 (MOhm),R5 (MOhm),R6 (MOhm),R7 (MOhm),R8 (MOhm),R9 (MOhm),R10 (MOhm),R11 (MOhm),R12 (MOhm),R13 (MOhm),R14 (MOhm)Resistance values R1-R7 correspond to FIGARO TGS 3870 A-04 sensors, whereas R8-R14 correspond to FIS SB-500-12 units.The time series are sampled at 3.5 Hz.","The description of the experimental setup and chemical detection platform can be found in [1-2]. The dataset has been used also in [3]. [1] BurguÃ©s, Javier, Juan Manuel JimÃ©nez-Soto, and Santiago Marco. 'Estimation of the limit of detection in semiconductor gas sensors through linearized calibration models.' Analytica chimica acta 1013 (2018): 13-25. [2] BurguÃ©s, Javier, and Santiago Marco. 'Multivariate estimation of the limit of detection by orthogonal partial least squares in temperature-modulated MOX sensors.' Analytica chimica acta 1019 (2018): 49-64. [3] Fernandez, Luis, Jia Yan, Jordi Fonollosa, Javier BurguÃ©s, Agustin Gutierrez, and Santiago Marco. 'A practical method to estimate the resolving power of a chemical sensor array: application to feature selection.' Frontiers in chemistry 6 (2018). references to papers that have cited this data set in the past (if any).","The following citations are requested if you use the dataset:  BurguÃ©s, Javier, Juan Manuel JimÃ©nez-Soto, and Santiago Marco. 'Estimation of the limit of detection in semiconductor gas sensors through linearized calibration models.' Analytica chimica acta 1013 (2018): 13-25 BurguÃ©s, Javier, and Santiago Marco. 'Multivariate estimation of the limit of detection by orthogonal partial least squares in temperature-modulated MOX sensors.' Analytica chimica acta 1019 (2018): 49-64.",
http://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction,473,Appliances energy prediction Data Set,../machine-learning-databases/00374/,"Multivariate, Time-Series",19735,Computer,Real,29,2/15/2017,Regression,N/A,121897,"Luis Candanedo, luismiguel.candanedoibarra '@' umons.ac.be, University of Mons (UMONS).","The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for 10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters. Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis (rp5.ru), and merged together with the experimental data sets using the date and time column. Two random variables have been included in the data set for testing the regression models and to filter out non predictive attributes (parameters). For more information about the house, data collection, R scripts and figures, please refer to the paper and to the following github repository: [Web Link] ","date time year-month-day hour:minute:second Appliances, energy use in Whlights, energy use of light fixtures in the house in WhT1, Temperature in kitchen area, in CelsiusRH_1, Humidity in kitchen area, in %T2, Temperature in living room area, in CelsiusRH_2, Humidity in living room area, in %T3, Temperature in laundry room areaRH_3, Humidity in laundry room area, in %T4, Temperature in office room, in CelsiusRH_4, Humidity in office room, in %T5, Temperature in bathroom, in CelsiusRH_5, Humidity in bathroom, in %T6, Temperature outside the building (north side), in CelsiusRH_6, Humidity outside the building (north side), in %T7, Temperature in ironing room , in CelsiusRH_7, Humidity in ironing room, in %T8, Temperature in teenager room 2, in CelsiusRH_8, Humidity in teenager room 2, in %T9, Temperature in parents room, in CelsiusRH_9, Humidity in parents room, in %To, Temperature outside (from Chievres weather station), in CelsiusPressure (from Chievres weather station), in mm HgRH_out, Humidity outside (from Chievres weather station), in %Wind speed (from Chievres weather station), in m/sVisibility (from Chievres weather station), in kmTdewpoint (from Chievres weather station), Â°Crv1, Random variable 1, nondimensionalrv2, Random variable 2, nondimensional Where indicated, hourly data (then interpolated) from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis, rp5.ru. Permission was obtained from Reliable Prognosis for the distribution of the 4.5 months of weather data.","Luis M. Candanedo, Veronique Feldheim, Dominique Deramaix, Data driven prediction models of energy use of appliances in a low-energy house, Energy and Buildings, Volume 140, 1 April 2017, Pages 81-97, ISSN 0378-7788, [Web Link].","Luis M. Candanedo, Veronique Feldheim, Dominique Deramaix, Data driven prediction models of energy use of appliances in a low-energy house, Energy and Buildings, Volume 140, 1 April 2017, Pages 81-97, ISSN 0378-7788, [Web Link].",
http://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression,474,Mice Protein Expression Data Set,../machine-learning-databases/00342/,Multivariate,1080,Life,Real,82,8/4/2015,"Classification, Clustering",Yes,79082,"Clara Higuera Department of Software Engineering and Artificial Intelligence, Faculty of Informatics and the Department of Biochemistry and Molecular Biology, Faculty of Chemistry, University Complutense, Madrid, Spain.Email: clarahiguera '@' ucm.es  Katheleen J. Gardiner, creator and owner of the protein expression data, is currently with the Linda Crnic Institute for Down Syndrome, Department of Pediatrics, Department of Biochemistry and Molecular Genetics, Human Medical Genetics and Genomics, and Neuroscience Programs, University of Colorado, School of Medicine, Aurora, Colorado, USA.Email: katheleen.gardiner '@' ucdenver.edu  Krzysztof J. Cios is currently with the Department of Computer Science, Virginia Commonwealth University, Richmond, Virginia, USA, and IITiS Polish Academy of Sciences, Poland. Email: kcios '@' vcu.edu ","The data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse. The eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not. Classes:c-CS-s: control mice, stimulated to learn, injected with saline (9 mice)c-CS-m: control mice, stimulated to learn, injected with memantine (10 mice)c-SC-s: control mice, not stimulated to learn, injected with saline (9 mice)c-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice) t-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice)t-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice)t-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice)t-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice) The aim is to identify subsets of proteins that are discriminant between the classes.","1 Mouse ID 2..78 Values of expression levels of 77 proteins; the names of proteins are followed by â€œ_nâ€  indicating that they were measured in the nuclear fraction. For example: DYRK1A_n79 Genotype: control (c) or trisomy (t)80 Treatment type: memantine (m) or saline (s)81 Behavior: context-shock (CS) or shock-context (SC)82 Class: c-CS-s, c-CS-m, c-SC-s, c-SC-m,  t-CS-s, t-CS-m, t-SC-s, t-SC-m ","The posted data were analyzed by:Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126  The data are a subset of the data analyzed by: Ahmed MM, Dhanasekaran AR, Block A, Tong S, Costa ACS, Stasko M, et al. (2015) Protein Dynamics Associated with Failed and Rescued Learning in the Ts65Dn Mouse Model of Down Syndrome. PLoS ONE 10(3): e0119491. [Web Link]  ","Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126 ",
http://archive.ics.uci.edu/ml/datasets/Parkinson+Dataset+with+replicated+acoustic+features+,475,Parkinson Dataset with replicated acoustic features  Data Set,../machine-learning-databases/00489/,Multivariate,240,Life,N/A,46,4/10/2019,Classification,N/A,19851,"Carlos J. PÃ©rezDepartamento de MatemÃ¡ticas, Universidad de Extremadura, CÃ¡ceres (Spain)Email: carper '@' unex.es ","Important remarks before using this dataset:  1. Each row can not be used independently, because is one of the three replications of one individual. Nature of data is dependent    for each subject, but independent from one to another subject. So, traditional technique from machine learning can not be applied to this dataset, because those techniques are based on the independent nature of the instances. There are 240 instances but for only 80 subjects, so they are not independent. Techniques as those presented in Naranjo et al. (2016), Naranjo et al. (2017) or other specifically designed can be used.  2. The concept of replication considered here does not match the classical concept of statistical repeated measurements. The term 'replications' refers to the collection of features extracted from voice recordings belonging to the same subject. Since, in this context, features are extracted from multiple consecutive voice recordings from the same subject, in principle, the features should be identical. The imperfections in technology and the own biological variability result in non-identical replicated features that are more similar to one another than features from different subjects.  3. All information about how the dataset was generated is presented in Naranjo et al. (2016). ","1. ID: Subjects's identifier. 2. Recording: Number of the recording.3. Status: 0=Healthy; 1=PD4. Gender: 0=Man; 1=Woman  5. Pitch local perturbation measures: relative jitter (Jitter_rel), absolute jitter (Jitter_abs), relative average perturbation (Jitter_RAP), and pitch perturbation quotient (Jitter_PPQ).6. Amplitude perturbation measures: local shimmer (Shim_loc), shimmer in dB (Shim_dB), 3-point amplitude perturbation quotient (Shim_APQ3), 5-point amplitude perturbation quotient (Shim_APQ5), and 11-point amplitude perturbation quotient (Shim_APQ11).7. Harmonic-to-noise ratio measures: harmonic-to-noise ratio in the frequency band 0-500 Hz (HNR05), in 0-1500 Hz (HNR15), in 0-2500 Hz (HNR25), in 0-3500 Hz (HNR35), and in 0-3800 Hz (HNR38).8. Mel frequency cepstral coefficient-based spectral measures of order 0 to 12 (MFCC0, MFCC1,..., MFCC12) and their derivatives (Delta0, Delta1,..., Delta12).9. Recurrence period density entropy (RPDE).10. Detrended fluctuation analysis (DFA).11. Pitch period entropy (PPE).12. Glottal-to-noise excitation ratio (GNE).","Naranjo, L., PÃ©rez, C.J., Campos-Roca, Y., MartÃ­n, J.: Addressing voice recording replications for Parkinsonâ€™s disease detection. Expert Systems With Applications 46, 286-292 (2016)  Naranjo, L., PÃ©rez, C.J., MartÃ­n, J., Campos-Roca, Y.: A two-stage variable selection and classification approach for Parkinsonâ€™s disease detection by using voice recording  replications. Computer Methods and Programs in Biomedicine 142, 147-156 (2017)","Naranjo, L., PÃ©rez, C.J., Campos-Roca, Y., MartÃ­n, J.: Addressing voice recording replications for Parkinsonâ€™s disease detection. Expert Systems With Applications 46, 286-292 (2016)",
http://archive.ics.uci.edu/ml/datasets/ser+Knowledge+Modeling+Data+%28Students%27+Knowledge+Levels+on+DC+Electrical+Machines%29,476,ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines) Data Set,../machine-learning-databases/00263/,Multivariate,403,Computer,Real,5,6/20/2013,Classification,N/A,37684," -- Creators: Hamdi Tolga Kahraman, Ilhami Colak, Seref Sagiroglu   -- Institution: Faculty of Technology, Department of Software Engineering, Karadeniz Technical University, Trabzon, Turkiye   -- Donor: Students of Department of Electrical Education of Gazi University      -- Date: October, 2009Kahraman, H. T. (2009). Designing and Application of Web-Based Adaptive Intelligent Education System. Gazi University Ph. D. Thesis, Turkey, 1-156.","-- The users' knowledge class were classified by the authors      using intuitive knowledge classifier (a hybrid ML technique of k-NN and meta-heuristic exploring methods), k-nearest neighbor algorithm.       See article for more details on how the users' data was collected and evaluated by the user modeling server. 	Kahraman, H. T., Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,         Knowledge Based Systems, vol. 37, pp. 283-295, 2013.          Kahraman, H. T. (2009). Designing and Application of Web-Based Adaptive Intelligent Education System. Gazi University Ph. D. Thesis, Turkey, 1-156.","         STG (The degree of study time for goal object materails), (input value) 	SCG (The degree of repetition number of user for goal object materails) (input value) 	STR (The degree of study time of user for related objects with goal object) (input value) 	LPR (The exam performance of user for related objects with goal object) (input value) 	PEG (The exam performance of user for goal objects) (input value) 	UNS (The knowledge level of user) (target value)  Class Distribution: the class value (UNS).        Very Low: 50	Low:129	Middle: 122	high 130","        Kahraman, H. T., Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,         Knowledge Based Systems, vol. 37, pp. 283-295, 2013.  ","NOTE: Reuse of this database is unlimited with citation for Dr. Hamdi Tolga KAHRAMAN and et. al, the following published paper: 	Kahraman, H. T., Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,         Knowledge Based Systems, vol. 37, pp. 283-295, 2013.  ",
http://archive.ics.uci.edu/ml/datasets/Farm+Ads,477,Farm Ads Data Set,../machine-learning-databases/00218/,Text,4143,Business,N/A,54877,10/18/2011,Classification,N/A,74326,"Chris Mesterharm and Michael J. PazzaniRutgers, The State University of New Jerseymesterha '@' cs.rutgers.edu ","This data was collected from text ads found on twelve websites that deal with various farm animal related topics.  Information from the ad creative and the ad landing page is included.  The binary labels are based on whether or not the content owner approves of the ad. For each ad, we include the words on the ad creative and the words from the landing page.  Each word from the creative is given a prefixof 'ad-'.  Title and header HTML markups are noted in a similar way in the text of the landing page.  We have already performed stemming andstop word removal.  Each ad is on a single line.  The first word in the line is the label of the instance.  It is 1 for accepted ads and -1 for rejected ads. We have also included a straightforward bag-of-words representation of our data.  We use the SVMlight sparse vector format.  The first valueis the label followed by every nonzero attribute.  Each of these attributes is encoded as index:value.  This is the representation used for the relevant paper cited below.",Text words in file farm-ads.  SVMlight format sparse vectors in file farm-ads-vect.,"Active Learning using On-line Algorithms. Chris Mesterharm, Michael J. Pazzani. In KDD 2011.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Buzz+in+social+media+,478,Buzz in social media  Data Set,../machine-learning-databases/00248/,"Time-Series, Multivariate",140000,Computer,"Integer, Real",77,5/27/2013,"Regression, Classification",N/A,157268,"Creators :    François Kawala (1,2) Ahlame Douzal (1) Eric Gaussier (1) Eustache Diemert (2)Institutions :    (1) Université  Joseph Fourier (Grenoble I)       Laboratoire d'informatique de Grenoble (LIG)   (2) BestofMedia GroupDonor:    BestofMedia (ediemert '@' bestofmedia.com)",Please see [Web Link],Please see [Web Link],"Prédictions d’activité dans les réseaux sociaux en ligne (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conférence sur les Modèles et l′Analyse des Réseaux : Approches Mathématiques et Informatique (MARAMI), pp. 16, 2013.","Prédictions d’activité dans les réseaux sociaux en ligne (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conférence sur les Modèles et l′Analyse des Réseaux : Approches Mathématiques et Informatique (MARAMI), pp. 16, 2013.",
http://archive.ics.uci.edu/ml/datasets/Amazon+Access+Samples,479,Amazon Access Samples Data Set,../machine-learning-databases/00216/,"Time-Series, Domain-Theory",30000,Business,N/A,20000,9/13/2011,"Regression, Clustering, Causal-Discovery",N/A,205596,"Dataset creator and donator: Ken Montanez email: kenmonta[at]cal.berkeley.edu institution: Information Security, Amazon Corp.","This is a sparse data set, less than 10% of the attributes are used for each sample. The link is to a '*.tgz' file which contains two files:[amzn-anon-access-samples-2.0.csv] this file contains the access for users[amzn-anon-access-samples-history-2.0.csv] this file contains the access history for a given user","__amzn-anon-access-samples-2.0.csv__This is a sparse data set containing users and their assigned access. The file contains 4 categories of attributes.1) [PERSON_{ATTRIBUTE}] This category describes the 'user' who was given access. The [PERSON_ID] column is the primary key column for the file. There is one row per user.PERSON_ID: id of the userPERSON_MGR_ID: id of the user's managerPERSON_ROLLUP_1: user grouping idPERSON_ROLLUP_2: user grouping idPERSON_ROLLUP_3: user grouping idPERSON_DEPTNAME: department desciption idPERSON_LOCATION: region idPERSON_BUSINESS_TITLE: title idPERSON_BUSINESS_TITLE_DETAIL: description idPERSON_JOB_CODE: job code idPERSON_COMPANY: company idPERSON_JOB_FAMILY: job family id 2) [RESOURCE_{ID}] This category of attributes are the resources that a users can possibly have access to. A user will have a 1 in this column if the have access to it otherwise it will be 0. 3) [GROUP_{ID}] - This category of attributes are the groups that a users can possibly have access to. A user will have a 1 in this column if the have access to it otherwise it will be 0. 4) [SYSTEM_SUPPORT_{ID}] - This category of attributes are the system that a user can possibly be supporting. A user will have a 1 in this column if the have can possibly be supporting it, otherwise it will be 0. __amzn-anon-access-samples-history-2.0.csv__Permissions Time series data. Here is a short description of the columns:ACTION: either 'remove_access' or 'add_access'TARGET_NAME: either the {RESOURCE_ID} or {GROUP_ID}LOGIN: the id of the user that is obtaining or losing accessREQUEST_DATE: YYYY-MM-DD HH:MM:SSAUTHORIZATION_DATE: YYYY-MM-DD HH:MM:SS",N/A,Please refer to the Machine Learning Repository's citation policy.,
http://archive.ics.uci.edu/ml/datasets/Breast+Tissue,480,Breast Tissue Data Set,../machine-learning-databases/00192/,Multivariate,106,Life,Real,10,5/10/2010,Classification,N/A,125419,"JP Marques de Sá, INEB-Instituto de Engenharia Biomédica, Porto, Portugal; e-mail: jpmdesa '@' gmail.com J Jossinet, inserm, Lyon, France","Impedance measurements were made at the frequencies: 15.625, 31.25, 62.5, 125, 250, 500, 1000 KHzImpedance measurements of freshly excised breast tissue were made at the follwoing frequencies: 15.625, 31.25, 62.5, 125, 250, 500, 1000 KHz. These measurements plotted in the (real, -imaginary) plane constitute the impedance spectrum from where the breast tissue features are computed.The dataset can be used for predicting the classification of either the original 6 classes or of 4 classes by merging together the fibro-adenoma, mastopathy and glandular classes whose discrimination is not important (they cannot be accurately discriminated anyway).","I0	Impedivity (ohm) at zero frequencyPA500	phase angle at 500 KHzHFS	high-frequency slope of phase angleDA	impedance distance between spectral endsAREA	area under spectrumA/DA	area normalized by DAMAX IP	maximum of the spectrumDR	distance between I0 and real part of the maximum frequency pointP	length of the spectral curveClass   car(carcinoma), fad (fibro-adenoma), mas (mastopathy), gla (glandular), con (connective), adi (adipose). The ","Jossinet J (1996) Variability of impedivity in normal and pathological breast tissue. Med. & Biol. Eng. & Comput, 34: 346-350.Silva JE, Marques de Sá JP, Jossinet J (2000) Classification of Breast Tissue by Electrical Impedance Spectroscopy. Med & Bio Eng & Computing, 38:26-30.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Immunotherapy+Dataset,481,Immunotherapy Dataset Data Set,../machine-learning-databases/00428/,Univariate,90,Life,"Integer, Real",8,1/4/2018,Classification,N/A,49477,"Name: Fahime Khozeimeh, MDemail: fahime.khozeime '@' yahoo.com institution: Faculty of  Medicine, Mashhad University of Medical Sciences, Mashhad, Iran. Name: Pouran Layegh, Professor of Dermatologyemail: layeghpo '@' mums.ac.ir institution: Mashhad University of Medical Sciences, Mashhad, Iranwebsite: http://research.mums.ac.ir/webdocument/load.action?webdocument_code=8001&masterCode=8000703  Name:Roohallah Alizadehsani, PhD studentemail: alizadeh_roohallah '@' yahoo.cominstitution: Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Victoria 3217, Australia.website: http://ce.sharif.ir/~ralizadeh/  Name: Mohamad Roshanzamir, PhD candidateemail: mohamad.roshanzamir '@' ec.iut.ac.irinstitution: Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran. ",Provide all relevant information about your data set.,Provide information about each attribute in your data set.,"1. F. Khozeimeh, R. Alizadehsani, M. Roshanzamir, A. Khosravi, P. Layegh, and S. Nahavandi, 'An expert system for selecting wart treatment method,' Computers in Biology and Medicine, vol. 81, pp. 167-175, 2/1/ 2017.2. F. Khozeimeh, F. Jabbari Azad, Y. Mahboubi Oskouei, M. Jafari, S. Tehranian, R. Alizadehsani, et al., 'Intralesional immunotherapy compared to cryotherapy in the treatment of warts,' International Journal of Dermatology, 2017, DOI: 10.1111/ijd.135353. Intralesional immunotherapy with Candida antigen compared to cryotherapy in the treatment of warts. M Teimoorian, F Khozeimeh, P Layegh, R AlizadehsaniAmerican Academy of Dermatology, 2016","1. F. Khozeimeh, R. Alizadehsani, M. Roshanzamir, A. Khosravi, P. Layegh, and S. Nahavandi, 'An expert system for selecting wart treatment method,' Computers in Biology and Medicine, vol. 81, pp. 167-175, 2/1/ 2017.2. F. Khozeimeh, F. Jabbari Azad, Y. Mahboubi Oskouei, M. Jafari, S. Tehranian, R. Alizadehsani, et al., 'Intralesional immunotherapy compared to cryotherapy in the treatment of warts,' International Journal of Dermatology, 2017, DOI: 10.1111/ijd.13535",
http://archive.ics.uci.edu/ml/datasets/Opinosis+Opinion+%26frasl%3B+Review,482,Opinosis Opinion ⁄ Review Data Set,../machine-learning-databases/opinion/,Text,51,Computer,N/A,N/A,7/6/2010,N/A,N/A,49236,"Kavita Ganesankganes2 '@' illinois.edu http://kavita-ganesan.com/opinosis-opinion-dataset","This dataset contains sentences extracted from user reviews on a given topic. Example topics are â€œperformance of Toyota Camryâ€ and â€œsound quality of ipod nanoâ€, etc. In total there are 51 such topics  with each topic having approximately 100 sentences (on the average). The reviews were obtained from various sources - Tripadvisor (hotels), Edmunds.com (cars) and Amazon.com (various electronics). The dataset file also comes with gold standard summaries used for the Opinosis summarization paper (see relevant papers). ",N/A,"Kavita Ganesan, ChengXiang Zhai, Jiawei Han. Opinosis: A Graph Based Approach to Abstractive Summarization of Highly Redundant Opinions. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010). Beijing, China.","Kavita Ganesan, ChengXiang Zhai, Jiawei Han. Opinosis: A Graph Based Approach to Abstractive Summarization of Highly Redundant Opinions. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010). Beijing, China.",
http://archive.ics.uci.edu/ml/datasets/UNIX+User+Data,483,UNIX User Data Data Set,../machine-learning-databases/UNIX_user_data-mld/,"Text, Sequential",N/A,Computer,N/A,N/A,N/A,N/A,N/A,55223,"Terran Lane:terran '@' ecn.purdue.edu","This file contains 9 sets of sanitized user data drawn from thecommand histories of 8 UNIX computer users at Purdue over the courseof up to 2 years (USER0 and USER1 were generated by the same person,working on different platforms and different projects).  The data isdrawn from tcsh(1) history files and has been parsed and sanitized toremove filenames, user names, directory structures, web addresses,host names, and other possibly identifying items.  Command names,flags, and shell metacharacters have been preserved.  Additionally,**SOF** and **EOF** tokens have been inserted at the start and end ofshell sessions, respectively.  Sessions are concatenated by date orderand tokens appear in the order issued within the shell session, but notimestamps are included in this data.  For example, the two sessions:",N/A,N/A,"This data is made available under conditions of anonymity for the contributing users and may be used for research purposes only. Summaries and research results employing this data may be published, but literal tokens or token sequences from the data may not be published except with express consent of the originators of the data. No portion of this data may be released with or included in a commercial product, nor may any portion of this data be sold or redistributed for profit or as part of of a profit-making endeavor.",Stefan Aeberhard and Danny Coomans and De Vel. THE PERFORMANCE OF STATISTICAL PATTERN RECOGNITION METHODS IN HIGH DIMENSIONAL SETTINGS. James Cook University.  [View Context].
http://archive.ics.uci.edu/ml/datasets/Plants,484,Plants Data Set,../machine-learning-databases/plants/,Multivariate,22632,Life,Categorical,70,12/31/2008,Clustering,Yes,191947,"Original source: USDA plants database: http://plants.usda.gov/index.html  Extracted and encoded by W. Hämäläinen, Department of Computer Science, University of Helsinki, Finland. whamalai '@' cs.helsinki.fi ",The data is in the transactional form. It contains the Latin names (species or genus) and state abbreviations. ,Each row contains a Latin name (species or genus) and a list of state abbreviations. ,"Hämäläinen, W. and Nykänen, M.: Efficient discovery of statistically significant association rules. Proceedings of the 8th IEEE International Conference on Data Mining (ICDM 2008), pp. 203-212. IEEE Computer Society 2008.","Even if the data is processed, it is good to give a reference to the original source:USDA, NRCS. 2008. The PLANTS Database ([Web Link], 31 December 2008). National Plant Data Center, Baton Rouge, LA 70874-4490 USA.",
http://archive.ics.uci.edu/ml/datasets/Car+Evaluation,485,Car Evaluation Data Set,../machine-learning-databases/car/,Multivariate,1728,N/A,Categorical,6,6/1/1997,Classification,No,1212646,"Creator:  Marko Bohanec Donors:  1. Marko Bohanec   (marko.bohanec '@' ijs.si)2. Blaz Zupan      (blaz.zupan '@' ijs.si)","Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure: CAR                      car acceptability. PRICE                  overall price. . buying               buying price. . maint                price of the maintenance. TECH                   technical characteristics. . COMFORT              comfort. . . doors              number of doors. . . persons            capacity in terms of persons to carry. . . lug_boot           the size of luggage boot. . safety               estimated safety of the car Input attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see [Web Link]). The Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety. Because of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.","Class Values: unacc, acc, good, vgood Attributes: buying:   vhigh, high, med, low.maint:    vhigh, high, med, low.doors:    2, 3, 4, 5more.persons:  2, 4, more.lug_boot: small, med, big.safety:   low, med, high.","M. Bohanec and V. Rajkovic: Knowledge acquisition and explanation for multi-attribute decision making. In 8th Intl Workshop on Expert Systems and their Applications, Avignon, France. pages 59-78, 1988.[Web Link]  B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by function decomposition. ICML-97, Nashville, TN. 1997 (to appear)[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Qingping Tao Ph. D. MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004.  [View Context].Daniel J. Lizotte and Omid Madani and Russell Greiner. Budgeted Learning of Naive-Bayes Classifiers. UAI. 2003.  [View Context].Jianbin Tan and David L. Dowe. MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes. Australian Conference on Artificial Intelligence. 2003.  [View Context].Marc Sebban and Richard Nock and Stéphane Lallich. Stopping Criterion for Boosting-Based Data Reduction Techniques: from Binary to Multiclass Problem. Journal of Machine Learning Research, 3. 2002.  [View Context].Nikunj C. Oza and Stuart J. Russell. Experimental comparisons of online and batch versions of bagging and boosting. KDD. 2001.  [View Context].Marc Sebban and Richard Nock and Jean-Hugues Chauchat and Ricco Rakotomalala. Impact of learning set quality and size on decision tree performances. Int. J. Comput. Syst. Signal, 1. 2000.  [View Context].Iztok Savnik and Peter A. Flach. Discovery of multivalued dependencies from relations. Intell. Data Anal, 4. 2000.  [View Context].Jie Cheng and Russell Greiner. Comparing Bayesian Network Classifiers. UAI. 1999.  [View Context].Huan Liu. A Family of Efficient Rule Generators. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Zhiqiang Yang and Sheng Zhong and Rebecca N. Wright. Privacy-Preserving Classification of Customer Data without Loss of Accuracy. Computer Science Department, Stevens Institute of Technology.  [View Context].Jos'e L. Balc'azar. Rules with Bounded Negations and the Coverage Inference Scheme. Dept. LSI, UPC.  [View Context].Shi Zhong and Weiyu Tang and Taghi M. Khoshgoftaar. Boosted Noise Filters for Identifying Mislabeled Data. Department of Computer Science and Engineering Florida Atlantic University.  [View Context].Hyunwoo Kim and Wei-Yin Loh. Classification Trees with Bivariate Linear Discriminant Node Models. Department of Statistics Department of Statistics University of Tennessee University of Wisconsin.  [View Context].Daniel J. Lizotte. Library Release Form Name of Author. Budgeted Learning of Naive Bayes Classifiers.  [View Context].Nikunj C. Oza and Stuart J. Russell. Online Bagging and Boosting. Computer Science Division University of California.  [View Context].Daniel J. Lizotte and Omid Madani and Russell Greiner. Budgeted Learning, Part II: The Na#ve-Bayes Case. Department of Computing Science University of Alberta.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Gastrointestinal+Lesions+in+Regular+Colonoscopy,486,Gastrointestinal Lesions in Regular Colonoscopy Data Set,../machine-learning-databases/00408/,Multivariate,76,Computer,Real,698,10/15/2016,Classification,N/A,17677,"Pablo Mesejo, pablomesejo '@' gmail.com, Inria, FranceDaniel Pizarro, dani.pizarro '@' gmail.com, University of AlcalÃ¡, Spain","This dataset contains the features extracted from a database of colonoscopic videos showing gastrointestinal lesions. It also contains the ground truth collected from both expert image inspection and histology (in an xlsx file). There are features vectors for 76 lesions, and there are 3 types of lesion: hyperplasic, adenoma and serrated adenoma. It is possible to consider this classification problem as a binary one by combining adenoma and serrated adenoma in the same class. According to this, hyperplasic lesions would belong to the class 'benign' while the other two types of gastrointestinal lesions would go to the 'malignant' class.  The first line/row of the dataset corresponds to the lesion name (text label). Every lesion appears twice because it has been recorded using two types of lights: white light (WL) and narrow band imaging (NBI). The second line/row represents the type of lesion (3 for adenoma, 1 for hyperplasic, and 2 for serrated). And, finally, the third line/row is the type of light used (1 for WL and 2 for NBI). All other rows are the raw features (without any kind of preprocessing):422 2D TEXTURAL FEATURES- First 166 features: AHT: Autocorrelation Homogeneous Texture (Invariant Gabor Texture)- Next 256: Rotational Invariant LBP76 2D COLOR FEATURES- 16 Color Naming- 13 Discriminative Color- 7 Hue- 7 Opponent- 33 color gray-level co-occurrence matrix200 3D SHAPE FEATURES- 100 shapeDNA- 100 KPCA The main objective of this dataset is to study how good computers can be at diagnosing gastrointestinal lesions from regular colonoscopic videos. In order to compare the performance of machine learning methods with the one offered by humans, we provide the file ground_truth.xlsx that includes the ground truth after histopathology and the opinion of 7 clinicians (4 experts and 3 beginners). An automatic tissue classification approach could save clinician's time by avoiding chromoendoscopy, a time-consuming staining procedure using indigo carmine, as well as could help to assess the severity of individual lesions in patients with many polyps, so that the gastroenterologist would directly focus on those requiring polypectomy. A possible way of proceeding with the classification is to concatenate the information from the two types of light for each lesion, i.e. create a single vector of 1396 elements per lesion. The technical goal is to maximize accuracy while minimizing false positives (lesions that do not need resection but that are classified as if they do) and false negatives (lesions that do need resection but that are classified as if they do not need it). In particular, we are specially interested on maximizing accuracy while reducing false negatives, i.e. minimizing the number of adenoma and serrated adenoma that are classified as hyperplasic. The opposite case is not that serious: the resection of a hyperplasic polyp considering it as an adenoma or serrated adenoma. Another interesting experiment would consist on compare the performance of the best machine learning method we can get with the one provided by human operators (experts and beginners). The best results obtained so far, in the binary case, using leave-one-out and Random Forest with 1000 trees (using color+texture+3D with NBI), corresponded to an accuracy of ~89,5%, sensitivity ~94,5% and specificity ~76% (considering as positive condition the resection). This is the best confusion matrix found so far:                     Classified as		Resection	No-ResectionResection       52			3No-Resection	5			16 The best results obtained in the multi-class case, using leave-one-out and Random Subspace of SVMs (color+texture+3D using WL), were as follows:                   Classified as	Hyp.	       Ser.     	Ade.Hyp.	18		0		3Ser.	2		9		4Ade.	7		4		29 Overall Accuracy : 0.7368 Acc Hyp.  	0.84Acc Ser.	0.87Acc Ade.	0.76Sen Hyp.	0.86	Sen Ser.	0.6Sen Ade.	0.725Spe Hyp.	0.84Spe Ser.	0.93Spe Ade.	0.81","First 422 attributes: 2D TEXTURAL FEATURES- 166 features: AHT: Autocorrelation Homogeneous Texture (Invariant Gabor Texture)- Next 256: Rotational Invariant LBP Next 76 attributes: 2D COLOR FEATURES- 16 Color Naming- 13 Discriminative Color- 7 Hue- 7 Opponent- 33 color gray-level co-occurrence matrix Last 200 attributes: 3D SHAPE FEATURES- 100 shapeDNA- 100 KPCA","This dataset was gathered and released as part of the research published in P. Mesejo et al., 'Computer-Aided Classification of Gastrointestinal Lesions in Regular Colonoscopy,' in IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2051-2063, Sept. 2016. ([Web Link])","If you use this dataset, please, cite the following research paper: P. Mesejo et al., 'Computer-Aided Classification of Gastrointestinal Lesions in Regular Colonoscopy,' in IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2051-2063, Sept. 2016.",
http://archive.ics.uci.edu/ml/datasets/Machine+Learning+based+ZZAlpha+Ltd.+Stock+Recommendations+2012-2014,487,Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014 Data Set,../machine-learning-databases/00337/,"Sequential, Time-Series",314080,Business,Real,N/A,6/6/2015,Classification,Yes,51645,"(a) Original owners of data: ZZAlpha Ltd., 4729 E. Sunrise #109, Tucson AZ 85718 USA, info '@' zzalpha.com    (b) Donor of database: Kevin Pratt, Chief Scientist, ZZAlpha Ltd. on behalf of ZZAlpha Ltd.","1. Title of Database: Machine Learning based ZZAlpha Stock Recommendations2. Sources:   (a) Original owners of data: ZZAlpha Ltd., 4729 E. Sunrise #109, Tucson AZ 85718 USA, info '@' zzalpha.com    (b) Donor of database: Kevin Pratt, Chief Scientist, ZZAlpha Ltd. on behalf of ZZAlpha Ltd.   (c) Date received: 6-Jun-2015 3. Past Usage:   (a) Pratt, Kevin.  Proof Protocol for a Machine Learning Technique Making Longitudinal Predictions in Dynamic Contexts. (ACM KDD 2015)    (b) Attribute predicted: for each stock in each portfolio, opening price change over 5 trading days    (c) Indication of study's results.  Significant predictions in multiple portfolios.  See publications.4. Relevant Information Paragraph:   The files were zipped (on a Windows machine) by year.   The data here are the ZZAlphaÂ® machine learning recommendations made for various US traded stock portfolios the morning of each day during the 3 year period Jan 1, 2012 - Dec 31, 2014.  They are deposited here in .txt form for easy accessibility (and as a convenience to users, have had results included for each recommendation).  A .pdf version of the original recommendations file was certified by Digistamp (.p7s) at time of creation each day for stringent auditability.  Please contact info '@' zzalpha.com if you desire to purchase the set of the certified .pdf, .p7s file pairs.  The certified set contains only the recommendations, not the results included in the deposited set here.For convenience, the data deposited includes calculated returns (outcomes) for each recommended transaction.  The returns obviously were not part of the original recommendations when made, but were appended later.  Returns were calculated several days after sale day.The date inside the file reflects the date for which morning trading recommendation was made.  The evaluation of the recommendations, as described in the KDD 2015 article mentioned above, involved comparison of the opening price of the day of recommendation to the opening price five market days later.  As mentioned in the article, evaluation must be adjusted by trading costs and constraints.A recommendation portfolio consists of a segment, a size (1,2,5,10,20), and a side (Long or Short),  and the ticker symbols of the companies recommended for price increase (or decrease in the case of Short) from the opening price to the opening price 5 trading days later.The stocks included must first pass a general screen of $3 recent price and 80,000 recent daily average share volume for inclusion.  Thus penny stocks and micro-caps are not present and even some large cap, but very low prices stocks are omitted.  All stocks must be traded on NYSE, NASDAQ or AMEX at the time of recommendation.The daily file contains all recommendations for all portfolios for the day.  Both long and short recommendations are included. Long entries have duplicates. These are the portfolios:  (Note other portfolios limited to ETFs (exchange traded funds) may be listed each day.  Due to data issues those are incomplete across the time period.)  5. Number of Instances: 755 market days, 41 portfolios, 5 sizes of portfolios, Long and Short6. Number of Attributes    The data set submitted does not include attributes used for prediction. This data is provided as a benchmark of machine learning results in a longitudinal 3 yr period.  Here is a sample content of a line in the files: Jan 04 2005_006 Big_100_5_LONG_SHORT_F.pdf, L, AA 0.959 =25.97/27.09, AMAT 0.950 =14.70/15.46, EBAY 0.930 =53.33/57.31, PFE 0.995 =19.84/19.95, UPS 0.980 =71.72/73.16, Avg of 5 = 0.963 The above indicates recommendations were made before market open on Jan 4, 2005.  This portfolio was limited to the biggest 100 cap stocks and was of size 5.  It was for 'L' or long recommendations.  The five stocks recommended are shown by ticker, result, price at sale divided by price at purchase.  The average for the five is shown.  Note: The user of this data set must implement its own parser of these files.  The contributor does NOT provide one.Note: The prices used are adjusted prices based on data when results were calculated.  Back-calculation of the adjusted prices using newer data may give different prices, but the ratios will remain the same (+/- rounding errors). 7. For Each Attribute: Not applicable8. Missing Attribute Values: On some days for a few portfolios, results may be missing.  These are tagged as 'missing'.9. Class Distribution: Distribution of positive and negative outcomes vary by portfolio, size, and day. ",See above,"Pratt, Kevin.  Proof Protocol for a Machine Learning Technique Making Longitudinal Predictions in Dynamic Contexts. (ACM KDD 2015)",Please cite as 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',
http://archive.ics.uci.edu/ml/datasets/UJI+Pen+Characters+%28Version+2%29,488,UJI Pen Characters (Version 2) Data Set,../machine-learning-databases/uji-penchars/version2/,"Multivariate, Sequential",11640,Computer,Integer,N/A,1/22/2009,Classification,N/A,65185,"        F. Prat(*), M. J. Castro(+), D. Llorens(*), A. Marzal(*), and J. M. Vilar(*)         * Departamento de Lenguajes y Sistemas Informáticos          Universitat Jaume I (UJI), 12071 Castellón, SPAIN         + Departamento de Sistemas Informáticos y Computación          Universidad Politécnica de Valencia (UPV), 46071 Valencia, SPAIN  fprat '@' lsi.uji.es         December 2008","We have created the UJIpenchars2 character database by collecting samples from 60 writers at two different sites in two phases: 1st phase, 11 writers, carried out at UJI. 2nd phase, 49 writers, carried out at UPV (44 writers) and UJI (5).Each writer contributed with letters, digits, and other characters and two samples were collected for each pair writer/character. The complete lexicon is as follows:66 letters (33 per case): The 52 ASCII letters. The 14 Spanish non-ASCII letters:Letter n with tilde (2 characters). Vowels with acute accent (10 characters). Letter u with diaeresis (2 characters). The 10 digits.Other 21 characters: The 16 ASCII ones shown in the following line:            . , ; : ? ! ' ' ( ) % - @ $ < > 5 non-ASCII ones: Inverted question and exclamation marks (2 characters). Masculine and feminine ordinal indicators (2 characters). The euro sign (1 character). So the total number of samples in this database is 11640:  60 writers x (66+10+21) characters x 2 repetitions UJIpenchars is a subset of UJIpenchars2 with only 1364 samples: the ASCII letters and digits collected at UJI during the 1st acquisition phase. We have not defined a standard task for UJIpenchars2, but divided the writer set into two disjoint subsets in order to ease the definition of writer independent tasks:40 'trn' writers: The 11 1st phase UJI writers. 29 UPV writers.20 'tst' writers: The 5 2nd phase UJI writers. 15 UPV writers.The distribution of our database consists of 2 files: This 'uji2.names'. The file 'ujipenchars2.txt' containing all the samples in a format described later.The handwriting samples were collected on a Toshiba Portégé M400 Tablet PC using its cordless stylus. Each one of the 60 writers completed 2 non-consecutive sessions. In each session, the corresponding writer was asked to write one exemplar for each character in the lexicon. The acquisition program shows a set of boxes on the screen, one for each required character, and writers are told to write only inside those boxes. Each acquisition box is approximately 13.6 millimetres wide and 20.4 millimetres tall and contais two horizontal guides at approximate distances of 7.5 and 12.7 millimetres from top, respectively. Writers were instructed to clear the content of the corresponding box by using an on-screen button and try again whenever they made a mistake or were unhappy with the writing of any character. Subjects were monitored only when writing their first exemplars and every sample considered OK by its writer was accepted, even if some of its points lay out of the corresponding acquisition box. Only X and Y coordinate information was recorded along the strokes by the acquisition program, without, for instance, pressure level values or timing information. Thus, in multi-stroke samples, no information at all was recorded between strokes. Both coordinates were expressed as integer ink units, with the origin lying at the top left corner of the corresponding acquisition box. X values grow left-to-right and Y values grow downwards. Although we have employed the same acquisition program on identical hardware at UJI and UPV, we have observed that acquisition files seem to show that UPV samples have been collected using acquisition boxes larger than UJI ones. This is due to a different configuration parameter value that, at UPV, makes the acquisition program translate 1 millimetre into 152 ink units, instead of using the standard UJI ratio: 100 ink units per millimetre. If box homogenisation is needed, it can be easily achieved, for instance, by dividing UPV coordinate values by 1.52. We have also observed that runs of consecutive points with identical coordinates were frequently acquired inside strokes; such runs were preserved in this database, so it is up to its users to decide whether to avoid them by an appropriate preprocessing step or not. Although it is a paper mainly devoted to UJIpenchars,            D. Llorens et al.:  'The UJIpenchars Database: A Pen-Based Database of Isolated Handwritten Characters'         Proc. of the 6th International Conference on Language Resources and Evaluation.   2008. contains useful information about UJIpenchars2. It can be found in [Web Link]. ","The file 'ujipenchars2.txt' is a text one with a simple format where all database samples are represented. Because some non-ASCII characters are needed, UTF-8 encoding is employed. In order to describe how attributes are represented in 'ujipenchars2.txt', it is worth explaining the general syntax of the file first. From the higher-level point of view, this file is composed of comment lines and sample representations. A comment line is one beginning with two slashes. In 'ujipenchars2.txt', we have employed comment lines for two purposes:Prior to the set of samples corresponding to each site, a comment acts as a reminder of the number of ink units per length unit on the Tablet PC screen, so these two comments can be found in 'ujipenchars2.txt':      // UJI: 100 units per millimetre       // UPV: 152 units per millimetre  Prior to each sample representation, an ASCII comment tells you which character it represents. For ASCII characters (for instance, an uppercase u), comments may look like this:      // ASCII char: U For non-ASCII characters (for instance, a lowercase o with acute accent), the character identity is represented by means of its HTML entity name:      // Non-ASCII char: oacute A sample representation is composed of a header line followed by the representation of its *sequence of strokes*, where the header line consists of three blank-separated elements: the word 'WORD', the representation of the *character identity*, and the *session identifier*.  For instance, a semicolon sample representation may look like this:           WORD ; trn_UJI_W03-01             NUMSTROKES 2             POINTS 9 # 541 1001 541 1001 540 987 540 987 530 977 530 977 530 977 530 977 530 977             POINTS 8 # 518 1227 500 1257 480 1291 470 1309 465 1318 458 1330 458 1330 471 1312  A detailed description on how information about each attribute is represented in 'ujipenchars2.txt' follows:Character identity: It is represented by the character itself (';' in the previous example), one out of 97 possibilities. Remember that UTF-8 encoding is employed, so non-ASCII characters need more than a byte to be encoded.  Session identifier: It is composed by a long writer identifier ('trn_UJI_W03' in the previous example) and a repetition number ('01' or '02') separated by a hyphen, where a long writer identifier consists of three elements separated by underscores:A writer set identifier, 'trn' (writers for training) or 'tst' (writers for test). A site identifier, 'UJI' or 'UPV'. A short writer identifier, like 'W03' in the previous example. Writers are numbered from 1 to 60.  Sequence of strokes: Its representation consists of a number of lines where individual elements are separated by blanks. The elements of the first line are the word 'NUMSTROKES' and an unsigned integer representing the number of strokes in the sample. This number varies from 1 to 5 in 'ujipenchars2.txt'. And, for each stroke, a line represents its points with the following elements:The word 'POINTS'. An unsigned integer representing the number of points in the stroke. A hash character. For each point in the stroke, two integers representing its X and Y coordinates in ink units. Remember that X values grow left-to-right, Y values grow downwards, and the ratio of length to ink units varies from site to site. Moreover, we have observed some negative coordinate values in 'ujipenchars2.txt'.","D. Llorens et al.,  'The UJIpenchars Database: A Pen-Based Database of Isolated Handwritten Characters'Proc. of the 6th International Conference on Language Resources and Evaluation.  2008. ","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/MONK%27s+Problems,489,MONK's Problems Data Set,../machine-learning-databases/monks-problems/,Multivariate,432,N/A,Categorical,7,10/1/1992,Classification,No,211055,"Donor:  Sebastian ThrunSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213, USAE-mail: thrun '@' cs.cmu.edu","The MONK's problem were the basis of a first international comparison of learning algorithms. The result of this comparison is summarized in ""The MONK's Problems - A Performance Comparison of Different Learning algorithms"" by S.B. Thrun, J. Bala, E. Bloedorn, I.  Bratko, B. Cestnik, J. Cheng, K. De Jong, S.  Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J.  Kreuziger, R.S. Michalski, T. Mitchell, P.  Pachowicz, Y. Reich H.  Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang has been published as Technical Report CS-CMU-91-197, Carnegie Mellon University in Dec. 1991. One significant characteristic of this comparison is that it was performed by a collection of researchers, each of whom was an advocate of the technique they tested (often they were the creators of the various methods). In this sense, the results are less biased than in comparisons performed by a single person advocating a specific learning method, and more accurately reflect the generalization behavior of the learning techniques as applied by knowledgeable users. There are three MONK's problems.  The domains for all MONK's problems are the same (described below).  One of the MONK's problems has noise added. For each problem, the domain has been partitioned into a train and test set.","    1. class: 0, 1     2. a1:    1, 2, 3    3. a2:    1, 2, 3    4. a3:    1, 2    5. a4:    1, 2, 3    6. a5:    1, 2, 3, 4    7. a6:    1, 2    8. Id:    (A unique symbol for each instance)","Wnek, J., ""Hypothesis-driven Constructive Induction,"" PhD dissertation, School of Information Technology and Engineering, Reports of Machine Learning and Inference Laboratory, MLI 93-2, Center for Artificial Intelligence, George Mason University, March 1993.[Web Link]  Wnek, J. and Michalski, R.S., ""Comparing Symbolic and Subsymbolic Learning: Three Studies,"" in Machine Learning: A Multistrategy Approach, Vol. 4., R.S. Michalski and G. Tecuci (Eds.), Morgan Kaufmann, San Mateo, CA, 1993.[Web Link]  See File: thrun.comparison.ps.Z","Please refer to the Machine Learning
Repository's citation policy","Jianbin Tan and David L. Dowe. MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes. Australian Conference on Artificial Intelligence. 2003.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski. Ensembles of Similarity-based Models. Intelligent Information Systems. 2001.  [View Context].Alexey Tsymbal and Seppo Puuronen and Vagan Y. Terziyan. Arbiter Meta-Learning with Dynamic Selection of Classifiers and Its Experimental Investigation. ADBIS. 1999.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Blai Bonet and Hector Geffner. Learning Sorting and Decision Trees with POMDPs. ICML. 1998.  [View Context].Jan C. Bioch and D. Meer and Rob Potharst. Bivariate Decision Trees. PKDD. 1997.  [View Context].Ron Kohavi. The Power of Decision Tables. ECML. 1995.  [View Context].Geoffrey I. Webb. OPUS: An Efficient Admissible Algorithm for Unordered Search. J. Artif. Intell. Res. (JAIR, 3. 1995.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski. Meta-learning: searching in the model space. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Ron Kohavi and Brian Frasca. Useful Feature Subsets and Rough Set Reducts. the Third International Workshop on Rough Sets and Soft Computing.  [View Context].Chotirat Ann and Dimitrios Gunopulos. Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection. Computer Science Department University of California.  [View Context].Wl odzisl/aw Duch and Rafal Adamczak and Krzysztof Grabczewski and Norbert Jankowski. Control and Cybernetics. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Ron Kohavi and Dan Sommerfield. To Appear in KDD-98 Targeting Business Users with Decision Table Classifiers. Data Mining and Visualization Silicon Graphics, Inc.  [View Context].Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. A hybrid method for extraction of logical rules from data. Department of Computer Methods, Nicholas Copernicus University.  [View Context].Karol Grudzi nski and Wl/odzisl/aw Duch. SBL-PM: A Simple Algorithm for Selection of Reference Instances in Similarity Based Methods. Department of Computer Methods, Nicholas Copernicus University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Musk+%28Version+2%29,490,Musk (Version 2) Data Set,../machine-learning-databases/musk/,Multivariate,6598,Physical,Integer,168,9/12/1994,Classification,No,72150,"Creators:   AI Group at Arris Pharmaceutical Corporationcontact:  David Chapman or Ajay JainArris Pharmaceutical Corporation385 Oyster Point Blvd.South San Francisco, CA 94080415-737-8600zvona '@' arris.com, jain '@' arris.com  Donor:      Tom DietterichDepartment of Computer ScienceOregon State UniversityCorvallis, OR 97331503-737-5559tgd '@' cs.orst.edu","This dataset describes a set of 102 molecules of which 39 are judged by human experts to be musks and the remaining 63 molecules are judged to be non-musks.  The goal is to learn to predict whether new molecules will be musks or non-musks.  However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule.  Because bonds can rotate, a single molecule can adopt many different shapes.  To generate this data set, all the low-energy conformations of the molecules were generated to produce 6,598 conformations.  Then, a feature vector was extracted that describes each conformation.  This many-to-one relationship between feature vectors and molecules is called the ""multiple instance problem"".  When learning a classifier for this data, the classifier should classify a molecule as ""musk"" if ANY of its conformations is classified as a musk.  A molecule should be classified as ""non-musk"" if NONE of its conformations is classified as a musk.","   molecule_name:       Symbolic name of each molecule.  Musks have names such as MUSK-188.  Non-musks have names such as NON-MUSK-jp13.   conformation_name:   Symbolic name of each conformation.  These have the format MOL_ISO+CONF, where MOL is the molecule number, ISO is the stereoisomer number (usually 1), and CONF is the conformation number.    f1 through f162:     These are ""distance features"" along rays (see paper cited above).  The distances are measured in hundredths of Angstroms.  The distances may be negative or positive, since they are actually measured relative to an origin placed along each ray.  The origin was defined by a ""consensus musk"" surface that is no longer used.  Hence, any experiments with the data should treat these feature values as lying on an arbitrary continuous scale.  In particular, the algorithm should not make any use of the zero point or the sign of each feature value.    f163:                This is the distance of the oxygen atom in the molecule to a designated point in 3-space. This is also called OXY-DIS.   f164:                OXY-X: X-displacement from the designated point.   f165:                OXY-Y: Y-displacement from the designated point.   f166:                OXY-Z: Z-displacement from the designated point.    class:               0 => non-musk, 1 => musk    Please note that the molecule_name and conformation_name attributes should not be used to predict the class.","Dietterich, T. G., Jain, A., Lathrop, R., Lozano-Perez, T. (1994). A comparison of dynamic reposing and tangent distance for drug activity prediction.  Advances in Neural Information Processing Systems, 6.  San Mateo, CA: Morgan Kaufmann.  216--223.[Web Link]  Jain, A. N., Dietterich, T. G., Lathrop, R. H., Chapman, D., Critchlow, R. E., Bauer, B. E., Webster, T. A., Lozano-Perez, T.  Compass: A shape-based machine learning tool for drug design.  Computer-Aided Molecular Design. [Web Link]  Dietterich, T. G., Lathrop, R. H., Lozano-Perez, T. Solving the multiple-instance problem with axis-parallel rectangles.  Artificial Intelligence.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Qingping Tao Ph. D. MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004.  [View Context].Qingping Tao and Stephen Scott and N. V. Vinodchandran and Thomas T. Osugi. SVM-based generalized multiple-instance learning via approximate box counting. ICML. 2004.  [View Context].Giorgio Valentini. Random Aggregated and Bagged Ensembles of SVMs: An Empirical Bias?Variance Analysis. Multiple Classifier Systems. 2004.  [View Context].Giorgio Valentini. Ensemble methods based on bias--variance analysis Theses Series DISI-TH-2003. Dipartimento di Informatica e Scienze dell'Informazione . 2003.  [View Context].Zhi-Hua Zhou and Min-Ling Zhang. Ensembles of Multi-instance Learners. ECML. 2003.  [View Context].Giorgio Valentini and Thomas G. Dietterich. Low Bias Bagged Support Vector Machines. ICML. 2003.  [View Context].Stephen D. Bay. Combining Nearest Neighbor Classifiers Through Multiple Feature Subsets. ICML. 1998.  [View Context].Hendrik Blockeel and Luc De Raedt. Lookahead and Discretization in ILP. ILP. 1997.  [View Context].Zhi-Hua Zhou and Min-Ling Zhang. Solving Multi-Instance Problems with Classifier Ensemble Based on Constructive Clustering. National Laboratory for Novel Software Technology.  [View Context].Hendrik Blockeel and Luc De Raedt. Top-down Induction of Logical Decision Trees. Katholieke Universiteit Leuven Department of Computer Science.  [View Context].Zhi-Hua Zhou and Hua Zhou. Multi-Instance Learning: A Survey. National Laboratory for Novel Software Technology.  [View Context].Zhi-Hua Zhou and Min-Ling Zhang. Neural Networks for Multi-Instance Learning. National Laboratory for Novel Software Technology, Nanjing University.  [View Context].Giorgio Valentini. An experimental bias--variance analysis of SVM ensembles based on resampling techniques.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Dermatology,491,Dermatology Data Set,../machine-learning-databases/dermatology/,Multivariate,366,Life,"Categorical, Integer",33,1/1/1998,Classification,Yes,222240,"Original Owners: 1. Nilsel Ilter, M.D., Ph.D., Gazi University, School of Medicine06510 Ankara, TurkeyPhone: +90 (312) 214 1080 2. H. Altay Guvenir, PhD., Bilkent University,Department of Computer Engineering and Information Science,06533 Ankara, TurkeyPhone: +90 (312) 266 4133Email: guvenir '@' cs.bilkent.edu.tr  Donor:  H. Altay Guvenir,Bilkent University,Department of Computer Engineering and Information Science,06533 Ankara, TurkeyPhone: +90 (312) 266 4133Email: guvenir '@' cs.bilkent.edu.tr","This database contains 34 attributes, 33 of which are linear valued and one of them is nominal.  The differential diagnosis of erythemato-squamous diseases is a real problem in dermatology. They all share the clinical features of erythema and scaling, with very little differences. The diseases in this group are psoriasis, seboreic dermatitis, lichen planus, pityriasis rosea, cronic dermatitis, and pityriasis rubra pilaris. Usually a biopsy is necessary for the diagnosis but unfortunately these diseases share many histopathological features as well. Another difficulty for the differential diagnosis is that a disease may show the features of another disease at the beginning stage and may have the characteristic features at the following stages. Patients were first evaluated clinically with 12 features. Afterwards, skin samples were taken for the evaluation of 22 histopathological features. The values of the histopathological features are determined by an analysis of the samples under a microscope.  In the dataset constructed for this domain, the family history feature has the value 1 if any of these diseases has been observed in the family, and 0 otherwise. The age feature simply represents the age of the patient. Every other feature (clinical and histopathological) was given a degree in the range of 0 to 3. Here, 0 indicates that the feature was not present, 3 indicates the largest amount possible, and 1, 2 indicate the relative intermediate values. The names and id numbers of the patients were recently removed from the database.","      Clinical Attributes: (take values 0, 1, 2, 3, unless otherwise indicated)      1: erythema      2: scaling      3: definite borders      4: itching      5: koebner phenomenon      6: polygonal papules      7: follicular papules      8: oral mucosal involvement      9: knee and elbow involvement     10: scalp involvement     11: family history, (0 or 1)     34: Age (linear)      Histopathological Attributes: (take values 0, 1, 2, 3)     12: melanin incontinence     13: eosinophils in the infiltrate     14: PNL infiltrate     15: fibrosis of the papillary dermis     16: exocytosis     17: acanthosis     18: hyperkeratosis     19: parakeratosis     20: clubbing of the rete ridges     21: elongation of the rete ridges     22: thinning of the suprapapillary epidermis     23: spongiform pustule     24: munro microabcess     25: focal hypergranulosis     26: disappearance of the granular layer     27: vacuolisation and damage of basal layer     28: spongiosis     29: saw-tooth appearance of retes     30: follicular horn plug     31: perifollicular parakeratosis     32: inflammatory monoluclear inflitrate     33: band-like infiltrate","G. Demiroz, H. A. Govenir, and N. Ilter, ""Learning Differential Diagnosis of Eryhemato-Squamous Diseases using Voting Feature Intervals"", Aritificial Intelligence in Medicine[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Vassilis Athitsos and Stan Sclaroff. Boosting Nearest Neighbor Classifiers for Multiclass Recognition. Boston University Computer Science Tech. Report No, 2004-006. 2004.  [View Context].Gisele L. Pappa and Alex Alves Freitas and Celso A A Kaestner. Attribute Selection with a Multi-objective Genetic Algorithm. SBIA. 2002.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. An Ant Colony Based System for Data Mining: Applications to Medical Data. CEFET-PR, CPGEI Av. Sete de Setembro, 3165.  [View Context].Gisele L. Pappa and Alex Alves Freitas and Celso A A Kaestner. AMultiobjective Genetic Algorithm for Attribute Selection. Computing Laboratory Pontificia Universidade Catolica do Parana University of Kent at Canterbury.  [View Context].Perry Moerland. Mixtures of latent variable models for density estimation and classification. E S E A R C H R E P R O R T I D I A P D a l l e M o l l e I n s t i t u t e f o r Pe r cep t ua l A r t i f i c i a l Intelligence .  [View Context].H. Altay Guvenir. A Classification Learning Algorithm Robust to Irrelevant Features. Bilkent University, Department of Computer Engineering and Information Science.  [View Context].M. V. Fidelis and Heitor S. Lopes and Alex Alves Freitas. Discovering Comprehensible Classification Rules with a Genetic Algorithm. UEPG, CPD CEFET-PR, CPGEI PUC-PR, PPGIA Praa Santos Andrade, s/n Av. Sete de Setembro.  [View Context].Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery. CEFET-PR, Curitiba.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King%29,492,Chess (King-Rook vs. King) Data Set,../machine-learning-databases/chess/king-rook-vs-king/,Multivariate,28056,Game,"Categorical, Integer",6,6/1/1994,Classification,No,126843,"Creators:  Database generated by Michael Bain and Arthur van Hoff at the Turing Institute, Glasgow, UK. Donor:  Michael Bain (mike '@' cse.unsw.edu.au), AI Lab, Computer ScienceUniversity of New South Wales, Sydney 2052, Australia.(tel) +61 2 385 3939(fax) +61 2 663 4576","An Inductive Logic Programming (ILP) or relational learning framework is assumed (Muggleton, 1992). The learning system is provided with examples of chess positions described only by the coordinates of the pieces on the board. Background knowledge in the form of row and column differences is also supplied. The relations necessary to form a correct and concise classifier for the target concept must be discovered by the learning system (the examples already provide a complete extensional definition). The task is closely related to Quinlan's (1983) application of ID3 to classify White King and Rook against Black King and Knight (KRKN) positions as lost 2-ply or lost 3-ply. The framework is similar in that the example positions supply only low-grade data. An important difference is that additional background predicates of the kind supplied in the KRKN study via hand-crafted attributes are not provided for this KRK domain. Chess endgames are complex domains which are enumerable. Endgame databases are tables of stored game-theoretic values for the enumerated elements (legal positions) of the domain. The game-theoretic values stored denote whether or not positions are won for either side, or include also the depth of win (number of moves) assuming minimax-optimal play. From the point of view of experiments on computer induction such databases provide not only a source of examples but also an oracle (Roycroft, 1986) for testing induced rules. However a chess endgame database differs from, say, a relational database containing details of parts and suppliers in the following important respect. The combinatorics of computing the required game-theoretic values for individual position entries independently would be prohibitive. Therefore all the database entries are generated in a single iterative process using the ``standard backup'' algorithm (Thompson, 1986). A KRK database was described by Clarke (1977). The current database was described and used for machine learning experiments in Bain (1992; 1994). It should be noted that our database is not guaranteed correct, but the class distribution is the same as Clarke's database. In (Bain 1992; 1994) the task was classification of positions in the database as won for white in a fixed number of moves, assuming optimal play by both sides. The problem was structured into separate sub-problems by depth-of-win ordered draw, zero, one, ..., sixteen. When learning depth d all examples at depths > d are used as negatives. Quinlan (1994) applied Foil to learn a complete and correct solution for this task. The typical complexity of induced classifiers in this domain suggest that the task is demanding when background knowledge is restricted.","   1. White King file (column)   2. White King rank (row)   3. White Rook file   4. White Rook rank   5. Black King file   6. Black King rank   7. optimal depth-of-win for White in 0 to 16 moves, otherwise drawn {draw, zero, one, two, ..., sixteen}.","M. Bain. ""Learning optimal chess strategies"", ILP 92:  ICOT TM-1182, S. Muggleton, Institute for New Generation Computer Technology, Tokyo, Japan.[Web Link]  M. Bain. Learning Logical Exceptions in Chess.  PhD dissertation. University of Strathclyde. 1994.[Web Link]  M. R. B. Clarke. A Quantitative Study of King and Pawn Against King.  Advances in Computer Chess, 1, 108-110. M. R. B. Clarke, ed.  Edinburgh University Press. Edinburgh. 1977[Web Link]  S. Muggleton. Inductive Logic Programming, 3--27. S. Muggleton, ed. Academic Press, London, 1992.[Web Link]  J. R. Quinlan. Learning Efficient Classification Procedures and their Application to Chess End Games.Machine Learning: An Artificial Intelligence Approach. 464--482. R. Michalski and J. Carbonnel and T. Mitchell, eds. Tioga, 1983. Palo Alto, CA. [Web Link]  A. J. Roycroft. Database ""Oracles'': Necessary and desirable features. International Computer Chess Association Journal. 8, 2, 1986. 100--104.[Web Link]  K. Thompson. Retrograde Analysis of Certain Endgames.International Computer Chess Association Journal. 8, 3, 1986.  131-139.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Manuel Oliveira. Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted. University of Alberta Library. 2005.  [View Context].Marcus Hutter and Marco Zaffalon. Distribution of Mutual Information from Complete and Incomplete Data. CoRR, csLG/0403025. 2004.  [View Context].Ira Cohen and Fabio Gagliardi Cozman and Nicu Sebe and Marcelo Cesar Cirelo and Thomas S. Huang. Semisupervised Learning of Classifiers: Theory, Algorithms, and Their Application to Human-Computer Interaction. IEEE Trans. Pattern Anal. Mach. Intell, 26. 2004.  [View Context].Douglas Burdick and Manuel Calimlim and Jason Flannick and Johannes Gehrke and Tomi Yiu. MAFIA: A Performance Study of Mining Maximal Frequent Itemsets. FIMI. 2003.  [View Context].Russell Greiner and Wei Zhou. Structural Extension to Logistic Regression: Discriminative Parameter Learning of Belief Net Classifiers. AAAI/IAAI. 2002.  [View Context].Tanzeem Choudhury and James M. Rehg and Vladimir Pavlovic and Alex Pentland. Boosting and Structure Learning in Dynamic Bayesian Networks for Audio-Visual Speaker Detection. ICPR (3). 2002.  [View Context].Marco Zaffalon and Marcus Hutter. Robust Feature Selection by Mutual Information Distributions. CoRR, csAI/0206006. 2002.  [View Context].Michael G. Madden. Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. CoRR, csLG/0211003. 2002.  [View Context].James Bailey and Thomas Manoukian and Kotagiri Ramamohanarao. Fast Algorithms for Mining Emerging Patterns. PKDD. 2002.  [View Context].Jie Cheng and Russell Greiner. Learning Bayesian Belief Network Classifiers: Algorithms and System. Canadian Conference on AI. 2001.  [View Context].Boonserm Kijsirikul and Sukree Sinthupinyo and Kongsak Chongkasemwongse. Approximate Match of Rules Using Backpropagation Neural Networks. Machine Learning, 44. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. DeEPs: A New Instance-based Discovery and Classification System. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001.  [View Context].Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao. Instance-Based Classification by Emerging Patterns. PKDD. 2000.  [View Context].Mark A. Hall. Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning. Doctor of Philosophy at The University of Waikato. 1999.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].Adam J. Grove and Dale Schuurmans. Boosting in the Limit: Maximizing the Margin of Learned Ensembles. AAAI/IAAI. 1998.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Brian R. Gaines. Structured and Unstructured Induction with EDAGs. KDD. 1995.  [View Context].Ron Kohavi and Dan Sommerfield. Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology. KDD. 1995.  [View Context].Grigorios Tsoumakas and Ioannis P. Vlahavas. Fuzzy Meta-Learning: Preliminary Results. Greek Secretariat for Research and Technology.  [View Context].Nikunj C. Oza and Stuart J. Russell. Online Bagging and Boosting. Computer Science Division University of California.  [View Context].Hankil Yoon and Khaled A. Alsabti and Sanjay Ranka. Tree-based Incremental Classification for Large Datasets. CISE Department, University of Florida.  [View Context].Omid Madani and David M. Pennock and Gary William Flake. Co-Validation: Using Model Disagreement to Validate Classification Algorithms. Yahoo! Research Labs.  [View Context].M. A. Galway and Michael G. Madden. DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm. Department of Information Technology National University of Ireland, Galway.  [View Context].BayesianClassifi552 Pat Langley and Wayne Iba. In Proceedings of the Tenth National ConferenceonArtifi256 Intelligence( 42840. Lambda Kevin Thompson.  [View Context].Jerome H. Friedman and Ron Kohavi and Youngkeol Yun. To appear in AAAI-96 Lazy Decision Trees. Statistics Department and Stanford Linear Accelerator Center Stanford University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Sonar%2C+Mines+vs.+Rocks%29,493,"Connectionist Bench (Sonar, Mines vs. Rocks) Data Set",../machine-learning-databases/undocumented/connectionist-bench/sonar/,Multivariate,208,Physical,Real,60,N/A,Classification,N/A,181029,"The data set was contributed to the benchmark collection by Terry Sejnowski, now at the Salk Institute and the University of California at San Deigo.  The data set was developed in collaboration with R. Paul Gorman of Allied-Signal Aerospace Technology Center.","The file ""sonar.mines"" contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions.  The file ""sonar.rocks"" contains 97 patterns obtained from rocks under similar conditions.  The transmitted sonar signal is a frequency-modulated chirp, rising in frequency.  The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock. Each pattern is a set of 60 numbers in the range 0.0 to 1.0.  Each number represents the energy within a particular frequency band, integrated over a certain period of time.  The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp. The label associated with each record contains the letter ""R"" if the object is a rock and ""M"" if it is a mine (metal cylinder).  The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.",N/A,"1. Gorman, R. P., and Sejnowski, T. J. (1988).  ""Analysis of Hidden Units in a Layered Network Trained to Classify Sonar Targets"" in Neural Networks, Vol. 1, pp. 75-89.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Zhi-Hua Zhou and Yuan Jiang. NeC4.5: Neural Ensemble Based C4.5. IEEE Trans. Knowl. Data Eng, 16. 2004.  [View Context].Jianbin Tan and David L. Dowe. MML Inference of Oblique Decision Trees. Australian Conference on Artificial Intelligence. 2004.  [View Context].Jeremy Kubica and Andrew Moore. Probabilistic Noise Identification and Data Cleaning. ICDM. 2003.  [View Context].Dennis DeCoste. Anytime Query-Tuned Kernel Machines via Cholesky Factorization. SDM. 2003.  [View Context].Fei Sha and Lawrence K. Saul and Daniel D. Lee. Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines. NIPS. 2002.  [View Context].Marina Skurichina and Ludmila Kuncheva and Robert P W Duin. Bagging and Boosting for the Nearest Mean Classifier: Effects of Sample Size on Diversity and Accuracy. Multiple Classifier Systems. 2002.  [View Context].Dennis DeCoste. Anytime Interval-Valued Outputs for Kernel Machines: Fast Support Vector Machine Classification via Distance Geometry. ICML. 2002.  [View Context].Ayhan Demiriz and Kristin P. Bennett and Mark J. Embrechts. A Genetic Algorithm Approach for Semi-Supervised Clustering. E-Business Department, Verizon Inc.. 2002.  [View Context].Michail Vlachos and Carlotta Domeniconi and Dimitrios Gunopulos and George Kollios and Nick Koudas. Non-linear dimensionality reduction techniques for classification and visualization. KDD. 2002.  [View Context].Xavier Llor and David E. Goldberg and Ivan Traus and Ester Bernad i Mansilla. Accuracy, Parsimony, and Generality in Evolutionary Learning Systems via Multiobjective Selection. IWLCS. 2002.  [View Context].Wl/odzisl/aw Duch and Karol Grudzinski. Ensembles of Similarity-based Models. Intelligent Information Systems. 2001.  [View Context].Kristin P. Bennett and Ayhan Demiriz and John Shawe-Taylor. A Column Generation Algorithm For Boosting. ICML. 2000.  [View Context].Chris Drummond and Robert C. Holte. Explicitly representing expected cost: an alternative to ROC representation. KDD. 2000.  [View Context].Juan J. Rodr##guez and Carlos J. Alonso and Henrik Bostrom. Boosting Interval Based Literals. 2000.  [View Context].Chris Drummond and Robert C. Holte. Exploiting the Cost (In)sensitivity of Decision Tree Splitting Criteria. ICML. 2000.  [View Context].Carlotta Domeniconi and Jing Peng and Dimitrios Gunopulos. An Adaptive Metric Machine for Pattern Classification. NIPS. 2000.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Improved Generalization Through Explicit Optimization of Margins. Machine Learning, 38. 2000.  [View Context].Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining. Institute of Information Science. 1999.  [View Context].Art B. Owen. Tubular neighbors for regression and classification. Stanford University. 1999.  [View Context].Stavros J. Perantonis and Vassilis Virvilis. Input Feature Extraction for Multilayered Perceptrons Using Supervised Principal Component Analysis. Neural Processing Letters, 10. 1999.  [View Context].Jing Peng and Bir Bhanu. Feature Relevance Estimation for Image Databases. Multimedia Information Systems. 1999.  [View Context].Lorne Mason and Jonathan Baxter and Peter L. Bartlett and Marcus Frean. Boosting Algorithms as Gradient Descent. NIPS. 1999.  [View Context].Ayhan Demiriz and Kristin P. Bennett and Mark J. Embrechts. Semi-Supervised Clustering Using Genetic Algorithms. Dept. 1999.  [View Context].Kagan Tumer and Joydeep Ghosh. Robust Combining of Disparate Classifiers through Order Statistics. CoRR, csLG/9905013. 1999.  [View Context].Hiroshi Shimodaira and Jun Okui and Mitsuru Nakai. Modified Minimum Classification Error Learning and Its Application to Neural Networks. SSPR/SPR. 1998.  [View Context].Richard Maclin. Boosting Classifiers Regionally. AAAI/IAAI. 1998.  [View Context].Lorne Mason and Peter L. Bartlett and Jonathan Baxter. Direct Optimization of Margins Improves Generalization in Combined Classifiers. NIPS. 1998.  [View Context].Thomas G. Dietterich. Machine-Learning Research. AI Magazine, 18. 1997.  [View Context].Richard Maclin and David W. Opitz. An Empirical Evaluation of Bagging and Boosting. AAAI/IAAI. 1997.  [View Context].Perry Moerland and E. Fiesler and I. Ubarretxena-Belandia. Martigny - Valais - Suisse Discrete All-Positive Multilayer Perceptrons for Optical Implementation. E S E A R C H R E P R O R T I D I A P. 1997.  [View Context].Erin J. Bredensteiner and Kristin P. Bennett. Feature Minimization within Decision Trees. National Science Foundation. 1996.  [View Context].Christos Emmanouilidis and A. Hunter and Dr J. MacIntyre. A Multiobjective Evolutionary Setting for Feature Selection and a Commonality-Based Crossover Operator. Centre for Adaptive Systems, School of Computing, Engineering and Technology University of Sunderland.  [View Context].Elena Smirnova and Ida G. Sprinkhuizen-Kuyper and I. Nalbantis and b. ERIM and Universiteit Rotterdam. Unanimous Voting using Support Vector Machines. IKAT, Universiteit Maastricht.  [View Context].Alain Rakotomamonjy. Leave-One-Out errors in Bipartite Ranking SVM. PSI CNRS FRE2645 INSA de Rouen Avenue de l'universite.  [View Context].Hiroshi Shimodaira and Jun Okui and Mitsuru Nakai. IMPROVING THE GENERALIZATION PERFORMANCE OF THE MCE/GPD LEARNING. School of Information Science Japan Advanced Institute of Science and Technology Tatsunokuchi, Ishikawa.  [View Context].Charles Campbell and Nello Cristianini. Simple Learning Algorithms for Training Support Vector Machines. Dept. of Engineering Mathematics.  [View Context].Ayhan Demiriz and Kristin P. Bennett. Chapter 1 OPTIMIZATIONAPPROACHESTOSEMI-SUPERVISED LEARNING. Department of Decision Sciences and Engineering Systems & Department of Mathematical Sciences, Rensselaer Polytechnic Institute.  [View Context].Ronaldo C. Prati and Peter A. Flach. ROCCER: A ROC convex hull rule learning algorithm. Institute of Mathematics and Computer Science at University of So Paulo.  [View Context].Perry Moerland. Mixtures of latent variable models for density estimation and classification. E S E A R C H R E P R O R T I D I A P D a l l e M o l l e I n s t i t u t e f o r Pe r cep t ua l A r t i f i c i a l Intelligence .  [View Context].Stefan Aeberhard and O. de Vel and Danny Coomans. New Fast Algorithms for Variable Selection based on Classifier Performance. James Cook University.  [View Context].Kristin P. Bennett and Erin J. Bredensteiner. Geometry in Learning. Department of Mathematical Sciences Rensselaer Polytechnic Institute.  [View Context].Carlotta Domeniconi and Bojun Yan. On Error Correlation and Accuracy of Nearest Neighbor Ensemble Classifiers. Information and Software Engineering Department George Mason University.  [View Context].Chris Drummond and Robert C. Holte. C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling. Institute for Information Technology, National Research Council Canada.  [View Context].Alexander K. Seewald. Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften.  [View Context].ESEARCH R and D. R. Ort and Perry Moerland and E. Fiesler and I. Ubarretxena-Belandia. Multilayer Perceptrons for Optical Implementation. Optical Engineering, ol.  [View Context].Yin Zhang and W. Nick Street. Bagging with Adaptive Costs. Management Sciences Department University of Iowa Iowa City.  [View Context].Chiranjib Bhattacharyya. Robust Classification of noisy data using Second Order Cone Programming approach. Dept. Computer Science and Automation, Indian Institute of Science.  [View Context].Andrew Watkins and Jon Timmis and Lois C. Boggess. Artificial Immune Recognition System (AIRS): An ImmuneInspired Supervised Learning Algorithm. (abw5,jt6@kent.ac.uk) Computing Laboratory, University of Kent.  [View Context].Perry Moerland and E. Fiesler and I. Ubarretxena-Belandia. Incorporating LCLV Non-Linearities in Optical Multilayer Neural Networks. Preprint of an article published in Applied Optics.  [View Context].Maria Salamo and Elisabet Golobardes. Analysing Rough Sets weighting methods for Case-Based Reasoning Systems. Enginyeria i Arquitectura La Salle.  [View Context].Jakub Zavrel. An Empirical Re-Examination of Weighted Voting for k-NN. Computational Linguistics.  [View Context].Rudy Setiono and Huan Liu. Neural-Network Feature Selector. Department of Information Systems and Computer Science National University of Singapore.  [View Context].Wl/odzisl/aw Duch and Jerzy J. Korczak. Optimization and global minimization methods suitable for neural networks. Department of Computer Methods, Nicholas Copernicus University.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Automobile,495,Automobile Data Set,../machine-learning-databases/autos/,Multivariate,205,N/A,"Categorical, Integer, Real",26,5/19/1987,Regression,Yes,524634,"Creator/Donor:  Jeffrey C. Schlimmer (Jeffrey.Schlimmer '@' a.gp.cs.cmu.edu) Sources: 1) 1985 Model Import Car and Truck Specifications, 1985 Ward's Automotive Yearbook.2) Personal Auto Manuals, Insurance Services Office, 160 Water Street, New York, NY 10038 3) Insurance Collision Report, Insurance Institute for Highway Safety, Watergate 600, Washington, DC 20037","This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars.  The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price.   Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale.  Actuarians call this process ""symboling"".  A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe. The third factor is the relative average loss payment per insured vehicle year.  This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year. Note: Several of the attributes in the database could be used as a ""class"" attribute.","Attribute: Attribute Range   1. symboling:                -3, -2, -1, 0, 1, 2, 3.  2. normalized-losses:        continuous from 65 to 256.  3. make:                                                    alfa-romero, audi, bmw, chevrolet, dodge, honda,                               isuzu, jaguar, mazda, mercedes-benz, mercury,                               mitsubishi, nissan, peugot, plymouth, porsche,                               renault, saab, subaru, toyota, volkswagen, volvo   4. fuel-type:                diesel, gas.  5. aspiration:               std, turbo.  6. num-of-doors:             four, two.  7. body-style:               hardtop, wagon, sedan, hatchback, convertible.  8. drive-wheels:             4wd, fwd, rwd.  9. engine-location:          front, rear. 10. wheel-base:               continuous from 86.6 120.9. 11. length:                   continuous from 141.1 to 208.1. 12. width:                    continuous from 60.3 to 72.3. 13. height:                   continuous from 47.8 to 59.8. 14. curb-weight:              continuous from 1488 to 4066. 15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor. 16. num-of-cylinders:         eight, five, four, six, three, twelve, two. 17. engine-size:              continuous from 61 to 326. 18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi. 19. bore:                     continuous from 2.54 to 3.94. 20. stroke:                   continuous from 2.07 to 4.17. 21. compression-ratio:        continuous from 7 to 23. 22. horsepower:               continuous from 48 to 288. 23. peak-rpm:                 continuous from 4150 to 6600. 24. city-mpg:                 continuous from 13 to 49. 25. highway-mpg:              continuous from 16 to 54. 26. price:                    continuous from 5118 to 45400.","Kibler, D., Aha, D.W., & Albert,M. (1989).  Instance-based prediction of real-valued attributes. Computational Intelligence,  Vol 5, 51--57.[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Geraldine E. Rosario and Elke A. Rundensteiner and David C. Brown and Matthew O. Ward. Mapping Nominal Values to Numbers for Effective Visualization. INFOVIS. 2003.  [View Context].Wai Lam and Kin Keung and Charles X. Ling. PR 1527. Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong. 2001.  [View Context].Yongge Wang. A New Approach to Fitting Linear Models in High Dimensional Spaces. Alastair Scott (Department of Statistics, University of Auckland).  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Somerville+Happiness+Survey,496,Somerville Happiness Survey Data Set,../machine-learning-databases/00479/,N/A,143,Life,Integer,7,5/24/2018,Classification,N/A,18565,"Waldemar W. Koczkodaj, wkoczkodaj@gmail, independent researcher.","It is a case of supervised learning with the use of Receiver Operating Characteristic (ROC) to select the minimal set of attributes preserving or increasing predictability of the data. ","D = decision attribute (D) with values 0 (unhappy) and 1 (happy)X1 = the availability of information about the city servicesX2 = the cost of housingX3 = the overall quality of public schoolsX4 = your trust in the local policeX5 = the maintenance of streets and sidewalks X6 = the availability of social community events Attributes X1 to X6 have values 1 to 5.","Koczkodaj, W.W.; Li, F.; Wolny-Dominiak, A., RatingScaleReduction package: stepwise rating scale item reduction without predictability loss, R JOURNAL, 10(1): 43-55, 2018. W.W. Koczkodaj, T. Kakiashvili, A. Szymanska, J. Montero-Marin, R. Araya, J. Garcia-Campayo, K. Rutkowski, D. Strzalka, How to reduce the number of rating scale items without predictability loss? Scientometrics, 111(2): 581-593, 2017. Project R package: [Web Link]","For the method: W.W. Koczkodaj, T. Kakiashvili, A. Szymanska, J. Montero-Marin, R. Araya, J. Garcia-Campayo, K. Rutkowski, D. Strzalka, How to reduce the number of rating scale items without predictability loss? Scientometrics, 111(2): 581-593, 2017.",
http://archive.ics.uci.edu/ml/datasets/Smartphone+Dataset+for+Human+Activity+Recognition+%28HAR%29+in+Ambient+Assisted+Living+%28AAL%29,497,Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL) Data Set,../machine-learning-databases/00364/,Time-Series,5744,Computer,Real,561,3/9/2016,Classification,N/A,48257,"-- Creators: Kadian Alicia Davis (1), Evans Boateng Owusu (2)     1 -- Department of Electrical, Electronic, Telecommunications Engineering and Naval Architecture (DITEN),           University of Genova, Genoa - Italy     2 -- Independent Researcher,           Eindhoven,           The Netherlands      Donors: E. B. Owusu (owboateng '@' gmail.com), K. A. Davis (kadian.davis '@' gmail.com)     -- Date: March, 2016","This dataset is an addition to the dataset at  [Web Link]       We collected more dataset to improve the accuracy of our HAR algorithms applied in       a Social connectedness experiment in the domain of Ambient Assisted Living.       The dataset was collected from the in-built accelerometer and gyroscope of a       smartphone worn around the waist of participants. See waist_mounted_phone.PNG.      The data was collected from 30 participants within the age group of 22-79 years.       Each activity (standing, sitting, laying, walking, walking upstairs, walking downstairs) was       performed for 60secs and the 3-axial linear acceleration and 3-axial angular velocity  were       collected at a constant rate of 50Hz.","For each record in the dataset it is provided:    - Triaxial acceleration from the accelerometer (total acceleration).      Filenames: final_acc_train.txt, final_acc_test.txt   - Triaxial Angular velocity from the gyroscope.      Filenames: final_gyro_train.txt, final_gyro_test.txt   - A 561-feature vector with time and frequency domain variables      (extracted from the triaxial data)      Filenames: final_X_train.txt, final_X_test.txt     For more information about the features extracted see (features.txt and features_info.txt)   - The corresponding activity labels. Filenames: final_y_train.txt and final_y_test.txt.","Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.","Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/PPG-DaLiA,498,PPG-DaLiA Data Set,../machine-learning-databases/00495/,"Multivariate, Time-Series",8300000,Computer,Real,11,7/30/2019,Regression,N/A,17754,"Attila Reiss, Robert Bosch GmbH, Corporate Research, Germany, firstname.lastname '@' de.bosch.comIna Indlekofer, Bosch Sensortec GmbH, Germany, firstname.lastname '@' bosch-sensortec.comPhilip Schmidt, Robert Bosch GmbH, Corporate Research, Germany, firstname.lastname '@' de.bosch.com","PPG-DaLiA is a publicly available dataset for PPG-based heart rate estimation. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects while performing a wide range of activities under close to real-life conditions. The included ECG data provides heart rate ground truth. The included PPG- and 3D-accelerometer data can be used for heart rate estimation, while compensating for motion artefacts. Details can be found in the dataset's readme-file, as well as in [1].","Raw sensor data was recorded with two devices: a chest-worn device (RespiBAN) and a wrist-worn device (Empatica E4).The RespiBAN device provides the following sensor data: electrocardiogram (ECG), respiration, and three-axis acceleration. All signals are sampled at 700 Hz.The Empatica E4 device provides the following sensor data: blood volume pulse (BVP, 64 Hz), electrodermal activity (EDA, 4 Hz), body temperature (4 Hz), and three-axis acceleration (32 Hz). The dataset's readme-file contains all further details with respect to the dataset structure, data format (RespiBAN device, Empatica E4 device, synchronised data), study protocol, ground truth generation, etc.","[1] Attila Reiss, Ina Indlekofer, Philip Schmidt, and Kristof Van Laerhoven. 2019. Deep PPG: Large-scale Heart Rate Estimation with Convolutional Neural Networks. MDPI Sensors, 19(14).","You may use this data for scientific, non-commercial purposes, provided that you give credit to the owners when publishing any work based on this data. Please acknowledge publication [1].We recommend to refer to this dataset as PPG-DaLiA, or 'PPG dataset for motion compensation and heart rate estimation in Daily Life Activities'.",
http://archive.ics.uci.edu/ml/datasets/Parkinsons,499,Parkinsons Data Set,../machine-learning-databases/parkinsons/,Multivariate,197,Life,Real,23,6/26/2008,Classification,N/A,264327,"The dataset was created by Max Little of the University of Oxford, in collaboration with the National Centre for Voice and Speech, Denver, Colorado, who recorded the speech signals. The original study published the feature extraction methods for general voice disorders.","This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (""name"" column). The main aim of the data is to discriminate healthy people from those with PD, according to ""status"" column which is set to 0 for healthy and 1 for PD.  The data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around six recordings per patient, the name of the patient is identified in the first column.For further information or to pass on comments, please contact Max Little (littlem '@' robots.ox.ac.uk). Further details are contained in the following reference -- if you use this dataset, please cite:Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering (to appear).","Matrix column entries (attributes):name - ASCII subject name and recording numberMDVP:Fo(Hz) - Average vocal fundamental frequencyMDVP:Fhi(Hz) - Maximum vocal fundamental frequencyMDVP:Flo(Hz) - Minimum vocal fundamental frequencyMDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequencyMDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitudeNHR,HNR - Two measures of ratio of noise to tonal components in the voicestatus - Health status of the subject (one) - Parkinson's, (zero) - healthyRPDE,D2 - Two nonlinear dynamical complexity measuresDFA - Signal fractal scaling exponentspread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation",N/A,"If you use this dataset, please cite the following paper: 'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM. BioMedical Engineering OnLine 2007, 6:23 (26 June 2007)",
http://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data,500,KDD Cup 1999 Data Data Set,../machine-learning-databases/kddcup99-mld/,Multivariate,4000000,Computer,"Categorical, Integer",42,1/1/1999,Classification,N/A,155954,N/A,Please see task description.,N/A,"Salvatore J. Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis, and Philip K. Chan. Cost-based Modeling and Evaluation for Data Mining With Application to Fraud and Intrusion Detection: Results from the JAM Project. [Web Link]","Please refer to the Machine Learning
Repository's citation policy","Stephen D. Bay and Dennis F. Kibler and Michael J. Pazzani and Padhraic Smyth. The UCI KDD Archive of Large Data Sets for Data Mining Research and Experimentation. SIGKDD Explorations, 2. 2000.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/NSF+Research+Award+Abstracts+1990-2003,501,NSF Research Award Abstracts 1990-2003 Data Set,../machine-learning-databases/nsfabs-mld/,Text,129000,N/A,N/A,N/A,11/18/2003,N/A,N/A,47750,"Original Owner and Donor Abstracts provided by: Michael J. PazzaniICS Department, School of Computer Science, UCI, Irvine CA, 92697, USApazzani '@' ics.uci.edu  Bag-of-word data provided by: Amnon MeyersICS Department, School of Computer Science, UCI, Irvine CA, 92697, USAameyers '@' ics.uci.edu ","The abstracts, one per file, were furnished by the NSF (National Science Foundation). A sample abstract is shown in the next section. The bag-of-word data was produced by automatically processing the abstracts with a text analyzer called NSFAbst, built using VisualText. While most fields of the output are very accurate, the authors were not extracted from the Investigator: field with 100% accuracy, due to wide variability in that field. The word list came from a separate process, and may not include all the words of interest in the abstracts. ",N/A,N/A,"Please refer to the Machine Learning
Repository's citation policy",
http://archive.ics.uci.edu/ml/datasets/Carbon+Nanotubes,502,Carbon Nanotubes Data Set,../machine-learning-databases/00448/,Univariate,10721,Computer,Real,8,4/5/2018,Regression,N/A,37372,"Mehmet ACI- Mersin University, Dept of Computer Engineering, maci '@' mersin.edu.trMutlu AVCI- Cukurova University, Dept of Biomedical Engineering, mavci '@' cu.edu.tr","CASTEP can simulate a wide range of properties of materials proprieties using density functional theory (DFT). DFT is the most successful method calculates atomic coordinates faster than other mathematical approaches, and it also reaches more accurate results. The dataset is generated with CASTEP using CNT geometry optimization. Many CNTs are simulated in CASTEP, then geometry optimizations are calculated. Initial coordinates of all carbon atoms are generated randomly. Different chiral vectors are used for each CNT simulation. The atom type is selected as carbon, bond length is used as 1.42 AÂ° (default value). CNT calculation parameters are used as default parameters. To finalize the computation, CASTEP uses a parameter named as elec_energy_tol (electrical energy tolerance) (default 1x10-5 eV) which represents that the change in the total energy from one iteration to the next remains below some tolerance value per atom for a few self-consistent field steps. Initial atomic coordinates (u, v, w), chiral vector (n, m) and calculated atomic coordinates (uâ€™, vâ€™, wâ€™) are obtained from the output files.","The summary of the attributes is given below. Please read the papers ([Web Link] and [Web Link]) for detailed descriptions of the attributes.  Chiral indice n: n parameter of the selected chiral vector.Chiral indice m: n parameter of the selected chiral vector.Initial atomic coordinate u: Randomly generated u parameter of the initial atomic coordinates of all carbon atoms.Initial atomic coordinate v: Randomly generated v parameter of the initial atomic coordinates of all carbon atoms.Initial atomic coordinate w: Randomly generated w parameter of the initial atomic coordinates of all carbon atoms.Calculated atomic coordinate uâ€™: Calculated uâ€™ parameter of the atomic coordinates of all carbon atoms.Calculated atomic coordinate vâ€™: Calculated vâ€™ parameter of the atomic coordinates of all carbon atoms.Calculated atomic coordinate wâ€™: Calculated wâ€™ parameter of the atomic coordinates of all carbon atoms.","ACI, M , AVCI, M . (2016). ARTIFICIAL NEURAL NETWORK APPROACH FOR ATOMIC COORDINATE PREDICTION OF CARBON NANOTUBES.Applied Physics A, 122, 631. [Web Link]","Please cite as:ACI, M , AVCI, M . (2016). ARTIFICIAL NEURAL NETWORK APPROACH FOR ATOMIC COORDINATE PREDICTION OF CARBON NANOTUBES.Applied Physics A, 122, 631. [Web Link] andACI, M , AVCI, M , ACI, Ã‡ . (2017). REDUCING SIMULATION DURATION OF CARBON NANOTUBE USING SUPPORT VECTOR REGRESSION METHOD. Journal of the Faculty of Engineering and Architecture of Gazi University, 32 (3), 901-907. DOI: 10.17341/gazimmfd.337642",
http://archive.ics.uci.edu/ml/datasets/Adult,503,Adult Data Set,../machine-learning-databases/adult/,Multivariate,48842,Social,"Categorical, Integer",14,5/1/1996,Classification,Yes,1880062,"Donor:  Ronny Kohavi and Barry BeckerData Mining and VisualizationSilicon Graphics.e-mail: ronnyk '@' live.com for questions.","Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)) Prediction task is to determine whether a person makes over 50K a year.","Listing of attributes: >50K, <=50K. age: continuous.workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.fnlwgt: continuous.education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.education-num: continuous.marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.sex: Female, Male.capital-gain: continuous.capital-loss: continuous.hours-per-week: continuous.native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.","Ron Kohavi, ""Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid"", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996[Web Link]","Please refer to the Machine Learning
Repository's citation policy","Rakesh Agrawal and Ramakrishnan ikant and Dilys Thomas. Privacy Preserving OLAP. SIGMOD Conference. 2005.  [View Context].Saharon Rosset. Model selection via the AUC. ICML. 2004.  [View Context].Rich Caruana and Alexandru Niculescu-Mizil. An Empirical Evaluation of Supervised Learning for ROC Area. ROCAI. 2004.  [View Context].Rich Caruana and Alexandru Niculescu-Mizil and Geoff Crew and Alex Ksikes. Ensemble selection from libraries of models. ICML. 2004.  [View Context].Bianca Zadrozny. Learning and evaluating classifiers under sample selection bias. ICML. 2004.  [View Context].Wei-Chun Kao and Kai-Min Chung and Lucas Assun and Chih-Jen Lin. Decomposition Methods for Linear Support Vector Machines. Neural Computation, 16. 2004.  [View Context].Bart Hamers and J. A. K Suykens. Coupled Transductive Ensemble Learning of Kernel Models. Bart De Moor. 2003.  [View Context].Andrew W. Moore and Weng-Keen Wong. Optimal Reinsertion: A New Search Operator for Accelerated and More Accurate Bayesian Network Structure Learning. ICML. 2003.  [View Context].Alexander J. Smola and Vishy Vishwanathan and Eleazar Eskin. Laplace Propagation. NIPS. 2003.  [View Context].I. Yoncaci. Maximum a Posteriori Tree Augmented Naive Bayes Classifiers. O EN INTEL.LIG ` ENCIA ARTIFICIAL CSIC. 2003.  [View Context].Christopher R. Palmer and Christos Faloutsos. Electricity Based External Similarity of Categorical Attributes. PAKDD. 2003.  [View Context].S. Sathiya Keerthi and Chih-Jen Lin. Asymptotic Behaviors of Support Vector Machines with Gaussian Kernel. Neural Computation, 15. 2003.  [View Context].Thomas Serafini and G. Zanghirati and Del Zanna and T. Serafini and Gaetano Zanghirati and Luca Zanni. DIPARTIMENTO DI MATEMATICA. Gradient Projection Methods for. 2003.  [View Context].Ramesh Natarajan and Edwin P D Pednault. Segmented Regression Estimators for Massive Data Sets. SDM. 2002.  [View Context].Bianca Zadrozny and Charles Elkan. Transforming classifier scores into accurate multiclass probability estimates. KDD. 2002.  [View Context].Nitesh V. Chawla and Kevin W. Bowyer and Lawrence O. Hall and W. Philip Kegelmeyer. SMOTE: Synthetic Minority Over-sampling Technique. J. Artif. Intell. Res. (JAIR, 16. 2002.  [View Context].S. Sathiya Keerthi and Kaibo Duan and Shirish Krishnaj Shevade and Aun Neow Poo. A Fast Dual Algorithm for Kernel Logistic Regression. ICML. 2002.  [View Context].Bernhard Pfahringer and Geoffrey Holmes and Richard Kirkby. Optimizing the Induction of Alternating Decision Trees. PAKDD. 2001.  [View Context].Stephen D. Bay and Michael J. Pazzani. Detecting Group Differences: Mining Contrast Sets. Data Min. Knowl. Discov, 5. 2001.  [View Context].Jie Cheng and Russell Greiner. Learning Bayesian Belief Network Classifiers: Algorithms and System. Canadian Conference on AI. 2001.  [View Context].Zhiyuan Chen and Johannes Gehrke and Flip Korn. Query Optimization In Compressed Database Systems. SIGMOD Conference. 2001.  [View Context].Stephen D. Bay. Multivariate Discretization for Set Mining. Knowl. Inf. Syst, 3. 2001.  [View Context].Kristin P. Bennett and Ayhan Demiriz and John Shawe-Taylor. A Column Generation Algorithm For Boosting. ICML. 2000.  [View Context].Dmitry Pavlov and Jianchang Mao and Byron Dom. Scaling-Up Support Vector Machines Using Boosting Algorithm. ICPR. 2000.  [View Context].Gary M. Weiss and Haym Hirsh. A Quantitative Study of Small Disjuncts: Experiments and Results. Department of Computer Science Rutgers University. 2000.  [View Context].Dmitry Pavlov and Darya Chudova and Padhraic Smyth. Towards scalable support vector machines using squashing. KDD. 2000.  [View Context].Petri Kontkanen and Jussi Lahtinen and Petri Myllymaki and Tomi Silander and Henry Tirri. Proceedings of Pre- and Post-processing in Machine Learning and Data Mining: Theoretical Aspects and Applications, a workshop within Machine Learning and Applications. Complex Systems Computation Group (CoSCo). 1999.  [View Context].Jie Cheng and Russell Greiner. Comparing Bayesian Network Classifiers. UAI. 1999.  [View Context].Yk Huhtala and Juha Kärkkäinen and Pasi Porkka and Hannu Toivonen. Efficient Discovery of Functional and Approximate Dependencies Using Partitions. ICDE. 1998.  [View Context].John C. Platt. Using Analytic QP and Sparseness to Speed Training of Support Vector Machines. NIPS. 1998.  [View Context].Ron Kohavi. Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid. KDD. 1996.  [View Context].Jeff G. Schneider and Andrew W. Moore. Active Learning in Discrete Input Spaces. School of Computer Science Carnegie Mellon University.  [View Context].Omid Madani and David M. Pennock and Gary William Flake. Co-Validation: Using Model Disagreement to Validate Classification Algorithms. Yahoo! Research Labs.  [View Context].Ron Kohavi and Barry G. Becker and Dan Sommerfield. Improving Simple Bayes. Data Mining and Visualization Group Silicon Graphics, Inc.  [View Context].Shi Zhong and Weiyu Tang and Taghi M. Khoshgoftaar. Boosted Noise Filters for Identifying Mislabeled Data. Department of Computer Science and Engineering Florida Atlantic University.  [View Context].David R. Musicant. DATA MINING VIA MATHEMATICAL PROGRAMMING AND MACHINE LEARNING. Doctor of Philosophy (Computer Sciences) UNIVERSITY.  [View Context].William W. Cohen and Yoram Singer. A Simple, Fast, and Effective Rule Learner. AT&T Labs--Research Shannon Laboratory.  [View Context].Haixun Wang and Philip S. Yu. SSDT-NN: A Subspace-Splitting Decision Tree Classifier with Application to Target Selection. IBM T. J. Watson Research Center.  [View Context].S. V. N Vishwanathan and Alexander J. Smola and M. Narasimha Murty. considerably faster than competing methods such as Sequential Minimal Optimization or the Nearest Point Algorithm. Machine Learning Program, National ICT for Australia.  [View Context].Grigorios Tsoumakas and Ioannis P. Vlahavas. Fuzzy Meta-Learning: Preliminary Results. Greek Secretariat for Research and Technology.  [View Context].Josep Roure Alcobe. Incremental Hill-Climbing Search Applied to Bayesian Network Structure Learning. Escola Universitria Politcnica de Mataro.  [View Context].Ayhan Demiriz and Kristin P. Bennett and John Shawe and I. Nouretdinov V.. Linear Programming Boosting via Column Generation. Dept. of Decision Sciences and Eng. Systems, Rensselaer Polytechnic Institute.  [View Context].Chris Giannella and Bassem Sayrafi. An Information Theoretic Histogram for Single Dimensional Selectivity Estimation. Department of Computer Science, Indiana University Bloomington.  [View Context].Rong-En Fan and P. -H Chen and C. -J Lin. Working Set Selection Using the Second Order Information for Training SVM. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Petri Kontkanen and Jussi Lahtinen and Petri Myllymaki and Tomi Silander and Henry Tirri. USING BAYESIAN NETWORKS FOR VISUALIZING HIGH-DIMENSIONAL DATA. Complex Systems Computation Group (CoSCo).  [View Context].Ahmed Hussain Khan and Intensive Care. Multiplier-Free Feedforward Networks. 174.  [View Context].Luc Hoegaerts and J. A. K Suykens and J. Vandewalle and Bart De Moor. Subset Based Least Squares Subspace Regression in RKHS. Katholieke Universiteit Leuven Department of Electrical Engineering, ESAT-SCD-SISTA.  [View Context].David R. Musicant and Alexander Feinberg. Active Set Support Vector Regression.  [View Context].Luc Hoegaerts and J. A. K Suykens and J. Vandewalle and Bart De Moor. Primal Space Sparse Kernel Partial Least Squares Regression for Large Scale Problems Special Session paper . Katholieke Universiteit Leuven Department of Electrical Engineering, ESAT-SCD-SISTA.  [View Context].Kuan-ming Lin and Chih-Jen Lin. A Study on Reduced Support Vector Machines. Department of Computer Science and Information Engineering National Taiwan University.  [View Context].Luca Zanni. An Improved Gradient Projection-based Decomposition Technique for Support Vector Machines. Dipartimento di Matematica, Universitdi Modena e Reggio Emilia.  [View Context]."
http://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring,504,Parkinsons Telemonitoring Data Set,../machine-learning-databases/parkinsons/telemonitoring/,Multivariate,5875,Life,"Integer, Real",26,10/29/2009,Regression,N/A,149279,"The dataset was created by Athanasios Tsanas (tsanasthanasis '@' gmail.com) and Max Little (littlem '@' physics.ox.ac.uk) of the University of Oxford, in collaboration with 10 medical centers in the US and Intel Corporation who developed the telemonitoring device to record the speech signals. The original study used a range of linear and nonlinear regression methods to predict the clinician's Parkinson's disease symptom score on the UPDRS scale.","This dataset is composed of a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease recruited to a six-month trial of a telemonitoring device for remote symptom progression monitoring. The recordings were automatically captured in the patient's homes. Columns in the table contain subject number, subject age, subject gender, time interval from baseline recruitment date, motor UPDRS, total UPDRS, and 16 biomedical voice measures. Each row corresponds to one of 5,875 voice recording from these individuals. The main aim of the data is to predict the motor and total UPDRS scores ('motor_UPDRS' and 'total_UPDRS') from the 16 voice measures. The data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around 200 recordings per patient, the subject number of the patient is identified in the first column. For further information or to pass on comments, please contact Athanasios Tsanas (tsanasthanasis '@' gmail.com) or Max Little (littlem '@' physics.ox.ac.uk). Further details are contained in the following reference -- if you use this dataset, please cite:Athanasios Tsanas, Max A. Little, Patrick E. McSharry, Lorraine O. Ramig (2009),'Accurate telemonitoring of Parkinson’s disease progression by non-invasive speech tests',IEEE Transactions on Biomedical Engineering (to appear). Further details about the biomedical voice measures can be found in:Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2009), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering, 56(4):1015-1022","subject# - Integer that uniquely identifies each subjectage - Subject agesex - Subject gender '0' - male, '1' - femaletest_time - Time since recruitment into the trial. The integer part is the number of days since recruitment. motor_UPDRS - Clinician's motor UPDRS score, linearly interpolatedtotal_UPDRS - Clinician's total UPDRS score, linearly interpolatedJitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of variation in fundamental frequencyShimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - Several measures of variation in amplitudeNHR,HNR - Two measures of ratio of noise to tonal components in the voiceRPDE - A nonlinear dynamical complexity measureDFA - Signal fractal scaling exponentPPE - A nonlinear measure of fundamental frequency variation ","Little MA, McSharry PE, Hunter EJ, Ramig LO (2009), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering, 56(4):1015-1022 Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM. 'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', BioMedical Engineering OnLine 2007, 6:23 (26 June 2007)","If you use this dataset, please cite the following paper:A Tsanas, MA Little, PE McSharry, LO Ramig (2009)'Accurate telemonitoring of Parkinson’s disease progression by non-invasive speech tests',IEEE Transactions on Biomedical Engineering (to appear).",
http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime,505,Communities and Crime Data Set,../machine-learning-databases/communities/,Multivariate,1994,Social,Real,128,7/13/2009,Regression,Yes,286446,"Creator: Michael Redmond (redmond '@' lasalle.edu); Computer Science; La Salle University; Philadelphia, PA, 19141, USA    -- culled from 1990 US Census, 1995 US FBI Uniform Crime Report, 1990 US Law Enforcement Management and Administrative Statistics Survey, available from ICPSR at U of Michigan.  -- Donor: Michael Redmond (redmond '@' lasalle.edu); Computer Science; La Salle University; Philadelphia, PA, 19141, USA  -- Date: July 2009","  Many variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=122), plus the attribute to be predicted (Per Capita Violent Crimes). The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units.   The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in incorrect values for per capita violent crime. These cities are not included in the dataset. Many of these omitted communities were from the midwestern USA.   Data is described below based on original values. All numeric data was normalized into the decimal range  0.00-1.00 using an Unsupervised, equal-interval binning method. Attributes retain their distribution and skew (hence for example the population attribute has a mean value of  0.06 because most communities are small). E.g. An attribute described as 'mean people per household' is actually the normalized (0-1) version of that value.   The normalization preserves rough ratios of values WITHIN an attribute (e.g. double the value for double the population within the available precision - except for extreme values (all values more than 3 SD above the mean are normalized to 1.00; all values more than 3 SD below the mean are nromalized to  0.00)).   However, the normalization does not preserve relationships between values BETWEEN attributes (e.g. it would not be meaningful to compare the value for whitePerCap with the value for blackPerCap for a community)   A limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data. .arff header for Weka: @relation crimepredict @attribute state numeric@attribute county numeric@attribute community numeric@attribute communityname string@attribute fold numeric@attribute population numeric@attribute householdsize numeric@attribute racepctblack numeric@attribute racePctWhite numeric@attribute racePctAsian numeric@attribute racePctHisp numeric@attribute agePct12t21 numeric@attribute agePct12t29 numeric@attribute agePct16t24 numeric@attribute agePct65up numeric@attribute numbUrban numeric@attribute pctUrban numeric@attribute medIncome numeric@attribute pctWWage numeric@attribute pctWFarmSelf numeric@attribute pctWInvInc numeric@attribute pctWSocSec numeric@attribute pctWPubAsst numeric@attribute pctWRetire numeric@attribute medFamInc numeric@attribute perCapInc numeric@attribute whitePerCap numeric@attribute blackPerCap numeric@attribute indianPerCap numeric@attribute AsianPerCap numeric@attribute OtherPerCap numeric@attribute HispPerCap numeric@attribute NumUnderPov numeric@attribute PctPopUnderPov numeric@attribute PctLess9thGrade numeric@attribute PctNotHSGrad numeric@attribute PctBSorMore numeric@attribute PctUnemployed numeric@attribute PctEmploy numeric@attribute PctEmplManu numeric@attribute PctEmplProfServ numeric@attribute PctOccupManu numeric@attribute PctOccupMgmtProf numeric@attribute MalePctDivorce numeric@attribute MalePctNevMarr numeric@attribute FemalePctDiv numeric@attribute TotalPctDiv numeric@attribute PersPerFam numeric@attribute PctFam2Par numeric@attribute PctKids2Par numeric@attribute PctYoungKids2Par numeric@attribute PctTeen2Par numeric@attribute PctWorkMomYoungKids numeric@attribute PctWorkMom numeric@attribute NumIlleg numeric@attribute PctIlleg numeric@attribute NumImmig numeric@attribute PctImmigRecent numeric@attribute PctImmigRec5 numeric@attribute PctImmigRec8 numeric@attribute PctImmigRec10 numeric@attribute PctRecentImmig numeric@attribute PctRecImmig5 numeric@attribute PctRecImmig8 numeric@attribute PctRecImmig10 numeric@attribute PctSpeakEnglOnly numeric@attribute PctNotSpeakEnglWell numeric@attribute PctLargHouseFam numeric@attribute PctLargHouseOccup numeric@attribute PersPerOccupHous numeric@attribute PersPerOwnOccHous numeric@attribute PersPerRentOccHous numeric@attribute PctPersOwnOccup numeric@attribute PctPersDenseHous numeric@attribute PctHousLess3BR numeric@attribute MedNumBR numeric@attribute HousVacant numeric@attribute PctHousOccup numeric@attribute PctHousOwnOcc numeric@attribute PctVacantBoarded numeric@attribute PctVacMore6Mos numeric@attribute MedYrHousBuilt numeric@attribute PctHousNoPhone numeric@attribute PctWOFullPlumb numeric@attribute OwnOccLowQuart numeric@attribute OwnOccMedVal numeric@attribute OwnOccHiQuart numeric@attribute RentLowQ numeric@attribute RentMedian numeric@attribute RentHighQ numeric@attribute MedRent numeric@attribute MedRentPctHousInc numeric@attribute MedOwnCostPctInc numeric@attribute MedOwnCostPctIncNoMtg numeric@attribute NumInShelters numeric@attribute NumStreet numeric@attribute PctForeignBorn numeric@attribute PctBornSameState numeric@attribute PctSameHouse85 numeric@attribute PctSameCity85 numeric@attribute PctSameState85 numeric@attribute LemasSwornFT numeric@attribute LemasSwFTPerPop numeric@attribute LemasSwFTFieldOps numeric@attribute LemasSwFTFieldPerPop numeric@attribute LemasTotalReq numeric@attribute LemasTotReqPerPop numeric@attribute PolicReqPerOffic numeric@attribute PolicPerPop numeric@attribute RacialMatchCommPol numeric@attribute PctPolicWhite numeric@attribute PctPolicBlack numeric@attribute PctPolicHisp numeric@attribute PctPolicAsian numeric@attribute PctPolicMinor numeric@attribute OfficAssgnDrugUnits numeric@attribute NumKindsDrugsSeiz numeric@attribute PolicAveOTWorked numeric@attribute LandArea numeric@attribute PopDens numeric@attribute PctUsePubTrans numeric@attribute PolicCars numeric@attribute PolicOperBudg numeric@attribute LemasPctPolicOnPatr numeric@attribute LemasGangUnitDeploy numeric@attribute LemasPctOfficDrugUn numeric@attribute PolicBudgPerPop numeric@attribute ViolentCrimesPerPop numeric @data  ","Attribute Information: (122 predictive, 5 non-predictive, 1 goal)  -- state: US state (by number) - not counted as predictive above, but if considered, should be consided nominal (nominal)   -- county: numeric code for county - not predictive, and many missing values (numeric)  -- community: numeric code for community - not predictive and many missing values (numeric)  -- communityname: community name - not predictive - for information only (string)  -- fold: fold number for non-random 10 fold cross validation, potentially useful for debugging, paired tests - not predictive (numeric)  -- population: population for community: (numeric - decimal)  -- householdsize: mean people per household (numeric - decimal)  -- racepctblack: percentage of population that is african american (numeric - decimal)  -- racePctWhite: percentage of population that is caucasian (numeric - decimal)  -- racePctAsian: percentage of population that is of asian heritage (numeric - decimal)  -- racePctHisp: percentage of population that is of hispanic heritage (numeric - decimal)  -- agePct12t21: percentage of population that is 12-21 in age (numeric - decimal)  -- agePct12t29: percentage of population that is 12-29 in age (numeric - decimal)  -- agePct16t24: percentage of population that is 16-24 in age (numeric - decimal)  -- agePct65up: percentage of population that is 65 and over in age (numeric - decimal)  -- numbUrban: number of people living in areas classified as urban (numeric - decimal)  -- pctUrban: percentage of people living in areas classified as urban (numeric - decimal)  -- medIncome: median household income (numeric - decimal)  -- pctWWage: percentage of households with wage or salary income in 1989 (numeric - decimal)  -- pctWFarmSelf: percentage of households with farm or self employment income in 1989 (numeric - decimal)  -- pctWInvInc: percentage of households with investment / rent income in 1989 (numeric - decimal)  -- pctWSocSec: percentage of households with social security income in 1989 (numeric - decimal)  -- pctWPubAsst: percentage of households with public assistance income in 1989 (numeric - decimal)  -- pctWRetire: percentage of households with retirement income in 1989 (numeric - decimal)  -- medFamInc: median family income (differs from household income for non-family households) (numeric - decimal)  -- perCapInc: per capita income (numeric - decimal)  -- whitePerCap: per capita income for caucasians (numeric - decimal)  -- blackPerCap: per capita income for african americans (numeric - decimal)  -- indianPerCap: per capita income for native americans (numeric - decimal)  -- AsianPerCap: per capita income for people with asian heritage (numeric - decimal)  -- OtherPerCap: per capita income for people with 'other' heritage (numeric - decimal)  -- HispPerCap: per capita income for people with hispanic heritage (numeric - decimal)  -- NumUnderPov: number of people under the poverty level (numeric - decimal)  -- PctPopUnderPov: percentage of people under the poverty level (numeric - decimal)  -- PctLess9thGrade: percentage of people 25 and over with less than a 9th grade education (numeric - decimal)  -- PctNotHSGrad: percentage of people 25 and over that are not high school graduates (numeric - decimal)  -- PctBSorMore: percentage of people 25 and over with a bachelors degree or higher education (numeric - decimal)  -- PctUnemployed: percentage of people 16 and over, in the labor force, and unemployed (numeric - decimal)  -- PctEmploy: percentage of people 16 and over who are employed (numeric - decimal)  -- PctEmplManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)  -- PctEmplProfServ: percentage of people 16 and over who are employed in professional services (numeric - decimal)  -- PctOccupManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)   ########  -- PctOccupMgmtProf: percentage of people 16 and over who are employed in management or professional occupations (numeric - decimal)  -- MalePctDivorce: percentage of males who are divorced (numeric - decimal)  -- MalePctNevMarr: percentage of males who have never married (numeric - decimal)  -- FemalePctDiv: percentage of females who are divorced (numeric - decimal)  -- TotalPctDiv: percentage of population who are divorced (numeric - decimal)  -- PersPerFam: mean number of people per family (numeric - decimal)  -- PctFam2Par: percentage of families (with kids) that are headed by two parents (numeric - decimal)  -- PctKids2Par: percentage of kids in family housing with two parents (numeric - decimal)  -- PctYoungKids2Par: percent of kids 4 and under in two parent households (numeric - decimal)  -- PctTeen2Par: percent of kids age 12-17 in two parent households (numeric - decimal)  -- PctWorkMomYoungKids: percentage of moms of kids 6 and under in labor force (numeric - decimal)  -- PctWorkMom: percentage of moms of kids under 18 in labor force (numeric - decimal)  -- NumIlleg: number of kids born to never married (numeric - decimal)  -- PctIlleg: percentage of kids born to never married (numeric - decimal)  -- NumImmig: total number of people known to be foreign born (numeric - decimal)  -- PctImmigRecent: percentage of _immigrants_ who immigated within last 3 years (numeric - decimal)  -- PctImmigRec5: percentage of _immigrants_ who immigated within last 5 years (numeric - decimal)  -- PctImmigRec8: percentage of _immigrants_ who immigated within last 8 years (numeric - decimal)  -- PctImmigRec10: percentage of _immigrants_ who immigated within last 10 years (numeric - decimal)  -- PctRecentImmig: percent of _population_ who have immigrated within the last 3 years (numeric - decimal)  -- PctRecImmig5: percent of _population_ who have immigrated within the last 5 years (numeric - decimal)  -- PctRecImmig8: percent of _population_ who have immigrated within the last 8 years (numeric - decimal)  -- PctRecImmig10: percent of _population_ who have immigrated within the last 10 years (numeric - decimal)  -- PctSpeakEnglOnly: percent of people who speak only English (numeric - decimal)  -- PctNotSpeakEnglWell: percent of people who do not speak English well (numeric - decimal)  -- PctLargHouseFam: percent of family households that are large (6 or more) (numeric - decimal)  -- PctLargHouseOccup: percent of all occupied households that are large (6 or more people) (numeric - decimal)  -- PersPerOccupHous: mean persons per household (numeric - decimal)  -- PersPerOwnOccHous: mean persons per owner occupied household (numeric - decimal)  -- PersPerRentOccHous: mean persons per rental household (numeric - decimal)  -- PctPersOwnOccup: percent of people in owner occupied households (numeric - decimal)  -- PctPersDenseHous: percent of persons in dense housing (more than 1 person per room) (numeric - decimal)  -- PctHousLess3BR: percent of housing units with less than 3 bedrooms (numeric - decimal)  -- MedNumBR: median number of bedrooms (numeric - decimal)  -- HousVacant: number of vacant households (numeric - decimal)  -- PctHousOccup: percent of housing occupied (numeric - decimal)  -- PctHousOwnOcc: percent of households owner occupied (numeric - decimal)  -- PctVacantBoarded: percent of vacant housing that is boarded up (numeric - decimal)  -- PctVacMore6Mos: percent of vacant housing that has been vacant more than 6 months (numeric - decimal)  -- MedYrHousBuilt: median year housing units built (numeric - decimal)  -- PctHousNoPhone: percent of occupied housing units without phone (in 1990, this was rare!) (numeric - decimal)  -- PctWOFullPlumb: percent of housing without complete plumbing facilities (numeric - decimal)  -- OwnOccLowQuart: owner occupied housing - lower quartile value (numeric - decimal)  -- OwnOccMedVal: owner occupied housing - median value (numeric - decimal)  -- OwnOccHiQuart: owner occupied housing - upper quartile value (numeric - decimal)  -- RentLowQ: rental housing - lower quartile rent (numeric - decimal)  -- RentMedian: rental housing - median rent (Census variable H32B from file STF1A) (numeric - decimal)  -- RentHighQ: rental housing - upper quartile rent (numeric - decimal)  -- MedRent: median gross rent (Census variable H43A from file STF3A - includes utilities) (numeric - decimal)  -- MedRentPctHousInc: median gross rent as a percentage of household income (numeric - decimal)  -- MedOwnCostPctInc: median owners cost as a percentage of household income - for owners with a mortgage (numeric - decimal)  -- MedOwnCostPctIncNoMtg: median owners cost as a percentage of household income - for owners without a mortgage (numeric - decimal)  -- NumInShelters: number of people in homeless shelters (numeric - decimal)  -- NumStreet: number of homeless people counted in the street (numeric - decimal)  -- PctForeignBorn: percent of people foreign born (numeric - decimal)  -- PctBornSameState: percent of people born in the same state as currently living (numeric - decimal)  -- PctSameHouse85: percent of people living in the same house as in 1985 (5 years before) (numeric - decimal)  -- PctSameCity85: percent of people living in the same city as in 1985 (5 years before) (numeric - decimal)  -- PctSameState85: percent of people living in the same state as in 1985 (5 years before) (numeric - decimal)  -- LemasSwornFT: number of sworn full time police officers (numeric - decimal)  -- LemasSwFTPerPop: sworn full time police officers per 100K population (numeric - decimal)  -- LemasSwFTFieldOps: number of sworn full time police officers in field operations (on the street as opposed to administrative etc) (numeric - decimal)  -- LemasSwFTFieldPerPop: sworn full time police officers in field operations (on the street as opposed to administrative etc) per 100K population (numeric - decimal)  -- LemasTotalReq: total requests for police (numeric - decimal)  -- LemasTotReqPerPop: total requests for police per 100K popuation (numeric - decimal)  -- PolicReqPerOffic: total requests for police per police officer (numeric - decimal)  -- PolicPerPop: police officers per 100K population (numeric - decimal)  -- RacialMatchCommPol: a measure of the racial match between the community and the police force. High values indicate proportions in community and police force are similar (numeric - decimal)  -- PctPolicWhite: percent of police that are caucasian (numeric - decimal)  -- PctPolicBlack: percent of police that are african american (numeric - decimal)  -- PctPolicHisp: percent of police that are hispanic (numeric - decimal)  -- PctPolicAsian: percent of police that are asian (numeric - decimal)  -- PctPolicMinor: percent of police that are minority of any kind (numeric - decimal)  -- OfficAssgnDrugUnits: number of officers assigned to special drug units (numeric - decimal)  -- NumKindsDrugsSeiz: number of different kinds of drugs seized (numeric - decimal)  -- PolicAveOTWorked: police average overtime worked (numeric - decimal)  -- LandArea: land area in square miles (numeric - decimal)  -- PopDens: population density in persons per square mile (numeric - decimal)  -- PctUsePubTrans: percent of people using public transit for commuting (numeric - decimal)  -- PolicCars: number of police cars (numeric - decimal)  -- PolicOperBudg: police operating budget (numeric - decimal)  -- LemasPctPolicOnPatr: percent of sworn full time police officers on patrol (numeric - decimal)  -- LemasGangUnitDeploy: gang unit deployed (numeric - decimal - but really ordinal - 0 means NO, 1 means YES,  0.5 means Part Time)  -- LemasPctOfficDrugUn: percent of officers assigned to drug units (numeric - decimal)  -- PolicBudgPerPop: police operating budget per population (numeric - decimal)  -- ViolentCrimesPerPop: total number of violent crimes per 100K popuation (numeric - decimal) GOAL attribute (to be predicted) Summary Statistics:			Min	Max	 Mean	 SD	Correl	Median	 Mode	Missingpopulation		0	1	 0.06	 0.13	 0.37	 0.02	 0.01	0householdsize		0	1	 0.46	 0.16	-0.03	 0.44	 0.41	0racepctblack		0	1	 0.18	 0.25	 0.63	 0.06	 0.01	0racePctWhite		0	1	 0.75	 0.24	-0.68	 0.85	 0.98	0racePctAsian		0	1	 0.15	 0.21	 0.04	 0.07	 0.02	0racePctHisp		0	1	 0.14	 0.23	 0.29	 0.04	 0.01	0agePct12t21		0	1	 0.42	 0.16	 0.06	 0.4	 0.38	0agePct12t29		0	1	 0.49	 0.14	 0.15	 0.48	 0.49	0agePct16t24		0	1	 0.34	 0.17	 0.10	 0.29	 0.29	0agePct65up		0	1	 0.42	 0.18	 0.07	 0.42	 0.47	0numbUrban		0	1	 0.06	 0.13	 0.36	 0.03	 0	0pctUrban		0	1	 0.70	 0.44	 0.08	 1	 1	0medIncome		0	1	 0.36	 0.21	-0.42	 0.32	 0.23	0pctWWage		0	1	 0.56	 0.18	-0.31	 0.56	 0.58	0pctWFarmSelf		0	1	 0.29	 0.20	-0.15	 0.23	 0.16	0pctWInvInc		0	1	 0.50	 0.18	-0.58	 0.48	 0.41	0pctWSocSec		0	1	 0.47	 0.17	 0.12	 0.475	 0.56	0pctWPubAsst		0	1	 0.32	 0.22	 0.57	 0.26	 0.1	0pctWRetire		0	1	 0.48	 0.17	-0.10	 0.47	 0.44	0medFamInc		0	1	 0.38	 0.20	-0.44	 0.33	 0.25	0perCapInc		0	1	 0.35	 0.19	-0.35	 0.3	 0.23	0whitePerCap		0	1	 0.37	 0.19	-0.21	 0.32	 0.3	0blackPerCap		0	1	 0.29	 0.17	-0.28	 0.25	 0.18	0indianPerCap		0	1	 0.20	 0.16	-0.09	 0.17	 0	0AsianPerCap		0	1	 0.32	 0.20	-0.16	 0.28	 0.18	0OtherPerCap		0	1	 0.28	 0.19	-0.13	 0.25	 0	1HispPerCap		0	1	 0.39	 0.18	-0.24	 0.345	 0.3	0NumUnderPov		0	1	 0.06	 0.13	 0.45	 0.02	 0.01	0PctPopUnderPov		0	1	 0.30	 0.23	 0.52	 0.25	 0.08	0PctLess9thGrade		0	1	 0.32	 0.21	 0.41	 0.27	 0.19	0PctNotHSGrad		0	1	 0.38	 0.20	 0.48	 0.36	 0.39	0PctBSorMore		0	1	 0.36	 0.21	-0.31	 0.31	 0.18	0PctUnemployed		0	1	 0.36	 0.20	 0.50	 0.32	 0.24	0PctEmploy		0	1	 0.50	 0.17	-0.33	 0.51	 0.56	0PctEmplManu		0	1	 0.40	 0.20	-0.04	 0.37	 0.26	0PctEmplProfServ		0	1	 0.44	 0.18	-0.07	 0.41	 0.36	0PctOccupManu		0	1	 0.39	 0.20	 0.30	 0.37	 0.32	0PctOccupMgmtProf	0	1	 0.44	 0.19	-0.34	 0.4	 0.36	0MalePctDivorce		0	1	 0.46	 0.18	 0.53	 0.47	 0.56	0MalePctNevMarr		0	1	 0.43	 0.18	 0.30	 0.4	 0.38	0FemalePctDiv		0	1	 0.49	 0.18	 0.56	 0.5	 0.54	0TotalPctDiv		0	1	 0.49	 0.18	 0.55	 0.5	 0.57	0PersPerFam		0	1	 0.49	 0.15	 0.14	 0.47	 0.44	0PctFam2Par		0	1	 0.61	 0.20	-0.71	 0.63	 0.7	0PctKids2Par		0	1	 0.62	 0.21	-0.74	 0.64	 0.72	0PctYoungKids2Par	0	1	 0.66	 0.22	-0.67	 0.7	 0.91	0PctTeen2Par		0	1	 0.58	 0.19	-0.66	 0.61	 0.6	0PctWorkMomYoungKids	0	1	 0.50	 0.17	-0.02	 0.51	 0.51	0PctWorkMom		0	1	 0.53	 0.18	-0.15	 0.54	 0.57	0NumIlleg		0	1	 0.04	 0.11	 0.47	 0.01	 0	0PctIlleg		0	1	 0.25	 0.23	 0.74	 0.17	 0.09	0NumImmig		0	1	 0.03	 0.09	 0.29	 0.01	 0	0PctImmigRecent		0	1	 0.32	 0.22	 0.17	 0.29	 0	0PctImmigRec5		0	1	 0.36	 0.21	 0.22	 0.34	 0	0PctImmigRec8		0	1	 0.40	 0.20	 0.25	 0.39	 0.26	0PctImmigRec10		0	1	 0.43	 0.19	 0.29	 0.43	 0.43	0PctRecentImmig		0	1	 0.18	 0.24	 0.23	 0.09	 0.01	0PctRecImmig5		0	1	 0.18	 0.24	 0.25	 0.08	 0.02	0PctRecImmig8		0	1	 0.18	 0.24	 0.25	 0.09	 0.02	0PctRecImmig10		0	1	 0.18	 0.23	 0.26	 0.09	 0.02	0PctSpeakEnglOnly	0	1	 0.79	 0.23	-0.24	 0.87	 0.96	0PctNotSpeakEnglWell	0	1	 0.15	 0.22	 0.30	 0.06	 0.03	0PctLargHouseFam		0	1	 0.27	 0.20	 0.38	 0.2	 0.17	0PctLargHouseOccup	0	1	 0.25	 0.19	 0.29	 0.19	 0.19	0PersPerOccupHous	0	1	 0.46	 0.17	-0.04	 0.44	 0.37	0PersPerOwnOccHous	0	1	 0.49	 0.16	-0.12	 0.48	 0.45	0PersPerRentOccHous	0	1	 0.40	 0.19	 0.25	 0.36	 0.32	0PctPersOwnOccup		0	1	 0.56	 0.20	-0.53	 0.56	 0.54	0PctPersDenseHous	0	1	 0.19	 0.21	 0.45	 0.11	 0.06	0PctHousLess3BR		0	1	 0.50	 0.17	 0.47	 0.51	 0.53	0MedNumBR		0	1	 0.31	 0.26	-0.36	 0.5	 0.5	0HousVacant		0	1	 0.08	 0.15	 0.42	 0.03	 0.01	0PctHousOccup		0	1	 0.72	 0.19	-0.32	 0.77	 0.88	0PctHousOwnOcc		0	1	 0.55	 0.19	-0.47	 0.54	 0.52	0PctVacantBoarded	0	1	 0.20	 0.22	 0.48	 0.13	 0	0PctVacMore6Mos		0	1	 0.43	 0.19	 0.02	 0.42	 0.44	0MedYrHousBuilt		0	1	 0.49	 0.23	-0.11	 0.52	 0	0PctHousNoPhone		0	1	 0.26	 0.24	 0.49	 0.185	 0.01	0PctWOFullPlumb		0	1	 0.24	 0.21	 0.36	 0.19	 0	0OwnOccLowQuart		0	1	 0.26	 0.22	-0.21	 0.18	 0.09	0OwnOccMedVal		0	1	 0.26	 0.23	-0.19	 0.17	 0.08	0OwnOccHiQuart		0	1	 0.27	 0.24	-0.17	 0.18	 0.08	0RentLowQ		0	1	 0.35	 0.22	-0.25	 0.31	 0.13	0RentMedian		0	1	 0.37	 0.21	-0.24	 0.33	 0.19	0RentHighQ		0	1	 0.42	 0.25	-0.23	 0.37	 1	0MedRent			0	1	 0.38	 0.21	-0.24	 0.34	 0.17	0MedRentPctHousInc	0	1	 0.49	 0.17	 0.33	 0.48	 0.4	0MedOwnCostPctInc	0	1	 0.45	 0.19	 0.06	 0.45	 0.41	0MedOwnCostPctIncNoMtg	0	1	 0.40	 0.19	 0.05	 0.37	 0.24	0NumInShelters		0	1	 0.03	 0.10	 0.38	 0	 0	0NumStreet		0	1	 0.02	 0.10	 0.34	 0	 0	0PctForeignBorn		0	1	 0.22	 0.23	 0.19	 0.13	 0.03	0PctBornSameState	0	1	 0.61	 0.20	-0.08	 0.63	 0.78	0PctSameHouse85		0	1	 0.54	 0.18	-0.16	 0.54	 0.59	0PctSameCity85		0	1	 0.63	 0.20	 0.08	 0.67	 0.74	0PctSameState85		0	1	 0.65	 0.20	-0.02	 0.7	 0.79	0LemasSwornFT		0	1	 0.07	 0.14	 0.34	 0.02	 0.02	1675LemasSwFTPerPop		0	1	 0.22	 0.16	 0.15	 0.18	 0.2	1675LemasSwFTFieldOps	0	1	 0.92	 0.13	-0.33	 0.97	 0.98	1675LemasSwFTFieldPerPop	0	1	 0.25	 0.16	 0.16	 0.21	 0.19	1675LemasTotalReq		0	1	 0.10	 0.16	 0.35	 0.04	 0.02	1675LemasTotReqPerPop	0	1	 0.22	 0.16	 0.27	 0.17	 0.14	1675PolicReqPerOffic	0	1	 0.34	 0.20	 0.17	 0.29	 0.23	1675PolicPerPop		0	1	 0.22	 0.16	 0.15	 0.18	 0.2	1675RacialMatchCommPol	0	1	 0.69	 0.23	-0.46	 0.74	 0.78	1675PctPolicWhite		0	1	 0.73	 0.22	-0.44	 0.78	 0.72	1675PctPolicBlack		0	1	 0.22	 0.24	 0.54	 0.12	 0	1675PctPolicHisp		0	1	 0.13	 0.20	 0.12	 0.06	 0	1675PctPolicAsian		0	1	 0.11	 0.23	 0.10	 0	 0	1675PctPolicMinor		0	1	 0.26	 0.23	 0.49	 0.2	 0.07	1675OfficAssgnDrugUnits	0	1	 0.08	 0.12	 0.34	 0.04	 0.03	1675NumKindsDrugsSeiz	0	1	 0.56	 0.20	 0.13	 0.57	 0.57	1675PolicAveOTWorked	0	1	 0.31	 0.23	 0.03	 0.26	 0.19	1675LandArea		0	1	 0.07	 0.11	 0.20	 0.04	 0.01	0PopDens			0	1	 0.23	 0.20	 0.28	 0.17	 0.09	0PctUsePubTrans		0	1	 0.16	 0.23	 0.15	 0.07	 0.01	0PolicCars		0	1	 0.16	 0.21	 0.38	 0.08	 0.02	1675PolicOperBudg		0	1	 0.08	 0.14	 0.34	 0.03	 0.02	1675LemasPctPolicOnPatr	0	1	 0.70	 0.21	-0.08	 0.75	 0.74	1675LemasGangUnitDeploy	0	1	 0.44	 0.41	 0.12	 0.5	 0	1675LemasPctOfficDrugUn	0	1	 0.09	 0.24	 0.35	 0	 0	0PolicBudgPerPop		0	1	 0.20	 0.16	 0.10	 0.15	 0.12	1675ViolentCrimesPerPop	0	1	 0.24	 0.23	 1.00	 0.15	 0.03	0 Distribution of the Goal Variable (Violent Crimes per Population):   Range	Frequency0.000-0.067	4840.067-0.133	4200.133-0.200	2840.200-0.267	1770.267-0.333	1420.333-0.400	1130.400-0.467	 590.467-0.533	 760.533-0.600	 570.600-0.667	 380.667-0.733	 370.733-0.800	 200.800-0.867	 230.867-0.933	 140.933-1.000	 50","  No published results using this specific dataset.    Related dataset used in Redmond and Baveja 'A data-driven software tool for enabling cooperative information sharing among police departments' in European Journal of Operational Research 141 (2002) 660-678;   That article includes a description of the integration of the three sources of data, however, this data is normalized differently and more/different attributes are included.","  Please cite the UCI Machine Learning Repository, my sources and my related paper:   U. S. Department of Commerce, Bureau of the Census, Census Of Population And Housing 1990 United States: Summary Tape File 1a & 3a (Computer Files),    U.S. Department Of Commerce, Bureau Of The Census Producer, Washington, DC and Inter-university Consortium for Political and Social Research Ann Arbor, Michigan. (1992)    U.S. Department of Justice, Bureau of Justice Statistics, Law Enforcement Management And Administrative Statistics (Computer File) U.S. Department Of Commerce, Bureau Of The Census Producer, Washington, DC and Inter-university Consortium for Political and Social Research Ann Arbor, Michigan. (1992)    U.S. Department of Justice, Federal Bureau of Investigation, Crime in the United States (Computer File) (1995)    Redmond, M. A. and A. Baveja: A Data-Driven Software Tool for Enabling Cooperative Information Sharing Among Police Departments. European Journal of Operational Research 141 (2002) 660-678. ",
http://archive.ics.uci.edu/ml/datasets/Gas+Sensor+Array+Drift+Dataset,506,Gas Sensor Array Drift Dataset Data Set,../machine-learning-databases/00224/,Multivariate,13910,Computer,Real,128,4/25/2012,Classification,N/A,143094,"Creators: 		Alexander Vergara (vergara '@' ucsd.edu)			BioCircutis Institute			University of California San Diego			San Diego, California, USADonors of the Dataset:	Alexander Vergara (vergara '@' ucsd.edu)			Ramon Huerta (rhuerta '@' ucsd.edu)","This archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations. The goal is to achieve good performance (or as low degradation as possible) over time, as reported in the paper mentioned below in Section 2: Data collection. The primary purpose of providing this dataset is to make it freely accessible on-line to the chemo-sensor research community and artificial intelligence to develop strategies to cope with sensor/concept drift. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.The dataset was gathered within January 2007 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. Being completely operated by a fully computerized environment â€”controlled by a LabVIEWâ€“National Instruments software on a PC fitted with the appropriate serial data acquisition boards. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors for compensating real drift.The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, each dosed at a wide variety of concentration values ranging from 5 to 1000 ppmv. See Tables 1 and 2 of the below cited manuscript for details on the gas identity name, concentration values, and time distribution sequence of the measurement recordings considered in this dataset.Batch10.dat was updated on 10/14/2013 to correct some corrupted values in the last 120 lines of the file.An extension of this dataset with the concentration values is available at Gas Sensor Array Drift Dataset at Different Concentrations Data Set [Web Link]","The response of the said sensors is read-out in the form of the resistance across the active layer of each sensor; hence each measurement produced a 16-channel time series, each of which represented by an aggregate of features reflecting all the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. In particular, two distinct types of features were considered in the creation of this dataset: (i) The so-called steady-state feature (Î”R), defined as the difference of the maximal resistance change and the baseline and its normalized version expressed by the ratio of the maximal resistance and the baseline values when the chemical vapor is present in the test chamber. And (ii), an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement procedure under controlled conditions, namely the exponential moving average (emaÎ±). These aggregate of features is a transform, borrowed from the field of econometrics originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the said transient portion into a real scalar,  by estimating the maximum value â€”minimum for the decaying portion of the sensor responseâ€” of its exponential moving average (emaÎ±), with an initial condition set to zero and a scalar smoothing parameter of the operator, Î±, that defines both the quality of the feature and the time of its occurrence along the time series the scalar, set to range between 0 and 1. In particular, three different values for Î± were set to obtain three different feature values from the pre-recorded rising portion of the sensor response  and three additional features with the same Î± values but for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. For a more detailed analysis and discussion on these features as well as a graphical illustration of them please refer to Section 2.3 and Figure 2, respectively of the annotated manuscript.Once the abovementioned features are calculated, one is to form a feature vector containing the 8 features extracted from each particular sensor multiplied by the 16 sensors considered here. In the end, the resulting 128-dimensional feature vector containing all the features indicated above (8 features Ã— 16 sensors) is organized as follows:Î”R_1, |Î”R|_1, EMAi0.001_1, EMAi0.01_1, EMAi0.1_1, EMAd0.001_1, EMAd0.01_1, EMAd0.1_1, Î”R_2, |Î”R|_2, EMAi0.001_2, EMAi0.01_2, EMAi0.1_2, EMAd0.001_2, EMAd0.01_2, EMAd0.1_2,..., Î”R_16, |Î”R|_16, EMAi0.001_16, EMAi0.01_16, EMAi0.1_16, EMAd0.001_16, EMAd0.01_16, EMAd0.1_16,where: â€œÎ”R_1â€ and â€œ|Î”R|_1â€ is the Î”R and the normalized Î”R feature, respectively, â€œEMAi0.001_1â€, â€œEMAi0.01_1â€, and â€œEMAi0.1_1â€, the emaÎ± of the rising transient portion of the sensor response for Î± equals to 0.001, 0.01, and 0.1, respectively, and â€œEMAd0.001_1â€, â€œEMAd0.01_1â€, and â€œEMAd0.1_1â€, the emaÎ± of the decaying transient portion of the sensor response for Î± equals to 0.001, 0.01, and 0.1, respectively, all corresponding to sensor # 1; â€œÎ”R_2â€ and â€œ|Î”R|_2â€ is the Î”R and the normalized Î”R feature, respectively, â€œEMAi0.001_2â€, â€œEMAi0.01_2â€, and â€œEMAi0.1_2â€, the emaÎ± of the rising transient portion of the sensor response for Î± equals to 0.001, 0.01, and 0.1, respectively, and â€œEMAd0.001_2â€, â€œEMAd0.01_2â€, and â€œEMAd0.1_2â€, the emaÎ± of the decaying transient portion of the sensor response for Î± equals to 0.001, 0.01, and 0.1, respectively, all corresponding to sensor # 2; and so forth up until sensor # 16, forming thus the 128-dimensional feature vector that is to be fetched to the classifiers for training.For processing purposes, the data is organized into ten batches, each containing the number of measurements per class and month indicated in the table below. This reorganization of data was done to ensure having a sufficient and as uniformly distributed as possible number of experiments in each class and month when training the classifier.Dataset organization details. Each row corresponds to months that were combined to form a batch:Batch ID	Month IDsBatch 1	        Months 1 and 2Batch 2	        Months 3, 4, 8, 9 and 10Batch 3	        Months 11, 12, and 13Batch 4	        Months 14 and 15Batch 5	        Month 16Batch 6	        Months 17, 18, 19, and 20Batch 7	        Month 21Batch 8	        Months 22 and 23Batch 9	        Months 24 and 30Batch 10	Month 36The data format follows the same coding style as in libsvm, in which one indicates the class each data point belongs to (1: Ethanol; 2: Ethylene; 3:Ammonia; 4: Acetaldehyde; 5: Acetone; 6: Toluene), and, then, the collection of features in a format x:v, where x stands for the feature number and v for the actual value of the feature. For example, in 1 1:15596.162100 2:1.868245 3:2.371604 4:2.803678 5:7.512213 â€¦ 128:-2.654529 The number â€œ1â€ stands for the class number (in this case Ethanol), whereas the remaining 128 columns list the actual feature values for each measurement recording organized as described above. Finally, to make the results presented in the associated article reproducible for the reader, please use the following parameter values in the training task:â€¢	folds: 10â€¢	log2c = -5, 10, 1â€¢	log2g = -10, 5, 1â€¢	Scale the features in the training set appropriately to lie between -1 and +1.â€¢	And use the following cross validation parameters:Batch	C	Gamma (É¤)	Rate1	256.0	0.03125	        98.87642	64.0	0.00390625	99.75883	128.0	0.03125	        100.04	1.0	0.25	        100.05	2.0	0.015625	99.49246	256.0	0.0009765625	99.52177	64.0	0.0625	        99.97238	1024.0	0.0078125	99.65999	2.0	0.00390625	100.0",N/A,"Please cite:Alexander Vergara and Shankar Vembu and Tuba Ayhan and Margaret A. Ryan and Margie L. Homer and RamÃ³n Huerta, Chemical gas sensor drift compensation using classifier ensembles, Sensors and Actuators B: Chemical (2012) doi: 10.1016/j.snb.2012.01.074.",
