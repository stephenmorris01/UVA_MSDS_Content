---
title: "STAT 6021 Homework 1"
author: "Kip McCharen"
date: "7/13/2020"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

<!-- (R required) R provides some data sets though its datasets package that you can readily use. The list of the data sets, as well as their descriptions, can be found here. We will look at a classic data set concerning the Old Faithful geyser at Yellowstone National Park. To load this data set, just type faithful. You may attach the data by typing attach(faithful). The data set contains 272 observations on two variables: eruptions is the eruption time in minutes, and waiting is the waiting time to the next eruption. It is hypothesized that the waiting time to the next eruption can be predicted using the eruption time of the current eruption. During the Washburn Expedition of 1870, members noticed the geyser erupted at regular intervals, thus leading to its name Old Faithful. 
(a) What is the response variable in this analysis? What is predictor in this analysis?-->

## Question 1a, Old Faithful
* Response variable: *waiting*, time elapsed (in minutes) between eruption events
* Predictor variable: *eruptions*, time elapsed (in minutes) during an eruption event

***

<!-- of the two variables. How would you describe the relationship between the two variables? -->
##(1b) Scatterplot 
```{r setup, include=TRUE, echo=TRUE}
print(names(faithful))
print(head(faithful))
print(summary(faithful))
print(nrow(faithful))
result <- lm(faithful$waiting~faithful$eruptions)

plot(faithful$eruptions, faithful$waiting,
     ylab='Waiting time(min)',
     xlab='Eruption Time(min)',
     main='Plot for waiting time and eruption time')
abline(result,col="red")
```
I would describe the relationship between the two variables as grouped at extremes. There is no clear straight line in the graph. 

***
<!-- #(c) What is the correlation between the eruption times and waiting times for the next eruption? #Interpret this correlation contextually. How reliable is this interpretation?  -->
##(1c) Correlation

```{r}
cor(faithful$waiting, faithful$eruptions)
```

Even though the correlation is ~0.9, this interpretation is not extremely reliable due to the relationship obviously not being directly linear in the graph. 

***
<!--(d) Use the lm() function to fit a linear regression for the two variables. Where are the values of beta^1, ^ 0, R2, and ^2 for this linear regression? -->

##(1d) Fit linear regression

```{r}
result <- lm(faithful$waiting~faithful$eruptions)
summary(result)
B1 <- result$coef[2]
print(B1)
mean(result$residuals^2)
```
$\hat{\beta_1}$, the slope, is "Estimate" column for the faithful$eruptions row. 10.7296
$\hat{\beta_0}$, the intercept, is "Estimate" column for the (Intercept) row. 33.4744
$\textit{R}^2$, the regression coefficient, is labeled "Multiple R-squared". 0.8115
$\hat{\sigma}^2$, the mean squared error, is not in the default summary results. The value is 34.718

***

<!-- (e) Interpret the values of beta hat 1, beta hat 0 contextually. Does the value of beta hat 0 make sense in this context? -->

##(1e) Interpreting
If they had meaning, we could say based on these values that a 1-minute increase in the length of eruption will increase the waiting time between eruptions by 10.7296 minutes on average.
There are no values in the dataset where either Waiting time or Eruption time is 0, so the intercept $\hat{\beta_0}$ is not meaningful. It doesn't make reasonable sense for either time to be zero, it would not then be an event to record. 
$\hat{\beta_1}$ is not especially meaningful given that the p-value is so low, but mostly when looking at the plot this is not even a linear model. 

***

<!-- (f) Use the anova() function to produce the ANOVA table for this linear regression. What is the value of the ANOVA F statistic? What null and alternative hypotheses are being tested here? What is a relevant conclusion based on this ANOVA F statistic? -->
<!-- 3.876 f critical value qf -->
<!-- qf(0.95, 1,270) -->

##(1f) ANOVA
```{R}
anova <- anova(result)
```

The ANOVA F statistic is 1,162.1
Null hypothesis: $\hat{\beta_1}$ = 0
Alt Hypothesis: $\hat{\beta_1}$ $\neq$ 0
The p-value is very low (2.2e-16) and our test statistic is very high therefore we can reject the null hypothesis.

***

<!-- (g) Obtain the 95% confidence interval for the slope, beta1. Is this confidence interval consistent with your conclusion from part 1f? Briefly explain. -->
<!-- CI 10.1 and 11.3 beta1 is way outside, so we can reject it -->
##(1g) 95% Confidence Interval
```{R}
CI <- confint(result,level = 0.95)
print(CI[2,])
```
The confidence interval for $\beta_1$ is 10.1 to 11.3, whereas the null hypothesis $\hat{\beta_1}$ = 0 is far outside the bounds of the CI. Therefore we can reject the null.

***

(h) The latest eruption at Old Faithful lasted for 3.5 minutes. Obtain an appropriate 95% interval that predicts the waiting time for the next eruption.
just plug 3.5 into slope of the line equation?
thought he wanted a prediction interval, same as previous except chg key to prediction
59.36 and 82.69
#null and alternative hypotheses 
#βˆ1 == 0
#βˆ1 interpretation: A 1-minute increase in the length of eruption will increase the waiting time by 10.7296 minutes on average.

```{R}


```
#critical value 
#qf function?
#conclusion: there is a linear relationship between the variables 

#what is the critical value?
 # 1 - alpha  
 # df1 = 1 
 # df2 = n - 2
# look at anova and take DF from there 


(i) What is the 95% interval for the average waiting time for the next eruption among current eruptions that last 3.5 minutes? 
71.3 and ____

(j) Create a residual plot, an ACF plot of the residuals, and the QQ plot of the residuals. Based on these plots, are the regression assumptions met? Is your answer surprising, given the context of this data set?
how to do residual plot?

```{r}

acf(result$residuals, main="Auto-Correlation Function of Residuals")

```

writing out hypothesis statement -> we reject the null because f stat is significantly greater than f value. Just checking if there's a linear correlation between the two. 

***
<!-- # 2. (R required) For this question, we will use the cornnit data set from the faraway package. Be sure to install and load the faraway package [faraway], and then load the data set. The data explore the relationship between corn yield (bushels per acre) and nitrogen (pounds per acre) fertilizer application in a study carried out in Wisconsin. -->
##################################################################

#Question 2: Corn yield

```{r}

library(faraway)
attach(cornnit)
print(names(cornnit))
print(head(cornnit))
print(summary(cornnit))
print(nrow(cornnit))

```

# (a) What is the response variable and predictor for this study? Create a scatterplot of the data, and interpret the scatterplot.
#   Predictor: nitrogen, pounds per acre of nitrogen fertilizer used on corn fields
#   Response: yield, bushels per acre of corn grown in the fields which were amended with nitrogen fertilizer

# (b) Fit a linear regression without any transformations. Create the corresponding residual plot. Based only on the residual plot, what transformation will you consider first? Be sure to explain your reason.
```{r}
lreg<-lm(nitrogen~yield)
print(lreg)
plot(x=cornnit$nitrogen, y=cornnit$yield, 
     xlab='Pounds Per Acre', 
     ylab='Bushesl Per Acre', 
     main='Plot Corn Yield and N Fertilizer')
```

# (c) Create a Box Cox plot for the profile loglikelihoods. How does this plot aid in your data transformation?
#   
```{r}
more_plots <- function(lm_version){
  #'ALL THE LM DIAGNOSTIC PLOTS, also print the LM summary
  library(MASS)
  print(summary(lm_version))
  par(mfrow = c(3, 2))
  plot(result$model, main = "Basic Data Scatterplot")
  abline(result,col = "red")
  plot(lm_version)
  boxcox(lm_version)
}
results<- lm(cornnit$yield~cornnit$nitrogen)
more_plots(results)
```


```{r}

cornnit$yield_y3 <- cornnit$yield^(3)
results_transform <- lm(cornnit$yield_y3~cornnit$nitrogen)
more_plots(results_transform)

#transform x var
cornnit$N_mult <- cornnit$nitrogen ^ 0.25
results_transform <- lm(cornnit$yield_y2~cornnit$N_mult)
more_plots(results_transform)

```
##Model Formula
$\hat{y}^3 = \hat{\beta_1} x^.25 + \hat{\beta_0} + \epsilon$

 
# (d) Perform the necessary transformation to the data. Refit the regression with the transformed variable(s) and assess the regression assumptions. You may have to apply transformations a number of times. Be sure to explain the reason behind each of your transformations. Perform the needed transformations until the regression assumptions are met. What is the regression equation that you will use?




# Note: in part 2d, there are a number of solutions that will work. You must clearly
# document your reasons for each of your transformations.


***

3. (No R required) A substance used in biological and medical research is shipped by airfreight to users in cartons of 1000 ampules. The data consist of 10 shipments. The variables are number of times the carton was transferred from one aircraft to another during the shipment route (transfer), and the number of ampules found to be broken upon arrival (broken). We want to fit a simple linear regression. A simple linear regression model is fitted using R. You may assume all the regression assumptions are met. The corresponding output from R is shown next, with some values missing.

The following values are also provided for you, and may be used for the rest of this question: x = 1,
P10
i=1
(xi 􀀀 x)2 = 10.

(a) Calculate the value of R2, and interpret this value in context.
Rsq is the sumsq regression / sum sqr total 

```{r}
# ss regr + ss resid = ss total 
# 
# from ANOVA 
#   SSR / (SSR + SSP)
#   160 / (160 + 7.6)
#   
#   
#   F == 160 / 2.2 = 72.72
#     f critical 5.32 which is < f val
#   t test = 8.5288
#   
```
(b) Carry out a hypothesis test to assess if there is a linear relationship between the variables of interest.

(c) Calculate a 95% confidence interval that estimates the unknown value of the population slope.
  t multiplier <- 2.36 used qt
  test statistic +- multiplier * standard error
  
(d) A consultant believes the mean number of broken ampules when no transfers are made is different from 9. Conduct an appropriate hypothesis test (state the hypotheses statements, calculate the test statistic, and write the corresponding conclusion in context, in response to his belief).
```{r}
calculated_t_statistics <- -10.66
# 4.0-9.0 / 4.69
# 
# 10.2-9 /  SE in coefficients table
# how do we know we're doing intercept value and not regression?
# equation in paragraph? 2.3? had this equation
# no transfers means x = 0, just get y intercept 
# t statistic 1.809
# pvalue? 0.1080
# 
# critical value <- 2.306

```
***

4. (No R required) A chemist studied the concentration of a solution, y, over time, x, by fitting a simple linear regression. The scatterplot of the dataset, and the residual plot from the regression model are shown in Figure 1.

(a) The profile log-likelihoods for the parameter, , of the Box-Cox power transformation, is shown in Figure 2. Your classmate says that you should apply a log transformation to the response variable first. Do you agree with your classmate?
Be sure to justify your answer.

(b) Your classmate is adamant on applying the log transformation to the response variable, and fits the regression model. The R output is shown in Figure 3. Write down the estimated regression equation for this model. How do we interpret the regression coeficients ^ 1 and ^ 0 in context?

in one of the pdfs 
went through a derivation of course of how we interpret a new predicted y variable in comparison to original y value 
if you follow the derivation correctly (difficult) basically says the predicted response is mult by exp(e^B1) when B1 increases by 1 unit 
for the intercept coefficient - the predicted concentration is e^1.508 when time is 0

log(yhat = exp(b0 + b1x)
if you square x, any new x you're predicting is also squared
do you just put exp in front of whole equation because it's transformed?
***

5. Reminder: please complete the Module 1 to 4 Guided Question Set Participation Self- and Peer-Evaluation Questions via Test & Quizzes by July 21.

Figure 1: Scatterplot of Concentration of Solution against Time (left). Residual Plot from
SLR (right)
Figure 2: Prole Log-likelihoods for $\lambda$
Figure 3: R Output after Transforming Response Variable.

predict.lm(lR results, sliced df)  needs corresponding value online

hierarchical principal
  if you have a higher order term, you should have all the lower order terms as well
  
if you have x^2 you should also have x?
  